[
  {
    "variables": {
      "dataset": "pandas.DataFrame(shape=(5043, 28), columns=[\"color\", \"director_name\", \"num_critic_for_reviews\", \"duration\", \"director_facebook_likes\", \"actor_3_facebook_likes\", \"actor_2_name\", \"actor_1_facebook_likes\", \"gross\", \"genres\", \"actor_1_name\", \"movie_title\", \"num_voted_users\", \"cast_total_facebook_likes\", \"actor_3_name\", \"facenumber_in_poster\", \"plot_keywords\", \"movie_imdb_link\", \"num_user_for_reviews\", \"language\", \"country\", \"content_rating\", \"budget\", \"title_year\", \"actor_2_facebook_likes\", \"imdb_score\", \"aspect_ratio\", \"movie_facebook_likes\"])\n          color   director_name  num_critic_for_reviews  duration  director_facebook_likes  actor_3_facebook_likes    actor_2_name  ...  content_rating       budget title_year actor_2_facebook_likes imdb_score  aspect_ratio  movie_facebook_likes\n    0     Color   James Cameron           723.0             178.0             0.0                    855.0          Joel David ...  ...           PG-13  237000000.0     2009.0           936.0               7.9          1.78           33000      \n    1     Color  Gore Verbinski           302.0             169.0           563.0                   1000.0           Orlando Bloom  ...           PG-13  300000000.0     2007.0          5000.0               7.1          2.35               0      \n    ...     ...             ...             ...               ...             ...                      ...                     ...  ...             ...          ...        ...             ...               ...           ...             ...      \n    5041  Color     Daniel Hsia            14.0             100.0             0.0                    489.0           Daniel Henney  ...           PG-13          NaN     2012.0           719.0               6.3          2.35             660      \n    5042  Color        Jon Gunn            43.0              90.0            16.0                     16.0          Brian Herzl...  ...              PG       1100.0     2004.0            23.0               6.6          1.85             456"
    },
    "codes": [
      "import pandas as pd\n\ndataset = pd.read_csv(\"data/movie_metadata.csv\")",
      "dataset.isnull().sum()"
    ],
    "request": "List the major genres in the dataset. Show the result in a DataFrame with columns `genre` and `count` (number of movies of that genre).\n",
    "answer": "# Create a new variable to avoid unintentional modifications to raw DataFrame.\ngenres = pd.DataFrame({\n    \"movie\": dataset[\"movie_title\"],\n    \"genre\": dataset[\"genres\"].apply(lambda x: x.split(\"|\")[0]),\n})\n\n# Count the number of movies in each genre.\ngenres.groupby(\"genre\").count()[[\"movie\"]].rename(columns={\"movie\": \"count\"}).reset_index()"
  },
  {
    "variables": {
      "iris": "pandas.DataFrame(shape=(150, 5), columns=[\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\", \"Species\"])\n         SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm         Species\n    Id                                                                           \n    1              5.1           3.5            1.4           0.2     Iris-setosa\n    2              4.9           3.0            1.4           0.2     Iris-setosa\n    ..             ...           ...            ...           ...             ...\n    149            6.2           3.4            5.4           2.3  Iris-virginica\n    150            5.9           3.0            5.1           1.8  Iris-virginica",
      "z": "5.735584236235733",
      "pval": "0.05682424941067306"
    },
    "codes": [
      "import pandas as pd\nimport numpy as np",
      "iris = pd.read_csv(\"data/iris.csv\", index_col=\"Id\")",
      "from scipy.stats import normaltest\nz, pval = normaltest(iris[\"SepalLengthCm\"])\npval"
    ],
    "request": "Analyze the correlations of the dataset. Eliminate upper triangle for readability.\n",
    "answer": "corr = iris.select_dtypes(\"number\").corr(method=\"pearson\")\ncorr.where(np.tril(np.ones(corr.shape)).astype(bool))"
  },
  {
    "variables": {
      "train_data": "pandas.DataFrame(shape=(891, 12), columns=[\"PassengerId\", \"Survived\", \"Pclass\", \"Name\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Ticket\", \"Fare\", \"Cabin\", \"Embarked\"])\n         PassengerId  Survived  Pclass            Name     Sex   Age  SibSp  Parch     Ticket     Fare Cabin Embarked\n    0              1         0       3  Braund, Mr....    male  22.0      1      0  A/5 21171   7.2500   NaN        S\n    1              2         1       1  Cumings, Mr...  female  38.0      1      0   PC 17599  71.2833   C85        C\n    ..           ...       ...     ...             ...     ...   ...    ...    ...        ...      ...   ...      ...\n    889          890         1       1  Behr, Mr. K...    male  26.0      0      0     111369  30.0000  C148        C\n    890          891         0       3  Dooley, Mr....    male  32.0      0      0     370376   7.7500   NaN        Q",
      "test_data": "pandas.DataFrame(shape=(418, 11), columns=[\"PassengerId\", \"Pclass\", \"Name\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Ticket\", \"Fare\", \"Cabin\", \"Embarked\"])\n         PassengerId  Pclass            Name     Sex   Age  SibSp  Parch  Ticket     Fare Cabin Embarked\n    0            892       3  Kelly, Mr. ...    male  34.5      0      0  330911   7.8292   NaN        Q\n    1            893       3  Wilkes, Mrs...  female  47.0      1      0  363272   7.0000   NaN        S\n    ..           ...     ...             ...     ...   ...    ...    ...     ...      ...   ...      ...\n    416         1308       3  Ware, Mr. F...    male   NaN      0      0  359309   8.0500   NaN        S\n    417         1309       3  Peter, Mast...    male   NaN      1      1    2668  22.3583   NaN        C",
      "women": "pandas.Series(shape=(314,))"
    },
    "codes": [
      "import numpy as np\nimport pandas as pd",
      "train_data = pd.read_csv(\"data/titanic_train.csv\")\ntrain_data.shape",
      "test_data = pd.read_csv(\"data/titanic_test.csv\")\ntest_data.shape",
      "women = train_data.loc[train_data.Sex == \"female\"][\"Survived\"]\nsum(women) / len(women) * 100"
    ],
    "request": "List out the names with age 42.\n",
    "answer": "train_data.loc[train_data.Age == 42, \"Name\"].tolist()"
  },
  {
    "variables": {
      "twc": "pandas.DataFrame(shape=(93, 8), columns=[\"tweet_id\", \"author_id\", \"inbound\", \"created_at\", \"text\", \"response_tweet_id\", \"in_response_to_tweet_id\", \"text_wo_punct\"])\n        tweet_id     author_id  inbound      created_at            text response_tweet_id  in_response_to_tweet_id   text_wo_punct\n    0     119237        105834     True  Wed Oct 11 ...  @AppleSuppo...          119236               NaN           applesuppor...\n    1     119238  ChaseSupport    False  Wed Oct 11 ...  @105835 You...             NaN          119239.0           105835 your...\n    ..       ...           ...      ...             ...             ...             ...               ...                      ...\n    91    119333        105861     True  Wed Oct 11 ...  @Tesco bit ...   119335,119336          119332.0           tesco bit o...\n    92    119335         Tesco    False  Wed Oct 11 ...  @105861 If ...             NaN          119333.0           105861 if t..."
    },
    "codes": [
      "import numpy as np\nimport pandas as pd",
      "twc = pd.read_csv(\"data/twc-sample.csv\")",
      "import string\n\ndef remove_punctuation(text: str):\n    return text.lower().translate(str.maketrans(\"\", \"\", string.punctuation))\n\ntwc[\"text_wo_punct\"] = twc[\"text\"].apply(remove_punctuation)"
    ],
    "request": "Remove English stopwords from the `text_wo_punct` column. Save the result in a new column `text_wo_stopwords`.\n",
    "answer": "from nltk.corpus import stopwords\n\nSTOPWORDS = set(stopwords.words(\"english\"))\n\ntwc[\"text_wo_stopwords\"] = twc[\"text_wo_punct\"].apply(\n    lambda text: \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n)"
  },
  {
    "variables": {
      "df": "pandas.DataFrame(shape=(1599, 12), columns=[\"fixed acidity\", \"volatile acidity\", \"citric acid\", \"residual sugar\", \"chlorides\", \"free sulfur dioxide\", \"total sulfur dioxide\", \"density\", \"pH\", \"sulphates\", \"alcohol\", \"quality\"])\n          fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  alcohol  quality\n    0               7.4           0.700           0.00             1.9      0.076            11.0                 34.0        0.99780  3.51       0.56      9.4        5\n    1               7.8           0.880           0.00             2.6      0.098            25.0                 67.0        0.99680  3.20       0.68      9.8        5\n    ...             ...             ...            ...             ...        ...             ...                  ...            ...   ...        ...      ...      ...\n    1597            5.9           0.645           0.12             2.0      0.075            32.0                 44.0        0.99547  3.57       0.71     10.2        5\n    1598            6.0           0.310           0.47             3.6      0.067            18.0                 42.0        0.99549  3.39       0.66     11.0        6",
      "z": "pandas.DataFrame(shape=(1599, 12), columns=[\"fixed acidity\", \"volatile acidity\", \"citric acid\", \"residual sugar\", \"chlorides\", \"free sulfur dioxide\", \"total sulfur dioxide\", \"density\", \"pH\", \"sulphates\", \"alcohol\", \"quality\"])\n          fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  free sulfur dioxide  total sulfur dioxide   density        pH  sulphates   alcohol   quality\n    0          0.528360        0.961877       1.391472        0.453218   0.243707        0.466193             0.379133        0.558274  1.288643   0.579207  0.960246  0.787823\n    1          0.298547        1.967442       1.391472        0.043416   0.223875        0.872638             0.624363        0.028261  0.719933   0.128950  0.584777  0.787823\n    ...             ...             ...            ...             ...        ...             ...                  ...             ...       ...        ...       ...       ...\n    1597       1.390155        0.654620       0.775267        0.382271   0.264960        1.542054             0.075043        0.676657  1.677400   0.305990  0.209308  0.787823\n    1598       1.332702        1.216849       1.021999        0.752894   0.434990        0.203223             0.135861        0.666057  0.511130   0.010924  0.541630  0.450848",
      "X": "pandas.DataFrame(shape=(1599, 11), columns=[\"fixed acidity\", \"volatile acidity\", \"citric acid\", \"residual sugar\", \"chlorides\", \"free sulfur dioxide\", \"total sulfur dioxide\", \"density\", \"pH\", \"sulphates\", \"alcohol\"])\n          fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  alcohol\n    0               7.4           0.700           0.00             1.9      0.076            11.0                 34.0        0.99780  3.51       0.56      9.4\n    1               7.8           0.880           0.00             2.6      0.098            25.0                 67.0        0.99680  3.20       0.68      9.8\n    ...             ...             ...            ...             ...        ...             ...                  ...            ...   ...        ...      ...\n    1597            5.9           0.645           0.12             2.0      0.075            32.0                 44.0        0.99547  3.57       0.71     10.2\n    1598            6.0           0.310           0.47             3.6      0.067            18.0                 42.0        0.99549  3.39       0.66     11.0",
      "y": "pandas.Series(shape=(1599,))"
    },
    "codes": [
      "import pandas as pd",
      "df = pd.read_csv(\"data/winequality-red.csv\")",
      "import numpy as np\nfrom scipy import stats\n\nz = np.abs(stats.zscore(df))\ndf[(z < 3).all(axis=1)]",
      "from sklearn.model_selection import train_test_split\n\nX = df.drop(columns=\"quality\")\ny = df[\"quality\"]"
    ],
    "request": "Split X and y into train and test sets. Use 20% of the data for testing.\nSet random state to 42.\nFit a RandomForestClassifier `clf` with 100 estimators on the training data, also using random state 42.\n",
    "answer": "from sklearn.ensemble import RandomForestClassifier\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\nclf = RandomForestClassifier(n_estimators=100, random_state=42)\nclf.fit(X_train, y_train)"
  }
]