[{"id": "hpob-rpart-preproc-4796-openml-cylinder-bands-14968-271", "modules": [{"role": "dataset", "module": "openml-cylinder-bands-14968"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0003090546338984518, "minbucket": 1, "minsplit": 2}}}], "metrics": 0.753704, "context": "openml-cylinder-bands-14968", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-cylinder-bands-14968-205", "modules": [{"role": "dataset", "module": "openml-cylinder-bands-14968"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0009380288524522998, "minbucket": 1, "minsplit": 2}}}], "metrics": 0.753704, "context": "openml-cylinder-bands-14968", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-cylinder-bands-14968-251", "modules": [{"role": "dataset", "module": "openml-cylinder-bands-14968"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.001985846562152561, "minbucket": 1, "minsplit": 2}}}], "metrics": 0.751852, "context": "openml-cylinder-bands-14968", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-cylinder-bands-14968-273", "modules": [{"role": "dataset", "module": "openml-cylinder-bands-14968"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.003949287299097721, "minbucket": 1, "minsplit": 2}}}], "metrics": 0.751852, "context": "openml-cylinder-bands-14968", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-cylinder-bands-14968-250", "modules": [{"role": "dataset", "module": "openml-cylinder-bands-14968"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.00117214366497242, "minbucket": 1, "minsplit": 4}}}], "metrics": 0.748148, "context": "openml-cylinder-bands-14968", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-irish-3543-289", "modules": [{"role": "dataset", "module": "openml-irish-3543"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.00035786961545649894, "minbucket": 1, "minsplit": 64}}}], "metrics": 0.988, "context": "openml-irish-3543", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-irish-3543-103", "modules": [{"role": "dataset", "module": "openml-irish-3543"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.007997734377838182, "minbucket": 4, "minsplit": 4}}}], "metrics": 0.988, "context": "openml-irish-3543", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-irish-3543-096", "modules": [{"role": "dataset", "module": "openml-irish-3543"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.004454778300818169, "minbucket": 32, "minsplit": 64}}}], "metrics": 0.988, "context": "openml-irish-3543", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-irish-3543-097", "modules": [{"role": "dataset", "module": "openml-irish-3543"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.005963156211242172, "minbucket": 2, "minsplit": 32}}}], "metrics": 0.988, "context": "openml-irish-3543", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-irish-3543-098", "modules": [{"role": "dataset", "module": "openml-irish-3543"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.09190123811535791, "minbucket": 4, "minsplit": 8}}}], "metrics": 0.988, "context": "openml-irish-3543", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-profb-3561-146", "modules": [{"role": "dataset", "module": "openml-profb-3561"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.04110352124382511, "minbucket": 16, "minsplit": 2}}}], "metrics": 0.712798, "context": "openml-profb-3561", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-profb-3561-031", "modules": [{"role": "dataset", "module": "openml-profb-3561"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.05060433740034941, "minbucket": 32, "minsplit": 64}}}], "metrics": 0.712798, "context": "openml-profb-3561", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-profb-3561-087", "modules": [{"role": "dataset", "module": "openml-profb-3561"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.07804422332033949, "minbucket": 2, "minsplit": 128}}}], "metrics": 0.712798, "context": "openml-profb-3561", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-profb-3561-088", "modules": [{"role": "dataset", "module": "openml-profb-3561"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0630174791145751, "minbucket": 32, "minsplit": 64}}}], "metrics": 0.712798, "context": "openml-profb-3561", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-profb-3561-190", "modules": [{"role": "dataset", "module": "openml-profb-3561"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0381971512893079, "minbucket": 16, "minsplit": 4}}}], "metrics": 0.712798, "context": "openml-profb-3561", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-autouniv-au7-700-9905-123", "modules": [{"role": "dataset", "module": "openml-autouniv-au7-700-9905"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.009257692202242986, "minbucket": 1, "minsplit": 32}}}], "metrics": 0.538571, "context": "openml-autouniv-au7-700-9905", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-autouniv-au7-700-9905-160", "modules": [{"role": "dataset", "module": "openml-autouniv-au7-700-9905"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.010136262040493504, "minbucket": 4, "minsplit": 32}}}], "metrics": 0.532857, "context": "openml-autouniv-au7-700-9905", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-autouniv-au7-700-9905-281", "modules": [{"role": "dataset", "module": "openml-autouniv-au7-700-9905"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.002378996543555459, "minbucket": 8, "minsplit": 16}}}], "metrics": 0.527143, "context": "openml-autouniv-au7-700-9905", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-autouniv-au7-700-9905-238", "modules": [{"role": "dataset", "module": "openml-autouniv-au7-700-9905"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.00022879611426735084, "minbucket": 2, "minsplit": 32}}}], "metrics": 0.527143, "context": "openml-autouniv-au7-700-9905", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-autouniv-au7-700-9905-124", "modules": [{"role": "dataset", "module": "openml-autouniv-au7-700-9905"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.00159815281497429, "minbucket": 8, "minsplit": 8}}}], "metrics": 0.527143, "context": "openml-autouniv-au7-700-9905", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-monks-problems-1-3492-010", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0009032769178733143, "minbucket": 1, "minsplit": 2}}}], "metrics": 0.971223, "context": "openml-monks-problems-1-3492", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-monks-problems-1-3492-115", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0019197330486480405, "minbucket": 1, "minsplit": 4}}}], "metrics": 0.96223, "context": "openml-monks-problems-1-3492", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-monks-problems-1-3492-061", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0005376661301479019, "minbucket": 1, "minsplit": 4}}}], "metrics": 0.96223, "context": "openml-monks-problems-1-3492", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-monks-problems-1-3492-214", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0010380679180681338, "minbucket": 1, "minsplit": 4}}}], "metrics": 0.96223, "context": "openml-monks-problems-1-3492", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-monks-problems-1-3492-124", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0011771501354885803, "minbucket": 1, "minsplit": 4}}}], "metrics": 0.96223, "context": "openml-monks-problems-1-3492", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-segment-36-021", "modules": [{"role": "dataset", "module": "openml-segment-36"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.00022540590915234903, "minbucket": 1, "minsplit": 2}}}], "metrics": 0.963636, "context": "openml-segment-36", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-segment-36-098", "modules": [{"role": "dataset", "module": "openml-segment-36"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0004643945590886729, "minbucket": 1, "minsplit": 2}}}], "metrics": 0.962338, "context": "openml-segment-36", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-segment-36-033", "modules": [{"role": "dataset", "module": "openml-segment-36"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0003294040151714353, "minbucket": 2, "minsplit": 4}}}], "metrics": 0.960173, "context": "openml-segment-36", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-segment-36-283", "modules": [{"role": "dataset", "module": "openml-segment-36"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.00044692997936500515, "minbucket": 2, "minsplit": 8}}}], "metrics": 0.955844, "context": "openml-segment-36", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-segment-36-153", "modules": [{"role": "dataset", "module": "openml-segment-36"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.000488160566317156, "minbucket": 2, "minsplit": 8}}}], "metrics": 0.955411, "context": "openml-segment-36", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-balance-scale-11-243", "modules": [{"role": "dataset", "module": "openml-balance-scale-11"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.005818637066714531, "minbucket": 4, "minsplit": 4}}}], "metrics": 0.8032, "context": "openml-balance-scale-11", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-balance-scale-11-124", "modules": [{"role": "dataset", "module": "openml-balance-scale-11"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.004303747123027979, "minbucket": 8, "minsplit": 2}}}], "metrics": 0.8016, "context": "openml-balance-scale-11", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-balance-scale-11-029", "modules": [{"role": "dataset", "module": "openml-balance-scale-11"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0020353970992722393, "minbucket": 2, "minsplit": 4}}}], "metrics": 0.8, "context": "openml-balance-scale-11", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-balance-scale-11-189", "modules": [{"role": "dataset", "module": "openml-balance-scale-11"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0015047423025353606, "minbucket": 2, "minsplit": 2}}}], "metrics": 0.7984, "context": "openml-balance-scale-11", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-balance-scale-11-081", "modules": [{"role": "dataset", "module": "openml-balance-scale-11"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0016729464444389796, "minbucket": 2, "minsplit": 2}}}], "metrics": 0.7984, "context": "openml-balance-scale-11", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-breast-w-15-137", "modules": [{"role": "dataset", "module": "openml-breast-w-15"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.003531790224953, "minbucket": 1, "minsplit": 2}}}], "metrics": 0.951359, "context": "openml-breast-w-15", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-breast-w-15-267", "modules": [{"role": "dataset", "module": "openml-breast-w-15"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.00217762521915502, "minbucket": 8, "minsplit": 2}}}], "metrics": 0.949928, "context": "openml-breast-w-15", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-breast-w-15-092", "modules": [{"role": "dataset", "module": "openml-breast-w-15"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.00922653929488785, "minbucket": 4, "minsplit": 2}}}], "metrics": 0.949928, "context": "openml-breast-w-15", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-breast-w-15-198", "modules": [{"role": "dataset", "module": "openml-breast-w-15"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0017972916584133604, "minbucket": 4, "minsplit": 8}}}], "metrics": 0.949928, "context": "openml-breast-w-15", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-breast-w-15-270", "modules": [{"role": "dataset", "module": "openml-breast-w-15"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0011121886657323395, "minbucket": 4, "minsplit": 2}}}], "metrics": 0.949928, "context": "openml-breast-w-15", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-qsar-biodeg-9957-210", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.004893536467363082, "minbucket": 1, "minsplit": 2}}}], "metrics": 0.82654, "context": "openml-qsar-biodeg-9957", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-qsar-biodeg-9957-160", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.004852218982586785, "minbucket": 1, "minsplit": 2}}}], "metrics": 0.82654, "context": "openml-qsar-biodeg-9957", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-qsar-biodeg-9957-088", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0045701619335141806, "minbucket": 1, "minsplit": 8}}}], "metrics": 0.82654, "context": "openml-qsar-biodeg-9957", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-qsar-biodeg-9957-256", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0052115316897273735, "minbucket": 2, "minsplit": 8}}}], "metrics": 0.825592, "context": "openml-qsar-biodeg-9957", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-qsar-biodeg-9957-120", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.006336957501925982, "minbucket": 2, "minsplit": 8}}}], "metrics": 0.825592, "context": "openml-qsar-biodeg-9957", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-climate-model-simulation-crashes-9980-091", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0190214315624162, "minbucket": 64, "minsplit": 32}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-9980", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-climate-model-simulation-crashes-9980-156", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.006100778052190628, "minbucket": 64, "minsplit": 32}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-9980", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-climate-model-simulation-crashes-9980-074", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.00040680693422903285, "minbucket": 64, "minsplit": 8}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-9980", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-climate-model-simulation-crashes-9980-075", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.029426440348674386, "minbucket": 64, "minsplit": 64}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-9980", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-climate-model-simulation-crashes-9980-169", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.02655441510974061, "minbucket": 64, "minsplit": 32}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-9980", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-pc4-3902-163", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.026975784387009604, "minbucket": 4, "minsplit": 64}}}], "metrics": 0.901235, "context": "openml-pc4-3902", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-pc4-3902-204", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.03803860046918052, "minbucket": 1, "minsplit": 16}}}], "metrics": 0.901235, "context": "openml-pc4-3902", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-pc4-3902-170", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.03704784573106482, "minbucket": 8, "minsplit": 2}}}], "metrics": 0.901235, "context": "openml-pc4-3902", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-pc4-3902-154", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.03145154544398071, "minbucket": 4, "minsplit": 2}}}], "metrics": 0.901235, "context": "openml-pc4-3902", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-pc4-3902-046", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.03613559043112218, "minbucket": 8, "minsplit": 2}}}], "metrics": 0.901235, "context": "openml-pc4-3902", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-blood-transfusion-service-center-10101-040", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0020183021966302603, "minbucket": 8, "minsplit": 64}}}], "metrics": 0.795455, "context": "openml-blood-transfusion-service-center-10101", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-blood-transfusion-service-center-10101-130", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0021980970785339107, "minbucket": 8, "minsplit": 64}}}], "metrics": 0.795455, "context": "openml-blood-transfusion-service-center-10101", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-blood-transfusion-service-center-10101-036", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.000208712276525846, "minbucket": 8, "minsplit": 64}}}], "metrics": 0.795455, "context": "openml-blood-transfusion-service-center-10101", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-blood-transfusion-service-center-10101-134", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0032494590578730108, "minbucket": 8, "minsplit": 64}}}], "metrics": 0.794118, "context": "openml-blood-transfusion-service-center-10101", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-blood-transfusion-service-center-10101-139", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.005987469537504881, "minbucket": 8, "minsplit": 16}}}], "metrics": 0.792781, "context": "openml-blood-transfusion-service-center-10101", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-diabetes-37-197", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.013201029119922401, "minbucket": 32, "minsplit": 64}}}], "metrics": 0.764323, "context": "openml-diabetes-37", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-diabetes-37-184", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0013369656886393505, "minbucket": 64, "minsplit": 16}}}], "metrics": 0.760417, "context": "openml-diabetes-37", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-diabetes-37-254", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0008737509185649848, "minbucket": 64, "minsplit": 128}}}], "metrics": 0.760417, "context": "openml-diabetes-37", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-diabetes-37-107", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0029556980340912594, "minbucket": 64, "minsplit": 8}}}], "metrics": 0.760417, "context": "openml-diabetes-37", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-diabetes-37-057", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0025478244577091993, "minbucket": 64, "minsplit": 16}}}], "metrics": 0.760417, "context": "openml-diabetes-37", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-phoneme-9952-161", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.000704144735875762, "minbucket": 2, "minsplit": 8}}}], "metrics": 0.874722, "context": "openml-phoneme-9952", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-phoneme-9952-252", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0006004258562119782, "minbucket": 2, "minsplit": 8}}}], "metrics": 0.874352, "context": "openml-phoneme-9952", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-phoneme-9952-114", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0004822553589297161, "minbucket": 2, "minsplit": 2}}}], "metrics": 0.874167, "context": "openml-phoneme-9952", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-phoneme-9952-220", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0007741984444254718, "minbucket": 4, "minsplit": 4}}}], "metrics": 0.873427, "context": "openml-phoneme-9952", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-phoneme-9952-104", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0007093069244595469, "minbucket": 4, "minsplit": 4}}}], "metrics": 0.873427, "context": "openml-phoneme-9952", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-artificial-characters-14964-035", "modules": [{"role": "dataset", "module": "openml-artificial-characters-14964"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.00020341924243459593, "minbucket": 1, "minsplit": 8}}}], "metrics": 0.787238, "context": "openml-artificial-characters-14964", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-artificial-characters-14964-208", "modules": [{"role": "dataset", "module": "openml-artificial-characters-14964"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.000240521817420485, "minbucket": 1, "minsplit": 4}}}], "metrics": 0.768056, "context": "openml-artificial-characters-14964", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-artificial-characters-14964-121", "modules": [{"role": "dataset", "module": "openml-artificial-characters-14964"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.00023148817541664198, "minbucket": 2, "minsplit": 2}}}], "metrics": 0.767861, "context": "openml-artificial-characters-14964", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-artificial-characters-14964-279", "modules": [{"role": "dataset", "module": "openml-artificial-characters-14964"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.00021444969632774313, "minbucket": 2, "minsplit": 8}}}], "metrics": 0.752789, "context": "openml-artificial-characters-14964", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-artificial-characters-14964-293", "modules": [{"role": "dataset", "module": "openml-artificial-characters-14964"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0003105288452111547, "minbucket": 2, "minsplit": 2}}}], "metrics": 0.741535, "context": "openml-artificial-characters-14964", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-monks-problems-2-3493-103", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0004580542318456978, "minbucket": 1, "minsplit": 4}}}], "metrics": 0.993344, "context": "openml-monks-problems-2-3493", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-monks-problems-2-3493-294", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0028120601317003393, "minbucket": 1, "minsplit": 4}}}], "metrics": 0.993344, "context": "openml-monks-problems-2-3493", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-monks-problems-2-3493-061", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.000868437981959722, "minbucket": 1, "minsplit": 4}}}], "metrics": 0.993344, "context": "openml-monks-problems-2-3493", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-monks-problems-2-3493-276", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0008122909643841681, "minbucket": 1, "minsplit": 4}}}], "metrics": 0.993344, "context": "openml-monks-problems-2-3493", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-monks-problems-2-3493-076", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.00020602094652396485, "minbucket": 1, "minsplit": 2}}}], "metrics": 0.991681, "context": "openml-monks-problems-2-3493", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-banknote-authentication-10093-287", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0011125334685428406, "minbucket": 1, "minsplit": 8}}}], "metrics": 0.98688, "context": "openml-banknote-authentication-10093", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-banknote-authentication-10093-026", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.00023394133454967503, "minbucket": 1, "minsplit": 2}}}], "metrics": 0.986152, "context": "openml-banknote-authentication-10093", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-banknote-authentication-10093-253", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0006860814918746111, "minbucket": 1, "minsplit": 4}}}], "metrics": 0.986152, "context": "openml-banknote-authentication-10093", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-banknote-authentication-10093-050", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.000464287972192599, "minbucket": 2, "minsplit": 8}}}], "metrics": 0.985423, "context": "openml-banknote-authentication-10093", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-banknote-authentication-10093-285", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.002063384450863179, "minbucket": 2, "minsplit": 8}}}], "metrics": 0.985423, "context": "openml-banknote-authentication-10093", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-ilpd-9971-149", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.07154080844753914, "minbucket": 32, "minsplit": 8}}}], "metrics": 0.713551, "context": "openml-ilpd-9971", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-ilpd-9971-277", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.03902422483039689, "minbucket": 32, "minsplit": 64}}}], "metrics": 0.713551, "context": "openml-ilpd-9971", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-ilpd-9971-245", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0642124800266341, "minbucket": 8, "minsplit": 32}}}], "metrics": 0.713551, "context": "openml-ilpd-9971", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-ilpd-9971-080", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.059189690042958126, "minbucket": 64, "minsplit": 32}}}], "metrics": 0.713551, "context": "openml-ilpd-9971", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-ilpd-9971-200", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.050894281001856174, "minbucket": 1, "minsplit": 2}}}], "metrics": 0.713551, "context": "openml-ilpd-9971", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-cardiotocography-9979-298", "modules": [{"role": "dataset", "module": "openml-cardiotocography-9979"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.004096260371114741, "minbucket": 8, "minsplit": 64}}}], "metrics": 0.998589, "context": "openml-cardiotocography-9979", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-cardiotocography-9979-186", "modules": [{"role": "dataset", "module": "openml-cardiotocography-9979"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.014435412937875394, "minbucket": 16, "minsplit": 64}}}], "metrics": 0.998589, "context": "openml-cardiotocography-9979", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-cardiotocography-9979-139", "modules": [{"role": "dataset", "module": "openml-cardiotocography-9979"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.00033081242651977375, "minbucket": 32, "minsplit": 64}}}], "metrics": 0.998589, "context": "openml-cardiotocography-9979", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-cardiotocography-9979-134", "modules": [{"role": "dataset", "module": "openml-cardiotocography-9979"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0022595568231521695, "minbucket": 2, "minsplit": 2}}}], "metrics": 0.998589, "context": "openml-cardiotocography-9979", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-cardiotocography-9979-133", "modules": [{"role": "dataset", "module": "openml-cardiotocography-9979"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0013675334548441103, "minbucket": 8, "minsplit": 4}}}], "metrics": 0.998589, "context": "openml-cardiotocography-9979", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-vowel-3022-021", "modules": [{"role": "dataset", "module": "openml-vowel-3022"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0004251328251975899, "minbucket": 1, "minsplit": 2}}}], "metrics": 0.842424, "context": "openml-vowel-3022", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-vowel-3022-272", "modules": [{"role": "dataset", "module": "openml-vowel-3022"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0004290415513974551, "minbucket": 1, "minsplit": 2}}}], "metrics": 0.842424, "context": "openml-vowel-3022", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-vowel-3022-130", "modules": [{"role": "dataset", "module": "openml-vowel-3022"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0008777793384048078, "minbucket": 1, "minsplit": 2}}}], "metrics": 0.836364, "context": "openml-vowel-3022", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-vowel-3022-213", "modules": [{"role": "dataset", "module": "openml-vowel-3022"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0008764169215392928, "minbucket": 1, "minsplit": 2}}}], "metrics": 0.836364, "context": "openml-vowel-3022", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-vowel-3022-111", "modules": [{"role": "dataset", "module": "openml-vowel-3022"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0005480403744231602, "minbucket": 1, "minsplit": 4}}}], "metrics": 0.824242, "context": "openml-vowel-3022", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-synthetic-control-3512-161", "modules": [{"role": "dataset", "module": "openml-synthetic-control-3512"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.00047570890493253215, "minbucket": 1, "minsplit": 4}}}], "metrics": 0.91, "context": "openml-synthetic-control-3512", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-synthetic-control-3512-055", "modules": [{"role": "dataset", "module": "openml-synthetic-control-3512"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.00140121100100284, "minbucket": 1, "minsplit": 4}}}], "metrics": 0.91, "context": "openml-synthetic-control-3512", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-synthetic-control-3512-181", "modules": [{"role": "dataset", "module": "openml-synthetic-control-3512"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0002893873596694263, "minbucket": 1, "minsplit": 8}}}], "metrics": 0.91, "context": "openml-synthetic-control-3512", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-synthetic-control-3512-120", "modules": [{"role": "dataset", "module": "openml-synthetic-control-3512"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0021520246584408394, "minbucket": 1, "minsplit": 4}}}], "metrics": 0.91, "context": "openml-synthetic-control-3512", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-synthetic-control-3512-194", "modules": [{"role": "dataset", "module": "openml-synthetic-control-3512"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0020850711895772896, "minbucket": 1, "minsplit": 8}}}], "metrics": 0.91, "context": "openml-synthetic-control-3512", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-soybean-41-072", "modules": [{"role": "dataset", "module": "openml-soybean-41"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0019415446233654193, "minbucket": 1, "minsplit": 2}}}], "metrics": 0.934114, "context": "openml-soybean-41", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-soybean-41-298", "modules": [{"role": "dataset", "module": "openml-soybean-41"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.000497229605397543, "minbucket": 1, "minsplit": 2}}}], "metrics": 0.925329, "context": "openml-soybean-41", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-soybean-41-269", "modules": [{"role": "dataset", "module": "openml-soybean-41"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0029152115407025505, "minbucket": 1, "minsplit": 16}}}], "metrics": 0.925329, "context": "openml-soybean-41", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-soybean-41-003", "modules": [{"role": "dataset", "module": "openml-soybean-41"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0002861371077726879, "minbucket": 1, "minsplit": 16}}}], "metrics": 0.925329, "context": "openml-soybean-41", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-soybean-41-132", "modules": [{"role": "dataset", "module": "openml-soybean-41"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0030959897863194297, "minbucket": 1, "minsplit": 16}}}], "metrics": 0.925329, "context": "openml-soybean-41", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-credit-approval-29-048", "modules": [{"role": "dataset", "module": "openml-credit-approval-29"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0104346438389983, "minbucket": 8, "minsplit": 4}}}], "metrics": 0.857971, "context": "openml-credit-approval-29", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-credit-approval-29-246", "modules": [{"role": "dataset", "module": "openml-credit-approval-29"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.008131363576182422, "minbucket": 16, "minsplit": 2}}}], "metrics": 0.856522, "context": "openml-credit-approval-29", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-credit-approval-29-189", "modules": [{"role": "dataset", "module": "openml-credit-approval-29"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0016102037534531603, "minbucket": 1, "minsplit": 128}}}], "metrics": 0.856522, "context": "openml-credit-approval-29", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-credit-approval-29-075", "modules": [{"role": "dataset", "module": "openml-credit-approval-29"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.006289981897114892, "minbucket": 16, "minsplit": 32}}}], "metrics": 0.856522, "context": "openml-credit-approval-29", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-credit-approval-29-168", "modules": [{"role": "dataset", "module": "openml-credit-approval-29"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0008865722570975094, "minbucket": 1, "minsplit": 128}}}], "metrics": 0.856522, "context": "openml-credit-approval-29", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-steel-plates-fault-9967-299", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.00039512445187895115, "minbucket": 16, "minsplit": 32}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-steel-plates-fault-9967-111", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0011235180785711, "minbucket": 4, "minsplit": 32}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-steel-plates-fault-9967-103", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0025898510761649903, "minbucket": 8, "minsplit": 2}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-steel-plates-fault-9967-105", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0002574659800711011, "minbucket": 32, "minsplit": 64}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-steel-plates-fault-9967-106", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.00021400776928243582, "minbucket": 4, "minsplit": 8}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-collins-3567-150", "modules": [{"role": "dataset", "module": "openml-collins-3567"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0006222649465061029, "minbucket": 4, "minsplit": 4}}}], "metrics": 1.0, "context": "openml-collins-3567", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-collins-3567-219", "modules": [{"role": "dataset", "module": "openml-collins-3567"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0028913857857027605, "minbucket": 4, "minsplit": 8}}}], "metrics": 1.0, "context": "openml-collins-3567", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-collins-3567-038", "modules": [{"role": "dataset", "module": "openml-collins-3567"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.000450615835607153, "minbucket": 2, "minsplit": 8}}}], "metrics": 1.0, "context": "openml-collins-3567", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-collins-3567-155", "modules": [{"role": "dataset", "module": "openml-collins-3567"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0005889396508598378, "minbucket": 4, "minsplit": 8}}}], "metrics": 1.0, "context": "openml-collins-3567", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-collins-3567-195", "modules": [{"role": "dataset", "module": "openml-collins-3567"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0033766197353810104, "minbucket": 1, "minsplit": 8}}}], "metrics": 1.0, "context": "openml-collins-3567", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-wilt-9914-182", "modules": [{"role": "dataset", "module": "openml-wilt-9914"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.005415930616792129, "minbucket": 2, "minsplit": 8}}}], "metrics": 0.983261, "context": "openml-wilt-9914", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-wilt-9914-051", "modules": [{"role": "dataset", "module": "openml-wilt-9914"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0062047341682797685, "minbucket": 2, "minsplit": 8}}}], "metrics": 0.983054, "context": "openml-wilt-9914", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-wilt-9914-119", "modules": [{"role": "dataset", "module": "openml-wilt-9914"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.008526547328137166, "minbucket": 2, "minsplit": 2}}}], "metrics": 0.983054, "context": "openml-wilt-9914", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-wilt-9914-034", "modules": [{"role": "dataset", "module": "openml-wilt-9914"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.00517419921396867, "minbucket": 2, "minsplit": 2}}}], "metrics": 0.983054, "context": "openml-wilt-9914", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-wilt-9914-146", "modules": [{"role": "dataset", "module": "openml-wilt-9914"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.006094352684512432, "minbucket": 1, "minsplit": 4}}}], "metrics": 0.982848, "context": "openml-wilt-9914", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-mfeat-morphological-18-041", "modules": [{"role": "dataset", "module": "openml-mfeat-morphological-18"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0016322113673635597, "minbucket": 1, "minsplit": 4}}}], "metrics": 0.7275, "context": "openml-mfeat-morphological-18", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-mfeat-morphological-18-058", "modules": [{"role": "dataset", "module": "openml-mfeat-morphological-18"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0030900566713438883, "minbucket": 8, "minsplit": 2}}}], "metrics": 0.7235, "context": "openml-mfeat-morphological-18", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-mfeat-morphological-18-120", "modules": [{"role": "dataset", "module": "openml-mfeat-morphological-18"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0029780734364029796, "minbucket": 2, "minsplit": 8}}}], "metrics": 0.723, "context": "openml-mfeat-morphological-18", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-mfeat-morphological-18-020", "modules": [{"role": "dataset", "module": "openml-mfeat-morphological-18"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.00271475094946111, "minbucket": 4, "minsplit": 32}}}], "metrics": 0.723, "context": "openml-mfeat-morphological-18", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-mfeat-morphological-18-270", "modules": [{"role": "dataset", "module": "openml-mfeat-morphological-18"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.002513372450060439, "minbucket": 8, "minsplit": 32}}}], "metrics": 0.7225, "context": "openml-mfeat-morphological-18", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-monks-problems-3-3494-299", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0008818457337047147, "minbucket": 1, "minsplit": 8}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-monks-problems-3-3494-068", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0019766402877930698, "minbucket": 1, "minsplit": 16}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-monks-problems-3-3494-176", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.00135415596062204, "minbucket": 1, "minsplit": 4}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-monks-problems-3-3494-177", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.009088062958811446, "minbucket": 4, "minsplit": 8}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-monks-problems-3-3494-082", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.000240018472639318, "minbucket": 1, "minsplit": 8}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-car-21-218", "modules": [{"role": "dataset", "module": "openml-car-21"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.00020675432251250584, "minbucket": 1, "minsplit": 2}}}], "metrics": 0.98206, "context": "openml-car-21", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-car-21-171", "modules": [{"role": "dataset", "module": "openml-car-21"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.00024200334147138987, "minbucket": 1, "minsplit": 2}}}], "metrics": 0.98206, "context": "openml-car-21", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-car-21-193", "modules": [{"role": "dataset", "module": "openml-car-21"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.00046998062565957314, "minbucket": 1, "minsplit": 2}}}], "metrics": 0.98206, "context": "openml-car-21", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-car-21-061", "modules": [{"role": "dataset", "module": "openml-car-21"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0007138195854647362, "minbucket": 1, "minsplit": 2}}}], "metrics": 0.980903, "context": "openml-car-21", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-car-21-120", "modules": [{"role": "dataset", "module": "openml-car-21"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.00021682285282646302, "minbucket": 2, "minsplit": 4}}}], "metrics": 0.976273, "context": "openml-car-21", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-analcatdata-dmft-3560-086", "modules": [{"role": "dataset", "module": "openml-analcatdata-dmft-3560"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.002833830635039299, "minbucket": 8, "minsplit": 64}}}], "metrics": 0.227102, "context": "openml-analcatdata-dmft-3560", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-analcatdata-dmft-3560-039", "modules": [{"role": "dataset", "module": "openml-analcatdata-dmft-3560"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0025591739551334204, "minbucket": 8, "minsplit": 64}}}], "metrics": 0.227102, "context": "openml-analcatdata-dmft-3560", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-analcatdata-dmft-3560-277", "modules": [{"role": "dataset", "module": "openml-analcatdata-dmft-3560"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.000484681448249612, "minbucket": 8, "minsplit": 64}}}], "metrics": 0.223338, "context": "openml-analcatdata-dmft-3560", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-analcatdata-dmft-3560-068", "modules": [{"role": "dataset", "module": "openml-analcatdata-dmft-3560"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.005344735763495759, "minbucket": 8, "minsplit": 4}}}], "metrics": 0.222083, "context": "openml-analcatdata-dmft-3560", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-analcatdata-dmft-3560-082", "modules": [{"role": "dataset", "module": "openml-analcatdata-dmft-3560"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.000619982854645767, "minbucket": 2, "minsplit": 64}}}], "metrics": 0.222083, "context": "openml-analcatdata-dmft-3560", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-vehicle-53-284", "modules": [{"role": "dataset", "module": "openml-vehicle-53"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0009922381787054214, "minbucket": 1, "minsplit": 4}}}], "metrics": 0.712766, "context": "openml-vehicle-53", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-vehicle-53-040", "modules": [{"role": "dataset", "module": "openml-vehicle-53"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.00021989534746761084, "minbucket": 1, "minsplit": 8}}}], "metrics": 0.711584, "context": "openml-vehicle-53", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-vehicle-53-031", "modules": [{"role": "dataset", "module": "openml-vehicle-53"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.00033311558192158783, "minbucket": 1, "minsplit": 8}}}], "metrics": 0.711584, "context": "openml-vehicle-53", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-vehicle-53-263", "modules": [{"role": "dataset", "module": "openml-vehicle-53"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0008500682724884652, "minbucket": 2, "minsplit": 2}}}], "metrics": 0.70331, "context": "openml-vehicle-53", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-vehicle-53-029", "modules": [{"role": "dataset", "module": "openml-vehicle-53"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0002163603272276031, "minbucket": 2, "minsplit": 4}}}], "metrics": 0.70331, "context": "openml-vehicle-53", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-anneal-2-236", "modules": [{"role": "dataset", "module": "openml-anneal-2"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0012111144144586797, "minbucket": 1, "minsplit": 4}}}], "metrics": 0.939866, "context": "openml-anneal-2", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-anneal-2-039", "modules": [{"role": "dataset", "module": "openml-anneal-2"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0008634486558302063, "minbucket": 1, "minsplit": 4}}}], "metrics": 0.939866, "context": "openml-anneal-2", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-anneal-2-278", "modules": [{"role": "dataset", "module": "openml-anneal-2"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0003227516670894159, "minbucket": 1, "minsplit": 4}}}], "metrics": 0.939866, "context": "openml-anneal-2", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-anneal-2-149", "modules": [{"role": "dataset", "module": "openml-anneal-2"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.007678425973376911, "minbucket": 2, "minsplit": 8}}}], "metrics": 0.932071, "context": "openml-anneal-2", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-anneal-2-218", "modules": [{"role": "dataset", "module": "openml-anneal-2"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.006598296095200453, "minbucket": 2, "minsplit": 8}}}], "metrics": 0.932071, "context": "openml-anneal-2", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-kc1-3917-178", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.010623063394923903, "minbucket": 32, "minsplit": 32}}}], "metrics": 0.85633, "context": "openml-kc1-3917", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-kc1-3917-086", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.010373377270008694, "minbucket": 32, "minsplit": 64}}}], "metrics": 0.85633, "context": "openml-kc1-3917", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-kc1-3917-276", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.012919757896819201, "minbucket": 32, "minsplit": 8}}}], "metrics": 0.85633, "context": "openml-kc1-3917", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-kc1-3917-066", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0105528834227142, "minbucket": 32, "minsplit": 2}}}], "metrics": 0.85633, "context": "openml-kc1-3917", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-kc1-3917-164", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.011525382147816503, "minbucket": 32, "minsplit": 4}}}], "metrics": 0.85633, "context": "openml-kc1-3917", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-kc2-3913-221", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.09655432605696417, "minbucket": 64, "minsplit": 4}}}], "metrics": 0.848659, "context": "openml-kc2-3913", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-kc2-3913-058", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.00039379977852078296, "minbucket": 64, "minsplit": 16}}}], "metrics": 0.848659, "context": "openml-kc2-3913", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-kc2-3913-081", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.01953932652259649, "minbucket": 64, "minsplit": 32}}}], "metrics": 0.848659, "context": "openml-kc2-3913", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-kc2-3913-078", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0006204850899093633, "minbucket": 64, "minsplit": 4}}}], "metrics": 0.848659, "context": "openml-kc2-3913", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-kc2-3913-206", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.060680703274462, "minbucket": 1, "minsplit": 128}}}], "metrics": 0.848659, "context": "openml-kc2-3913", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-pc3-3903-196", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0008445560666991289, "minbucket": 4, "minsplit": 128}}}], "metrics": 0.898273, "context": "openml-pc3-3903", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-pc3-3903-293", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.002567409967203769, "minbucket": 4, "minsplit": 128}}}], "metrics": 0.898273, "context": "openml-pc3-3903", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-pc3-3903-236", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0005126956340000111, "minbucket": 4, "minsplit": 128}}}], "metrics": 0.898273, "context": "openml-pc3-3903", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-pc3-3903-133", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0022850407325029198, "minbucket": 4, "minsplit": 128}}}], "metrics": 0.898273, "context": "openml-pc3-3903", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-pc3-3903-173", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.07960854241966935, "minbucket": 8, "minsplit": 2}}}], "metrics": 0.897633, "context": "openml-pc3-3903", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-eucalyptus-2079-165", "modules": [{"role": "dataset", "module": "openml-eucalyptus-2079"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.006292362315169651, "minbucket": 4, "minsplit": 4}}}], "metrics": 0.64538, "context": "openml-eucalyptus-2079", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-eucalyptus-2079-087", "modules": [{"role": "dataset", "module": "openml-eucalyptus-2079"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.022106562626315888, "minbucket": 1, "minsplit": 4}}}], "metrics": 0.644022, "context": "openml-eucalyptus-2079", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-eucalyptus-2079-226", "modules": [{"role": "dataset", "module": "openml-eucalyptus-2079"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.020221769684160198, "minbucket": 1, "minsplit": 16}}}], "metrics": 0.644022, "context": "openml-eucalyptus-2079", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-eucalyptus-2079-076", "modules": [{"role": "dataset", "module": "openml-eucalyptus-2079"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.0202025654118337, "minbucket": 2, "minsplit": 64}}}], "metrics": 0.644022, "context": "openml-eucalyptus-2079", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-rpart-preproc-4796-openml-eucalyptus-2079-080", "modules": [{"role": "dataset", "module": "openml-eucalyptus-2079"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-preproc-4796", "config": {"cp": 0.00544301168802422, "minbucket": 4, "minsplit": 16}}}], "metrics": 0.644022, "context": "openml-eucalyptus-2079", "schema": "rpart-preproc-4796", "source": "hpob"}, {"id": "hpob-svm-5527-openml-click-prediction-small-7295-050", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.0028447079756027988, "gamma": 0.1441253748646349, "kernel": "radial"}}}], "metrics": 0.832708, "context": "openml-click-prediction-small-7295", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-click-prediction-small-7295-118", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.0012471161541672306, "gamma": 0.139958424707001, "kernel": "radial"}}}], "metrics": 0.832682, "context": "openml-click-prediction-small-7295", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-click-prediction-small-7295-012", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.00196571711211164, "gamma": 0.027328379337289894, "kernel": "radial"}}}], "metrics": 0.832682, "context": "openml-click-prediction-small-7295", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-click-prediction-small-7295-084", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.002685420314955599, "gamma": 0.028331931739848302, "kernel": "radial"}}}], "metrics": 0.832657, "context": "openml-click-prediction-small-7295", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-click-prediction-small-7295-098", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.0013773699215269602, "gamma": 0.0345040156495788, "kernel": "radial"}}}], "metrics": 0.832632, "context": "openml-click-prediction-small-7295", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-click-prediction-small-14971-231", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.0024566102089327102, "gamma": 0.08112095254163053, "kernel": "radial"}}}], "metrics": 0.832657, "context": "openml-click-prediction-small-14971", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-click-prediction-small-14971-247", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.004687038896510501, "gamma": 0.07564471411930064, "kernel": "radial"}}}], "metrics": 0.832582, "context": "openml-click-prediction-small-14971", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-click-prediction-small-14971-037", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.0024631551352834696, "gamma": 0.1707984975474, "kernel": "radial"}}}], "metrics": 0.832582, "context": "openml-click-prediction-small-14971", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-click-prediction-small-14971-225", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.0025077976150226305, "gamma": 0.09580839358874141, "kernel": "radial"}}}], "metrics": 0.832582, "context": "openml-click-prediction-small-14971", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-click-prediction-small-14971-073", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.0063412972689060884, "gamma": 0.09426556907175065, "kernel": "radial"}}}], "metrics": 0.832557, "context": "openml-click-prediction-small-14971", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-sylva-agnostic-3889-317", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.00125527439259051, "kernel": "linear"}}}], "metrics": 0.990969, "context": "openml-sylva-agnostic-3889", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-sylva-agnostic-3889-322", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.0011836514864757204, "kernel": "linear"}}}], "metrics": 0.9909, "context": "openml-sylva-agnostic-3889", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-sylva-agnostic-3889-218", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.9616521272703412, "degree": 2, "kernel": "polynomial"}}}], "metrics": 0.98958, "context": "openml-sylva-agnostic-3889", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-sylva-agnostic-3889-169", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.9252282546040227, "degree": 2, "kernel": "polynomial"}}}], "metrics": 0.98958, "context": "openml-sylva-agnostic-3889", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-sylva-agnostic-3889-310", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.7150943384105423, "degree": 2, "kernel": "polynomial"}}}], "metrics": 0.98951, "context": "openml-sylva-agnostic-3889", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-bank-marketing-14965-359", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 6.581985303313586, "gamma": 0.04171206711579422, "kernel": "radial"}}}], "metrics": 0.905642, "context": "openml-bank-marketing-14965", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-bank-marketing-14965-316", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 2.0673204041178206, "gamma": 0.0786239355617743, "kernel": "radial"}}}], "metrics": 0.905134, "context": "openml-bank-marketing-14965", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-bank-marketing-14965-072", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 122.06829127036396, "gamma": 0.00684565691521138, "kernel": "radial"}}}], "metrics": 0.904913, "context": "openml-bank-marketing-14965", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-bank-marketing-14965-024", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 58.94783217470086, "gamma": 0.009776423528486457, "kernel": "radial"}}}], "metrics": 0.904802, "context": "openml-bank-marketing-14965", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-bank-marketing-14965-403", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 42.47936839210479, "gamma": 0.013856308975707004, "kernel": "radial"}}}], "metrics": 0.90478, "context": "openml-bank-marketing-14965", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-nomao-9977-286", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 19.858445568330982, "gamma": 0.010002678160923713, "kernel": "radial"}}}], "metrics": 0.965037, "context": "openml-nomao-9977", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-nomao-9977-374", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 17.161921633937602, "gamma": 0.011578233982563798, "kernel": "radial"}}}], "metrics": 0.96495, "context": "openml-nomao-9977", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-nomao-9977-230", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 46.6891856579015, "gamma": 0.00656264696605792, "kernel": "radial"}}}], "metrics": 0.964718, "context": "openml-nomao-9977", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-nomao-9977-346", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 92.40131781497591, "gamma": 0.0035560248273557404, "kernel": "radial"}}}], "metrics": 0.964573, "context": "openml-nomao-9977", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-nomao-9977-319", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 9.952895472234022, "gamma": 0.011875018170147899, "kernel": "radial"}}}], "metrics": 0.964515, "context": "openml-nomao-9977", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-nomao-145854-080", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 21.601872605598977, "gamma": 0.011190345182082605, "kernel": "radial"}}}], "metrics": 0.965095, "context": "openml-nomao-145854", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-nomao-145854-300", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 13.820578905481094, "gamma": 0.013632705556862601, "kernel": "radial"}}}], "metrics": 0.965037, "context": "openml-nomao-145854", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-nomao-145854-206", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 12.59276337250519, "gamma": 0.013821170546916096, "kernel": "radial"}}}], "metrics": 0.964921, "context": "openml-nomao-145854", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-nomao-145854-514", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 23.1606534290768, "gamma": 0.00844937392158402, "kernel": "radial"}}}], "metrics": 0.964921, "context": "openml-nomao-145854", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-nomao-145854-023", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 20.14455298410311, "gamma": 0.00808064067081371, "kernel": "radial"}}}], "metrics": 0.964863, "context": "openml-nomao-145854", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-electricity-146012-112", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 5.160160604281351, "gamma": 0.7048547533991513, "kernel": "radial"}}}], "metrics": 0.84748, "context": "openml-electricity-146012", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-electricity-146012-447", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 1.4611967180112586, "gamma": 1.5155371443506713, "kernel": "radial"}}}], "metrics": 0.845648, "context": "openml-electricity-146012", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-electricity-146012-585", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.8304686603086148, "gamma": 2.29392532947323, "kernel": "radial"}}}], "metrics": 0.844964, "context": "openml-electricity-146012", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-electricity-146012-256", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 6.649594103685189, "gamma": 0.5062832351698305, "kernel": "radial"}}}], "metrics": 0.844368, "context": "openml-electricity-146012", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-electricity-146012-235", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 12.682816163554692, "gamma": 0.359229562596807, "kernel": "radial"}}}], "metrics": 0.841609, "context": "openml-electricity-146012", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-climate-model-simulation-crashes-9980-475", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.004215300661919809, "gamma": 0.0036756754732864107, "kernel": "radial"}}}], "metrics": 0.916667, "context": "openml-climate-model-simulation-crashes-9980", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-climate-model-simulation-crashes-9980-499", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 69.65464365557779, "gamma": 166.7083249616749, "kernel": "radial"}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-9980", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-climate-model-simulation-crashes-9980-426", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 395.23498055435124, "gamma": 42.0030396728147, "kernel": "radial"}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-9980", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-climate-model-simulation-crashes-9980-444", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.07580364604558243, "kernel": "linear"}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-9980", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-climate-model-simulation-crashes-9980-442", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.2830774795432031, "gamma": 0.34479588103694064, "kernel": "radial"}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-9980", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-electricity-219-449", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 10.114607737164489, "gamma": 0.8630622337744334, "kernel": "radial"}}}], "metrics": 0.854718, "context": "openml-electricity-219", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-electricity-219-413", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 15.991235362426695, "gamma": 0.6803139847986205, "kernel": "radial"}}}], "metrics": 0.854387, "context": "openml-electricity-219", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-electricity-219-926", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 4.646089483819096, "gamma": 1.1924424701734901, "kernel": "radial"}}}], "metrics": 0.852291, "context": "openml-electricity-219", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-electricity-219-932", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 10.946027892595803, "gamma": 0.5884478344863503, "kernel": "radial"}}}], "metrics": 0.850591, "context": "openml-electricity-219", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-electricity-219-365", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 1.1202830829557213, "gamma": 2.2762976487467808, "kernel": "radial"}}}], "metrics": 0.847833, "context": "openml-electricity-219", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-bank-marketing-145833-066", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 6.561849471097473, "gamma": 0.04130050977550102, "kernel": "radial"}}}], "metrics": 0.905731, "context": "openml-bank-marketing-145833", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-bank-marketing-145833-330", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 8.135892786178315, "gamma": 0.03833820146082112, "kernel": "radial"}}}], "metrics": 0.90551, "context": "openml-bank-marketing-145833", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-bank-marketing-145833-431", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 15.161679204533485, "gamma": 0.0246495550661128, "kernel": "radial"}}}], "metrics": 0.905333, "context": "openml-bank-marketing-145833", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-bank-marketing-145833-656", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 1.9767283419321395, "gamma": 0.08784188329888529, "kernel": "radial"}}}], "metrics": 0.905311, "context": "openml-bank-marketing-145833", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-bank-marketing-145833-668", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 4.349887682614761, "gamma": 0.043627563445855694, "kernel": "radial"}}}], "metrics": 0.905244, "context": "openml-bank-marketing-145833", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-musk-3950-2064", "modules": [{"role": "dataset", "module": "openml-musk-3950"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 452.58453706882085, "gamma": 0.010103723824682003, "kernel": "radial"}}}], "metrics": 1.0, "context": "openml-musk-3950", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-musk-3950-1605", "modules": [{"role": "dataset", "module": "openml-musk-3950"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 18.346112698428, "gamma": 0.007384060679523152, "kernel": "radial"}}}], "metrics": 1.0, "context": "openml-musk-3950", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-musk-3950-742", "modules": [{"role": "dataset", "module": "openml-musk-3950"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 32.065963559681784, "gamma": 0.006947786742484021, "kernel": "radial"}}}], "metrics": 1.0, "context": "openml-musk-3950", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-musk-3950-1616", "modules": [{"role": "dataset", "module": "openml-musk-3950"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 272.0662804967339, "gamma": 0.009027447997596692, "kernel": "radial"}}}], "metrics": 1.0, "context": "openml-musk-3950", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-musk-3950-783", "modules": [{"role": "dataset", "module": "openml-musk-3950"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 726.8046766338413, "gamma": 0.00650214642862253, "kernel": "radial"}}}], "metrics": 1.0, "context": "openml-musk-3950", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-phoneme-9952-268", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 1.3728142599053899, "gamma": 9.77251743850581, "kernel": "radial"}}}], "metrics": 0.90322, "context": "openml-phoneme-9952", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-phoneme-9952-2621", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 2.19558058808265, "gamma": 7.393035525172026, "kernel": "radial"}}}], "metrics": 0.90285, "context": "openml-phoneme-9952", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-phoneme-9952-153", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 3.0333168083052438, "gamma": 11.563811332396403, "kernel": "radial"}}}], "metrics": 0.901925, "context": "openml-phoneme-9952", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-phoneme-9952-2045", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 2.8913547162805617, "gamma": 11.316057255920011, "kernel": "radial"}}}], "metrics": 0.900999, "context": "openml-phoneme-9952", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-phoneme-9952-1010", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 9.260817059815125, "gamma": 7.675646780879322, "kernel": "radial"}}}], "metrics": 0.900999, "context": "openml-phoneme-9952", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-mozilla4-3899-1247", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 876.9422696939923, "gamma": 1.1399628671074205, "kernel": "radial"}}}], "metrics": 0.907816, "context": "openml-mozilla4-3899", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-mozilla4-3899-1456", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 450.1853581969148, "gamma": 1.11061936348054, "kernel": "radial"}}}], "metrics": 0.907494, "context": "openml-mozilla4-3899", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-mozilla4-3899-1655", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 196.99717655839513, "gamma": 1.2447332678443108, "kernel": "radial"}}}], "metrics": 0.907044, "context": "openml-mozilla4-3899", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-mozilla4-3899-1136", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 295.02289779125863, "gamma": 1.2419725509261008, "kernel": "radial"}}}], "metrics": 0.906787, "context": "openml-mozilla4-3899", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-mozilla4-3899-1505", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 120.07342028158013, "gamma": 1.3210341472103708, "kernel": "radial"}}}], "metrics": 0.906594, "context": "openml-mozilla4-3899", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-magictelescope-3954-2448", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 74.34090619422018, "gamma": 0.062145404043428304, "kernel": "radial"}}}], "metrics": 0.876446, "context": "openml-magictelescope-3954", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-magictelescope-3954-2890", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 223.5535008010069, "gamma": 0.07431260874984826, "kernel": "radial"}}}], "metrics": 0.876288, "context": "openml-magictelescope-3954", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-magictelescope-3954-2053", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 87.32418537218022, "gamma": 0.05964387764349863, "kernel": "radial"}}}], "metrics": 0.876236, "context": "openml-magictelescope-3954", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-magictelescope-3954-590", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 6.1011865807808565, "gamma": 0.21232284084746902, "kernel": "radial"}}}], "metrics": 0.876236, "context": "openml-magictelescope-3954", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-magictelescope-3954-2227", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 31.73921705097849, "gamma": 0.1703268825951159, "kernel": "radial"}}}], "metrics": 0.876183, "context": "openml-magictelescope-3954", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-gina-agnostic-3891-1058", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 4.533880722851977, "degree": 2, "kernel": "polynomial"}}}], "metrics": 0.930507, "context": "openml-gina-agnostic-3891", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-gina-agnostic-3891-447", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 4.432986832507818, "degree": 2, "kernel": "polynomial"}}}], "metrics": 0.930219, "context": "openml-gina-agnostic-3891", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-gina-agnostic-3891-1248", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 3.4759978644815677, "degree": 2, "kernel": "polynomial"}}}], "metrics": 0.929931, "context": "openml-gina-agnostic-3891", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-gina-agnostic-3891-2448", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 3.5067768500714274, "degree": 2, "kernel": "polynomial"}}}], "metrics": 0.929642, "context": "openml-gina-agnostic-3891", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-gina-agnostic-3891-1356", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 3.570214322860892, "degree": 2, "kernel": "polynomial"}}}], "metrics": 0.929642, "context": "openml-gina-agnostic-3891", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-diabetes-145976-1078", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.7407891247217113, "gamma": 0.04399820867483092, "kernel": "radial"}}}], "metrics": 0.78125, "context": "openml-diabetes-145976", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-diabetes-145976-2614", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 1.0905351289928604, "gamma": 0.03278642287694688, "kernel": "radial"}}}], "metrics": 0.78125, "context": "openml-diabetes-145976", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-diabetes-145976-2673", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 2.47585730848994, "gamma": 0.0130139346234801, "kernel": "radial"}}}], "metrics": 0.78125, "context": "openml-diabetes-145976", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-diabetes-145976-736", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.991551118024694, "gamma": 0.03440217018337099, "kernel": "radial"}}}], "metrics": 0.779948, "context": "openml-diabetes-145976", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-diabetes-145976-3841", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.5987132581062722, "gamma": 0.043665614091311526, "kernel": "radial"}}}], "metrics": 0.779948, "context": "openml-diabetes-145976", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-monks-problems-1-3492-1727", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 48.063739945965935, "degree": 3, "kernel": "polynomial"}}}], "metrics": 1.0, "context": "openml-monks-problems-1-3492", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-monks-problems-1-3492-1012", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 3.8682947717391416, "gamma": 0.8423718899661066, "kernel": "radial"}}}], "metrics": 1.0, "context": "openml-monks-problems-1-3492", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-monks-problems-1-3492-3497", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 854.5921690662514, "degree": 3, "kernel": "polynomial"}}}], "metrics": 1.0, "context": "openml-monks-problems-1-3492", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-monks-problems-1-3492-2474", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 422.6909101579335, "degree": 2, "kernel": "polynomial"}}}], "metrics": 1.0, "context": "openml-monks-problems-1-3492", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-monks-problems-1-3492-902", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 155.598352150942, "degree": 2, "kernel": "polynomial"}}}], "metrics": 1.0, "context": "openml-monks-problems-1-3492", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-madelon-9976-1317", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 8.978822071156785, "gamma": 0.007833715930508278, "kernel": "radial"}}}], "metrics": 0.601154, "context": "openml-madelon-9976", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-madelon-9976-2380", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 19.217279880965393, "gamma": 0.005490451789604903, "kernel": "radial"}}}], "metrics": 0.6, "context": "openml-madelon-9976", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-madelon-9976-1388", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 598.2764077280294, "gamma": 0.006630382795233811, "kernel": "radial"}}}], "metrics": 0.6, "context": "openml-madelon-9976", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-madelon-9976-2965", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 4.73111974555031, "gamma": 0.0077930600076871115, "kernel": "radial"}}}], "metrics": 0.599231, "context": "openml-madelon-9976", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-madelon-9976-3393", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 72.0264763976286, "gamma": 0.005234409264457288, "kernel": "radial"}}}], "metrics": 0.599231, "context": "openml-madelon-9976", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-musk-146082-4077", "modules": [{"role": "dataset", "module": "openml-musk-146082"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 9.379917274448037, "gamma": 0.010116361656849903, "kernel": "radial"}}}], "metrics": 1.0, "context": "openml-musk-146082", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-musk-146082-141", "modules": [{"role": "dataset", "module": "openml-musk-146082"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 562.3012108415529, "gamma": 0.0153808501539048, "kernel": "radial"}}}], "metrics": 1.0, "context": "openml-musk-146082", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-musk-146082-606", "modules": [{"role": "dataset", "module": "openml-musk-146082"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 12.601545957556606, "gamma": 0.015742733899920498, "kernel": "radial"}}}], "metrics": 1.0, "context": "openml-musk-146082", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-musk-146082-2171", "modules": [{"role": "dataset", "module": "openml-musk-146082"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 7.434660953829183, "gamma": 0.010233315875344203, "kernel": "radial"}}}], "metrics": 1.0, "context": "openml-musk-146082", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-musk-146082-2146", "modules": [{"role": "dataset", "module": "openml-musk-146082"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 234.491471873235, "gamma": 0.006667074712932093, "kernel": "radial"}}}], "metrics": 1.0, "context": "openml-musk-146082", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-madelon-145853-2587", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 282.84137741461774, "gamma": 0.007887916857511239, "kernel": "radial"}}}], "metrics": 0.601154, "context": "openml-madelon-145853", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-madelon-145853-2911", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 1.01763287313855, "gamma": 0.006489279385704277, "kernel": "radial"}}}], "metrics": 0.600769, "context": "openml-madelon-145853", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-madelon-145853-2011", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 11.054340440065811, "gamma": 0.005254981682168269, "kernel": "radial"}}}], "metrics": 0.6, "context": "openml-madelon-145853", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-madelon-145853-2999", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 35.164329490258794, "gamma": 0.0054451541671804785, "kernel": "radial"}}}], "metrics": 0.6, "context": "openml-madelon-145853", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-madelon-145853-3417", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 1.136027310364319, "gamma": 0.00781569377001061, "kernel": "radial"}}}], "metrics": 0.599615, "context": "openml-madelon-145853", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-banknote-authentication-145834-2063", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 502.8644353085456, "gamma": 0.5430030104385337, "kernel": "radial"}}}], "metrics": 1.0, "context": "openml-banknote-authentication-145834", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-banknote-authentication-145834-2612", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 219.71326668082676, "gamma": 4.5652610198046375, "kernel": "radial"}}}], "metrics": 1.0, "context": "openml-banknote-authentication-145834", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-banknote-authentication-145834-2542", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 9.529423007331662, "gamma": 25.246695587168585, "kernel": "radial"}}}], "metrics": 1.0, "context": "openml-banknote-authentication-145834", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-banknote-authentication-145834-2549", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 117.88482892769406, "gamma": 0.006351992173737743, "kernel": "radial"}}}], "metrics": 1.0, "context": "openml-banknote-authentication-145834", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-banknote-authentication-145834-2559", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 3.8043185006805116, "gamma": 7.933251723294673, "kernel": "radial"}}}], "metrics": 1.0, "context": "openml-banknote-authentication-145834", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-monks-problems-3-146066-4125", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 31.72074822638741, "kernel": "linear"}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-monks-problems-3-146066-2593", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 6.3854750536037095, "kernel": "linear"}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-monks-problems-3-146066-3946", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 77.5137354458253, "kernel": "linear"}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-monks-problems-3-146066-2603", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 889.406644961135, "gamma": 0.006366045830779121, "kernel": "radial"}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-monks-problems-3-146066-2602", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 89.91532831117867, "kernel": "linear"}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-eeg-eye-state-14951-6537", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 950.0726913760263, "gamma": 0.8276415513544657, "kernel": "radial"}}}], "metrics": 0.902737, "context": "openml-eeg-eye-state-14951", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-eeg-eye-state-14951-6334", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 458.3085130907519, "gamma": 1.620264424534361, "kernel": "radial"}}}], "metrics": 0.900868, "context": "openml-eeg-eye-state-14951", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-eeg-eye-state-14951-6083", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 938.0317598193723, "gamma": 1.7218652891063706, "kernel": "radial"}}}], "metrics": 0.898999, "context": "openml-eeg-eye-state-14951", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-eeg-eye-state-14951-6737", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 145.22744961868304, "gamma": 1.9302431164679286, "kernel": "radial"}}}], "metrics": 0.89733, "context": "openml-eeg-eye-state-14951", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-eeg-eye-state-14951-6276", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 165.14795209710692, "gamma": 2.0943585472198785, "kernel": "radial"}}}], "metrics": 0.896729, "context": "openml-eeg-eye-state-14951", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-monks-problems-3-3494-2747", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 3.6976528790959704, "kernel": "linear"}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-monks-problems-3-3494-6588", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 111.45722236349397, "gamma": 0.009841746767037212, "kernel": "radial"}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-monks-problems-3-3494-1847", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 33.53688241885953, "kernel": "linear"}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-monks-problems-3-3494-4536", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 437.59470886732623, "kernel": "linear"}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-monks-problems-3-3494-4535", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 18.361700462831898, "kernel": "linear"}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-steel-plates-fault-9967-001", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 70.35794764744206, "kernel": "linear"}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-steel-plates-fault-9967-6549", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.006323047859794191, "kernel": "linear"}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-steel-plates-fault-9967-2929", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 465.795096636364, "kernel": "linear"}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-steel-plates-fault-9967-2933", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 41.559599719430196, "kernel": "linear"}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-steel-plates-fault-9967-6545", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 186.9458514195651, "kernel": "linear"}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-ada-agnostic-3896-4181", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.0480225869677071, "kernel": "linear"}}}], "metrics": 0.84897, "context": "openml-ada-agnostic-3896", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-ada-agnostic-3896-3734", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.05205092554586961, "kernel": "linear"}}}], "metrics": 0.848751, "context": "openml-ada-agnostic-3896", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-ada-agnostic-3896-3206", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.046383159395917084, "kernel": "linear"}}}], "metrics": 0.848751, "context": "openml-ada-agnostic-3896", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-ada-agnostic-3896-076", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.047878787618829285, "kernel": "linear"}}}], "metrics": 0.848751, "context": "openml-ada-agnostic-3896", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-ada-agnostic-3896-5057", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.0486427443425238, "kernel": "linear"}}}], "metrics": 0.848751, "context": "openml-ada-agnostic-3896", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-spambase-145979-1881", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 50.596167539829246, "gamma": 0.00564717660532163, "kernel": "radial"}}}], "metrics": 0.941317, "context": "openml-spambase-145979", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-spambase-145979-7498", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 47.79561284035408, "gamma": 0.005303318011356741, "kernel": "radial"}}}], "metrics": 0.941317, "context": "openml-spambase-145979", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-spambase-145979-7013", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 48.98509437520459, "gamma": 0.005805713724738101, "kernel": "radial"}}}], "metrics": 0.940882, "context": "openml-spambase-145979", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-spambase-145979-103", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 34.67444507072988, "gamma": 0.00694316540710694, "kernel": "radial"}}}], "metrics": 0.940665, "context": "openml-spambase-145979", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-spambase-145979-822", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 265.5365572444171, "gamma": 0.00217015129239012, "kernel": "radial"}}}], "metrics": 0.940448, "context": "openml-spambase-145979", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-kr-vs-kp-145953-3165", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 724.2307970514875, "degree": 4, "kernel": "polynomial"}}}], "metrics": 0.998123, "context": "openml-kr-vs-kp-145953", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-kr-vs-kp-145953-9583", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 762.1265601668223, "degree": 4, "kernel": "polynomial"}}}], "metrics": 0.998123, "context": "openml-kr-vs-kp-145953", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-kr-vs-kp-145953-9318", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 843.03929601587, "degree": 4, "kernel": "polynomial"}}}], "metrics": 0.998123, "context": "openml-kr-vs-kp-145953", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-kr-vs-kp-145953-8046", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 727.9045411531105, "degree": 4, "kernel": "polynomial"}}}], "metrics": 0.998123, "context": "openml-kr-vs-kp-145953", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-kr-vs-kp-145953-7786", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 782.3130084380853, "degree": 4, "kernel": "polynomial"}}}], "metrics": 0.998123, "context": "openml-kr-vs-kp-145953", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-kc1-3917-8490", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 5.4962228220212825, "gamma": 0.030095032122555, "kernel": "radial"}}}], "metrics": 0.861072, "context": "openml-kc1-3917", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-kc1-3917-4878", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 2.9347402521958297, "gamma": 0.042120341318147174, "kernel": "radial"}}}], "metrics": 0.860597, "context": "openml-kc1-3917", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-kc1-3917-815", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 2.9663090616331727, "gamma": 0.0410020991427199, "kernel": "radial"}}}], "metrics": 0.860597, "context": "openml-kc1-3917", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-kc1-3917-8460", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 4.563696086583409, "gamma": 0.030354439966773197, "kernel": "radial"}}}], "metrics": 0.860123, "context": "openml-kc1-3917", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-kc1-3917-3425", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 2.293665262775562, "gamma": 0.053175196191635125, "kernel": "radial"}}}], "metrics": 0.860123, "context": "openml-kc1-3917", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-wdbc-145878-5904", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.014451843147811798, "kernel": "linear"}}}], "metrics": 0.982425, "context": "openml-wdbc-145878", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-wdbc-145878-9738", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.016724188789285194, "kernel": "linear"}}}], "metrics": 0.982425, "context": "openml-wdbc-145878", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-wdbc-145878-3880", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.015369850709327499, "kernel": "linear"}}}], "metrics": 0.982425, "context": "openml-wdbc-145878", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-wdbc-145878-1323", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 9.163850027540212, "gamma": 0.003981519209617609, "kernel": "radial"}}}], "metrics": 0.982425, "context": "openml-wdbc-145878", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-wdbc-145878-3676", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.015785130020379994, "kernel": "linear"}}}], "metrics": 0.982425, "context": "openml-wdbc-145878", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-ozone-level-8hr-9978-752", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.3314746539275879, "gamma": 0.012480116704464105, "kernel": "radial"}}}], "metrics": 0.949092, "context": "openml-ozone-level-8hr-9978", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-ozone-level-8hr-9978-9559", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.304310622093722, "gamma": 0.015847623679779908, "kernel": "radial"}}}], "metrics": 0.949092, "context": "openml-ozone-level-8hr-9978", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-ozone-level-8hr-9978-6102", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.3623771402929372, "gamma": 0.0163310481675358, "kernel": "radial"}}}], "metrics": 0.949092, "context": "openml-ozone-level-8hr-9978", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-ozone-level-8hr-9978-5700", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.0202287824872405, "gamma": 0.01649516103899589, "kernel": "radial"}}}], "metrics": 0.949092, "context": "openml-ozone-level-8hr-9978", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-ozone-level-8hr-9978-5693", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.7259195970710423, "gamma": 0.015161762902878304, "kernel": "radial"}}}], "metrics": 0.949092, "context": "openml-ozone-level-8hr-9978", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-credit-g-145972-381", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 12.851452361196397, "gamma": 0.008964521830515047, "kernel": "radial"}}}], "metrics": 0.768, "context": "openml-credit-g-145972", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-credit-g-145972-1283", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 11.830972105636606, "gamma": 0.008569886364327456, "kernel": "radial"}}}], "metrics": 0.767, "context": "openml-credit-g-145972", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-credit-g-145972-5201", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 29.954499568109778, "gamma": 0.004997690210764, "kernel": "radial"}}}], "metrics": 0.766, "context": "openml-credit-g-145972", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-credit-g-145972-7095", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 9.751656950993167, "gamma": 0.007579802066466643, "kernel": "radial"}}}], "metrics": 0.766, "context": "openml-credit-g-145972", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-credit-g-145972-3328", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 3.3156503126433403, "gamma": 0.018732326334772103, "kernel": "radial"}}}], "metrics": 0.766, "context": "openml-credit-g-145972", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-diabetes-37-208", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.7488586586710619, "gamma": 0.0406684307143096, "kernel": "radial"}}}], "metrics": 0.78125, "context": "openml-diabetes-37", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-diabetes-37-2744", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 2.48363628185617, "gamma": 0.012869714045309297, "kernel": "radial"}}}], "metrics": 0.78125, "context": "openml-diabetes-37", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-diabetes-37-9478", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 4.445530910668258, "gamma": 0.008269127354739699, "kernel": "radial"}}}], "metrics": 0.779948, "context": "openml-diabetes-37", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-diabetes-37-4814", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 3.0294611507413403, "gamma": 0.010524314972289103, "kernel": "radial"}}}], "metrics": 0.779948, "context": "openml-diabetes-37", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-diabetes-37-5239", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.42675511165390995, "gamma": 0.030582782584782302, "kernel": "radial"}}}], "metrics": 0.779948, "context": "openml-diabetes-37", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-tic-tac-toe-49-001", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 133.08780714397793, "degree": 3, "kernel": "polynomial"}}}], "metrics": 1.0, "context": "openml-tic-tac-toe-49", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-tic-tac-toe-49-891", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 136.63916963698392, "degree": 4, "kernel": "polynomial"}}}], "metrics": 1.0, "context": "openml-tic-tac-toe-49", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-tic-tac-toe-49-8436", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 385.6951641310284, "degree": 3, "kernel": "polynomial"}}}], "metrics": 1.0, "context": "openml-tic-tac-toe-49", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-tic-tac-toe-49-5361", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 324.82599276554384, "degree": 3, "kernel": "polynomial"}}}], "metrics": 1.0, "context": "openml-tic-tac-toe-49", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-tic-tac-toe-49-2897", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 56.704238636322216, "degree": 3, "kernel": "polynomial"}}}], "metrics": 1.0, "context": "openml-tic-tac-toe-49", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-kr-vs-kp-3-5421", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 791.462645066995, "degree": 4, "kernel": "polynomial"}}}], "metrics": 0.998123, "context": "openml-kr-vs-kp-3", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-kr-vs-kp-3-2259", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 815.2149658846481, "degree": 4, "kernel": "polynomial"}}}], "metrics": 0.998123, "context": "openml-kr-vs-kp-3", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-kr-vs-kp-3-2714", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 747.7727015453937, "degree": 4, "kernel": "polynomial"}}}], "metrics": 0.998123, "context": "openml-kr-vs-kp-3", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-kr-vs-kp-3-6604", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 724.8630627878202, "degree": 4, "kernel": "polynomial"}}}], "metrics": 0.998123, "context": "openml-kr-vs-kp-3", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-kr-vs-kp-3-5687", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 746.8935005434025, "degree": 4, "kernel": "polynomial"}}}], "metrics": 0.998123, "context": "openml-kr-vs-kp-3", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-pc4-3902-3344", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 198.17579829329424, "gamma": 0.0027964449674305896, "kernel": "radial"}}}], "metrics": 0.916324, "context": "openml-pc4-3902", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-pc4-3902-7847", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 4.294393868176197, "kernel": "linear"}}}], "metrics": 0.915638, "context": "openml-pc4-3902", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-pc4-3902-8728", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 4.714661814340177, "kernel": "linear"}}}], "metrics": 0.915638, "context": "openml-pc4-3902", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-pc4-3902-605", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 4.173448243409788, "kernel": "linear"}}}], "metrics": 0.915638, "context": "openml-pc4-3902", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-pc4-3902-1370", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 4.7812171904787055, "kernel": "linear"}}}], "metrics": 0.915638, "context": "openml-pc4-3902", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-qsar-biodeg-145862-6079", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 15.053185703702912, "gamma": 0.047093308420065684, "kernel": "radial"}}}], "metrics": 0.887204, "context": "openml-qsar-biodeg-145862", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-qsar-biodeg-145862-8936", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 42.26595005333843, "gamma": 0.023513284986003195, "kernel": "radial"}}}], "metrics": 0.887204, "context": "openml-qsar-biodeg-145862", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-qsar-biodeg-145862-4737", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 18.299284108279284, "gamma": 0.046518621807197395, "kernel": "radial"}}}], "metrics": 0.887204, "context": "openml-qsar-biodeg-145862", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-qsar-biodeg-145862-5242", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 16.76712755483421, "gamma": 0.04612840701479801, "kernel": "radial"}}}], "metrics": 0.887204, "context": "openml-qsar-biodeg-145862", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-qsar-biodeg-145862-4154", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 9.13734525176407, "gamma": 0.027019270771870003, "kernel": "radial"}}}], "metrics": 0.886256, "context": "openml-qsar-biodeg-145862", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-phoneme-145857-723", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 1.90565474357438, "gamma": 8.824832572150006, "kernel": "radial"}}}], "metrics": 0.902665, "context": "openml-phoneme-145857", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-phoneme-145857-7864", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 2.6635635702878804, "gamma": 5.583459149399726, "kernel": "radial"}}}], "metrics": 0.902665, "context": "openml-phoneme-145857", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-phoneme-145857-543", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 2.5880213203638105, "gamma": 6.140241940595065, "kernel": "radial"}}}], "metrics": 0.902295, "context": "openml-phoneme-145857", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-phoneme-145857-8845", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 2.5022719322376803, "gamma": 7.750069232994742, "kernel": "radial"}}}], "metrics": 0.90211, "context": "openml-phoneme-145857", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-phoneme-145857-644", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 2.616924683376501, "gamma": 7.204263697759319, "kernel": "radial"}}}], "metrics": 0.90211, "context": "openml-phoneme-145857", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-ozone-level-8hr-145855-6320", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 1.281244861676781, "gamma": 0.015304857784443397, "kernel": "radial"}}}], "metrics": 0.949882, "context": "openml-ozone-level-8hr-145855", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-ozone-level-8hr-145855-4394", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.005932056415322291, "gamma": 0.012929484943345804, "kernel": "radial"}}}], "metrics": 0.949882, "context": "openml-ozone-level-8hr-145855", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-ozone-level-8hr-145855-7807", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 1.3134484438834293, "gamma": 0.016393483855555998, "kernel": "radial"}}}], "metrics": 0.949487, "context": "openml-ozone-level-8hr-145855", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-ozone-level-8hr-145855-1587", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.0015769626626817698, "gamma": 0.013067779738128102, "kernel": "radial"}}}], "metrics": 0.949487, "context": "openml-ozone-level-8hr-145855", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-ozone-level-8hr-145855-1432", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.09180729031698143, "gamma": 0.011282935952419899, "kernel": "radial"}}}], "metrics": 0.949092, "context": "openml-ozone-level-8hr-145855", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-pc1-3918-8397", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 8.79930253135846, "gamma": 1.2455439708970992, "kernel": "radial"}}}], "metrics": 0.94229, "context": "openml-pc1-3918", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-pc1-3918-12065", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 3.90110314316654, "gamma": 2.295114861820951, "kernel": "radial"}}}], "metrics": 0.940487, "context": "openml-pc1-3918", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-pc1-3918-7333", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 12.757952221707194, "gamma": 1.0850964455462904, "kernel": "radial"}}}], "metrics": 0.940487, "context": "openml-pc1-3918", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-pc1-3918-8877", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 2.7898742955649563, "gamma": 3.092094335571961, "kernel": "radial"}}}], "metrics": 0.940487, "context": "openml-pc1-3918", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-pc1-3918-5664", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 6.147474811020548, "gamma": 2.06309997840661, "kernel": "radial"}}}], "metrics": 0.940487, "context": "openml-pc1-3918", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-wilt-9889-11646", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 15.6102217459331, "gamma": 0.09440400016050875, "kernel": "radial"}}}], "metrics": 0.988634, "context": "openml-wilt-9889", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-wilt-9889-8436", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 13.540585493967699, "gamma": 0.09545269107260443, "kernel": "radial"}}}], "metrics": 0.988634, "context": "openml-wilt-9889", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-wilt-9889-10634", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 98.9578822630792, "gamma": 0.03803285238370549, "kernel": "radial"}}}], "metrics": 0.988634, "context": "openml-wilt-9889", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-wilt-9889-12867", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 17.289367153813995, "gamma": 0.06050367486348202, "kernel": "radial"}}}], "metrics": 0.988634, "context": "openml-wilt-9889", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-wilt-9889-7169", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 456.5209485775139, "gamma": 0.013967518844746995, "kernel": "radial"}}}], "metrics": 0.988634, "context": "openml-wilt-9889", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-qsar-biodeg-9957-10555", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 20.618814347476718, "gamma": 0.039019633660697, "kernel": "radial"}}}], "metrics": 0.8891, "context": "openml-qsar-biodeg-9957", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-qsar-biodeg-9957-11599", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 20.642853804137413, "gamma": 0.03647126925073849, "kernel": "radial"}}}], "metrics": 0.888152, "context": "openml-qsar-biodeg-9957", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-qsar-biodeg-9957-10928", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 6.535373699577373, "gamma": 0.03217595356855171, "kernel": "radial"}}}], "metrics": 0.886256, "context": "openml-qsar-biodeg-9957", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-qsar-biodeg-9957-10913", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 63.47602671544702, "gamma": 0.019791850895369698, "kernel": "radial"}}}], "metrics": 0.886256, "context": "openml-qsar-biodeg-9957", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-qsar-biodeg-9957-13362", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 65.79268431390592, "gamma": 0.018713758018270403, "kernel": "radial"}}}], "metrics": 0.886256, "context": "openml-qsar-biodeg-9957", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-hill-valley-9970-7823", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 1000.0, "kernel": "linear"}}}], "metrics": 0.745875, "context": "openml-hill-valley-9970", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-hill-valley-9970-14690", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 993.1149777682671, "kernel": "linear"}}}], "metrics": 0.745875, "context": "openml-hill-valley-9970", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-hill-valley-9970-16143", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 1000.0, "kernel": "linear"}}}], "metrics": 0.745875, "context": "openml-hill-valley-9970", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-hill-valley-9970-14016", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 1000.0, "kernel": "linear"}}}], "metrics": 0.745875, "context": "openml-hill-valley-9970", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-hill-valley-9970-14000", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 999.8496897063523, "kernel": "linear"}}}], "metrics": 0.745875, "context": "openml-hill-valley-9970", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-scene-3485-8085", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.1930533015705449, "kernel": "linear"}}}], "metrics": 0.989198, "context": "openml-scene-3485", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-scene-3485-12798", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.09476145581514414, "kernel": "linear"}}}], "metrics": 0.989198, "context": "openml-scene-3485", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-scene-3485-7554", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.19976824626825807, "kernel": "linear"}}}], "metrics": 0.989198, "context": "openml-scene-3485", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-scene-3485-11487", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.159307989679052, "kernel": "linear"}}}], "metrics": 0.989198, "context": "openml-scene-3485", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-scene-3485-14617", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.122110401389371, "kernel": "linear"}}}], "metrics": 0.989198, "context": "openml-scene-3485", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-spambase-43-15445", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 62.72359795339275, "gamma": 0.005153483182520968, "kernel": "radial"}}}], "metrics": 0.941752, "context": "openml-spambase-43", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-spambase-43-18523", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 34.28385434578609, "gamma": 0.0068137157039513795, "kernel": "radial"}}}], "metrics": 0.941317, "context": "openml-spambase-43", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-spambase-43-16795", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 45.9451903651073, "gamma": 0.005936904521253143, "kernel": "radial"}}}], "metrics": 0.940882, "context": "openml-spambase-43", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-spambase-43-16579", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 31.57191887244747, "gamma": 0.007303557751694791, "kernel": "radial"}}}], "metrics": 0.940665, "context": "openml-spambase-43", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-spambase-43-9116", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 94.04876189310671, "gamma": 0.00412743462758971, "kernel": "radial"}}}], "metrics": 0.940665, "context": "openml-spambase-43", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-blood-transfusion-service-center-145836-2097", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.9253612958253239, "gamma": 0.5112991776284213, "kernel": "radial"}}}], "metrics": 0.791444, "context": "openml-blood-transfusion-service-center-145836", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-blood-transfusion-service-center-145836-3064", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.8777758819484941, "gamma": 0.41903271247313983, "kernel": "radial"}}}], "metrics": 0.790107, "context": "openml-blood-transfusion-service-center-145836", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-blood-transfusion-service-center-145836-13785", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 1.3231830949648204, "gamma": 0.3989561534254775, "kernel": "radial"}}}], "metrics": 0.790107, "context": "openml-blood-transfusion-service-center-145836", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-blood-transfusion-service-center-145836-11163", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.9836420215585417, "gamma": 0.4277964479596431, "kernel": "radial"}}}], "metrics": 0.78877, "context": "openml-blood-transfusion-service-center-145836", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-blood-transfusion-service-center-145836-3416", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 0.002730186712234869, "gamma": 0.5371809854224443, "kernel": "radial"}}}], "metrics": 0.78877, "context": "openml-blood-transfusion-service-center-145836", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-hill-valley-145847-9990", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 1000.0, "kernel": "linear"}}}], "metrics": 0.745875, "context": "openml-hill-valley-145847", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-hill-valley-145847-8821", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 1000.0, "kernel": "linear"}}}], "metrics": 0.745875, "context": "openml-hill-valley-145847", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-hill-valley-145847-4142", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 1000.0, "kernel": "linear"}}}], "metrics": 0.745875, "context": "openml-hill-valley-145847", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-hill-valley-145847-15484", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 993.4177316072675, "kernel": "linear"}}}], "metrics": 0.745875, "context": "openml-hill-valley-145847", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-hill-valley-145847-18801", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 1000.0, "kernel": "linear"}}}], "metrics": 0.745875, "context": "openml-hill-valley-145847", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-pc3-3903-11312", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 1.4298858641877195, "gamma": 645.2539727357062, "kernel": "radial"}}}], "metrics": 0.904031, "context": "openml-pc3-3903", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-pc3-3903-5920", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 85.1978281360571, "gamma": 26.235497602300725, "kernel": "radial"}}}], "metrics": 0.904031, "context": "openml-pc3-3903", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-pc3-3903-6149", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 477.8572962072799, "gamma": 570.5335767577383, "kernel": "radial"}}}], "metrics": 0.904031, "context": "openml-pc3-3903", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-pc3-3903-15453", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 7.39450807188605, "gamma": 43.7523236694413, "kernel": "radial"}}}], "metrics": 0.904031, "context": "openml-pc3-3903", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-svm-5527-openml-pc3-3903-15442", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5527", "config": {"cost": 44.718086130114806, "gamma": 54.299839303954485, "kernel": "radial"}}}], "metrics": 0.904031, "context": "openml-pc3-3903", "schema": "svm-5527", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-heart-statlog-282-009", "modules": [{"role": "dataset", "module": "openml-heart-statlog-282"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.36532054090164573, "maxdepth": 26, "minbucket": 15, "minsplit": 10}}}], "metrics": 0.741573, "context": "openml-heart-statlog-282", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-heart-statlog-282-007", "modules": [{"role": "dataset", "module": "openml-heart-statlog-282"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.09189718862287699, "maxdepth": 29, "minbucket": 7, "minsplit": 6}}}], "metrics": 0.741573, "context": "openml-heart-statlog-282", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-heart-statlog-282-001", "modules": [{"role": "dataset", "module": "openml-heart-statlog-282"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.09137161325886842, "maxdepth": 11, "minbucket": 36, "minsplit": 7}}}], "metrics": 0.741573, "context": "openml-heart-statlog-282", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-heart-statlog-282-010", "modules": [{"role": "dataset", "module": "openml-heart-statlog-282"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.7262117142625152, "maxdepth": 24, "minbucket": 43, "minsplit": 59}}}], "metrics": 0.516854, "context": "openml-heart-statlog-282", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-heart-statlog-282-008", "modules": [{"role": "dataset", "module": "openml-heart-statlog-282"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.7466838294010608, "maxdepth": 17, "minbucket": 1, "minsplit": 58}}}], "metrics": 0.516854, "context": "openml-heart-statlog-282", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-haberman-272-011", "modules": [{"role": "dataset", "module": "openml-haberman-272"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.7262117142625152, "maxdepth": 24, "minbucket": 43, "minsplit": 59}}}], "metrics": 0.73, "context": "openml-haberman-272", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-haberman-272-010", "modules": [{"role": "dataset", "module": "openml-haberman-272"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.36532054090164573, "maxdepth": 26, "minbucket": 15, "minsplit": 10}}}], "metrics": 0.73, "context": "openml-haberman-272", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-haberman-272-009", "modules": [{"role": "dataset", "module": "openml-haberman-272"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.7466838294010608, "maxdepth": 17, "minbucket": 1, "minsplit": 58}}}], "metrics": 0.73, "context": "openml-haberman-272", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-haberman-272-008", "modules": [{"role": "dataset", "module": "openml-haberman-272"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.09189718862287699, "maxdepth": 29, "minbucket": 7, "minsplit": 6}}}], "metrics": 0.73, "context": "openml-haberman-272", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-haberman-272-007", "modules": [{"role": "dataset", "module": "openml-haberman-272"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.7804226744290443, "maxdepth": 4, "minbucket": 9, "minsplit": 52}}}], "metrics": 0.73, "context": "openml-haberman-272", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-spambase-145979-347", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.002499075077846649, "maxdepth": 22, "minbucket": 4, "minsplit": 56}}}], "metrics": 0.915888, "context": "openml-spambase-145979", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-spambase-145979-797", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0019817621748894508, "maxdepth": 24, "minbucket": 19, "minsplit": 43}}}], "metrics": 0.909368, "context": "openml-spambase-145979", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-spambase-145979-780", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0009615117985755213, "maxdepth": 6, "minbucket": 17, "minsplit": 45}}}], "metrics": 0.906977, "context": "openml-spambase-145979", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-spambase-145979-025", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.004683075176924469, "maxdepth": 24, "minbucket": 30, "minsplit": 44}}}], "metrics": 0.901543, "context": "openml-spambase-145979", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-spambase-145979-719", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.005748581776767972, "maxdepth": 16, "minbucket": 12, "minsplit": 16}}}], "metrics": 0.900674, "context": "openml-spambase-145979", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-diabetes-145976-465", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0074227605316788, "maxdepth": 19, "minbucket": 18, "minsplit": 3}}}], "metrics": 0.761719, "context": "openml-diabetes-145976", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-diabetes-145976-752", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.010702747788652791, "maxdepth": 16, "minbucket": 57, "minsplit": 26}}}], "metrics": 0.757812, "context": "openml-diabetes-145976", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-diabetes-145976-504", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.00800239847265184, "maxdepth": 13, "minbucket": 26, "minsplit": 37}}}], "metrics": 0.757812, "context": "openml-diabetes-145976", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-diabetes-145976-744", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.005828803342208268, "maxdepth": 15, "minbucket": 21, "minsplit": 36}}}], "metrics": 0.75651, "context": "openml-diabetes-145976", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-diabetes-145976-320", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.023212540366128104, "maxdepth": 24, "minbucket": 11, "minsplit": 15}}}], "metrics": 0.755208, "context": "openml-diabetes-145976", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-monks-problems-3-146066-076", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.00537553749270737, "maxdepth": 18, "minbucket": 8, "minsplit": 3}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-monks-problems-3-146066-275", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.015741387784853594, "maxdepth": 15, "minbucket": 4, "minsplit": 24}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-monks-problems-3-146066-448", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.009598944738879801, "maxdepth": 12, "minbucket": 10, "minsplit": 24}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-monks-problems-3-146066-499", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.2627603387761858, "maxdepth": 13, "minbucket": 17, "minsplit": 37}}}], "metrics": 0.963899, "context": "openml-monks-problems-3-146066", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-monks-problems-3-146066-487", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.16327895427346195, "maxdepth": 8, "minbucket": 43, "minsplit": 22}}}], "metrics": 0.963899, "context": "openml-monks-problems-3-146066", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-ilpd-145848-1971", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.7946106716360904, "maxdepth": 10, "minbucket": 29, "minsplit": 10}}}], "metrics": 0.713551, "context": "openml-ilpd-145848", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-ilpd-145848-627", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.2928529423031959, "maxdepth": 24, "minbucket": 42, "minsplit": 41}}}], "metrics": 0.713551, "context": "openml-ilpd-145848", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-ilpd-145848-661", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.4523579847835003, "maxdepth": 18, "minbucket": 23, "minsplit": 38}}}], "metrics": 0.713551, "context": "openml-ilpd-145848", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-ilpd-145848-662", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.9991155508276085, "maxdepth": 10, "minbucket": 45, "minsplit": 4}}}], "metrics": 0.713551, "context": "openml-ilpd-145848", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-ilpd-145848-663", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.3493965693585572, "maxdepth": 20, "minbucket": 4, "minsplit": 18}}}], "metrics": 0.713551, "context": "openml-ilpd-145848", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-nomao-9977-1596", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.00030740251056850004, "maxdepth": 19, "minbucket": 32, "minsplit": 19}}}], "metrics": 0.947628, "context": "openml-nomao-9977", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-nomao-9977-1971", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.002195927949994799, "maxdepth": 22, "minbucket": 17, "minsplit": 5}}}], "metrics": 0.944059, "context": "openml-nomao-9977", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-nomao-9977-1406", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0013982853222638397, "maxdepth": 28, "minbucket": 57, "minsplit": 4}}}], "metrics": 0.94255, "context": "openml-nomao-9977", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-nomao-9977-1698", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0028604519855230993, "maxdepth": 19, "minbucket": 31, "minsplit": 57}}}], "metrics": 0.941361, "context": "openml-nomao-9977", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-nomao-9977-106", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.003989777464792132, "maxdepth": 12, "minbucket": 41, "minsplit": 12}}}], "metrics": 0.93756, "context": "openml-nomao-9977", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-madelon-145853-1253", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.003922545753791931, "maxdepth": 20, "minbucket": 6, "minsplit": 14}}}], "metrics": 0.809615, "context": "openml-madelon-145853", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-madelon-145853-1730", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.005915842654556042, "maxdepth": 15, "minbucket": 7, "minsplit": 35}}}], "metrics": 0.805769, "context": "openml-madelon-145853", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-madelon-145853-695", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0039052874151617304, "maxdepth": 23, "minbucket": 18, "minsplit": 59}}}], "metrics": 0.787692, "context": "openml-madelon-145853", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-madelon-145853-725", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.005808593875169751, "maxdepth": 19, "minbucket": 30, "minsplit": 34}}}], "metrics": 0.783462, "context": "openml-madelon-145853", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-madelon-145853-1756", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.000549603190645576, "maxdepth": 22, "minbucket": 32, "minsplit": 20}}}], "metrics": 0.779615, "context": "openml-madelon-145853", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-gina-agnostic-3891-3403", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.004142217275127771, "maxdepth": 6, "minbucket": 15, "minsplit": 44}}}], "metrics": 0.871972, "context": "openml-gina-agnostic-3891", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-gina-agnostic-3891-162", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.005407941231876611, "maxdepth": 23, "minbucket": 14, "minsplit": 41}}}], "metrics": 0.867935, "context": "openml-gina-agnostic-3891", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-gina-agnostic-3891-3313", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.006214579970017078, "maxdepth": 15, "minbucket": 7, "minsplit": 11}}}], "metrics": 0.862745, "context": "openml-gina-agnostic-3891", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-gina-agnostic-3891-2203", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.000990391878783703, "maxdepth": 22, "minbucket": 37, "minsplit": 24}}}], "metrics": 0.858997, "context": "openml-gina-agnostic-3891", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-gina-agnostic-3891-3476", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0007176468450576071, "maxdepth": 16, "minbucket": 38, "minsplit": 2}}}], "metrics": 0.856978, "context": "openml-gina-agnostic-3891", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-musk-146082-3986", "modules": [{"role": "dataset", "module": "openml-musk-146082"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.1549538829665629, "maxdepth": 28, "minbucket": 24, "minsplit": 3}}}], "metrics": 0.999697, "context": "openml-musk-146082", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-musk-146082-1324", "modules": [{"role": "dataset", "module": "openml-musk-146082"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.22211371984556305, "maxdepth": 14, "minbucket": 9, "minsplit": 40}}}], "metrics": 0.999697, "context": "openml-musk-146082", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-musk-146082-1337", "modules": [{"role": "dataset", "module": "openml-musk-146082"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.6790356241933997, "maxdepth": 18, "minbucket": 55, "minsplit": 26}}}], "metrics": 0.999697, "context": "openml-musk-146082", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-musk-146082-1336", "modules": [{"role": "dataset", "module": "openml-musk-146082"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.28679879818335186, "maxdepth": 1, "minbucket": 20, "minsplit": 6}}}], "metrics": 0.999697, "context": "openml-musk-146082", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-musk-146082-1335", "modules": [{"role": "dataset", "module": "openml-musk-146082"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.900350517996028, "maxdepth": 29, "minbucket": 13, "minsplit": 44}}}], "metrics": 0.999697, "context": "openml-musk-146082", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-click-prediction-small-14971-741", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0007965619977563623, "maxdepth": 17, "minbucket": 23, "minsplit": 55}}}], "metrics": 0.834159, "context": "openml-click-prediction-small-14971", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-click-prediction-small-14971-3624", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0003063161227852111, "maxdepth": 5, "minbucket": 58, "minsplit": 45}}}], "metrics": 0.833108, "context": "openml-click-prediction-small-14971", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-click-prediction-small-14971-3207", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.00143546069264412, "maxdepth": 21, "minbucket": 44, "minsplit": 40}}}], "metrics": 0.832257, "context": "openml-click-prediction-small-14971", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-click-prediction-small-14971-1332", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.42710113309547315, "maxdepth": 21, "minbucket": 29, "minsplit": 6}}}], "metrics": 0.831581, "context": "openml-click-prediction-small-14971", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-click-prediction-small-14971-1327", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.08830788026787344, "maxdepth": 19, "minbucket": 16, "minsplit": 8}}}], "metrics": 0.831581, "context": "openml-click-prediction-small-14971", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-bank-marketing-14965-2574", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.002189963993057609, "maxdepth": 25, "minbucket": 9, "minsplit": 9}}}], "metrics": 0.904868, "context": "openml-bank-marketing-14965", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-bank-marketing-14965-005", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0021664203912019706, "maxdepth": 19, "minbucket": 24, "minsplit": 1}}}], "metrics": 0.90478, "context": "openml-bank-marketing-14965", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-bank-marketing-14965-2978", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.00239811994358897, "maxdepth": 10, "minbucket": 1, "minsplit": 1}}}], "metrics": 0.904691, "context": "openml-bank-marketing-14965", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-bank-marketing-14965-2100", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0022841104608029095, "maxdepth": 7, "minbucket": 43, "minsplit": 1}}}], "metrics": 0.904669, "context": "openml-bank-marketing-14965", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-bank-marketing-14965-276", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.002642214235290879, "maxdepth": 20, "minbucket": 22, "minsplit": 31}}}], "metrics": 0.904293, "context": "openml-bank-marketing-14965", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-click-prediction-small-7295-3976", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.000862133626267314, "maxdepth": 24, "minbucket": 14, "minsplit": 33}}}], "metrics": 0.834335, "context": "openml-click-prediction-small-7295", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-click-prediction-small-7295-2634", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0008735451217740768, "maxdepth": 19, "minbucket": 12, "minsplit": 33}}}], "metrics": 0.834034, "context": "openml-click-prediction-small-7295", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-click-prediction-small-7295-1792", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0007802571006119251, "maxdepth": 30, "minbucket": 27, "minsplit": 34}}}], "metrics": 0.834009, "context": "openml-click-prediction-small-7295", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-click-prediction-small-7295-3156", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.001038699347898364, "maxdepth": 14, "minbucket": 25, "minsplit": 16}}}], "metrics": 0.833484, "context": "openml-click-prediction-small-7295", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-click-prediction-small-7295-4481", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.00037428404428064784, "maxdepth": 25, "minbucket": 57, "minsplit": 17}}}], "metrics": 0.832682, "context": "openml-click-prediction-small-7295", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-ozone-level-8hr-145855-221", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.026546583913639205, "maxdepth": 6, "minbucket": 35, "minsplit": 2}}}], "metrics": 0.937253, "context": "openml-ozone-level-8hr-145855", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-ozone-level-8hr-145855-2338", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.028920635983720407, "maxdepth": 9, "minbucket": 33, "minsplit": 45}}}], "metrics": 0.937253, "context": "openml-ozone-level-8hr-145855", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-ozone-level-8hr-145855-4477", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.032862048300355697, "maxdepth": 12, "minbucket": 35, "minsplit": 34}}}], "metrics": 0.937253, "context": "openml-ozone-level-8hr-145855", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-ozone-level-8hr-145855-861", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.027635803848877514, "maxdepth": 28, "minbucket": 35, "minsplit": 19}}}], "metrics": 0.937253, "context": "openml-ozone-level-8hr-145855", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-ozone-level-8hr-145855-4403", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.032059427520632705, "maxdepth": 20, "minbucket": 39, "minsplit": 48}}}], "metrics": 0.937253, "context": "openml-ozone-level-8hr-145855", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-wilt-9889-3526", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.00017464271038770683, "maxdepth": 26, "minbucket": 10, "minsplit": 21}}}], "metrics": 0.981194, "context": "openml-wilt-9889", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-wilt-9889-1092", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.00485781178101897, "maxdepth": 5, "minbucket": 2, "minsplit": 45}}}], "metrics": 0.980988, "context": "openml-wilt-9889", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-wilt-9889-3027", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0049122990410774905, "maxdepth": 7, "minbucket": 6, "minsplit": 10}}}], "metrics": 0.980368, "context": "openml-wilt-9889", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-wilt-9889-2255", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.004516028736159209, "maxdepth": 25, "minbucket": 4, "minsplit": 25}}}], "metrics": 0.979955, "context": "openml-wilt-9889", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-wilt-9889-4870", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.011661865219846395, "maxdepth": 17, "minbucket": 9, "minsplit": 44}}}], "metrics": 0.979748, "context": "openml-wilt-9889", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-magictelescope-3954-2465", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0003550275530666109, "maxdepth": 17, "minbucket": 18, "minsplit": 57}}}], "metrics": 0.85021, "context": "openml-magictelescope-3954", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-magictelescope-3954-2964", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0004889007493853568, "maxdepth": 13, "minbucket": 27, "minsplit": 38}}}], "metrics": 0.848633, "context": "openml-magictelescope-3954", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-magictelescope-3954-245", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.000982572727277875, "maxdepth": 23, "minbucket": 18, "minsplit": 60}}}], "metrics": 0.847687, "context": "openml-magictelescope-3954", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-magictelescope-3954-2027", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0005188609309494499, "maxdepth": 23, "minbucket": 40, "minsplit": 53}}}], "metrics": 0.845741, "context": "openml-magictelescope-3954", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-magictelescope-3954-4060", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.000672505872696638, "maxdepth": 14, "minbucket": 42, "minsplit": 37}}}], "metrics": 0.845163, "context": "openml-magictelescope-3954", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-nomao-145854-5717", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0006387226119637492, "maxdepth": 27, "minbucket": 14, "minsplit": 56}}}], "metrics": 0.950326, "context": "openml-nomao-145854", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-nomao-145854-5333", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0007059333682060238, "maxdepth": 8, "minbucket": 10, "minsplit": 22}}}], "metrics": 0.949543, "context": "openml-nomao-145854", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-nomao-145854-087", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0001735470093786717, "maxdepth": 26, "minbucket": 34, "minsplit": 20}}}], "metrics": 0.947396, "context": "openml-nomao-145854", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-nomao-145854-1973", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0017072082798928, "maxdepth": 13, "minbucket": 39, "minsplit": 15}}}], "metrics": 0.944204, "context": "openml-nomao-145854", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-nomao-145854-1847", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0014275502715259797, "maxdepth": 16, "minbucket": 45, "minsplit": 4}}}], "metrics": 0.943798, "context": "openml-nomao-145854", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-electricity-146012-012", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0006262396298348901, "maxdepth": 28, "minbucket": 27, "minsplit": 17}}}], "metrics": 0.851099, "context": "openml-electricity-146012", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-electricity-146012-3717", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0007191022694110871, "maxdepth": 30, "minbucket": 14, "minsplit": 33}}}], "metrics": 0.848053, "context": "openml-electricity-146012", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-electricity-146012-2006", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0004983043134212491, "maxdepth": 29, "minbucket": 53, "minsplit": 27}}}], "metrics": 0.844236, "context": "openml-electricity-146012", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-electricity-146012-3558", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.000713939482718706, "maxdepth": 21, "minbucket": 48, "minsplit": 46}}}], "metrics": 0.840925, "context": "openml-electricity-146012", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-electricity-146012-5319", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.001056921139732003, "maxdepth": 25, "minbucket": 11, "minsplit": 12}}}], "metrics": 0.835717, "context": "openml-electricity-146012", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-madelon-9976-2987", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.00568100477792323, "maxdepth": 10, "minbucket": 8, "minsplit": 49}}}], "metrics": 0.801923, "context": "openml-madelon-9976", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-madelon-9976-5277", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0028250444982200937, "maxdepth": 24, "minbucket": 4, "minsplit": 34}}}], "metrics": 0.801538, "context": "openml-madelon-9976", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-madelon-9976-2451", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.004533143651112912, "maxdepth": 23, "minbucket": 4, "minsplit": 56}}}], "metrics": 0.801154, "context": "openml-madelon-9976", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-madelon-9976-3762", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.00311930052228272, "maxdepth": 25, "minbucket": 13, "minsplit": 35}}}], "metrics": 0.796923, "context": "openml-madelon-9976", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-madelon-9976-5508", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0073503865230828535, "maxdepth": 16, "minbucket": 4, "minsplit": 46}}}], "metrics": 0.792308, "context": "openml-madelon-9976", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-bank-marketing-145833-3396", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0012982752475887505, "maxdepth": 20, "minbucket": 21, "minsplit": 56}}}], "metrics": 0.904802, "context": "openml-bank-marketing-145833", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-bank-marketing-145833-6287", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0010192479774355887, "maxdepth": 24, "minbucket": 9, "minsplit": 7}}}], "metrics": 0.904736, "context": "openml-bank-marketing-145833", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-bank-marketing-145833-2413", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0013267446145415302, "maxdepth": 25, "minbucket": 5, "minsplit": 33}}}], "metrics": 0.904713, "context": "openml-bank-marketing-145833", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-bank-marketing-145833-229", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0015092850033193795, "maxdepth": 30, "minbucket": 8, "minsplit": 45}}}], "metrics": 0.904669, "context": "openml-bank-marketing-145833", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-bank-marketing-145833-5949", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.00203063449114561, "maxdepth": 10, "minbucket": 26, "minsplit": 54}}}], "metrics": 0.904559, "context": "openml-bank-marketing-145833", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-phoneme-145857-5569", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0008132377941161392, "maxdepth": 9, "minbucket": 16, "minsplit": 27}}}], "metrics": 0.848446, "context": "openml-phoneme-145857", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-phoneme-145857-1981", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0029214848134666684, "maxdepth": 12, "minbucket": 8, "minsplit": 7}}}], "metrics": 0.84789, "context": "openml-phoneme-145857", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-phoneme-145857-7098", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.00226531287878752, "maxdepth": 19, "minbucket": 23, "minsplit": 51}}}], "metrics": 0.846595, "context": "openml-phoneme-145857", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-phoneme-145857-1550", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0002049179118126629, "maxdepth": 18, "minbucket": 2, "minsplit": 43}}}], "metrics": 0.845855, "context": "openml-phoneme-145857", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-phoneme-145857-7534", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0040312068838626106, "maxdepth": 13, "minbucket": 13, "minsplit": 34}}}], "metrics": 0.845115, "context": "openml-phoneme-145857", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-phoneme-9952-8686", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.001083962090685965, "maxdepth": 13, "minbucket": 15, "minsplit": 31}}}], "metrics": 0.849001, "context": "openml-phoneme-9952", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-phoneme-9952-5248", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0031335488263517608, "maxdepth": 17, "minbucket": 19, "minsplit": 24}}}], "metrics": 0.84789, "context": "openml-phoneme-9952", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-phoneme-9952-4031", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.00035196885690093, "maxdepth": 28, "minbucket": 19, "minsplit": 32}}}], "metrics": 0.847705, "context": "openml-phoneme-9952", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-phoneme-9952-6854", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0023208837326616004, "maxdepth": 16, "minbucket": 7, "minsplit": 39}}}], "metrics": 0.847705, "context": "openml-phoneme-9952", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-phoneme-9952-8069", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0032686276197433466, "maxdepth": 19, "minbucket": 12, "minsplit": 22}}}], "metrics": 0.847335, "context": "openml-phoneme-9952", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-credit-g-145972-3409", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.011226233497634505, "maxdepth": 12, "minbucket": 4, "minsplit": 55}}}], "metrics": 0.752, "context": "openml-credit-g-145972", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-credit-g-145972-5840", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.013574432285875099, "maxdepth": 20, "minbucket": 20, "minsplit": 42}}}], "metrics": 0.75, "context": "openml-credit-g-145972", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-credit-g-145972-7146", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.010249386245757301, "maxdepth": 22, "minbucket": 4, "minsplit": 52}}}], "metrics": 0.75, "context": "openml-credit-g-145972", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-credit-g-145972-7776", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.008285041137039659, "maxdepth": 7, "minbucket": 5, "minsplit": 42}}}], "metrics": 0.748, "context": "openml-credit-g-145972", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-credit-g-145972-2276", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0123837456874549, "maxdepth": 28, "minbucket": 22, "minsplit": 33}}}], "metrics": 0.747, "context": "openml-credit-g-145972", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-qsar-biodeg-145862-6803", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.006748242939263578, "maxdepth": 14, "minbucket": 4, "minsplit": 16}}}], "metrics": 0.820853, "context": "openml-qsar-biodeg-145862", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-qsar-biodeg-145862-1524", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.011002033653110303, "maxdepth": 26, "minbucket": 2, "minsplit": 20}}}], "metrics": 0.820853, "context": "openml-qsar-biodeg-145862", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-qsar-biodeg-145862-6630", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.011578940723463904, "maxdepth": 6, "minbucket": 2, "minsplit": 9}}}], "metrics": 0.819905, "context": "openml-qsar-biodeg-145862", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-qsar-biodeg-145862-7891", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.009454577399790293, "maxdepth": 17, "minbucket": 4, "minsplit": 25}}}], "metrics": 0.818957, "context": "openml-qsar-biodeg-145862", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-qsar-biodeg-145862-9146", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.011514327658712898, "maxdepth": 18, "minbucket": 4, "minsplit": 58}}}], "metrics": 0.818009, "context": "openml-qsar-biodeg-145862", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-monks-problems-2-3493-115", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0042743316687643505, "maxdepth": 19, "minbucket": 1, "minsplit": 1}}}], "metrics": 0.991681, "context": "openml-monks-problems-2-3493", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-monks-problems-2-3493-1049", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.003266172653436661, "maxdepth": 27, "minbucket": 2, "minsplit": 1}}}], "metrics": 0.976705, "context": "openml-monks-problems-2-3493", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-monks-problems-2-3493-4559", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.00597880262173712, "maxdepth": 21, "minbucket": 2, "minsplit": 3}}}], "metrics": 0.955075, "context": "openml-monks-problems-2-3493", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-monks-problems-2-3493-9408", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0022380693651735794, "maxdepth": 17, "minbucket": 3, "minsplit": 2}}}], "metrics": 0.953411, "context": "openml-monks-problems-2-3493", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-monks-problems-2-3493-9827", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.011712096801400205, "maxdepth": 13, "minbucket": 3, "minsplit": 5}}}], "metrics": 0.90183, "context": "openml-monks-problems-2-3493", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-kr-vs-kp-145953-4668", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0035463733900338397, "maxdepth": 21, "minbucket": 7, "minsplit": 13}}}], "metrics": 0.974969, "context": "openml-kr-vs-kp-145953", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-kr-vs-kp-145953-1026", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.000125069573894143, "maxdepth": 17, "minbucket": 8, "minsplit": 58}}}], "metrics": 0.97403, "context": "openml-kr-vs-kp-145953", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-kr-vs-kp-145953-8407", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0030046565759926994, "maxdepth": 30, "minbucket": 9, "minsplit": 15}}}], "metrics": 0.973404, "context": "openml-kr-vs-kp-145953", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-kr-vs-kp-145953-576", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.002839275107160211, "maxdepth": 16, "minbucket": 9, "minsplit": 7}}}], "metrics": 0.973404, "context": "openml-kr-vs-kp-145953", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-kr-vs-kp-145953-2664", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.003997392190992828, "maxdepth": 28, "minbucket": 6, "minsplit": 31}}}], "metrics": 0.97184, "context": "openml-kr-vs-kp-145953", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-blood-transfusion-service-center-145836-9136", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0021023004617542, "maxdepth": 20, "minbucket": 10, "minsplit": 23}}}], "metrics": 0.796791, "context": "openml-blood-transfusion-service-center-145836", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-blood-transfusion-service-center-145836-9413", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0020252165220677903, "maxdepth": 28, "minbucket": 22, "minsplit": 41}}}], "metrics": 0.794118, "context": "openml-blood-transfusion-service-center-145836", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-blood-transfusion-service-center-145836-9209", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.002875914501398801, "maxdepth": 15, "minbucket": 22, "minsplit": 12}}}], "metrics": 0.794118, "context": "openml-blood-transfusion-service-center-145836", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-blood-transfusion-service-center-145836-6152", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0038260213866829883, "maxdepth": 30, "minbucket": 10, "minsplit": 18}}}], "metrics": 0.794118, "context": "openml-blood-transfusion-service-center-145836", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-blood-transfusion-service-center-145836-5103", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.00213808257356286, "maxdepth": 12, "minbucket": 22, "minsplit": 33}}}], "metrics": 0.794118, "context": "openml-blood-transfusion-service-center-145836", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-wdbc-145878-1966", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.006022815296798939, "maxdepth": 30, "minbucket": 2, "minsplit": 6}}}], "metrics": 0.943761, "context": "openml-wdbc-145878", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-wdbc-145878-7430", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.00434604560248554, "maxdepth": 14, "minbucket": 3, "minsplit": 12}}}], "metrics": 0.942004, "context": "openml-wdbc-145878", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-wdbc-145878-8598", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0043020813561975985, "maxdepth": 20, "minbucket": 6, "minsplit": 13}}}], "metrics": 0.938489, "context": "openml-wdbc-145878", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-wdbc-145878-8744", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.013817794558033301, "maxdepth": 12, "minbucket": 4, "minsplit": 6}}}], "metrics": 0.938489, "context": "openml-wdbc-145878", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-wdbc-145878-1352", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.013006241696327896, "maxdepth": 17, "minbucket": 2, "minsplit": 4}}}], "metrics": 0.938489, "context": "openml-wdbc-145878", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-hill-valley-145847-6719", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.00295368273034692, "maxdepth": 21, "minbucket": 16, "minsplit": 13}}}], "metrics": 0.570132, "context": "openml-hill-valley-145847", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-hill-valley-145847-2019", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0031851266346871895, "maxdepth": 17, "minbucket": 15, "minsplit": 54}}}], "metrics": 0.565182, "context": "openml-hill-valley-145847", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-hill-valley-145847-3686", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.000486930070817471, "maxdepth": 26, "minbucket": 7, "minsplit": 58}}}], "metrics": 0.564356, "context": "openml-hill-valley-145847", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-hill-valley-145847-3594", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.006244728977233171, "maxdepth": 26, "minbucket": 8, "minsplit": 7}}}], "metrics": 0.562706, "context": "openml-hill-valley-145847", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-hill-valley-145847-9767", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.003958598181977868, "maxdepth": 29, "minbucket": 17, "minsplit": 5}}}], "metrics": 0.561881, "context": "openml-hill-valley-145847", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-steel-plates-fault-9967-1974", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.013291208243370097, "maxdepth": 8, "minbucket": 6, "minsplit": 16}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-steel-plates-fault-9967-6452", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0021953027997165904, "maxdepth": 9, "minbucket": 1, "minsplit": 36}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-steel-plates-fault-9967-5349", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.015716769203916212, "maxdepth": 16, "minbucket": 34, "minsplit": 27}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-steel-plates-fault-9967-551", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0288030641920865, "maxdepth": 26, "minbucket": 23, "minsplit": 31}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-steel-plates-fault-9967-8463", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.04820222098603835, "maxdepth": 16, "minbucket": 1, "minsplit": 22}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-electricity-219-10582", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0004668870776891712, "maxdepth": 19, "minbucket": 34, "minsplit": 47}}}], "metrics": 0.85388, "context": "openml-electricity-219", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-electricity-219-595", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.00043148331567645115, "maxdepth": 29, "minbucket": 45, "minsplit": 29}}}], "metrics": 0.84823, "context": "openml-electricity-219", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-electricity-219-5548", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.00013911624662578119, "maxdepth": 13, "minbucket": 45, "minsplit": 28}}}], "metrics": 0.842205, "context": "openml-electricity-219", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-electricity-219-4430", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0008218825630843637, "maxdepth": 27, "minbucket": 1, "minsplit": 42}}}], "metrics": 0.841874, "context": "openml-electricity-219", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-electricity-219-7655", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0006841120146214959, "maxdepth": 28, "minbucket": 48, "minsplit": 8}}}], "metrics": 0.841433, "context": "openml-electricity-219", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-eeg-eye-state-14951-7934", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.00043810897730290905, "maxdepth": 24, "minbucket": 8, "minsplit": 37}}}], "metrics": 0.8247, "context": "openml-eeg-eye-state-14951", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-eeg-eye-state-14951-266", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0006496346857398749, "maxdepth": 16, "minbucket": 2, "minsplit": 49}}}], "metrics": 0.819626, "context": "openml-eeg-eye-state-14951", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-eeg-eye-state-14951-1732", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.00032750115022063287, "maxdepth": 20, "minbucket": 13, "minsplit": 56}}}], "metrics": 0.814152, "context": "openml-eeg-eye-state-14951", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-eeg-eye-state-14951-2206", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0010841299615800383, "maxdepth": 17, "minbucket": 26, "minsplit": 12}}}], "metrics": 0.805207, "context": "openml-eeg-eye-state-14951", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-eeg-eye-state-14951-11932", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0011501143988221902, "maxdepth": 24, "minbucket": 19, "minsplit": 10}}}], "metrics": 0.805207, "context": "openml-eeg-eye-state-14951", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-diabetes-37-8141", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.013459448406845296, "maxdepth": 22, "minbucket": 28, "minsplit": 2}}}], "metrics": 0.765625, "context": "openml-diabetes-37", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-diabetes-37-6967", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.007374551317095762, "maxdepth": 5, "minbucket": 14, "minsplit": 44}}}], "metrics": 0.764323, "context": "openml-diabetes-37", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-diabetes-37-10417", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.011791224062815304, "maxdepth": 8, "minbucket": 43, "minsplit": 43}}}], "metrics": 0.764323, "context": "openml-diabetes-37", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-diabetes-37-4507", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.009972162481769917, "maxdepth": 24, "minbucket": 45, "minsplit": 56}}}], "metrics": 0.764323, "context": "openml-diabetes-37", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-diabetes-37-8103", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.011871833756938599, "maxdepth": 15, "minbucket": 43, "minsplit": 16}}}], "metrics": 0.764323, "context": "openml-diabetes-37", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-steel-plates-fault-145872-1771", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.015960804589465305, "maxdepth": 8, "minbucket": 13, "minsplit": 41}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-steel-plates-fault-145872-1505", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.05574732034690678, "maxdepth": 6, "minbucket": 20, "minsplit": 34}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-steel-plates-fault-145872-1528", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0575640554841608, "maxdepth": 20, "minbucket": 13, "minsplit": 25}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-steel-plates-fault-145872-11112", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.010523281928524395, "maxdepth": 12, "minbucket": 12, "minsplit": 9}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-steel-plates-fault-145872-7060", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.006579777628555889, "maxdepth": 13, "minbucket": 24, "minsplit": 38}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-scene-3485-8601", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.024017978396639206, "maxdepth": 12, "minbucket": 13, "minsplit": 35}}}], "metrics": 0.9543, "context": "openml-scene-3485", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-scene-3485-7532", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.017105322733893997, "maxdepth": 18, "minbucket": 7, "minsplit": 14}}}], "metrics": 0.9543, "context": "openml-scene-3485", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-scene-3485-10287", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.030002778565883573, "maxdepth": 24, "minbucket": 2, "minsplit": 15}}}], "metrics": 0.9543, "context": "openml-scene-3485", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-scene-3485-10280", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.02143291284553711, "maxdepth": 23, "minbucket": 9, "minsplit": 46}}}], "metrics": 0.9543, "context": "openml-scene-3485", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-scene-3485-7579", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.02548307779468599, "maxdepth": 20, "minbucket": 4, "minsplit": 44}}}], "metrics": 0.9543, "context": "openml-scene-3485", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-sylva-agnostic-3889-11022", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0023263603750616293, "maxdepth": 9, "minbucket": 7, "minsplit": 11}}}], "metrics": 0.991247, "context": "openml-sylva-agnostic-3889", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-sylva-agnostic-3889-4780", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.001981910255178809, "maxdepth": 25, "minbucket": 8, "minsplit": 14}}}], "metrics": 0.991177, "context": "openml-sylva-agnostic-3889", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-sylva-agnostic-3889-274", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0020629541784524894, "maxdepth": 5, "minbucket": 5, "minsplit": 12}}}], "metrics": 0.990969, "context": "openml-sylva-agnostic-3889", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-sylva-agnostic-3889-8314", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0014770873192697796, "maxdepth": 14, "minbucket": 7, "minsplit": 1}}}], "metrics": 0.990969, "context": "openml-sylva-agnostic-3889", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-sylva-agnostic-3889-1864", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.00040389172025024906, "maxdepth": 28, "minbucket": 1, "minsplit": 55}}}], "metrics": 0.990761, "context": "openml-sylva-agnostic-3889", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-kr-vs-kp-3-8144", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0011228115133941196, "maxdepth": 30, "minbucket": 2, "minsplit": 27}}}], "metrics": 0.987484, "context": "openml-kr-vs-kp-3", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-kr-vs-kp-3-4857", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0017499073244631295, "maxdepth": 10, "minbucket": 3, "minsplit": 15}}}], "metrics": 0.985294, "context": "openml-kr-vs-kp-3", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-kr-vs-kp-3-2254", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0024614021483808806, "maxdepth": 19, "minbucket": 5, "minsplit": 18}}}], "metrics": 0.981227, "context": "openml-kr-vs-kp-3", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-kr-vs-kp-3-493", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0035503045026212894, "maxdepth": 30, "minbucket": 3, "minsplit": 15}}}], "metrics": 0.977159, "context": "openml-kr-vs-kp-3", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-kr-vs-kp-3-2903", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.00045890727303922213, "maxdepth": 17, "minbucket": 22, "minsplit": 47}}}], "metrics": 0.974656, "context": "openml-kr-vs-kp-3", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-monks-problems-1-3492-11018", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.007561801636964082, "maxdepth": 29, "minbucket": 5, "minsplit": 13}}}], "metrics": 0.895683, "context": "openml-monks-problems-1-3492", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-monks-problems-1-3492-526", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0107688204687089, "maxdepth": 13, "minbucket": 6, "minsplit": 8}}}], "metrics": 0.893885, "context": "openml-monks-problems-1-3492", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-monks-problems-1-3492-4124", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.01108049338907, "maxdepth": 8, "minbucket": 7, "minsplit": 14}}}], "metrics": 0.892086, "context": "openml-monks-problems-1-3492", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-monks-problems-1-3492-13260", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.010282740632444595, "maxdepth": 8, "minbucket": 5, "minsplit": 17}}}], "metrics": 0.888489, "context": "openml-monks-problems-1-3492", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-monks-problems-1-3492-5067", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.010367928009852805, "maxdepth": 7, "minbucket": 2, "minsplit": 6}}}], "metrics": 0.881295, "context": "openml-monks-problems-1-3492", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-banknote-authentication-145834-3345", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0009826162666082383, "maxdepth": 15, "minbucket": 1, "minsplit": 16}}}], "metrics": 0.985423, "context": "openml-banknote-authentication-145834", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-banknote-authentication-145834-2278", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0049630097880959505, "maxdepth": 19, "minbucket": 5, "minsplit": 8}}}], "metrics": 0.98105, "context": "openml-banknote-authentication-145834", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-banknote-authentication-145834-11963", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.00488679640218616, "maxdepth": 14, "minbucket": 1, "minsplit": 30}}}], "metrics": 0.98105, "context": "openml-banknote-authentication-145834", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-banknote-authentication-145834-4575", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0003732779830694199, "maxdepth": 26, "minbucket": 2, "minsplit": 27}}}], "metrics": 0.98105, "context": "openml-banknote-authentication-145834", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-banknote-authentication-145834-7852", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.00583307927697897, "maxdepth": 17, "minbucket": 9, "minsplit": 7}}}], "metrics": 0.980321, "context": "openml-banknote-authentication-145834", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-climate-model-simulation-crashes-9980-14891", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.427030609857664, "maxdepth": 29, "minbucket": 14, "minsplit": 45}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-9980", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-climate-model-simulation-crashes-9980-5070", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.6958906074821946, "maxdepth": 22, "minbucket": 10, "minsplit": 39}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-9980", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-climate-model-simulation-crashes-9980-5099", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.750873816136643, "maxdepth": 1, "minbucket": 55, "minsplit": 50}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-9980", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-climate-model-simulation-crashes-9980-5098", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.8478129370439802, "maxdepth": 20, "minbucket": 28, "minsplit": 55}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-9980", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-climate-model-simulation-crashes-9980-5097", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.7737622348893433, "maxdepth": 13, "minbucket": 6, "minsplit": 49}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-9980", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-pc1-3918-3585", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.03988974628262219, "maxdepth": 21, "minbucket": 23, "minsplit": 21}}}], "metrics": 0.93147, "context": "openml-pc1-3918", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-pc1-3918-12075", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.02936446148194372, "maxdepth": 9, "minbucket": 23, "minsplit": 11}}}], "metrics": 0.93147, "context": "openml-pc1-3918", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-pc1-3918-13517", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.014163537120819103, "maxdepth": 2, "minbucket": 6, "minsplit": 16}}}], "metrics": 0.93147, "context": "openml-pc1-3918", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-pc1-3918-5408", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.8154244615532464, "maxdepth": 8, "minbucket": 34, "minsplit": 11}}}], "metrics": 0.930568, "context": "openml-pc1-3918", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-pc1-3918-5420", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.33025871723182504, "maxdepth": 10, "minbucket": 2, "minsplit": 40}}}], "metrics": 0.930568, "context": "openml-pc1-3918", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-monks-problems-3-3494-13197", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.012115186483040505, "maxdepth": 29, "minbucket": 1, "minsplit": 22}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-monks-problems-3-3494-2989", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.01963828264959161, "maxdepth": 24, "minbucket": 4, "minsplit": 25}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-monks-problems-3-3494-10700", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.008137667255848652, "maxdepth": 27, "minbucket": 2, "minsplit": 8}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-monks-problems-3-3494-5943", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.00592219008356333, "maxdepth": 27, "minbucket": 2, "minsplit": 34}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-monks-problems-3-3494-3683", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.012382200623303708, "maxdepth": 24, "minbucket": 3, "minsplit": 10}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-mozilla4-3899-1988", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.000547034602984786, "maxdepth": 26, "minbucket": 1, "minsplit": 51}}}], "metrics": 0.946542, "context": "openml-mozilla4-3899", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-mozilla4-3899-9864", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0006406262353062632, "maxdepth": 10, "minbucket": 9, "minsplit": 49}}}], "metrics": 0.945899, "context": "openml-mozilla4-3899", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-mozilla4-3899-427", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0007021023727953433, "maxdepth": 14, "minbucket": 26, "minsplit": 48}}}], "metrics": 0.94532, "context": "openml-mozilla4-3899", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-mozilla4-3899-10369", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0005890358541160819, "maxdepth": 8, "minbucket": 25, "minsplit": 38}}}], "metrics": 0.94532, "context": "openml-mozilla4-3899", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-mozilla4-3899-8296", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.00046618602462112914, "maxdepth": 10, "minbucket": 21, "minsplit": 5}}}], "metrics": 0.945191, "context": "openml-mozilla4-3899", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-pc4-3902-4371", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0280413633979857, "maxdepth": 15, "minbucket": 19, "minsplit": 3}}}], "metrics": 0.902606, "context": "openml-pc4-3902", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-pc4-3902-11822", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.009120683122798798, "maxdepth": 3, "minbucket": 19, "minsplit": 35}}}], "metrics": 0.902606, "context": "openml-pc4-3902", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-pc4-3902-13480", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.04727406886629759, "maxdepth": 12, "minbucket": 19, "minsplit": 56}}}], "metrics": 0.902606, "context": "openml-pc4-3902", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-pc4-3902-5100", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.027619620489329113, "maxdepth": 18, "minbucket": 19, "minsplit": 49}}}], "metrics": 0.902606, "context": "openml-pc4-3902", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-pc4-3902-14366", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.03005548909530042, "maxdepth": 20, "minbucket": 19, "minsplit": 25}}}], "metrics": 0.902606, "context": "openml-pc4-3902", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-wdbc-9946-1451", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.006684319286048412, "maxdepth": 8, "minbucket": 3, "minsplit": 5}}}], "metrics": 0.943761, "context": "openml-wdbc-9946", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-wdbc-9946-9005", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0045365124776959405, "maxdepth": 25, "minbucket": 6, "minsplit": 3}}}], "metrics": 0.940246, "context": "openml-wdbc-9946", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-wdbc-9946-11954", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0022592115517705695, "maxdepth": 18, "minbucket": 5, "minsplit": 12}}}], "metrics": 0.940246, "context": "openml-wdbc-9946", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-wdbc-9946-4566", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.013289674820750996, "maxdepth": 14, "minbucket": 2, "minsplit": 4}}}], "metrics": 0.938489, "context": "openml-wdbc-9946", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-wdbc-9946-819", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0014046655803918806, "maxdepth": 20, "minbucket": 7, "minsplit": 11}}}], "metrics": 0.938489, "context": "openml-wdbc-9946", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-ilpd-9971-16936", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.054141210096329495, "maxdepth": 26, "minbucket": 30, "minsplit": 24}}}], "metrics": 0.713551, "context": "openml-ilpd-9971", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-ilpd-9971-5720", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.42232076561301923, "maxdepth": 6, "minbucket": 44, "minsplit": 11}}}], "metrics": 0.713551, "context": "openml-ilpd-9971", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-ilpd-9971-5751", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.7752773842610422, "maxdepth": 29, "minbucket": 7, "minsplit": 36}}}], "metrics": 0.713551, "context": "openml-ilpd-9971", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-ilpd-9971-5750", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.15668190776593993, "maxdepth": 27, "minbucket": 33, "minsplit": 43}}}], "metrics": 0.713551, "context": "openml-ilpd-9971", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-ilpd-9971-5749", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.6414229978643364, "maxdepth": 21, "minbucket": 47, "minsplit": 49}}}], "metrics": 0.713551, "context": "openml-ilpd-9971", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-qsar-biodeg-9957-6088", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.00430472561381757, "maxdepth": 30, "minbucket": 2, "minsplit": 1}}}], "metrics": 0.825592, "context": "openml-qsar-biodeg-9957", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-qsar-biodeg-9957-890", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.007554599486663939, "maxdepth": 25, "minbucket": 2, "minsplit": 46}}}], "metrics": 0.822749, "context": "openml-qsar-biodeg-9957", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-qsar-biodeg-9957-7449", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.00179911608099937, "maxdepth": 16, "minbucket": 14, "minsplit": 43}}}], "metrics": 0.821801, "context": "openml-qsar-biodeg-9957", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-qsar-biodeg-9957-14545", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0113179294228554, "maxdepth": 8, "minbucket": 1, "minsplit": 21}}}], "metrics": 0.820853, "context": "openml-qsar-biodeg-9957", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-qsar-biodeg-9957-7532", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.009923743486776947, "maxdepth": 23, "minbucket": 1, "minsplit": 26}}}], "metrics": 0.820853, "context": "openml-qsar-biodeg-9957", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-hill-valley-9970-4524", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0039034305907785917, "maxdepth": 22, "minbucket": 16, "minsplit": 15}}}], "metrics": 0.576733, "context": "openml-hill-valley-9970", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-hill-valley-9970-2452", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.00386152922399342, "maxdepth": 26, "minbucket": 9, "minsplit": 12}}}], "metrics": 0.566832, "context": "openml-hill-valley-9970", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-hill-valley-9970-13301", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0016502129681408395, "maxdepth": 12, "minbucket": 17, "minsplit": 9}}}], "metrics": 0.566007, "context": "openml-hill-valley-9970", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-hill-valley-9970-16031", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.004590511259064078, "maxdepth": 21, "minbucket": 13, "minsplit": 23}}}], "metrics": 0.562706, "context": "openml-hill-valley-9970", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-hill-valley-9970-2459", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.00458464718647301, "maxdepth": 30, "minbucket": 1, "minsplit": 47}}}], "metrics": 0.561881, "context": "openml-hill-valley-9970", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-ada-agnostic-3896-14944", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.005576042162626981, "maxdepth": 7, "minbucket": 2, "minsplit": 38}}}], "metrics": 0.848531, "context": "openml-ada-agnostic-3896", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-ada-agnostic-3896-12734", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.005339316960796709, "maxdepth": 18, "minbucket": 3, "minsplit": 20}}}], "metrics": 0.848531, "context": "openml-ada-agnostic-3896", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-ada-agnostic-3896-7112", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.005736672256514429, "maxdepth": 7, "minbucket": 2, "minsplit": 49}}}], "metrics": 0.848093, "context": "openml-ada-agnostic-3896", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-ada-agnostic-3896-11771", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.00398965103775263, "maxdepth": 5, "minbucket": 39, "minsplit": 60}}}], "metrics": 0.846997, "context": "openml-ada-agnostic-3896", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-ada-agnostic-3896-17578", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.005323557585850362, "maxdepth": 12, "minbucket": 7, "minsplit": 59}}}], "metrics": 0.846997, "context": "openml-ada-agnostic-3896", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-eeg-eye-state-9983-6538", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.00014534120671451102, "maxdepth": 16, "minbucket": 6, "minsplit": 22}}}], "metrics": 0.82984, "context": "openml-eeg-eye-state-9983", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-eeg-eye-state-9983-6726", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0009154788520187139, "maxdepth": 29, "minbucket": 13, "minsplit": 37}}}], "metrics": 0.814953, "context": "openml-eeg-eye-state-9983", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-eeg-eye-state-9983-487", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0005148613661527628, "maxdepth": 13, "minbucket": 16, "minsplit": 17}}}], "metrics": 0.813418, "context": "openml-eeg-eye-state-9983", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-eeg-eye-state-9983-15761", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.00011657451502978804, "maxdepth": 20, "minbucket": 28, "minsplit": 5}}}], "metrics": 0.806008, "context": "openml-eeg-eye-state-9983", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-eeg-eye-state-9983-5117", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0012619448196142904, "maxdepth": 14, "minbucket": 14, "minsplit": 5}}}], "metrics": 0.805674, "context": "openml-eeg-eye-state-9983", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-climate-model-simulation-crashes-145839-3167", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.0081357794649899, "maxdepth": 29, "minbucket": 43, "minsplit": 27}}}], "metrics": 0.918519, "context": "openml-climate-model-simulation-crashes-145839", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-climate-model-simulation-crashes-145839-19917", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.3583120756618682, "maxdepth": 17, "minbucket": 54, "minsplit": 4}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-145839", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-climate-model-simulation-crashes-145839-6808", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.9037184286233046, "maxdepth": 24, "minbucket": 52, "minsplit": 51}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-145839", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-climate-model-simulation-crashes-145839-6801", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.6409341368660324, "maxdepth": 30, "minbucket": 38, "minsplit": 31}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-145839", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5636-openml-climate-model-simulation-crashes-145839-6802", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5636", "config": {"cp": 0.3812686448752879, "maxdepth": 11, "minbucket": 57, "minsplit": 28}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-145839", "schema": "rpart-5636", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-ozone-level-8hr-9978-010", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.02766618591956789, "maxdepth": 30, "minbucket": 39, "minsplit": 23}}}], "metrics": 0.937253, "context": "openml-ozone-level-8hr-9978", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-ozone-level-8hr-9978-017", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.5684872427325697, "maxdepth": 8, "minbucket": 43, "minsplit": 26}}}], "metrics": 0.936859, "context": "openml-ozone-level-8hr-9978", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-ozone-level-8hr-9978-008", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.6069739765323697, "maxdepth": 17, "minbucket": 39, "minsplit": 31}}}], "metrics": 0.936859, "context": "openml-ozone-level-8hr-9978", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-ozone-level-8hr-9978-002", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.07047386531010275, "maxdepth": 12, "minbucket": 55, "minsplit": 6}}}], "metrics": 0.936859, "context": "openml-ozone-level-8hr-9978", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-ozone-level-8hr-9978-003", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.10602103307135405, "maxdepth": 5, "minbucket": 19, "minsplit": 31}}}], "metrics": 0.936859, "context": "openml-ozone-level-8hr-9978", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-haberman-272-041", "modules": [{"role": "dataset", "module": "openml-haberman-272"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.045077256329730205, "maxdepth": 9, "minbucket": 54, "minsplit": 37}}}], "metrics": 0.73, "context": "openml-haberman-272", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-haberman-272-020", "modules": [{"role": "dataset", "module": "openml-haberman-272"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.9262013551149512, "maxdepth": 13, "minbucket": 23, "minsplit": 49}}}], "metrics": 0.73, "context": "openml-haberman-272", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-haberman-272-018", "modules": [{"role": "dataset", "module": "openml-haberman-272"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.19321599060893122, "maxdepth": 27, "minbucket": 52, "minsplit": 36}}}], "metrics": 0.73, "context": "openml-haberman-272", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-haberman-272-017", "modules": [{"role": "dataset", "module": "openml-haberman-272"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.06975730991214507, "maxdepth": 20, "minbucket": 24, "minsplit": 2}}}], "metrics": 0.73, "context": "openml-haberman-272", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-haberman-272-016", "modules": [{"role": "dataset", "module": "openml-haberman-272"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.3978046031504867, "maxdepth": 4, "minbucket": 32, "minsplit": 5}}}], "metrics": 0.73, "context": "openml-haberman-272", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-heart-statlog-282-052", "modules": [{"role": "dataset", "module": "openml-heart-statlog-282"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.40956809318847975, "maxdepth": 7, "minbucket": 36, "minsplit": 18}}}], "metrics": 0.741573, "context": "openml-heart-statlog-282", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-heart-statlog-282-033", "modules": [{"role": "dataset", "module": "openml-heart-statlog-282"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.37578061519414224, "maxdepth": 8, "minbucket": 26, "minsplit": 46}}}], "metrics": 0.741573, "context": "openml-heart-statlog-282", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-heart-statlog-282-002", "modules": [{"role": "dataset", "module": "openml-heart-statlog-282"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.019717995945736803, "maxdepth": 17, "minbucket": 44, "minsplit": 28}}}], "metrics": 0.741573, "context": "openml-heart-statlog-282", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-heart-statlog-282-009", "modules": [{"role": "dataset", "module": "openml-heart-statlog-282"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.4541138647425919, "maxdepth": 11, "minbucket": 60, "minsplit": 25}}}], "metrics": 0.741573, "context": "openml-heart-statlog-282", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-heart-statlog-282-010", "modules": [{"role": "dataset", "module": "openml-heart-statlog-282"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.31826289713606215, "maxdepth": 26, "minbucket": 46, "minsplit": 28}}}], "metrics": 0.741573, "context": "openml-heart-statlog-282", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-nomao-145854-012", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0165132432546467, "maxdepth": 28, "minbucket": 60, "minsplit": 29}}}], "metrics": 0.914899, "context": "openml-nomao-145854", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-nomao-145854-040", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.10071955242417797, "maxdepth": 11, "minbucket": 33, "minsplit": 5}}}], "metrics": 0.899057, "context": "openml-nomao-145854", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-nomao-145854-042", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.055899271212890664, "maxdepth": 4, "minbucket": 2, "minsplit": 6}}}], "metrics": 0.899057, "context": "openml-nomao-145854", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-nomao-145854-041", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.11450432653762398, "maxdepth": 5, "minbucket": 49, "minsplit": 28}}}], "metrics": 0.899057, "context": "openml-nomao-145854", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-nomao-145854-018", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.14730193436369293, "maxdepth": 16, "minbucket": 2, "minsplit": 4}}}], "metrics": 0.899057, "context": "openml-nomao-145854", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-spambase-43-267", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.005740840390697118, "maxdepth": 28, "minbucket": 14, "minsplit": 51}}}], "metrics": 0.899804, "context": "openml-spambase-43", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-spambase-43-069", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.010481764499470594, "maxdepth": 25, "minbucket": 7, "minsplit": 21}}}], "metrics": 0.894153, "context": "openml-spambase-43", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-spambase-43-193", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.005254106765985491, "maxdepth": 14, "minbucket": 46, "minsplit": 29}}}], "metrics": 0.89198, "context": "openml-spambase-43", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-spambase-43-184", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.016035480827465684, "maxdepth": 26, "minbucket": 6, "minsplit": 11}}}], "metrics": 0.890024, "context": "openml-spambase-43", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-spambase-43-044", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.007546381263434889, "maxdepth": 3, "minbucket": 55, "minsplit": 19}}}], "metrics": 0.870898, "context": "openml-spambase-43", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-musk-146082-483", "modules": [{"role": "dataset", "module": "openml-musk-146082"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.049140415557101406, "maxdepth": 4, "minbucket": 54, "minsplit": 38}}}], "metrics": 0.999697, "context": "openml-musk-146082", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-musk-146082-121", "modules": [{"role": "dataset", "module": "openml-musk-146082"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.026875620644912113, "maxdepth": 5, "minbucket": 16, "minsplit": 8}}}], "metrics": 0.999697, "context": "openml-musk-146082", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-musk-146082-153", "modules": [{"role": "dataset", "module": "openml-musk-146082"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.713186502626538, "maxdepth": 14, "minbucket": 38, "minsplit": 56}}}], "metrics": 0.999697, "context": "openml-musk-146082", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-musk-146082-154", "modules": [{"role": "dataset", "module": "openml-musk-146082"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.2234445891179141, "maxdepth": 7, "minbucket": 46, "minsplit": 54}}}], "metrics": 0.999697, "context": "openml-musk-146082", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-musk-146082-155", "modules": [{"role": "dataset", "module": "openml-musk-146082"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.9396564978476609, "maxdepth": 19, "minbucket": 8, "minsplit": 49}}}], "metrics": 0.999697, "context": "openml-musk-146082", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-madelon-145853-475", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.004560919182747599, "maxdepth": 13, "minbucket": 11, "minsplit": 40}}}], "metrics": 0.795385, "context": "openml-madelon-145853", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-madelon-145853-335", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.003955047514662151, "maxdepth": 15, "minbucket": 23, "minsplit": 46}}}], "metrics": 0.791923, "context": "openml-madelon-145853", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-madelon-145853-158", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.008194025775790207, "maxdepth": 24, "minbucket": 7, "minsplit": 14}}}], "metrics": 0.786154, "context": "openml-madelon-145853", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-madelon-145853-026", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.009486935504153367, "maxdepth": 15, "minbucket": 6, "minsplit": 5}}}], "metrics": 0.775385, "context": "openml-madelon-145853", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-madelon-145853-207", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.003645263083651661, "maxdepth": 16, "minbucket": 54, "minsplit": 28}}}], "metrics": 0.771923, "context": "openml-madelon-145853", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-credit-g-145972-214", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.021171085007861298, "maxdepth": 19, "minbucket": 4, "minsplit": 30}}}], "metrics": 0.745, "context": "openml-credit-g-145972", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-credit-g-145972-375", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.015242296208068698, "maxdepth": 8, "minbucket": 5, "minsplit": 43}}}], "metrics": 0.744, "context": "openml-credit-g-145972", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-credit-g-145972-179", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0022707112900912795, "maxdepth": 7, "minbucket": 47, "minsplit": 3}}}], "metrics": 0.744, "context": "openml-credit-g-145972", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-credit-g-145972-236", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.012910868909582493, "maxdepth": 12, "minbucket": 12, "minsplit": 40}}}], "metrics": 0.742, "context": "openml-credit-g-145972", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-credit-g-145972-320", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.009126282699778675, "maxdepth": 15, "minbucket": 48, "minsplit": 54}}}], "metrics": 0.741, "context": "openml-credit-g-145972", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-monks-problems-3-146066-069", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.022724531295150497, "maxdepth": 4, "minbucket": 3, "minsplit": 23}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-monks-problems-3-146066-241", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.016939161515235893, "maxdepth": 14, "minbucket": 7, "minsplit": 17}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-monks-problems-3-146066-470", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.026751944965124105, "maxdepth": 3, "minbucket": 7, "minsplit": 29}}}], "metrics": 0.967509, "context": "openml-monks-problems-3-146066", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-monks-problems-3-146066-493", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.12071192817054706, "maxdepth": 14, "minbucket": 57, "minsplit": 7}}}], "metrics": 0.963899, "context": "openml-monks-problems-3-146066", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-monks-problems-3-146066-080", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.12988621548972995, "maxdepth": 6, "minbucket": 30, "minsplit": 9}}}], "metrics": 0.963899, "context": "openml-monks-problems-3-146066", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-bioresponse-145677-077", "modules": [{"role": "dataset", "module": "openml-bioresponse-145677"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.007865818154439331, "maxdepth": 8, "minbucket": 2, "minsplit": 57}}}], "metrics": 0.760331, "context": "openml-bioresponse-145677", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-bioresponse-145677-207", "modules": [{"role": "dataset", "module": "openml-bioresponse-145677"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.013746248728036887, "maxdepth": 16, "minbucket": 46, "minsplit": 4}}}], "metrics": 0.759264, "context": "openml-bioresponse-145677", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-bioresponse-145677-370", "modules": [{"role": "dataset", "module": "openml-bioresponse-145677"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.019130235242098604, "maxdepth": 25, "minbucket": 8, "minsplit": 50}}}], "metrics": 0.759264, "context": "openml-bioresponse-145677", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-bioresponse-145677-126", "modules": [{"role": "dataset", "module": "openml-bioresponse-145677"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.017057592684775608, "maxdepth": 8, "minbucket": 34, "minsplit": 14}}}], "metrics": 0.759264, "context": "openml-bioresponse-145677", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-bioresponse-145677-185", "modules": [{"role": "dataset", "module": "openml-bioresponse-145677"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.013137771685048899, "maxdepth": 17, "minbucket": 35, "minsplit": 23}}}], "metrics": 0.759264, "context": "openml-bioresponse-145677", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-banknote-authentication-145834-424", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.010655465240031498, "maxdepth": 27, "minbucket": 5, "minsplit": 35}}}], "metrics": 0.956997, "context": "openml-banknote-authentication-145834", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-banknote-authentication-145834-380", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.00251809524595737, "maxdepth": 24, "minbucket": 24, "minsplit": 38}}}], "metrics": 0.944606, "context": "openml-banknote-authentication-145834", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-banknote-authentication-145834-003", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0161757231060416, "maxdepth": 14, "minbucket": 16, "minsplit": 11}}}], "metrics": 0.940233, "context": "openml-banknote-authentication-145834", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-banknote-authentication-145834-267", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.014432807855680605, "maxdepth": 24, "minbucket": 24, "minsplit": 41}}}], "metrics": 0.939504, "context": "openml-banknote-authentication-145834", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-banknote-authentication-145834-059", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.006040546980127689, "maxdepth": 16, "minbucket": 29, "minsplit": 44}}}], "metrics": 0.936589, "context": "openml-banknote-authentication-145834", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-steel-plates-fault-145872-070", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.024395066948980092, "maxdepth": 26, "minbucket": 7, "minsplit": 8}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-steel-plates-fault-145872-482", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.008142560191825033, "maxdepth": 8, "minbucket": 34, "minsplit": 58}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-steel-plates-fault-145872-270", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.04636876511611043, "maxdepth": 24, "minbucket": 42, "minsplit": 21}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-steel-plates-fault-145872-208", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.018156167522445303, "maxdepth": 13, "minbucket": 25, "minsplit": 42}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-steel-plates-fault-145872-054", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.00125076499059796, "maxdepth": 23, "minbucket": 12, "minsplit": 39}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-qsar-biodeg-145862-303", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0117852682549506, "maxdepth": 5, "minbucket": 5, "minsplit": 22}}}], "metrics": 0.818957, "context": "openml-qsar-biodeg-145862", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-qsar-biodeg-145862-290", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.005676818715780971, "maxdepth": 7, "minbucket": 10, "minsplit": 44}}}], "metrics": 0.814218, "context": "openml-qsar-biodeg-145862", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-qsar-biodeg-145862-063", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.014376694273576102, "maxdepth": 26, "minbucket": 3, "minsplit": 39}}}], "metrics": 0.81327, "context": "openml-qsar-biodeg-145862", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-qsar-biodeg-145862-261", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.009071369359642272, "maxdepth": 21, "minbucket": 39, "minsplit": 12}}}], "metrics": 0.811374, "context": "openml-qsar-biodeg-145862", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-qsar-biodeg-145862-400", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.00977094418592751, "maxdepth": 6, "minbucket": 25, "minsplit": 38}}}], "metrics": 0.803791, "context": "openml-qsar-biodeg-145862", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-climate-model-simulation-crashes-145839-520", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.5463396955117581, "maxdepth": 17, "minbucket": 11, "minsplit": 4}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-145839", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-climate-model-simulation-crashes-145839-180", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.07610939925760028, "maxdepth": 3, "minbucket": 38, "minsplit": 20}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-145839", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-climate-model-simulation-crashes-145839-167", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.23985915531627794, "maxdepth": 15, "minbucket": 4, "minsplit": 5}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-145839", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-climate-model-simulation-crashes-145839-168", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.8891840834937985, "maxdepth": 2, "minbucket": 4, "minsplit": 54}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-145839", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-climate-model-simulation-crashes-145839-169", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.4112180705949664, "maxdepth": 4, "minbucket": 43, "minsplit": 31}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-145839", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-scene-3485-228", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0067999837290495585, "maxdepth": 11, "minbucket": 8, "minsplit": 4}}}], "metrics": 0.9543, "context": "openml-scene-3485", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-scene-3485-476", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.011067666516080496, "maxdepth": 30, "minbucket": 2, "minsplit": 58}}}], "metrics": 0.953885, "context": "openml-scene-3485", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-scene-3485-529", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.03705977083407338, "maxdepth": 22, "minbucket": 8, "minsplit": 37}}}], "metrics": 0.953469, "context": "openml-scene-3485", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-scene-3485-059", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.007195006993040439, "maxdepth": 11, "minbucket": 9, "minsplit": 58}}}], "metrics": 0.951807, "context": "openml-scene-3485", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-scene-3485-063", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.044758783590421077, "maxdepth": 19, "minbucket": 13, "minsplit": 27}}}], "metrics": 0.950976, "context": "openml-scene-3485", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-monks-problems-2-146065-306", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-146065"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.006166831760108468, "maxdepth": 19, "minbucket": 3, "minsplit": 20}}}], "metrics": 0.828619, "context": "openml-monks-problems-2-146065", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-monks-problems-2-146065-008", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-146065"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.022576396989077274, "maxdepth": 24, "minbucket": 10, "minsplit": 27}}}], "metrics": 0.767055, "context": "openml-monks-problems-2-146065", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-monks-problems-2-146065-499", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-146065"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.009899151914194227, "maxdepth": 17, "minbucket": 12, "minsplit": 11}}}], "metrics": 0.75208, "context": "openml-monks-problems-2-146065", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-monks-problems-2-146065-567", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-146065"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.02989630557820198, "maxdepth": 28, "minbucket": 10, "minsplit": 6}}}], "metrics": 0.747088, "context": "openml-monks-problems-2-146065", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-monks-problems-2-146065-401", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-146065"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.014688485704734895, "maxdepth": 5, "minbucket": 7, "minsplit": 1}}}], "metrics": 0.703827, "context": "openml-monks-problems-2-146065", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-monks-problems-3-3494-061", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.006498751633241772, "maxdepth": 29, "minbucket": 9, "minsplit": 8}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-monks-problems-3-3494-006", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0053956878207624005, "maxdepth": 13, "minbucket": 5, "minsplit": 30}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-monks-problems-3-3494-188", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.006478007121384141, "maxdepth": 7, "minbucket": 11, "minsplit": 16}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-monks-problems-3-3494-060", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.011314982718229298, "maxdepth": 10, "minbucket": 11, "minsplit": 3}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-monks-problems-3-3494-085", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.024040616985783, "maxdepth": 18, "minbucket": 10, "minsplit": 25}}}], "metrics": 0.983755, "context": "openml-monks-problems-3-3494", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-climate-model-simulation-crashes-9980-693", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.21319190616011605, "maxdepth": 10, "minbucket": 22, "minsplit": 26}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-9980", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-climate-model-simulation-crashes-9980-233", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.17469979513660094, "maxdepth": 6, "minbucket": 53, "minsplit": 18}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-9980", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-climate-model-simulation-crashes-9980-241", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.8701900583062319, "maxdepth": 15, "minbucket": 28, "minsplit": 11}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-9980", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-climate-model-simulation-crashes-9980-240", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.17525942174941295, "maxdepth": 12, "minbucket": 34, "minsplit": 51}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-9980", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-climate-model-simulation-crashes-9980-239", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.5881875273142004, "maxdepth": 28, "minbucket": 50, "minsplit": 19}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-9980", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-wdbc-145878-325", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.01009049469828606, "maxdepth": 4, "minbucket": 6, "minsplit": 4}}}], "metrics": 0.936731, "context": "openml-wdbc-145878", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-wdbc-145878-657", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.01775859080478551, "maxdepth": 16, "minbucket": 4, "minsplit": 16}}}], "metrics": 0.927944, "context": "openml-wdbc-145878", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-wdbc-145878-194", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.004843788158521062, "maxdepth": 11, "minbucket": 5, "minsplit": 23}}}], "metrics": 0.927944, "context": "openml-wdbc-145878", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-wdbc-145878-782", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.008063406620547182, "maxdepth": 7, "minbucket": 9, "minsplit": 25}}}], "metrics": 0.924429, "context": "openml-wdbc-145878", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-wdbc-145878-233", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.017665252492204308, "maxdepth": 15, "minbucket": 17, "minsplit": 40}}}], "metrics": 0.922671, "context": "openml-wdbc-145878", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-hill-valley-9970-196", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0012852581519633497, "maxdepth": 12, "minbucket": 17, "minsplit": 52}}}], "metrics": 0.565182, "context": "openml-hill-valley-9970", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-hill-valley-9970-584", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.004202139500901101, "maxdepth": 18, "minbucket": 2, "minsplit": 56}}}], "metrics": 0.54703, "context": "openml-hill-valley-9970", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-hill-valley-9970-105", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.007937279466912148, "maxdepth": 10, "minbucket": 6, "minsplit": 5}}}], "metrics": 0.523927, "context": "openml-hill-valley-9970", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-hill-valley-9970-405", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.004883152835443622, "maxdepth": 20, "minbucket": 32, "minsplit": 56}}}], "metrics": 0.523927, "context": "openml-hill-valley-9970", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-hill-valley-9970-736", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.005704192148894069, "maxdepth": 15, "minbucket": 51, "minsplit": 3}}}], "metrics": 0.521452, "context": "openml-hill-valley-9970", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-blood-transfusion-service-center-145836-001", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.006438850129395723, "maxdepth": 7, "minbucket": 47, "minsplit": 7}}}], "metrics": 0.791444, "context": "openml-blood-transfusion-service-center-145836", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-blood-transfusion-service-center-145836-273", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0173061214689165, "maxdepth": 9, "minbucket": 52, "minsplit": 24}}}], "metrics": 0.791444, "context": "openml-blood-transfusion-service-center-145836", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-blood-transfusion-service-center-145836-118", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.02064762537591158, "maxdepth": 16, "minbucket": 39, "minsplit": 30}}}], "metrics": 0.791444, "context": "openml-blood-transfusion-service-center-145836", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-blood-transfusion-service-center-145836-131", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0002175350043922661, "maxdepth": 23, "minbucket": 40, "minsplit": 20}}}], "metrics": 0.791444, "context": "openml-blood-transfusion-service-center-145836", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-blood-transfusion-service-center-145836-175", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.029795591889321803, "maxdepth": 30, "minbucket": 58, "minsplit": 21}}}], "metrics": 0.791444, "context": "openml-blood-transfusion-service-center-145836", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-bioresponse-14966-195", "modules": [{"role": "dataset", "module": "openml-bioresponse-14966"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.002408011054992681, "maxdepth": 7, "minbucket": 23, "minsplit": 19}}}], "metrics": 0.767262, "context": "openml-bioresponse-14966", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-bioresponse-14966-740", "modules": [{"role": "dataset", "module": "openml-bioresponse-14966"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.003237000836431981, "maxdepth": 25, "minbucket": 10, "minsplit": 22}}}], "metrics": 0.765396, "context": "openml-bioresponse-14966", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-bioresponse-14966-238", "modules": [{"role": "dataset", "module": "openml-bioresponse-14966"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0038390845827758315, "maxdepth": 19, "minbucket": 19, "minsplit": 58}}}], "metrics": 0.764596, "context": "openml-bioresponse-14966", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-bioresponse-14966-716", "modules": [{"role": "dataset", "module": "openml-bioresponse-14966"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.00583183759115636, "maxdepth": 11, "minbucket": 12, "minsplit": 9}}}], "metrics": 0.762997, "context": "openml-bioresponse-14966", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-bioresponse-14966-511", "modules": [{"role": "dataset", "module": "openml-bioresponse-14966"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.005198436260595923, "maxdepth": 13, "minbucket": 20, "minsplit": 58}}}], "metrics": 0.76273, "context": "openml-bioresponse-14966", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-musk-3950-992", "modules": [{"role": "dataset", "module": "openml-musk-3950"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.6454040984924877, "maxdepth": 8, "minbucket": 40, "minsplit": 15}}}], "metrics": 0.999697, "context": "openml-musk-3950", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-musk-3950-326", "modules": [{"role": "dataset", "module": "openml-musk-3950"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.3966457142330706, "maxdepth": 6, "minbucket": 57, "minsplit": 42}}}], "metrics": 0.999697, "context": "openml-musk-3950", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-musk-3950-339", "modules": [{"role": "dataset", "module": "openml-musk-3950"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.8050620788078762, "maxdepth": 26, "minbucket": 25, "minsplit": 54}}}], "metrics": 0.999697, "context": "openml-musk-3950", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-musk-3950-338", "modules": [{"role": "dataset", "module": "openml-musk-3950"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.07139618595354257, "maxdepth": 30, "minbucket": 37, "minsplit": 10}}}], "metrics": 0.999697, "context": "openml-musk-3950", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-musk-3950-337", "modules": [{"role": "dataset", "module": "openml-musk-3950"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.17239175008833385, "maxdepth": 12, "minbucket": 56, "minsplit": 34}}}], "metrics": 0.999697, "context": "openml-musk-3950", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-click-prediction-small-14971-998", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.47511936135813576, "maxdepth": 3, "minbucket": 22, "minsplit": 46}}}], "metrics": 0.831581, "context": "openml-click-prediction-small-14971", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-click-prediction-small-14971-328", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.9946589085109524, "maxdepth": 24, "minbucket": 38, "minsplit": 53}}}], "metrics": 0.831581, "context": "openml-click-prediction-small-14971", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-click-prediction-small-14971-341", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.3424155157361183, "maxdepth": 22, "minbucket": 17, "minsplit": 4}}}], "metrics": 0.831581, "context": "openml-click-prediction-small-14971", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-click-prediction-small-14971-340", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.5839642800226813, "maxdepth": 24, "minbucket": 7, "minsplit": 27}}}], "metrics": 0.831581, "context": "openml-click-prediction-small-14971", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-click-prediction-small-14971-339", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.2863596097402269, "maxdepth": 17, "minbucket": 28, "minsplit": 18}}}], "metrics": 0.831581, "context": "openml-click-prediction-small-14971", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-monks-problems-1-146064-928", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-146064"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.016224999383464504, "maxdepth": 24, "minbucket": 7, "minsplit": 17}}}], "metrics": 0.868705, "context": "openml-monks-problems-1-146064", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-monks-problems-1-146064-133", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-146064"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.018758860353752987, "maxdepth": 19, "minbucket": 9, "minsplit": 7}}}], "metrics": 0.866906, "context": "openml-monks-problems-1-146064", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-monks-problems-1-146064-300", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-146064"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.022405210120976016, "maxdepth": 17, "minbucket": 7, "minsplit": 1}}}], "metrics": 0.854317, "context": "openml-monks-problems-1-146064", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-monks-problems-1-146064-327", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-146064"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.010883356381580198, "maxdepth": 30, "minbucket": 4, "minsplit": 34}}}], "metrics": 0.836331, "context": "openml-monks-problems-1-146064", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-monks-problems-1-146064-485", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-146064"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.027570065047964512, "maxdepth": 24, "minbucket": 11, "minsplit": 24}}}], "metrics": 0.834532, "context": "openml-monks-problems-1-146064", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-amazon-employee-access-9911-1006", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-9911"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.97836874256134, "maxdepth": 24, "minbucket": 31, "minsplit": 40}}}], "metrics": 0.94211, "context": "openml-amazon-employee-access-9911", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-amazon-employee-access-9911-372", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-9911"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.4120275687262417, "maxdepth": 17, "minbucket": 26, "minsplit": 35}}}], "metrics": 0.94211, "context": "openml-amazon-employee-access-9911", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-amazon-employee-access-9911-387", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-9911"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.7642233627218756, "maxdepth": 18, "minbucket": 9, "minsplit": 36}}}], "metrics": 0.94211, "context": "openml-amazon-employee-access-9911", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-amazon-employee-access-9911-385", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-9911"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.24100416659600965, "maxdepth": 15, "minbucket": 29, "minsplit": 24}}}], "metrics": 0.94211, "context": "openml-amazon-employee-access-9911", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-amazon-employee-access-9911-384", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-9911"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.9832066641490903, "maxdepth": 16, "minbucket": 16, "minsplit": 46}}}], "metrics": 0.94211, "context": "openml-amazon-employee-access-9911", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-ozone-level-8hr-145855-214", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.025905944576859494, "maxdepth": 17, "minbucket": 43, "minsplit": 57}}}], "metrics": 0.937648, "context": "openml-ozone-level-8hr-145855", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-ozone-level-8hr-145855-334", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.032234012784808905, "maxdepth": 11, "minbucket": 36, "minsplit": 15}}}], "metrics": 0.937253, "context": "openml-ozone-level-8hr-145855", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-ozone-level-8hr-145855-1038", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.7575513270519667, "maxdepth": 23, "minbucket": 4, "minsplit": 14}}}], "metrics": 0.936859, "context": "openml-ozone-level-8hr-145855", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-ozone-level-8hr-145855-349", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.7601284467916934, "maxdepth": 3, "minbucket": 10, "minsplit": 5}}}], "metrics": 0.936859, "context": "openml-ozone-level-8hr-145855", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-ozone-level-8hr-145855-361", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.9059494041673845, "maxdepth": 7, "minbucket": 35, "minsplit": 23}}}], "metrics": 0.936859, "context": "openml-ozone-level-8hr-145855", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-blood-transfusion-service-center-10101-908", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.00581305654011667, "maxdepth": 21, "minbucket": 39, "minsplit": 18}}}], "metrics": 0.791444, "context": "openml-blood-transfusion-service-center-10101", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-blood-transfusion-service-center-10101-349", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.03459526918120682, "maxdepth": 6, "minbucket": 57, "minsplit": 13}}}], "metrics": 0.791444, "context": "openml-blood-transfusion-service-center-10101", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-blood-transfusion-service-center-10101-049", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.00632396497055888, "maxdepth": 14, "minbucket": 60, "minsplit": 54}}}], "metrics": 0.791444, "context": "openml-blood-transfusion-service-center-10101", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-blood-transfusion-service-center-10101-576", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0304531116805971, "maxdepth": 3, "minbucket": 57, "minsplit": 49}}}], "metrics": 0.791444, "context": "openml-blood-transfusion-service-center-10101", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-blood-transfusion-service-center-10101-217", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.027818447847291802, "maxdepth": 27, "minbucket": 40, "minsplit": 34}}}], "metrics": 0.791444, "context": "openml-blood-transfusion-service-center-10101", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-pc3-3903-1075", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.9664740613032129, "maxdepth": 1, "minbucket": 47, "minsplit": 32}}}], "metrics": 0.897633, "context": "openml-pc3-3903", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-pc3-3903-357", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.6577589657925071, "maxdepth": 13, "minbucket": 20, "minsplit": 15}}}], "metrics": 0.897633, "context": "openml-pc3-3903", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-pc3-3903-371", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.30789121350496984, "maxdepth": 8, "minbucket": 34, "minsplit": 35}}}], "metrics": 0.897633, "context": "openml-pc3-3903", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-pc3-3903-370", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.8851236341822886, "maxdepth": 11, "minbucket": 2, "minsplit": 4}}}], "metrics": 0.897633, "context": "openml-pc3-3903", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-pc3-3903-369", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.8604391167707739, "maxdepth": 11, "minbucket": 16, "minsplit": 40}}}], "metrics": 0.897633, "context": "openml-pc3-3903", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-pc1-3918-091", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.038817264542356095, "maxdepth": 4, "minbucket": 23, "minsplit": 31}}}], "metrics": 0.93147, "context": "openml-pc1-3918", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-pc1-3918-1078", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.9669979023117566, "maxdepth": 7, "minbucket": 31, "minsplit": 50}}}], "metrics": 0.930568, "context": "openml-pc1-3918", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-pc1-3918-360", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.4144397302832451, "maxdepth": 23, "minbucket": 34, "minsplit": 54}}}], "metrics": 0.930568, "context": "openml-pc1-3918", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-pc1-3918-374", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.8592865072958168, "maxdepth": 1, "minbucket": 20, "minsplit": 48}}}], "metrics": 0.930568, "context": "openml-pc1-3918", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-pc1-3918-373", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.6287515337415036, "maxdepth": 1, "minbucket": 2, "minsplit": 3}}}], "metrics": 0.930568, "context": "openml-pc1-3918", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-steel-plates-fault-9967-226", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.07038751377947634, "maxdepth": 12, "minbucket": 6, "minsplit": 38}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-steel-plates-fault-9967-754", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.009420485172793272, "maxdepth": 8, "minbucket": 25, "minsplit": 20}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-steel-plates-fault-9967-402", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.011187320744991305, "maxdepth": 27, "minbucket": 12, "minsplit": 6}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-steel-plates-fault-9967-188", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0038173535674810412, "maxdepth": 9, "minbucket": 14, "minsplit": 44}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-steel-plates-fault-9967-1020", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.05789539747163646, "maxdepth": 20, "minbucket": 9, "minsplit": 17}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-phishingwebsites-14952-125", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-14952"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.00217804446108639, "maxdepth": 24, "minbucket": 6, "minsplit": 7}}}], "metrics": 0.935323, "context": "openml-phishingwebsites-14952", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-phishingwebsites-14952-476", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-14952"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0017605206765234508, "maxdepth": 7, "minbucket": 1, "minsplit": 51}}}], "metrics": 0.933243, "context": "openml-phishingwebsites-14952", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-phishingwebsites-14952-287", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-14952"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0003488070167601111, "maxdepth": 19, "minbucket": 54, "minsplit": 44}}}], "metrics": 0.931886, "context": "openml-phishingwebsites-14952", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-phishingwebsites-14952-462", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-14952"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.003412428714707489, "maxdepth": 16, "minbucket": 15, "minsplit": 56}}}], "metrics": 0.923835, "context": "openml-phishingwebsites-14952", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-phishingwebsites-14952-702", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-14952"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.004734798504412172, "maxdepth": 14, "minbucket": 38, "minsplit": 33}}}], "metrics": 0.921574, "context": "openml-phishingwebsites-14952", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-wilt-9889-465", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0076250172521919015, "maxdepth": 20, "minbucket": 3, "minsplit": 44}}}], "metrics": 0.980988, "context": "openml-wilt-9889", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-wilt-9889-1002", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.010400392983481296, "maxdepth": 21, "minbucket": 7, "minsplit": 46}}}], "metrics": 0.980368, "context": "openml-wilt-9889", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-wilt-9889-505", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.012440348679572295, "maxdepth": 15, "minbucket": 1, "minsplit": 59}}}], "metrics": 0.977681, "context": "openml-wilt-9889", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-wilt-9889-581", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.01030579412579539, "maxdepth": 17, "minbucket": 14, "minsplit": 52}}}], "metrics": 0.977475, "context": "openml-wilt-9889", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-wilt-9889-395", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.024530358782410572, "maxdepth": 5, "minbucket": 7, "minsplit": 54}}}], "metrics": 0.976441, "context": "openml-wilt-9889", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-monks-problems-1-3492-809", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0180794589057565, "maxdepth": 12, "minbucket": 10, "minsplit": 9}}}], "metrics": 0.857914, "context": "openml-monks-problems-1-3492", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-monks-problems-1-3492-514", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0017524696256965401, "maxdepth": 12, "minbucket": 8, "minsplit": 9}}}], "metrics": 0.857914, "context": "openml-monks-problems-1-3492", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-monks-problems-1-3492-836", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.02428591012246911, "maxdepth": 19, "minbucket": 11, "minsplit": 10}}}], "metrics": 0.848921, "context": "openml-monks-problems-1-3492", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-monks-problems-1-3492-645", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.016657536786422098, "maxdepth": 30, "minbucket": 2, "minsplit": 30}}}], "metrics": 0.839928, "context": "openml-monks-problems-1-3492", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-monks-problems-1-3492-766", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.021117627092078296, "maxdepth": 18, "minbucket": 12, "minsplit": 33}}}], "metrics": 0.836331, "context": "openml-monks-problems-1-3492", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-gina-agnostic-3891-693", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0028771021705120796, "maxdepth": 25, "minbucket": 11, "minsplit": 47}}}], "metrics": 0.876874, "context": "openml-gina-agnostic-3891", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-gina-agnostic-3891-318", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0025409668985754306, "maxdepth": 22, "minbucket": 17, "minsplit": 50}}}], "metrics": 0.875721, "context": "openml-gina-agnostic-3891", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-gina-agnostic-3891-868", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0023493400610983405, "maxdepth": 17, "minbucket": 21, "minsplit": 32}}}], "metrics": 0.8688, "context": "openml-gina-agnostic-3891", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-gina-agnostic-3891-936", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0009871268946677447, "maxdepth": 25, "minbucket": 6, "minsplit": 5}}}], "metrics": 0.868512, "context": "openml-gina-agnostic-3891", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-gina-agnostic-3891-977", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0012721176560968202, "maxdepth": 17, "minbucket": 32, "minsplit": 11}}}], "metrics": 0.863899, "context": "openml-gina-agnostic-3891", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-bank-marketing-145833-781", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0035883359912782893, "maxdepth": 4, "minbucket": 51, "minsplit": 57}}}], "metrics": 0.901993, "context": "openml-bank-marketing-145833", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-bank-marketing-145833-689", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.006785909582301967, "maxdepth": 18, "minbucket": 33, "minsplit": 46}}}], "metrics": 0.90175, "context": "openml-bank-marketing-145833", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-bank-marketing-145833-869", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.005086376035958532, "maxdepth": 8, "minbucket": 55, "minsplit": 7}}}], "metrics": 0.901683, "context": "openml-bank-marketing-145833", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-bank-marketing-145833-1090", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0069897628225386085, "maxdepth": 18, "minbucket": 12, "minsplit": 15}}}], "metrics": 0.901639, "context": "openml-bank-marketing-145833", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-bank-marketing-145833-530", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.008670765145123003, "maxdepth": 28, "minbucket": 46, "minsplit": 6}}}], "metrics": 0.900378, "context": "openml-bank-marketing-145833", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-monks-problems-2-3493-576", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.022219374014437195, "maxdepth": 9, "minbucket": 9, "minsplit": 6}}}], "metrics": 0.777038, "context": "openml-monks-problems-2-3493", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-monks-problems-2-3493-1146", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.015277918598055796, "maxdepth": 10, "minbucket": 4, "minsplit": 40}}}], "metrics": 0.753744, "context": "openml-monks-problems-2-3493", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-monks-problems-2-3493-1213", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.014424629679322194, "maxdepth": 15, "minbucket": 1, "minsplit": 42}}}], "metrics": 0.75208, "context": "openml-monks-problems-2-3493", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-monks-problems-2-3493-198", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.005574843317642809, "maxdepth": 28, "minbucket": 3, "minsplit": 31}}}], "metrics": 0.75208, "context": "openml-monks-problems-2-3493", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-monks-problems-2-3493-371", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.028948126763477897, "maxdepth": 27, "minbucket": 2, "minsplit": 30}}}], "metrics": 0.747088, "context": "openml-monks-problems-2-3493", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-kc1-3917-1196", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.013312492223829001, "maxdepth": 23, "minbucket": 31, "minsplit": 56}}}], "metrics": 0.85633, "context": "openml-kc1-3917", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-kc1-3917-744", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.00846142641492188, "maxdepth": 10, "minbucket": 32, "minsplit": 35}}}], "metrics": 0.854433, "context": "openml-kc1-3917", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-kc1-3917-526", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.013608373405784392, "maxdepth": 7, "minbucket": 22, "minsplit": 18}}}], "metrics": 0.853959, "context": "openml-kc1-3917", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-kc1-3917-1241", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.02714779664054509, "maxdepth": 11, "minbucket": 31, "minsplit": 31}}}], "metrics": 0.853485, "context": "openml-kc1-3917", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-kc1-3917-934", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.02815236447602509, "maxdepth": 5, "minbucket": 33, "minsplit": 16}}}], "metrics": 0.853485, "context": "openml-kc1-3917", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-kr-vs-kp-3-939", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.002192954935505993, "maxdepth": 25, "minbucket": 1, "minsplit": 8}}}], "metrics": 0.982791, "context": "openml-kr-vs-kp-3", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-kr-vs-kp-3-665", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.00187705264650285, "maxdepth": 29, "minbucket": 29, "minsplit": 31}}}], "metrics": 0.969024, "context": "openml-kr-vs-kp-3", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-kr-vs-kp-3-738", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0074108451906591665, "maxdepth": 11, "minbucket": 41, "minsplit": 1}}}], "metrics": 0.968711, "context": "openml-kr-vs-kp-3", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-kr-vs-kp-3-601", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.004073267273977401, "maxdepth": 8, "minbucket": 12, "minsplit": 2}}}], "metrics": 0.968711, "context": "openml-kr-vs-kp-3", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-kr-vs-kp-3-555", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.004036616005375981, "maxdepth": 18, "minbucket": 39, "minsplit": 18}}}], "metrics": 0.968711, "context": "openml-kr-vs-kp-3", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-ilpd-9971-1457", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.43007087095864116, "maxdepth": 28, "minbucket": 2, "minsplit": 4}}}], "metrics": 0.713551, "context": "openml-ilpd-9971", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-ilpd-9971-505", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.7473027202602478, "maxdepth": 11, "minbucket": 24, "minsplit": 55}}}], "metrics": 0.713551, "context": "openml-ilpd-9971", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-ilpd-9971-485", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.7259079466409982, "maxdepth": 12, "minbucket": 10, "minsplit": 58}}}], "metrics": 0.713551, "context": "openml-ilpd-9971", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-ilpd-9971-486", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.9842600193176415, "maxdepth": 15, "minbucket": 20, "minsplit": 18}}}], "metrics": 0.713551, "context": "openml-ilpd-9971", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-ilpd-9971-487", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.8052177815068505, "maxdepth": 25, "minbucket": 59, "minsplit": 41}}}], "metrics": 0.713551, "context": "openml-ilpd-9971", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-ilpd-145848-1470", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.03965656918697061, "maxdepth": 24, "minbucket": 14, "minsplit": 3}}}], "metrics": 0.713551, "context": "openml-ilpd-145848", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-ilpd-145848-488", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.6086488034877927, "maxdepth": 25, "minbucket": 46, "minsplit": 13}}}], "metrics": 0.713551, "context": "openml-ilpd-145848", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-ilpd-145848-490", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.256110743789375, "maxdepth": 18, "minbucket": 13, "minsplit": 57}}}], "metrics": 0.713551, "context": "openml-ilpd-145848", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-ilpd-145848-491", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.317406252662092, "maxdepth": 9, "minbucket": 14, "minsplit": 57}}}], "metrics": 0.713551, "context": "openml-ilpd-145848", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-ilpd-145848-492", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.34498005191087666, "maxdepth": 4, "minbucket": 13, "minsplit": 1}}}], "metrics": 0.713551, "context": "openml-ilpd-145848", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-tic-tac-toe-49-805", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.012561785692721594, "maxdepth": 22, "minbucket": 9, "minsplit": 5}}}], "metrics": 0.924843, "context": "openml-tic-tac-toe-49", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-tic-tac-toe-49-1278", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.019770651992783, "maxdepth": 21, "minbucket": 4, "minsplit": 28}}}], "metrics": 0.916493, "context": "openml-tic-tac-toe-49", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-tic-tac-toe-49-723", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.013622916007786996, "maxdepth": 13, "minbucket": 14, "minsplit": 15}}}], "metrics": 0.913361, "context": "openml-tic-tac-toe-49", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-tic-tac-toe-49-950", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.008979383094608776, "maxdepth": 9, "minbucket": 17, "minsplit": 2}}}], "metrics": 0.911273, "context": "openml-tic-tac-toe-49", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-tic-tac-toe-49-657", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.012398735324293402, "maxdepth": 28, "minbucket": 12, "minsplit": 28}}}], "metrics": 0.911273, "context": "openml-tic-tac-toe-49", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-spambase-145979-1220", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0029190657030790986, "maxdepth": 21, "minbucket": 25, "minsplit": 52}}}], "metrics": 0.905673, "context": "openml-spambase-145979", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-spambase-145979-815", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.004274696048721665, "maxdepth": 17, "minbucket": 29, "minsplit": 1}}}], "metrics": 0.903065, "context": "openml-spambase-145979", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-spambase-145979-719", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.00688360182791948, "maxdepth": 8, "minbucket": 13, "minsplit": 46}}}], "metrics": 0.898935, "context": "openml-spambase-145979", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-spambase-145979-1377", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.005725928519293669, "maxdepth": 26, "minbucket": 28, "minsplit": 15}}}], "metrics": 0.895892, "context": "openml-spambase-145979", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-spambase-145979-427", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.009457989532873027, "maxdepth": 25, "minbucket": 6, "minsplit": 25}}}], "metrics": 0.894805, "context": "openml-spambase-145979", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-madelon-9976-168", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0027663288008421697, "maxdepth": 14, "minbucket": 11, "minsplit": 29}}}], "metrics": 0.796923, "context": "openml-madelon-9976", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-madelon-9976-935", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.00593794177509844, "maxdepth": 30, "minbucket": 16, "minsplit": 22}}}], "metrics": 0.793077, "context": "openml-madelon-9976", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-madelon-9976-960", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.006506387314200399, "maxdepth": 6, "minbucket": 1, "minsplit": 35}}}], "metrics": 0.791923, "context": "openml-madelon-9976", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-madelon-9976-870", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.003317811230570081, "maxdepth": 15, "minbucket": 21, "minsplit": 35}}}], "metrics": 0.791538, "context": "openml-madelon-9976", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-madelon-9976-742", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.00414870207421482, "maxdepth": 24, "minbucket": 19, "minsplit": 38}}}], "metrics": 0.791154, "context": "openml-madelon-9976", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-mozilla4-3899-211", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.00014407740198075768, "maxdepth": 29, "minbucket": 5, "minsplit": 17}}}], "metrics": 0.939337, "context": "openml-mozilla4-3899", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-mozilla4-3899-483", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0032192130409181086, "maxdepth": 16, "minbucket": 43, "minsplit": 19}}}], "metrics": 0.936057, "context": "openml-mozilla4-3899", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-mozilla4-3899-256", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0029128798585385104, "maxdepth": 15, "minbucket": 60, "minsplit": 7}}}], "metrics": 0.936057, "context": "openml-mozilla4-3899", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-mozilla4-3899-1687", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.10198628756441189, "maxdepth": 9, "minbucket": 59, "minsplit": 58}}}], "metrics": 0.934255, "context": "openml-mozilla4-3899", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-mozilla4-3899-632", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.39632978982515593, "maxdepth": 7, "minbucket": 48, "minsplit": 33}}}], "metrics": 0.934255, "context": "openml-mozilla4-3899", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-click-prediction-small-7295-405", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0006575863178819423, "maxdepth": 27, "minbucket": 20, "minsplit": 12}}}], "metrics": 0.834285, "context": "openml-click-prediction-small-7295", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-click-prediction-small-7295-1598", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0010497886057943113, "maxdepth": 27, "minbucket": 42, "minsplit": 43}}}], "metrics": 0.833484, "context": "openml-click-prediction-small-7295", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-click-prediction-small-7295-411", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0017588028520345695, "maxdepth": 20, "minbucket": 23, "minsplit": 30}}}], "metrics": 0.831806, "context": "openml-click-prediction-small-7295", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-click-prediction-small-7295-571", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.9913141317036007, "maxdepth": 9, "minbucket": 41, "minsplit": 2}}}], "metrics": 0.831581, "context": "openml-click-prediction-small-7295", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-click-prediction-small-7295-572", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.9822478358935568, "maxdepth": 27, "minbucket": 54, "minsplit": 6}}}], "metrics": 0.831581, "context": "openml-click-prediction-small-7295", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-electricity-219-1243", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.00010078883022069933, "maxdepth": 13, "minbucket": 1, "minsplit": 6}}}], "metrics": 0.864208, "context": "openml-electricity-219", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-electricity-219-1297", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0005497899208217861, "maxdepth": 22, "minbucket": 43, "minsplit": 46}}}], "metrics": 0.847656, "context": "openml-electricity-219", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-electricity-219-1737", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0010391349740326394, "maxdepth": 29, "minbucket": 24, "minsplit": 30}}}], "metrics": 0.835452, "context": "openml-electricity-219", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-electricity-219-837", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.00228270649202168, "maxdepth": 14, "minbucket": 10, "minsplit": 4}}}], "metrics": 0.816517, "context": "openml-electricity-219", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-electricity-219-1115", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0036778479650616596, "maxdepth": 13, "minbucket": 50, "minsplit": 1}}}], "metrics": 0.804025, "context": "openml-electricity-219", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-banknote-authentication-10093-517", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0026977941695600694, "maxdepth": 15, "minbucket": 2, "minsplit": 14}}}], "metrics": 0.984694, "context": "openml-banknote-authentication-10093", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-banknote-authentication-10093-768", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0003847739960998299, "maxdepth": 6, "minbucket": 9, "minsplit": 15}}}], "metrics": 0.980321, "context": "openml-banknote-authentication-10093", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-banknote-authentication-10093-1102", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.013262765884771897, "maxdepth": 9, "minbucket": 3, "minsplit": 7}}}], "metrics": 0.95481, "context": "openml-banknote-authentication-10093", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-banknote-authentication-10093-1641", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.012160185195878102, "maxdepth": 5, "minbucket": 15, "minsplit": 28}}}], "metrics": 0.947522, "context": "openml-banknote-authentication-10093", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-banknote-authentication-10093-328", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.010964925337955395, "maxdepth": 13, "minbucket": 16, "minsplit": 45}}}], "metrics": 0.947522, "context": "openml-banknote-authentication-10093", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-eeg-eye-state-14951-1790", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.00020798056609928612, "maxdepth": 29, "minbucket": 28, "minsplit": 32}}}], "metrics": 0.806409, "context": "openml-eeg-eye-state-14951", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-eeg-eye-state-14951-1576", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0010843511506915093, "maxdepth": 17, "minbucket": 55, "minsplit": 26}}}], "metrics": 0.784579, "context": "openml-eeg-eye-state-14951", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-eeg-eye-state-14951-532", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.002987903945520521, "maxdepth": 10, "minbucket": 2, "minsplit": 25}}}], "metrics": 0.767623, "context": "openml-eeg-eye-state-14951", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-eeg-eye-state-14951-871", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.004149986135214571, "maxdepth": 21, "minbucket": 35, "minsplit": 52}}}], "metrics": 0.748131, "context": "openml-eeg-eye-state-14951", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-eeg-eye-state-14951-1164", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.004433186196163301, "maxdepth": 21, "minbucket": 50, "minsplit": 18}}}], "metrics": 0.744059, "context": "openml-eeg-eye-state-14951", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-magictelescope-3954-060", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0008850627880543472, "maxdepth": 26, "minbucket": 21, "minsplit": 39}}}], "metrics": 0.849159, "context": "openml-magictelescope-3954", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-magictelescope-3954-418", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0002400930341333149, "maxdepth": 16, "minbucket": 38, "minsplit": 41}}}], "metrics": 0.846583, "context": "openml-magictelescope-3954", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-magictelescope-3954-440", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0005396245349198579, "maxdepth": 8, "minbucket": 27, "minsplit": 53}}}], "metrics": 0.844322, "context": "openml-magictelescope-3954", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-magictelescope-3954-151", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0015175970572978304, "maxdepth": 14, "minbucket": 33, "minsplit": 51}}}], "metrics": 0.84306, "context": "openml-magictelescope-3954", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-magictelescope-3954-1709", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0022520177833735898, "maxdepth": 9, "minbucket": 8, "minsplit": 5}}}], "metrics": 0.840536, "context": "openml-magictelescope-3954", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-bank-marketing-14965-820", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.002436470177397129, "maxdepth": 19, "minbucket": 34, "minsplit": 40}}}], "metrics": 0.904603, "context": "openml-bank-marketing-14965", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-bank-marketing-14965-1927", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0018479115631431305, "maxdepth": 17, "minbucket": 3, "minsplit": 41}}}], "metrics": 0.904581, "context": "openml-bank-marketing-14965", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-bank-marketing-14965-263", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.002460934857279059, "maxdepth": 11, "minbucket": 10, "minsplit": 15}}}], "metrics": 0.904492, "context": "openml-bank-marketing-14965", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-bank-marketing-14965-1897", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.0005758297000080351, "maxdepth": 8, "minbucket": 30, "minsplit": 33}}}], "metrics": 0.904183, "context": "openml-bank-marketing-14965", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-bank-marketing-14965-1854", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.003261102766171101, "maxdepth": 13, "minbucket": 57, "minsplit": 54}}}], "metrics": 0.903453, "context": "openml-bank-marketing-14965", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-amazon-employee-access-34539-2046", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-34539"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.8871990951545535, "maxdepth": 30, "minbucket": 33, "minsplit": 23}}}], "metrics": 0.94211, "context": "openml-amazon-employee-access-34539", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-amazon-employee-access-34539-747", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-34539"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.6180761586245153, "maxdepth": 20, "minbucket": 41, "minsplit": 22}}}], "metrics": 0.94211, "context": "openml-amazon-employee-access-34539", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-amazon-employee-access-34539-749", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-34539"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.8286490176640448, "maxdepth": 25, "minbucket": 9, "minsplit": 17}}}], "metrics": 0.94211, "context": "openml-amazon-employee-access-34539", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-amazon-employee-access-34539-750", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-34539"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.7159378274180004, "maxdepth": 18, "minbucket": 51, "minsplit": 21}}}], "metrics": 0.94211, "context": "openml-amazon-employee-access-34539", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-amazon-employee-access-34539-751", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-34539"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.22755525068603516, "maxdepth": 25, "minbucket": 38, "minsplit": 57}}}], "metrics": 0.94211, "context": "openml-amazon-employee-access-34539", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-wdbc-9946-1938", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.020492256556078798, "maxdepth": 27, "minbucket": 21, "minsplit": 23}}}], "metrics": 0.929701, "context": "openml-wdbc-9946", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-wdbc-9946-1498", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.014070004161819794, "maxdepth": 27, "minbucket": 5, "minsplit": 35}}}], "metrics": 0.924429, "context": "openml-wdbc-9946", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-wdbc-9946-383", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.007836383238807322, "maxdepth": 17, "minbucket": 16, "minsplit": 19}}}], "metrics": 0.9244288224956064, "context": "openml-wdbc-9946", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-wdbc-9946-168", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.005750009727105502, "maxdepth": 16, "minbucket": 11, "minsplit": 42}}}], "metrics": 0.922671353251318, "context": "openml-wdbc-9946", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-wdbc-9946-132", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.00031166703663766383, "maxdepth": 3, "minbucket": 2, "minsplit": 29}}}], "metrics": 0.922671353251318, "context": "openml-wdbc-9946", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-kc2-3913-001", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.12432773172147608, "maxdepth": 27, "minbucket": 44, "minsplit": 48}}}], "metrics": 0.848659, "context": "openml-kc2-3913", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-kc2-3913-1012", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.023672327336296404, "maxdepth": 1, "minbucket": 49, "minsplit": 32}}}], "metrics": 0.848659, "context": "openml-kc2-3913", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-kc2-3913-1122", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.17618425091020803, "maxdepth": 10, "minbucket": 33, "minsplit": 11}}}], "metrics": 0.848659, "context": "openml-kc2-3913", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-kc2-3913-1120", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.19741009379029312, "maxdepth": 7, "minbucket": 59, "minsplit": 49}}}], "metrics": 0.848659, "context": "openml-kc2-3913", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-rpart-5859-openml-kc2-3913-1119", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "rpart-5859", "config": {"cp": 0.13907494366392503, "maxdepth": 27, "minbucket": 34, "minsplit": 10}}}], "metrics": 0.848659, "context": "openml-kc2-3913", "schema": "rpart-5859", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-sylva-agnostic-3889-026", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.3940714364241808, "lambda": 0.05500008462144577}}}], "metrics": 0.98041, "context": "openml-sylva-agnostic-3889", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-sylva-agnostic-3889-009", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.9446004246663302, "lambda": 0.048997727169337715}}}], "metrics": 0.964432, "context": "openml-sylva-agnostic-3889", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-sylva-agnostic-3889-006", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.41294795408137114, "lambda": 0.10045220876254103}}}], "metrics": 0.958458, "context": "openml-sylva-agnostic-3889", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-sylva-agnostic-3889-025", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.8590642662554983, "lambda": 0.07392373736437205}}}], "metrics": 0.95158, "context": "openml-sylva-agnostic-3889", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-sylva-agnostic-3889-023", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.5829094545286149, "lambda": 0.10829818330408904}}}], "metrics": 0.944286, "context": "openml-sylva-agnostic-3889", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-heart-statlog-282-035", "modules": [{"role": "dataset", "module": "openml-heart-statlog-282"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.32345120555944706, "lambda": 0.0013659501189276497}}}], "metrics": 0.820225, "context": "openml-heart-statlog-282", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-heart-statlog-282-002", "modules": [{"role": "dataset", "module": "openml-heart-statlog-282"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.5399254648316653, "lambda": 0.004695371431188282}}}], "metrics": 0.820225, "context": "openml-heart-statlog-282", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-heart-statlog-282-033", "modules": [{"role": "dataset", "module": "openml-heart-statlog-282"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.841394693760574, "lambda": 0.0035198035603556306}}}], "metrics": 0.820225, "context": "openml-heart-statlog-282", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-heart-statlog-282-018", "modules": [{"role": "dataset", "module": "openml-heart-statlog-282"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.8587589805781837, "lambda": 0.0013963936320586096}}}], "metrics": 0.820225, "context": "openml-heart-statlog-282", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-heart-statlog-282-026", "modules": [{"role": "dataset", "module": "openml-heart-statlog-282"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.6006012649111452, "lambda": 0.00393031948630818}}}], "metrics": 0.820225, "context": "openml-heart-statlog-282", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-haberman-272-028", "modules": [{"role": "dataset", "module": "openml-haberman-272"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.24939555552080298, "lambda": 0.06550082705209503}}}], "metrics": 0.75, "context": "openml-haberman-272", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-haberman-272-043", "modules": [{"role": "dataset", "module": "openml-haberman-272"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.07589339388757936, "lambda": 0.08660715867170599}}}], "metrics": 0.75, "context": "openml-haberman-272", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-haberman-272-019", "modules": [{"role": "dataset", "module": "openml-haberman-272"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.2467226655524221, "lambda": 0.11796840745638401}}}], "metrics": 0.74, "context": "openml-haberman-272", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-haberman-272-023", "modules": [{"role": "dataset", "module": "openml-haberman-272"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.016091105465218403, "lambda": 0.05656613839939898}}}], "metrics": 0.74, "context": "openml-haberman-272", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-haberman-272-062", "modules": [{"role": "dataset", "module": "openml-haberman-272"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.0421924173668027, "lambda": 0.05765635571994746}}}], "metrics": 0.74, "context": "openml-haberman-272", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-ada-agnostic-3896-063", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.9190478573389349, "lambda": 0.00165388612059409}}}], "metrics": 0.842613, "context": "openml-ada-agnostic-3896", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-ada-agnostic-3896-006", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.7710179264493288, "lambda": 0.010801070990159894}}}], "metrics": 0.842613, "context": "openml-ada-agnostic-3896", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-ada-agnostic-3896-067", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.5585469875320792, "lambda": 0.004112011287793221}}}], "metrics": 0.842394, "context": "openml-ada-agnostic-3896", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-ada-agnostic-3896-068", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.5080999628942457, "lambda": 0.0035881480129486597}}}], "metrics": 0.842174, "context": "openml-ada-agnostic-3896", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-ada-agnostic-3896-013", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.40236634591817894, "lambda": 0.0035748461554882395}}}], "metrics": 0.842174, "context": "openml-ada-agnostic-3896", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-pc3-3903-078", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.08015588478408746, "lambda": 0.0014864406345322702}}}], "metrics": 0.898912, "context": "openml-pc3-3903", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-pc3-3903-095", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.763077600563318, "lambda": 0.0012712262171609599}}}], "metrics": 0.898912, "context": "openml-pc3-3903", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-pc3-3903-045", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.6222190416254101, "lambda": 2.512057094467679}}}], "metrics": 0.897633, "context": "openml-pc3-3903", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-pc3-3903-034", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.801642300730944, "lambda": 17.089449966995886}}}], "metrics": 0.897633, "context": "openml-pc3-3903", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-pc3-3903-036", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.6994970440234991, "lambda": 873.8068889035554}}}], "metrics": 0.897633, "context": "openml-pc3-3903", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-diabetes-37-098", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.47544870868548783, "lambda": 0.00122592390837231}}}], "metrics": 0.778646, "context": "openml-diabetes-37", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-diabetes-37-015", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.05078350536748767, "lambda": 0.002317527154662709}}}], "metrics": 0.778646, "context": "openml-diabetes-37", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-diabetes-37-017", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.14783379755206405, "lambda": 0.0017302025328871904}}}], "metrics": 0.778646, "context": "openml-diabetes-37", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-diabetes-37-022", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.8127520607620482, "lambda": 0.0018301624728338907}}}], "metrics": 0.777344, "context": "openml-diabetes-37", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-diabetes-37-058", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.433627130167931, "lambda": 0.0014225830627018299}}}], "metrics": 0.777344, "context": "openml-diabetes-37", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-click-prediction-small-14971-088", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.483950660501048, "lambda": 0.0010818453825796953}}}], "metrics": 0.832057, "context": "openml-click-prediction-small-14971", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-click-prediction-small-14971-073", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.33317164162397406, "lambda": 0.0014117905052252197}}}], "metrics": 0.831982, "context": "openml-click-prediction-small-14971", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-click-prediction-small-14971-019", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.47967935929298383, "lambda": 0.0014821567462704197}}}], "metrics": 0.831932, "context": "openml-click-prediction-small-14971", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-click-prediction-small-14971-061", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.47040570846982316, "lambda": 0.0022166711823047203}}}], "metrics": 0.831831, "context": "openml-click-prediction-small-14971", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-click-prediction-small-14971-029", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.21304142748229202, "lambda": 0.0053613582682279}}}], "metrics": 0.831681, "context": "openml-click-prediction-small-14971", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-blood-transfusion-service-center-10101-067", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.9640061817433689, "lambda": 0.015614671741141898}}}], "metrics": 0.775401, "context": "openml-blood-transfusion-service-center-10101", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-blood-transfusion-service-center-10101-009", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.3968137958388779, "lambda": 0.026412884781241798}}}], "metrics": 0.774064, "context": "openml-blood-transfusion-service-center-10101", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-blood-transfusion-service-center-10101-039", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.20198290602527588, "lambda": 0.05141046158004671}}}], "metrics": 0.774064, "context": "openml-blood-transfusion-service-center-10101", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-blood-transfusion-service-center-10101-055", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.7394602142110474, "lambda": 0.0257107538575266}}}], "metrics": 0.772727, "context": "openml-blood-transfusion-service-center-10101", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-blood-transfusion-service-center-10101-031", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.021630050551518797, "lambda": 0.04869472565277167}}}], "metrics": 0.772727, "context": "openml-blood-transfusion-service-center-10101", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-qsar-biodeg-9957-014", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.8085573333617299, "lambda": 0.0015702950277617805}}}], "metrics": 0.872986, "context": "openml-qsar-biodeg-9957", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-qsar-biodeg-9957-037", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.5964300308212641, "lambda": 0.0011868439051042796}}}], "metrics": 0.872038, "context": "openml-qsar-biodeg-9957", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-qsar-biodeg-9957-085", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.574587708276138, "lambda": 0.00132333661899255}}}], "metrics": 0.872038, "context": "openml-qsar-biodeg-9957", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-qsar-biodeg-9957-086", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.2871159463491291, "lambda": 0.0016430722742811403}}}], "metrics": 0.872038, "context": "openml-qsar-biodeg-9957", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-qsar-biodeg-9957-019", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.9393247237265111, "lambda": 0.0015407942453645105}}}], "metrics": 0.87109, "context": "openml-qsar-biodeg-9957", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-kr-vs-kp-3-058", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.14999115227945106, "lambda": 0.0013614033839253906}}}], "metrics": 0.967459, "context": "openml-kr-vs-kp-3", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-kr-vs-kp-3-072", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.8221640176441518, "lambda": 0.0014494110853146204}}}], "metrics": 0.967146, "context": "openml-kr-vs-kp-3", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-kr-vs-kp-3-048", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.5326553002767261, "lambda": 0.0017796619379636999}}}], "metrics": 0.966521, "context": "openml-kr-vs-kp-3", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-kr-vs-kp-3-052", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.03287361625805498, "lambda": 0.0020589296206174204}}}], "metrics": 0.965582, "context": "openml-kr-vs-kp-3", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-kr-vs-kp-3-063", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.59486373414509, "lambda": 0.00236914404837928}}}], "metrics": 0.96433, "context": "openml-kr-vs-kp-3", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-pc4-3902-089", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.08910000364519657, "lambda": 0.004722218336175592}}}], "metrics": 0.911523, "context": "openml-pc4-3902", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-pc4-3902-028", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.0621990707539022, "lambda": 0.005335174062396648}}}], "metrics": 0.910837, "context": "openml-pc4-3902", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-pc4-3902-099", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.006317845948413009, "lambda": 0.015393095169479397}}}], "metrics": 0.910151, "context": "openml-pc4-3902", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-pc4-3902-007", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.20740352401733397, "lambda": 0.0028459630627113296}}}], "metrics": 0.910151, "context": "openml-pc4-3902", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-pc4-3902-053", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.404937966198102, "lambda": 0.0022257833838061104}}}], "metrics": 0.910151, "context": "openml-pc4-3902", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-kc1-3917-021", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.07736907334290444, "lambda": 0.00849005571520106}}}], "metrics": 0.861072, "context": "openml-kc1-3917", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-kc1-3917-009", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.7961350292269138, "lambda": 0.004091401453652321}}}], "metrics": 0.860597, "context": "openml-kc1-3917", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-kc1-3917-060", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.222386699106917, "lambda": 0.012624653211094697}}}], "metrics": 0.860597, "context": "openml-kc1-3917", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-kc1-3917-004", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.5422157057862732, "lambda": 0.0031982806672733997}}}], "metrics": 0.860123, "context": "openml-kc1-3917", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-kc1-3917-075", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.16009496798030992, "lambda": 0.008121286088988043}}}], "metrics": 0.860123, "context": "openml-kc1-3917", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-monks-problems-1-3492-050", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.5405506495688107, "lambda": 0.11041914605739707}}}], "metrics": 0.746403, "context": "openml-monks-problems-1-3492", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-monks-problems-1-3492-065", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.0450677023570985, "lambda": 0.011246562486944096}}}], "metrics": 0.746403, "context": "openml-monks-problems-1-3492", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-monks-problems-1-3492-060", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.177260420687869, "lambda": 0.3845345891902448}}}], "metrics": 0.746403, "context": "openml-monks-problems-1-3492", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-monks-problems-1-3492-057", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.503002197418734, "lambda": 0.006568733679664862}}}], "metrics": 0.746403, "context": "openml-monks-problems-1-3492", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-monks-problems-1-3492-056", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.9914677489385008, "lambda": 0.0126375213648085}}}], "metrics": 0.746403, "context": "openml-monks-problems-1-3492", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-eeg-eye-state-14951-049", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.014697317436710001, "lambda": 0.0016338621975843103}}}], "metrics": 0.587583, "context": "openml-eeg-eye-state-14951", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-eeg-eye-state-14951-065", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.044485478598997, "lambda": 0.002220552364154279}}}], "metrics": 0.585915, "context": "openml-eeg-eye-state-14951", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-eeg-eye-state-14951-063", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.31273961270451495, "lambda": 0.0028047443520189193}}}], "metrics": 0.584379, "context": "openml-eeg-eye-state-14951", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-eeg-eye-state-14951-095", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.607105055062473, "lambda": 0.0018955123953947705}}}], "metrics": 0.584379, "context": "openml-eeg-eye-state-14951", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-eeg-eye-state-14951-005", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.023369204422831504, "lambda": 0.014713017123729494}}}], "metrics": 0.58004, "context": "openml-eeg-eye-state-14951", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-musk-3950-050", "modules": [{"role": "dataset", "module": "openml-musk-3950"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.6471567560754717, "lambda": 0.003781278573870531}}}], "metrics": 0.999697, "context": "openml-musk-3950", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-musk-3950-075", "modules": [{"role": "dataset", "module": "openml-musk-3950"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.8212156318429858, "lambda": 0.0011351665529477997}}}], "metrics": 0.999697, "context": "openml-musk-3950", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-musk-3950-002", "modules": [{"role": "dataset", "module": "openml-musk-3950"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.9369201931938533, "lambda": 0.0056185780827928}}}], "metrics": 0.999697, "context": "openml-musk-3950", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-musk-3950-017", "modules": [{"role": "dataset", "module": "openml-musk-3950"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.2745719854090361, "lambda": 0.010291138091522298}}}], "metrics": 0.999697, "context": "openml-musk-3950", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-musk-3950-018", "modules": [{"role": "dataset", "module": "openml-musk-3950"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.20429373479671797, "lambda": 0.004521422416944049}}}], "metrics": 0.999697, "context": "openml-musk-3950", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-hill-valley-9970-033", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.9626496983062482, "lambda": 0.0012516214913194795}}}], "metrics": 0.685644, "context": "openml-hill-valley-9970", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-hill-valley-9970-032", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.5937382685322311, "lambda": 0.0014964942913024803}}}], "metrics": 0.683168, "context": "openml-hill-valley-9970", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-hill-valley-9970-066", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.21229266904517993, "lambda": 0.00200308386418305}}}], "metrics": 0.681518, "context": "openml-hill-valley-9970", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-hill-valley-9970-097", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.24230151361077998, "lambda": 0.00224109038570894}}}], "metrics": 0.678218, "context": "openml-hill-valley-9970", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-hill-valley-9970-031", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.43514088860936484, "lambda": 0.00213237920417731}}}], "metrics": 0.672442, "context": "openml-hill-valley-9970", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-steel-plates-fault-9967-021", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.9049600457608702, "lambda": 0.005589284858708082}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-steel-plates-fault-9967-012", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.6317529086325321, "lambda": 0.023120718768207895}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-steel-plates-fault-9967-043", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.46545735018551276, "lambda": 0.0014587260313695804}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-steel-plates-fault-9967-030", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.510209074646607, "lambda": 0.0023005380601669395}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-steel-plates-fault-9967-057", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.9183597519829872, "lambda": 0.005936628749571151}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-ozone-level-8hr-9978-046", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.06218155350759633, "lambda": 0.0034200482415752713}}}], "metrics": 0.942778, "context": "openml-ozone-level-8hr-9978", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-ozone-level-8hr-9978-012", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.6964172245305031, "lambda": 0.004187905214369611}}}], "metrics": 0.941594, "context": "openml-ozone-level-8hr-9978", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-ozone-level-8hr-9978-026", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.8751906393397603, "lambda": 0.00392661504127774}}}], "metrics": 0.941594, "context": "openml-ozone-level-8hr-9978", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-ozone-level-8hr-9978-061", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.6906348850414158, "lambda": 0.0016677568920679905}}}], "metrics": 0.941594, "context": "openml-ozone-level-8hr-9978", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-ozone-level-8hr-9978-069", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.43976338760219513, "lambda": 0.003332540168952249}}}], "metrics": 0.9412, "context": "openml-ozone-level-8hr-9978", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-phoneme-9952-005", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.09532764454595745, "lambda": 0.00118248433818509}}}], "metrics": 0.74926, "context": "openml-phoneme-9952", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-phoneme-9952-017", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.817227906950191, "lambda": 0.0014097677014562398}}}], "metrics": 0.748705, "context": "openml-phoneme-9952", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-phoneme-9952-070", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.183048276400566, "lambda": 0.0018994727716283902}}}], "metrics": 0.748705, "context": "openml-phoneme-9952", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-phoneme-9952-043", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.746208741965145, "lambda": 0.0018635215617399093}}}], "metrics": 0.748335, "context": "openml-phoneme-9952", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-phoneme-9952-079", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.39910970668532, "lambda": 0.0018333029242647908}}}], "metrics": 0.748335, "context": "openml-phoneme-9952", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-gina-agnostic-3891-094", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.43312092840895117, "lambda": 0.0209559342643491}}}], "metrics": 0.876009, "context": "openml-gina-agnostic-3891", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-gina-agnostic-3891-052", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.8350530773703008, "lambda": 0.0114381391763635}}}], "metrics": 0.875721, "context": "openml-gina-agnostic-3891", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-gina-agnostic-3891-059", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.8789520449306822, "lambda": 0.009267701763322068}}}], "metrics": 0.875433, "context": "openml-gina-agnostic-3891", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-gina-agnostic-3891-084", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.439835066378489, "lambda": 0.022199210689959996}}}], "metrics": 0.875144, "context": "openml-gina-agnostic-3891", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-gina-agnostic-3891-012", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.189266884869337, "lambda": 0.0356990049971961}}}], "metrics": 0.874567, "context": "openml-gina-agnostic-3891", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-australian-125923-028", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.246183376463503, "lambda": 0.0549370417198118}}}], "metrics": 0.872464, "context": "openml-australian-125923", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-australian-125923-081", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.4520172527361661, "lambda": 0.04030635144886231}}}], "metrics": 0.872464, "context": "openml-australian-125923", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-australian-125923-001", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.44639372586496195, "lambda": 0.031833609176195106}}}], "metrics": 0.871014, "context": "openml-australian-125923", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-australian-125923-096", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.26430674822293193, "lambda": 0.03589361018210209}}}], "metrics": 0.871014, "context": "openml-australian-125923", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-australian-125923-091", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.4722318020019681, "lambda": 0.017893440805932588}}}], "metrics": 0.871014, "context": "openml-australian-125923", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-magictelescope-3954-182", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.9747949982363728, "lambda": 0.0020319364392558507}}}], "metrics": 0.790589, "context": "openml-magictelescope-3954", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-magictelescope-3954-007", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.49820763867571927, "lambda": 0.0014537763934897997}}}], "metrics": 0.790536, "context": "openml-magictelescope-3954", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-magictelescope-3954-102", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.217969662446901, "lambda": 0.00289777130814318}}}], "metrics": 0.790484, "context": "openml-magictelescope-3954", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-magictelescope-3954-172", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.23469005542099497, "lambda": 0.0012150653440951395}}}], "metrics": 0.790431, "context": "openml-magictelescope-3954", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-magictelescope-3954-030", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.9690657464623453, "lambda": 0.002109110025206119}}}], "metrics": 0.790431, "context": "openml-magictelescope-3954", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-mozilla4-3899-196", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.9114868377171458, "lambda": 0.011297071846906502}}}], "metrics": 0.854551, "context": "openml-mozilla4-3899", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-mozilla4-3899-057", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.978271030292287, "lambda": 0.03798083540514743}}}], "metrics": 0.8532, "context": "openml-mozilla4-3899", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-mozilla4-3899-008", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.7771660328678789, "lambda": 0.008734696227207883}}}], "metrics": 0.853007, "context": "openml-mozilla4-3899", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-mozilla4-3899-133", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.9160897780045867, "lambda": 0.00624408614813654}}}], "metrics": 0.852364, "context": "openml-mozilla4-3899", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-mozilla4-3899-153", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.941898423416913, "lambda": 0.00466596959020261}}}], "metrics": 0.851849, "context": "openml-mozilla4-3899", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-nomao-9977-199", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.029008764710649795, "lambda": 0.0015485951975626204}}}], "metrics": 0.947657, "context": "openml-nomao-9977", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-nomao-9977-099", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.12797632574327295, "lambda": 0.0012956974597850895}}}], "metrics": 0.947512, "context": "openml-nomao-9977", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-nomao-9977-100", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.29390654287524504, "lambda": 0.0011248183800861501}}}], "metrics": 0.947309, "context": "openml-nomao-9977", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-nomao-9977-096", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.2194423642311249, "lambda": 0.00148150816684013}}}], "metrics": 0.947077, "context": "openml-nomao-9977", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-nomao-9977-097", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.565228180431202, "lambda": 0.0011300242573774899}}}], "metrics": 0.94699, "context": "openml-nomao-9977", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-climate-model-simulation-crashes-9980-199", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.7209885056898001, "lambda": 172.95901325560183}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-9980", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-climate-model-simulation-crashes-9980-088", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.48100317822061495, "lambda": 5.940212770413071}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-9980", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-climate-model-simulation-crashes-9980-085", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.31541426613219103, "lambda": 1.3620074083507796}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-9980", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-climate-model-simulation-crashes-9980-084", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.3497182002127169, "lambda": 0.04132907857541609}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-9980", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-climate-model-simulation-crashes-9980-083", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.9897149684209383, "lambda": 16.6697281662833}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-9980", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-tic-tac-toe-49-138", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.8905166761785751, "lambda": 0.004235543413717422}}}], "metrics": 0.983299, "context": "openml-tic-tac-toe-49", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-tic-tac-toe-49-016", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.08602455042526133, "lambda": 0.0017097970728026496}}}], "metrics": 0.983299, "context": "openml-tic-tac-toe-49", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-tic-tac-toe-49-173", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.6341990466997028, "lambda": 0.005110983795139959}}}], "metrics": 0.983299, "context": "openml-tic-tac-toe-49", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-tic-tac-toe-49-023", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.2748526674065741, "lambda": 0.0016342673564115002}}}], "metrics": 0.983299, "context": "openml-tic-tac-toe-49", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-glmnet-5860-openml-tic-tac-toe-49-154", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5860", "config": {"alpha": 0.355880102079734, "lambda": 0.005773260441278593}}}], "metrics": 0.983299, "context": "openml-tic-tac-toe-49", "schema": "glmnet-5860", "source": "hpob"}, {"id": "hpob-svm-5891-openml-bioresponse-14966-001", "modules": [{"role": "dataset", "module": "openml-bioresponse-14966"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.0149819654315017, "kernel": "linear"}}}], "metrics": 0.764063, "context": "openml-bioresponse-14966", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-bioresponse-14966-034", "modules": [{"role": "dataset", "module": "openml-bioresponse-14966"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.0227108761766237, "kernel": "linear"}}}], "metrics": 0.762997, "context": "openml-bioresponse-14966", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-bioresponse-14966-033", "modules": [{"role": "dataset", "module": "openml-bioresponse-14966"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.0544048341665222, "kernel": "linear"}}}], "metrics": 0.753932, "context": "openml-bioresponse-14966", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-bioresponse-14966-003", "modules": [{"role": "dataset", "module": "openml-bioresponse-14966"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.383613961418452, "kernel": "linear"}}}], "metrics": 0.73607, "context": "openml-bioresponse-14966", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-bioresponse-14966-035", "modules": [{"role": "dataset", "module": "openml-bioresponse-14966"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 1.58439464286432, "kernel": "linear"}}}], "metrics": 0.721941, "context": "openml-bioresponse-14966", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-bioresponse-9910-025", "modules": [{"role": "dataset", "module": "openml-bioresponse-9910"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 16.9405627788385, "gamma": 0.00195072553323389, "kernel": "radial"}}}], "metrics": 0.781925, "context": "openml-bioresponse-9910", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-bioresponse-9910-020", "modules": [{"role": "dataset", "module": "openml-bioresponse-9910"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.00196270726087854, "kernel": "linear"}}}], "metrics": 0.766995, "context": "openml-bioresponse-9910", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-bioresponse-9910-008", "modules": [{"role": "dataset", "module": "openml-bioresponse-9910"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.00194803820321466, "kernel": "linear"}}}], "metrics": 0.766196, "context": "openml-bioresponse-9910", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-bioresponse-9910-022", "modules": [{"role": "dataset", "module": "openml-bioresponse-9910"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.00141881955234374, "kernel": "linear"}}}], "metrics": 0.765929, "context": "openml-bioresponse-9910", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-bioresponse-9910-021", "modules": [{"role": "dataset", "module": "openml-bioresponse-9910"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.00264427525000772, "kernel": "linear"}}}], "metrics": 0.765662, "context": "openml-bioresponse-9910", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-monks-problems-3-146066-045", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 191.008275867929, "kernel": "linear"}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-monks-problems-3-146066-066", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 125.971546402237, "kernel": "linear"}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-monks-problems-3-146066-061", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 543.190871280818, "gamma": 0.00136276615428886, "kernel": "radial"}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-monks-problems-3-146066-010", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 33.7577672466887, "kernel": "linear"}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-monks-problems-3-146066-087", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 46.1152930238515, "kernel": "linear"}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-electricity-146012-167", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 35.1763095770911, "gamma": 0.873777869207952, "kernel": "radial"}}}], "metrics": 0.858514, "context": "openml-electricity-146012", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-electricity-146012-158", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 2.75882875997474, "gamma": 2.95764295799861, "kernel": "radial"}}}], "metrics": 0.854343, "context": "openml-electricity-146012", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-electricity-146012-143", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 10.3335703012413, "gamma": 0.48282452683396, "kernel": "radial"}}}], "metrics": 0.846442, "context": "openml-electricity-146012", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-electricity-146012-095", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 19.8696574474979, "gamma": 0.388306397760248, "kernel": "radial"}}}], "metrics": 0.846288, "context": "openml-electricity-146012", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-electricity-146012-093", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.238022098990611, "gamma": 8.39869113610191, "kernel": "radial"}}}], "metrics": 0.845979, "context": "openml-electricity-146012", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-click-prediction-small-7295-203", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.00277876398085742, "gamma": 0.085915426654779, "kernel": "radial"}}}], "metrics": 0.832632, "context": "openml-click-prediction-small-7295", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-click-prediction-small-7295-214", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.00184065509498813, "gamma": 0.255105661756874, "kernel": "radial"}}}], "metrics": 0.832607, "context": "openml-click-prediction-small-7295", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-click-prediction-small-7295-018", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.0043786448747841, "gamma": 0.0126289890332555, "kernel": "radial"}}}], "metrics": 0.832607, "context": "openml-click-prediction-small-7295", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-click-prediction-small-7295-036", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.00706399025804038, "gamma": 0.00611667603568052, "kernel": "radial"}}}], "metrics": 0.832532, "context": "openml-click-prediction-small-7295", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-click-prediction-small-7295-191", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.00731531991234898, "gamma": 0.0090493527907119, "kernel": "radial"}}}], "metrics": 0.832532, "context": "openml-click-prediction-small-7295", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-qsar-biodeg-9957-010", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 7.14670084432, "gamma": 0.0101813733831922, "kernel": "radial"}}}], "metrics": 0.879621, "context": "openml-qsar-biodeg-9957", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-qsar-biodeg-9957-041", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 1.20285369574671, "gamma": 0.0757279635111373, "kernel": "radial"}}}], "metrics": 0.878673, "context": "openml-qsar-biodeg-9957", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-qsar-biodeg-9957-093", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 7.90802399976392, "gamma": 0.0129044631152511, "kernel": "radial"}}}], "metrics": 0.878673, "context": "openml-qsar-biodeg-9957", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-qsar-biodeg-9957-167", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 9.5868760517948, "gamma": 0.00550552152055648, "kernel": "radial"}}}], "metrics": 0.877725, "context": "openml-qsar-biodeg-9957", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-qsar-biodeg-9957-034", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 236.690846722036, "gamma": 0.00589569892681855, "kernel": "radial"}}}], "metrics": 0.877725, "context": "openml-qsar-biodeg-9957", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-click-prediction-small-14971-071", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.00128487945290159, "gamma": 0.131459111586218, "kernel": "radial"}}}], "metrics": 0.832708, "context": "openml-click-prediction-small-14971", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-click-prediction-small-14971-058", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.00102726071723971, "kernel": "linear"}}}], "metrics": 0.832557, "context": "openml-click-prediction-small-14971", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-click-prediction-small-14971-299", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.00109285638173722, "gamma": 0.242541604157537, "kernel": "radial"}}}], "metrics": 0.832557, "context": "openml-click-prediction-small-14971", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-click-prediction-small-14971-060", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.0034435915573689203, "gamma": 0.0148376421966003, "kernel": "radial"}}}], "metrics": 0.832557, "context": "openml-click-prediction-small-14971", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-click-prediction-small-14971-010", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.00140512137733704, "kernel": "linear"}}}], "metrics": 0.832532, "context": "openml-click-prediction-small-14971", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-bioresponse-145677-100", "modules": [{"role": "dataset", "module": "openml-bioresponse-145677"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 9.01987680074398, "gamma": 0.00140911801434432, "kernel": "radial"}}}], "metrics": 0.784058, "context": "openml-bioresponse-145677", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-bioresponse-145677-027", "modules": [{"role": "dataset", "module": "openml-bioresponse-145677"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 1.05016931951225, "gamma": 0.00234441229013871, "kernel": "radial"}}}], "metrics": 0.777393, "context": "openml-bioresponse-145677", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-bioresponse-145677-121", "modules": [{"role": "dataset", "module": "openml-bioresponse-145677"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 104.456852579892, "degree": 2, "kernel": "polynomial"}}}], "metrics": 0.768862, "context": "openml-bioresponse-145677", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-bioresponse-145677-011", "modules": [{"role": "dataset", "module": "openml-bioresponse-145677"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.00349614383380423, "kernel": "linear"}}}], "metrics": 0.768062, "context": "openml-bioresponse-145677", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-bioresponse-145677-124", "modules": [{"role": "dataset", "module": "openml-bioresponse-145677"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 676.938094354259, "degree": 3, "kernel": "polynomial"}}}], "metrics": 0.767795, "context": "openml-bioresponse-145677", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-ozone-level-8hr-145855-314", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.015108709354636, "gamma": 0.0117898199898566, "kernel": "radial"}}}], "metrics": 0.948303, "context": "openml-ozone-level-8hr-145855", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-ozone-level-8hr-145855-034", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.205245521961804, "gamma": 0.0213742490012335, "kernel": "radial"}}}], "metrics": 0.948303, "context": "openml-ozone-level-8hr-145855", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-ozone-level-8hr-145855-176", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.00490685993611661, "gamma": 0.0044677500523721, "kernel": "radial"}}}], "metrics": 0.947908, "context": "openml-ozone-level-8hr-145855", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-ozone-level-8hr-145855-165", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 4.31080730999822, "gamma": 0.021636070833539, "kernel": "radial"}}}], "metrics": 0.947908, "context": "openml-ozone-level-8hr-145855", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-ozone-level-8hr-145855-238", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 2.31276934593983, "gamma": 0.00911078099814497, "kernel": "radial"}}}], "metrics": 0.947514, "context": "openml-ozone-level-8hr-145855", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-australian-125923-310", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.00222363404776301, "kernel": "linear"}}}], "metrics": 0.873913, "context": "openml-australian-125923", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-australian-125923-330", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.00219005572388284, "kernel": "linear"}}}], "metrics": 0.873913, "context": "openml-australian-125923", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-australian-125923-256", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.0988547151838978, "gamma": 0.0731741473481199, "kernel": "radial"}}}], "metrics": 0.871014, "context": "openml-australian-125923", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-australian-125923-158", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.00175727509313031, "kernel": "linear"}}}], "metrics": 0.869565, "context": "openml-australian-125923", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-australian-125923-268", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.00190758550896008, "kernel": "linear"}}}], "metrics": 0.869565, "context": "openml-australian-125923", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-nomao-9977-376", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 85.2899445288139, "gamma": 0.00373378683943852, "kernel": "radial"}}}], "metrics": 0.964602, "context": "openml-nomao-9977", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-nomao-9977-165", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 107.667333436584, "gamma": 0.00672620761694589, "kernel": "radial"}}}], "metrics": 0.964341, "context": "openml-nomao-9977", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-nomao-9977-133", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 91.222952856487, "gamma": 0.00335646993621364, "kernel": "radial"}}}], "metrics": 0.964312, "context": "openml-nomao-9977", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-nomao-9977-184", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 196.829796082693, "gamma": 0.00271046182672189, "kernel": "radial"}}}], "metrics": 0.964167, "context": "openml-nomao-9977", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-nomao-9977-162", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 3.68373579713296, "gamma": 0.0169951784782286, "kernel": "radial"}}}], "metrics": 0.96408, "context": "openml-nomao-9977", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-qsar-biodeg-145862-212", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 45.0557126700978, "gamma": 0.0253262044583763, "kernel": "radial"}}}], "metrics": 0.887204, "context": "openml-qsar-biodeg-145862", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-qsar-biodeg-145862-150", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 12.657689796809, "gamma": 0.0230904248634721, "kernel": "radial"}}}], "metrics": 0.885308, "context": "openml-qsar-biodeg-145862", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-qsar-biodeg-145862-020", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 1.1449259571635, "gamma": 0.0525274374049271, "kernel": "radial"}}}], "metrics": 0.882464, "context": "openml-qsar-biodeg-145862", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-qsar-biodeg-145862-037", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 87.7536767690212, "gamma": 0.0260413987455011, "kernel": "radial"}}}], "metrics": 0.882464, "context": "openml-qsar-biodeg-145862", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-qsar-biodeg-145862-189", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 19.980662917994, "gamma": 0.0228765126794773, "kernel": "radial"}}}], "metrics": 0.882464, "context": "openml-qsar-biodeg-145862", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-credit-g-145972-143", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 11.4848197947933, "gamma": 0.0102487007488457, "kernel": "radial"}}}], "metrics": 0.766, "context": "openml-credit-g-145972", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-credit-g-145972-170", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 8.50643832111615, "gamma": 0.00439905450106585, "kernel": "radial"}}}], "metrics": 0.764, "context": "openml-credit-g-145972", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-credit-g-145972-299", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 7.05011270452158, "gamma": 0.0164409308052198, "kernel": "radial"}}}], "metrics": 0.763, "context": "openml-credit-g-145972", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-credit-g-145972-351", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.796109503450314, "gamma": 0.0595449610331797, "kernel": "radial"}}}], "metrics": 0.762, "context": "openml-credit-g-145972", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-credit-g-145972-211", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 39.8221885246915, "gamma": 0.00115481428576673, "kernel": "radial"}}}], "metrics": 0.761, "context": "openml-credit-g-145972", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-spambase-145979-019", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 720.707312680964, "gamma": 0.00169957203158318, "kernel": "radial"}}}], "metrics": 0.938709, "context": "openml-spambase-145979", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-spambase-145979-005", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 30.7179206230149, "gamma": 0.00884230914707983, "kernel": "radial"}}}], "metrics": 0.938274, "context": "openml-spambase-145979", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-spambase-145979-076", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 14.8974538555802, "gamma": 0.0114991773940797, "kernel": "radial"}}}], "metrics": 0.938057, "context": "openml-spambase-145979", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-spambase-145979-284", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 26.180387900671, "gamma": 0.00296283851641602, "kernel": "radial"}}}], "metrics": 0.938057, "context": "openml-spambase-145979", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-spambase-145979-030", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 49.7069715295555, "gamma": 0.0114603821276818, "kernel": "radial"}}}], "metrics": 0.937405, "context": "openml-spambase-145979", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-kr-vs-kp-145953-323", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 726.33507744883, "degree": 4, "kernel": "polynomial"}}}], "metrics": 0.998123, "context": "openml-kr-vs-kp-145953", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-kr-vs-kp-145953-213", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 306.045590105375, "degree": 5, "kernel": "polynomial"}}}], "metrics": 0.99781, "context": "openml-kr-vs-kp-145953", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-kr-vs-kp-145953-184", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 526.769555568692, "degree": 4, "kernel": "polynomial"}}}], "metrics": 0.99781, "context": "openml-kr-vs-kp-145953", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-kr-vs-kp-145953-193", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 297.652303256748, "degree": 5, "kernel": "polynomial"}}}], "metrics": 0.99781, "context": "openml-kr-vs-kp-145953", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-kr-vs-kp-145953-019", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 243.372574488719, "degree": 5, "kernel": "polynomial"}}}], "metrics": 0.997497, "context": "openml-kr-vs-kp-145953", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-kc1-3917-366", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 4.83393858494455, "gamma": 0.0404325269011365, "kernel": "radial"}}}], "metrics": 0.859175, "context": "openml-kc1-3917", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-kc1-3917-495", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 778.97841770105, "kernel": "linear"}}}], "metrics": 0.859175, "context": "openml-kc1-3917", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-kc1-3917-083", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 3.10769944817829, "gamma": 0.062310502511502, "kernel": "radial"}}}], "metrics": 0.858701, "context": "openml-kc1-3917", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-kc1-3917-328", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 2.20518113149645, "gamma": 0.0394004196691025, "kernel": "radial"}}}], "metrics": 0.856804, "context": "openml-kc1-3917", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-kc1-3917-190", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 24.8901290143837, "gamma": 0.019106671399294, "kernel": "radial"}}}], "metrics": 0.856804, "context": "openml-kc1-3917", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-banknote-authentication-145834-001", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 3.6439942840948, "gamma": 0.510811876414778, "kernel": "radial"}}}], "metrics": 1.0, "context": "openml-banknote-authentication-145834", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-banknote-authentication-145834-179", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.623787655888721, "gamma": 2.6030742277155, "kernel": "radial"}}}], "metrics": 1.0, "context": "openml-banknote-authentication-145834", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-banknote-authentication-145834-228", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 126.985815673007, "gamma": 2.018548014952, "kernel": "radial"}}}], "metrics": 1.0, "context": "openml-banknote-authentication-145834", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-banknote-authentication-145834-227", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 1.31703485841363, "gamma": 32.1002271525644, "kernel": "radial"}}}], "metrics": 1.0, "context": "openml-banknote-authentication-145834", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-banknote-authentication-145834-407", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 15.2069225407407, "gamma": 0.218911107454208, "kernel": "radial"}}}], "metrics": 1.0, "context": "openml-banknote-authentication-145834", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-climate-model-simulation-crashes-145839-238", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.001, "gamma": 0.0118721302453105, "kernel": "radial"}}}], "metrics": 0.916667, "context": "openml-climate-model-simulation-crashes-145839", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-climate-model-simulation-crashes-145839-232", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.015785341116578, "gamma": 0.00106882903635973, "kernel": "radial"}}}], "metrics": 0.916667, "context": "openml-climate-model-simulation-crashes-145839", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-climate-model-simulation-crashes-145839-312", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 1.09341721067069, "degree": 4, "kernel": "polynomial"}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-145839", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-climate-model-simulation-crashes-145839-143", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.019665260721651, "degree": 2, "kernel": "polynomial"}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-145839", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-climate-model-simulation-crashes-145839-314", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 371.400323477875, "degree": 2, "kernel": "polynomial"}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-145839", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-musk-146082-332", "modules": [{"role": "dataset", "module": "openml-musk-146082"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 495.724540924566, "gamma": 0.0155931994285934, "kernel": "radial"}}}], "metrics": 1.0, "context": "openml-musk-146082", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-musk-146082-043", "modules": [{"role": "dataset", "module": "openml-musk-146082"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 11.3259176546788, "gamma": 0.0141798109067968, "kernel": "radial"}}}], "metrics": 1.0, "context": "openml-musk-146082", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-musk-146082-069", "modules": [{"role": "dataset", "module": "openml-musk-146082"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 6.91093194242354, "gamma": 0.00871415269322727, "kernel": "radial"}}}], "metrics": 1.0, "context": "openml-musk-146082", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-musk-146082-267", "modules": [{"role": "dataset", "module": "openml-musk-146082"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 263.035685751948, "degree": 3, "kernel": "polynomial"}}}], "metrics": 0.999848, "context": "openml-musk-146082", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-musk-146082-184", "modules": [{"role": "dataset", "module": "openml-musk-146082"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 444.53949715869, "degree": 3, "kernel": "polynomial"}}}], "metrics": 0.999848, "context": "openml-musk-146082", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-phoneme-145857-388", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 2.73854595284591, "gamma": 9.670728002512, "kernel": "radial"}}}], "metrics": 0.900259, "context": "openml-phoneme-145857", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-phoneme-145857-296", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 2.13555650272795, "gamma": 10.3555890242533, "kernel": "radial"}}}], "metrics": 0.900259, "context": "openml-phoneme-145857", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-phoneme-145857-103", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 2.59275486137721, "gamma": 12.8565233286366, "kernel": "radial"}}}], "metrics": 0.900074, "context": "openml-phoneme-145857", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-phoneme-145857-190", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 7.15317458743117, "gamma": 10.3894818532615, "kernel": "radial"}}}], "metrics": 0.898964, "context": "openml-phoneme-145857", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-phoneme-145857-213", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 8.41329095273611, "gamma": 2.59484948424415, "kernel": "radial"}}}], "metrics": 0.897668, "context": "openml-phoneme-145857", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-credit-g-31-386", "modules": [{"role": "dataset", "module": "openml-credit-g-31"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 57.3428625863645, "gamma": 0.00341761146615264, "kernel": "radial"}}}], "metrics": 0.764, "context": "openml-credit-g-31", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-credit-g-31-209", "modules": [{"role": "dataset", "module": "openml-credit-g-31"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 193.811985322028, "gamma": 0.00185348818499552, "kernel": "radial"}}}], "metrics": 0.762, "context": "openml-credit-g-31", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-credit-g-31-299", "modules": [{"role": "dataset", "module": "openml-credit-g-31"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 59.2051812689708, "gamma": 0.00306219465556086, "kernel": "radial"}}}], "metrics": 0.762, "context": "openml-credit-g-31", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-credit-g-31-021", "modules": [{"role": "dataset", "module": "openml-credit-g-31"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 36.5856451006898, "gamma": 0.00121345694607404, "kernel": "radial"}}}], "metrics": 0.76, "context": "openml-credit-g-31", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-credit-g-31-379", "modules": [{"role": "dataset", "module": "openml-credit-g-31"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 3.01840380958934, "gamma": 0.0162098039403727, "kernel": "radial"}}}], "metrics": 0.758, "context": "openml-credit-g-31", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-electricity-219-073", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 7.78909256079147, "gamma": 2.82069861931599, "kernel": "radial"}}}], "metrics": 0.85591, "context": "openml-electricity-219", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-electricity-219-148", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 3.43134231959536, "gamma": 4.24529305742953, "kernel": "radial"}}}], "metrics": 0.854078, "context": "openml-electricity-219", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-electricity-219-496", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 2.42676323809459, "gamma": 2.2514804843762, "kernel": "radial"}}}], "metrics": 0.852489, "context": "openml-electricity-219", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-electricity-219-495", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 25.5833477042851, "gamma": 0.506004456938432, "kernel": "radial"}}}], "metrics": 0.852247, "context": "openml-electricity-219", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-electricity-219-494", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 8.23484863540439, "gamma": 0.64825624282555, "kernel": "radial"}}}], "metrics": 0.850371, "context": "openml-electricity-219", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-spambase-43-541", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 295.144354738722, "gamma": 0.00149490099953706, "kernel": "radial"}}}], "metrics": 0.939578, "context": "openml-spambase-43", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-spambase-43-020", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 750.001586150982, "gamma": 0.00148252415738566, "kernel": "radial"}}}], "metrics": 0.939144, "context": "openml-spambase-43", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-spambase-43-057", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 14.4600588462429, "gamma": 0.00924582892519115, "kernel": "radial"}}}], "metrics": 0.938926, "context": "openml-spambase-43", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-spambase-43-515", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 5.99617757095846, "gamma": 0.0105196593117566, "kernel": "radial"}}}], "metrics": 0.93784, "context": "openml-spambase-43", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-spambase-43-040", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 43.9901452506096, "gamma": 0.00176015374782097, "kernel": "radial"}}}], "metrics": 0.937188, "context": "openml-spambase-43", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-ilpd-145848-561", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 400.713670689208, "gamma": 895.701309697066, "kernel": "radial"}}}], "metrics": 0.723842, "context": "openml-ilpd-145848", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-ilpd-145848-514", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 17.5493989773217, "gamma": 559.140935762343, "kernel": "radial"}}}], "metrics": 0.723842, "context": "openml-ilpd-145848", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-ilpd-145848-047", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 14.4692295891926, "gamma": 291.31103215857, "kernel": "radial"}}}], "metrics": 0.723842, "context": "openml-ilpd-145848", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-ilpd-145848-212", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.001, "gamma": 212.805290890896, "kernel": "radial"}}}], "metrics": 0.723842, "context": "openml-ilpd-145848", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-ilpd-145848-018", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.0379622522169471, "gamma": 437.609691076476, "kernel": "radial"}}}], "metrics": 0.723842, "context": "openml-ilpd-145848", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-tic-tac-toe-49-402", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 248.982145025117, "degree": 5, "kernel": "polynomial"}}}], "metrics": 1.0, "context": "openml-tic-tac-toe-49", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-tic-tac-toe-49-337", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.0852479280169943, "gamma": 1.78106992954549, "kernel": "radial"}}}], "metrics": 1.0, "context": "openml-tic-tac-toe-49", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-tic-tac-toe-49-518", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 83.4530734274648, "gamma": 0.0411140323043566, "kernel": "radial"}}}], "metrics": 1.0, "context": "openml-tic-tac-toe-49", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-tic-tac-toe-49-342", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 160.633601195805, "degree": 4, "kernel": "polynomial"}}}], "metrics": 1.0, "context": "openml-tic-tac-toe-49", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-tic-tac-toe-49-046", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 518.901511643919, "degree": 2, "kernel": "polynomial"}}}], "metrics": 1.0, "context": "openml-tic-tac-toe-49", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-steel-plates-fault-145872-361", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.569162664538168, "kernel": "linear"}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-steel-plates-fault-145872-327", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.014678186115133, "kernel": "linear"}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-steel-plates-fault-145872-331", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.0875741369259994, "kernel": "linear"}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-steel-plates-fault-145872-339", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 144.023618546465, "kernel": "linear"}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-steel-plates-fault-145872-341", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.00550668534754256, "kernel": "linear"}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-banknote-authentication-10093-422", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.558426034012082, "gamma": 2.80468050814738, "kernel": "radial"}}}], "metrics": 1.0, "context": "openml-banknote-authentication-10093", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-banknote-authentication-10093-683", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.335998803411383, "gamma": 0.0699868008642392, "kernel": "radial"}}}], "metrics": 1.0, "context": "openml-banknote-authentication-10093", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-banknote-authentication-10093-401", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 92.3874038372431, "gamma": 0.0791353959387673, "kernel": "radial"}}}], "metrics": 1.0, "context": "openml-banknote-authentication-10093", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-banknote-authentication-10093-410", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 157.426092201833, "gamma": 3.6282324392123, "kernel": "radial"}}}], "metrics": 1.0, "context": "openml-banknote-authentication-10093", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-banknote-authentication-10093-696", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 21.7945677226541, "gamma": 0.0916935368710772, "kernel": "radial"}}}], "metrics": 1.0, "context": "openml-banknote-authentication-10093", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-phishingwebsites-14952-452", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-14952"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 14.0612022061997, "gamma": 0.778047732036731, "kernel": "radial"}}}], "metrics": 0.973406, "context": "openml-phishingwebsites-14952", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-phishingwebsites-14952-922", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-14952"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 33.7089461958954, "gamma": 0.775162839553746, "kernel": "radial"}}}], "metrics": 0.973406, "context": "openml-phishingwebsites-14952", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-phishingwebsites-14952-906", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-14952"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 847.361554752722, "gamma": 0.707425327175747, "kernel": "radial"}}}], "metrics": 0.973315, "context": "openml-phishingwebsites-14952", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-phishingwebsites-14952-440", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-14952"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 30.7996670250351, "gamma": 0.797378272514957, "kernel": "radial"}}}], "metrics": 0.972953, "context": "openml-phishingwebsites-14952", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-phishingwebsites-14952-432", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-14952"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 118.038536563938, "gamma": 0.638189332122378, "kernel": "radial"}}}], "metrics": 0.972863, "context": "openml-phishingwebsites-14952", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-ada-agnostic-3896-131", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.0523128520246308, "kernel": "linear"}}}], "metrics": 0.848531, "context": "openml-ada-agnostic-3896", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-ada-agnostic-3896-548", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.0508747250259525, "kernel": "linear"}}}], "metrics": 0.848531, "context": "openml-ada-agnostic-3896", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-ada-agnostic-3896-572", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.0466145906497641, "kernel": "linear"}}}], "metrics": 0.848531, "context": "openml-ada-agnostic-3896", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-ada-agnostic-3896-200", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.0449683874169408, "kernel": "linear"}}}], "metrics": 0.848312, "context": "openml-ada-agnostic-3896", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-ada-agnostic-3896-190", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.0564831427826138, "kernel": "linear"}}}], "metrics": 0.848312, "context": "openml-ada-agnostic-3896", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-hill-valley-9970-830", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 501.338066910461, "kernel": "linear"}}}], "metrics": 0.74505, "context": "openml-hill-valley-9970", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-hill-valley-9970-782", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 884.680385078849, "kernel": "linear"}}}], "metrics": 0.74505, "context": "openml-hill-valley-9970", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-hill-valley-9970-047", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 955.895434123615, "kernel": "linear"}}}], "metrics": 0.744224, "context": "openml-hill-valley-9970", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-hill-valley-9970-192", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 790.614044464077, "kernel": "linear"}}}], "metrics": 0.743399, "context": "openml-hill-valley-9970", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-hill-valley-9970-179", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 930.942130947782, "kernel": "linear"}}}], "metrics": 0.743399, "context": "openml-hill-valley-9970", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-magictelescope-3954-444", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 166.132429867968, "gamma": 0.0877407952279361, "kernel": "radial"}}}], "metrics": 0.876866, "context": "openml-magictelescope-3954", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-magictelescope-3954-080", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 90.3516413272388, "gamma": 0.0790501627990115, "kernel": "radial"}}}], "metrics": 0.876446, "context": "openml-magictelescope-3954", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-magictelescope-3954-829", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 25.4732696694276, "gamma": 0.138835198395623, "kernel": "radial"}}}], "metrics": 0.876288, "context": "openml-magictelescope-3954", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-magictelescope-3954-935", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 577.597672497531, "gamma": 0.0324612071131163, "kernel": "radial"}}}], "metrics": 0.875815, "context": "openml-magictelescope-3954", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-magictelescope-3954-945", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 528.061555893629, "gamma": 0.0439029276652263, "kernel": "radial"}}}], "metrics": 0.875762, "context": "openml-magictelescope-3954", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-bank-marketing-14965-567", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 332.48296636252, "gamma": 0.00485241940971089, "kernel": "radial"}}}], "metrics": 0.905266, "context": "openml-bank-marketing-14965", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-bank-marketing-14965-512", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 1.00713971609488, "gamma": 0.178534360327733, "kernel": "radial"}}}], "metrics": 0.904935, "context": "openml-bank-marketing-14965", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-bank-marketing-14965-259", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 1.11169311073112, "gamma": 0.207826102075608, "kernel": "radial"}}}], "metrics": 0.904935, "context": "openml-bank-marketing-14965", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-bank-marketing-14965-854", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.913080449449387, "gamma": 0.269879828053725, "kernel": "radial"}}}], "metrics": 0.904868, "context": "openml-bank-marketing-14965", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-bank-marketing-14965-222", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 12.3841191348298, "gamma": 0.0235111209893451, "kernel": "radial"}}}], "metrics": 0.904802, "context": "openml-bank-marketing-14965", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-eeg-eye-state-9983-547", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 482.613802437602, "gamma": 1.7484549272533, "kernel": "radial"}}}], "metrics": 0.899332, "context": "openml-eeg-eye-state-9983", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-eeg-eye-state-9983-1037", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 529.481776250541, "gamma": 1.64460091842808, "kernel": "radial"}}}], "metrics": 0.899199, "context": "openml-eeg-eye-state-9983", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-eeg-eye-state-9983-746", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 124.418838552739, "gamma": 1.76874311525446, "kernel": "radial"}}}], "metrics": 0.895995, "context": "openml-eeg-eye-state-9983", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-eeg-eye-state-9983-451", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 116.638081365017, "gamma": 1.38290201383494, "kernel": "radial"}}}], "metrics": 0.895794, "context": "openml-eeg-eye-state-9983", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-eeg-eye-state-9983-1015", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 71.96128631626, "gamma": 1.91717628688505, "kernel": "radial"}}}], "metrics": 0.892924, "context": "openml-eeg-eye-state-9983", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-kr-vs-kp-3-249", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 823.397214183258, "degree": 4, "kernel": "polynomial"}}}], "metrics": 0.998123, "context": "openml-kr-vs-kp-3", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-kr-vs-kp-3-013", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 753.48939483539, "degree": 4, "kernel": "polynomial"}}}], "metrics": 0.998123, "context": "openml-kr-vs-kp-3", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-kr-vs-kp-3-461", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 416.132069783062, "degree": 4, "kernel": "polynomial"}}}], "metrics": 0.99781, "context": "openml-kr-vs-kp-3", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-kr-vs-kp-3-747", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 301.311043749433, "degree": 5, "kernel": "polynomial"}}}], "metrics": 0.99781, "context": "openml-kr-vs-kp-3", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-kr-vs-kp-3-452", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 443.507056270822, "degree": 4, "kernel": "polynomial"}}}], "metrics": 0.99781, "context": "openml-kr-vs-kp-3", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-scene-3485-471", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.0986556324277607, "kernel": "linear"}}}], "metrics": 0.989198, "context": "openml-scene-3485", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-scene-3485-129", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.112630500879838, "kernel": "linear"}}}], "metrics": 0.989198, "context": "openml-scene-3485", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-scene-3485-244", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.143359112530136, "kernel": "linear"}}}], "metrics": 0.989198, "context": "openml-scene-3485", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-scene-3485-266", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.126986062450729, "kernel": "linear"}}}], "metrics": 0.989198, "context": "openml-scene-3485", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-scene-3485-189", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.121613256438288, "kernel": "linear"}}}], "metrics": 0.989198, "context": "openml-scene-3485", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-pc4-3902-540", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 4.09409217016636, "kernel": "linear"}}}], "metrics": 0.915638, "context": "openml-pc4-3902", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-pc4-3902-1075", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 1.89624806606983, "gamma": 0.00845187024233999, "kernel": "radial"}}}], "metrics": 0.915638, "context": "openml-pc4-3902", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-pc4-3902-1046", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 17.0053402823144, "kernel": "linear"}}}], "metrics": 0.915638, "context": "openml-pc4-3902", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-pc4-3902-348", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 4.38323917476362, "kernel": "linear"}}}], "metrics": 0.915638, "context": "openml-pc4-3902", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-pc4-3902-146", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 4.51033281690936, "kernel": "linear"}}}], "metrics": 0.915638, "context": "openml-pc4-3902", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-pc3-3903-913", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 2.71370978350601, "gamma": 46.9394130473809, "kernel": "radial"}}}], "metrics": 0.904031, "context": "openml-pc3-3903", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-pc3-3903-460", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 437.243243696451, "gamma": 205.111431830071, "kernel": "radial"}}}], "metrics": 0.904031, "context": "openml-pc3-3903", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-pc3-3903-202", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 280.072083421691, "gamma": 49.3815141599852, "kernel": "radial"}}}], "metrics": 0.904031, "context": "openml-pc3-3903", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-pc3-3903-200", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 41.1634836887974, "gamma": 55.8289528852805, "kernel": "radial"}}}], "metrics": 0.904031, "context": "openml-pc3-3903", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-pc3-3903-663", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 3.26313566003515, "gamma": 160.800470894127, "kernel": "radial"}}}], "metrics": 0.904031, "context": "openml-pc3-3903", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-wdbc-145878-595", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 7.34229165101438, "gamma": 0.00404595567365481, "kernel": "radial"}}}], "metrics": 0.982425, "context": "openml-wdbc-145878", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-wdbc-145878-141", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.0167437345978021, "kernel": "linear"}}}], "metrics": 0.982425, "context": "openml-wdbc-145878", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-wdbc-145878-118", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.015408899177192, "kernel": "linear"}}}], "metrics": 0.982425, "context": "openml-wdbc-145878", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-wdbc-145878-095", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.0155719935862846, "kernel": "linear"}}}], "metrics": 0.982425, "context": "openml-wdbc-145878", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-wdbc-145878-246", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.0103163295874226, "kernel": "linear"}}}], "metrics": 0.980668, "context": "openml-wdbc-145878", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-ilpd-9971-116", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 7.10004518091199, "gamma": 0.141056764672417, "kernel": "radial"}}}], "metrics": 0.727273, "context": "openml-ilpd-9971", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-ilpd-9971-719", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.0480765176510986, "gamma": 169.311018809496, "kernel": "radial"}}}], "metrics": 0.723842, "context": "openml-ilpd-9971", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-ilpd-9971-553", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 12.3872780803353, "gamma": 617.678966734529, "kernel": "radial"}}}], "metrics": 0.723842, "context": "openml-ilpd-9971", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-ilpd-9971-511", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.136753922176391, "gamma": 832.804350428006, "kernel": "radial"}}}], "metrics": 0.723842, "context": "openml-ilpd-9971", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-ilpd-9971-959", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 1.78593117044159, "gamma": 317.693216907818, "kernel": "radial"}}}], "metrics": 0.723842, "context": "openml-ilpd-9971", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-wdbc-9946-1002", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.0145446481669402, "kernel": "linear"}}}], "metrics": 0.982425, "context": "openml-wdbc-9946", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-wdbc-9946-1003", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.0149708497360273, "kernel": "linear"}}}], "metrics": 0.982425, "context": "openml-wdbc-9946", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-wdbc-9946-418", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.0162603201476701, "kernel": "linear"}}}], "metrics": 0.982425, "context": "openml-wdbc-9946", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-wdbc-9946-631", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.0150452519565938, "kernel": "linear"}}}], "metrics": 0.982425, "context": "openml-wdbc-9946", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-wdbc-9946-1094", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.0146539663637293, "kernel": "linear"}}}], "metrics": 0.982425, "context": "openml-wdbc-9946", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-monks-problems-1-146064-1154", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-146064"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 755.602970494229, "degree": 4, "kernel": "polynomial"}}}], "metrics": 1.0, "context": "openml-monks-problems-1-146064", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-monks-problems-1-146064-143", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-146064"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.872805933909601, "gamma": 0.38630015871006, "kernel": "radial"}}}], "metrics": 1.0, "context": "openml-monks-problems-1-146064", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-monks-problems-1-146064-597", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-146064"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 63.6622572607021, "degree": 3, "kernel": "polynomial"}}}], "metrics": 1.0, "context": "openml-monks-problems-1-146064", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-monks-problems-1-146064-1142", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-146064"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 630.160397797071, "degree": 2, "kernel": "polynomial"}}}], "metrics": 1.0, "context": "openml-monks-problems-1-146064", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-monks-problems-1-146064-1144", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-146064"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 169.1972688962, "degree": 3, "kernel": "polynomial"}}}], "metrics": 1.0, "context": "openml-monks-problems-1-146064", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-kc2-3913-657", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.506909986312201, "gamma": 0.0052514859842376, "kernel": "radial"}}}], "metrics": 0.850575, "context": "openml-kc2-3913", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-kc2-3913-1323", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.463387968326554, "gamma": 0.0103729190919924, "kernel": "radial"}}}], "metrics": 0.848659, "context": "openml-kc2-3913", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-kc2-3913-1059", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.350031764389521, "gamma": 0.0347611205404302, "kernel": "radial"}}}], "metrics": 0.848659, "context": "openml-kc2-3913", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-kc2-3913-507", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.161549178057048, "gamma": 0.0037528752170568, "kernel": "radial"}}}], "metrics": 0.846743, "context": "openml-kc2-3913", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-kc2-3913-656", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.113728972042059, "gamma": 0.00438089502146766, "kernel": "radial"}}}], "metrics": 0.846743, "context": "openml-kc2-3913", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-pc1-3918-1124", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 10.9325507743279, "gamma": 3.50983215277073, "kernel": "radial"}}}], "metrics": 0.940487, "context": "openml-pc1-3918", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-pc1-3918-845", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 3.93377528636929, "gamma": 2.7726034914939, "kernel": "radial"}}}], "metrics": 0.940487, "context": "openml-pc1-3918", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-pc1-3918-623", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 15.8711415731328, "gamma": 3.26605226945239, "kernel": "radial"}}}], "metrics": 0.940487, "context": "openml-pc1-3918", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-pc1-3918-321", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 2.67527101605975, "gamma": 3.60962264576462, "kernel": "radial"}}}], "metrics": 0.9395852119026149, "context": "openml-pc1-3918", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-pc1-3918-564", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 9.86058877443407, "gamma": 1.29739223659898, "kernel": "radial"}}}], "metrics": 0.939585, "context": "openml-pc1-3918", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-phishingwebsites-34537-934", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-34537"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 213.018696014833, "gamma": 0.770843578444566, "kernel": "radial"}}}], "metrics": 0.973406, "context": "openml-phishingwebsites-34537", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-phishingwebsites-34537-376", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-34537"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 669.444683597557, "gamma": 0.727310070792984, "kernel": "radial"}}}], "metrics": 0.973225, "context": "openml-phishingwebsites-34537", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-phishingwebsites-34537-379", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-34537"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 8.19500675287071, "gamma": 0.838918525771586, "kernel": "radial"}}}], "metrics": 0.973044, "context": "openml-phishingwebsites-34537", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-phishingwebsites-34537-899", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-34537"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 27.8894964644187, "gamma": 0.619672997278143, "kernel": "radial"}}}], "metrics": 0.972773, "context": "openml-phishingwebsites-34537", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-phishingwebsites-34537-760", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-34537"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 284.710887826988, "gamma": 0.402225434150562, "kernel": "radial"}}}], "metrics": 0.97223, "context": "openml-phishingwebsites-34537", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-steel-plates-fault-9967-761", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.0234163351741657, "kernel": "linear"}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-steel-plates-fault-9967-1108", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.0389612392727772, "kernel": "linear"}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-steel-plates-fault-9967-1110", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 9.07641759230654, "kernel": "linear"}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-steel-plates-fault-9967-802", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 4.09905431426389, "kernel": "linear"}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-steel-plates-fault-9967-106", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.0135405465970416, "kernel": "linear"}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-ozone-level-8hr-9978-640", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.563649433794576, "gamma": 0.0160960201040598, "kernel": "radial"}}}], "metrics": 0.949092, "context": "openml-ozone-level-8hr-9978", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-ozone-level-8hr-9978-679", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.102891289327323, "gamma": 0.015611867639995102, "kernel": "radial"}}}], "metrics": 0.949092, "context": "openml-ozone-level-8hr-9978", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-ozone-level-8hr-9978-1187", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.402900085925458, "gamma": 0.0152758601463309, "kernel": "radial"}}}], "metrics": 0.949092, "context": "openml-ozone-level-8hr-9978", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-ozone-level-8hr-9978-263", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.907960256159318, "gamma": 0.0199096523392613, "kernel": "radial"}}}], "metrics": 0.948698, "context": "openml-ozone-level-8hr-9978", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-ozone-level-8hr-9978-626", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 0.594945898843662, "gamma": 0.0131799442314711, "kernel": "radial"}}}], "metrics": 0.948698, "context": "openml-ozone-level-8hr-9978", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-madelon-9976-151", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 70.3029842035818, "gamma": 0.00769230262409709, "kernel": "radial"}}}], "metrics": 0.599231, "context": "openml-madelon-9976", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-madelon-9976-384", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 604.121230515192, "gamma": 0.005255364173229, "kernel": "radial"}}}], "metrics": 0.598846, "context": "openml-madelon-9976", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-madelon-9976-900", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 22.5697224920838, "gamma": 0.00613202937033601, "kernel": "radial"}}}], "metrics": 0.598846, "context": "openml-madelon-9976", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-madelon-9976-875", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 162.39720514221, "gamma": 0.00659765460323255, "kernel": "radial"}}}], "metrics": 0.598846, "context": "openml-madelon-9976", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-madelon-9976-1409", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 1.06251431071553, "degree": 3, "kernel": "polynomial"}}}], "metrics": 0.598846, "context": "openml-madelon-9976", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-wilt-9914-1351", "modules": [{"role": "dataset", "module": "openml-wilt-9914"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 8.14863351450735, "gamma": 0.16002918976554, "kernel": "radial"}}}], "metrics": 0.988427, "context": "openml-wilt-9914", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-wilt-9914-293", "modules": [{"role": "dataset", "module": "openml-wilt-9914"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 10.9576416156551, "gamma": 0.0791524531316487, "kernel": "radial"}}}], "metrics": 0.988427, "context": "openml-wilt-9914", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-wilt-9914-1101", "modules": [{"role": "dataset", "module": "openml-wilt-9914"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 28.0170390426596, "gamma": 0.0789940825097617, "kernel": "radial"}}}], "metrics": 0.988221, "context": "openml-wilt-9914", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-wilt-9914-380", "modules": [{"role": "dataset", "module": "openml-wilt-9914"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 12.3445621176436, "gamma": 0.0727989441590267, "kernel": "radial"}}}], "metrics": 0.988221, "context": "openml-wilt-9914", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-wilt-9914-1508", "modules": [{"role": "dataset", "module": "openml-wilt-9914"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 30.276148344529, "gamma": 0.0475601846648316, "kernel": "radial"}}}], "metrics": 0.988221, "context": "openml-wilt-9914", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-monks-problems-2-3493-499", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 208.992876728302, "gamma": 0.0957934667788159, "kernel": "radial"}}}], "metrics": 1.0, "context": "openml-monks-problems-2-3493", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-monks-problems-2-3493-736", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 1000.0, "degree": 2, "kernel": "polynomial"}}}], "metrics": 1.0, "context": "openml-monks-problems-2-3493", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-monks-problems-2-3493-1267", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 78.9557238252827, "gamma": 0.116013545469224, "kernel": "radial"}}}], "metrics": 1.0, "context": "openml-monks-problems-2-3493", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-monks-problems-2-3493-1373", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 686.256753947211, "degree": 2, "kernel": "polynomial"}}}], "metrics": 1.0, "context": "openml-monks-problems-2-3493", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-monks-problems-2-3493-501", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 656.72661894196, "gamma": 0.110835048129263, "kernel": "radial"}}}], "metrics": 1.0, "context": "openml-monks-problems-2-3493", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-eeg-eye-state-14951-1516", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 611.621845564981, "gamma": 1.29942384802929, "kernel": "radial"}}}], "metrics": 0.903672, "context": "openml-eeg-eye-state-14951", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-eeg-eye-state-14951-1060", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 906.523273641789, "gamma": 0.832459568429225, "kernel": "radial"}}}], "metrics": 0.90227, "context": "openml-eeg-eye-state-14951", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-eeg-eye-state-14951-1838", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 740.574437864225, "gamma": 1.56715261874767, "kernel": "radial"}}}], "metrics": 0.901402, "context": "openml-eeg-eye-state-14951", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-eeg-eye-state-14951-1512", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 446.806034045268, "gamma": 0.821740532655884, "kernel": "radial"}}}], "metrics": 0.899132, "context": "openml-eeg-eye-state-14951", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-svm-5891-openml-eeg-eye-state-14951-566", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "svm-5891", "config": {"cost": 953.7853678966, "gamma": 0.588015168827166, "kernel": "radial"}}}], "metrics": 0.898598, "context": "openml-eeg-eye-state-14951", "schema": "svm-5891", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-wilt-9914-057", "modules": [{"role": "dataset", "module": "openml-wilt-9914"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.0016146065479357098, "booster": "gbtree", "colsample_bylevel": 0.923035153886303, "colsample_bytree": 0.9058316139806055, "eta": 0.015560604179772198, "lambda": 0.024603391464953592, "max_depth": 13, "min_child_weight": 2.1878247667887316, "nrounds": 734, "subsample": 0.304724664473906}}}], "metrics": 0.984294, "context": "openml-wilt-9914", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-wilt-9914-063", "modules": [{"role": "dataset", "module": "openml-wilt-9914"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.44171513645560195, "booster": "gbtree", "colsample_bylevel": 0.743268955266103, "colsample_bytree": 0.8624844373505556, "eta": 0.0037384228972537686, "lambda": 4.216353291529443, "max_depth": 13, "min_child_weight": 1.0011308049706005, "nrounds": 4137, "subsample": 0.935878947633319}}}], "metrics": 0.983054, "context": "openml-wilt-9914", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-wilt-9914-016", "modules": [{"role": "dataset", "module": "openml-wilt-9914"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 5.1463056224270405, "booster": "gbtree", "colsample_bylevel": 0.511478210333735, "colsample_bytree": 0.6102255682297044, "eta": 0.25396479446568093, "lambda": 0.0013446020619768198, "max_depth": 11, "min_child_weight": 13.979743696938508, "nrounds": 2324, "subsample": 0.882274165633135}}}], "metrics": 0.982021, "context": "openml-wilt-9914", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-wilt-9914-001", "modules": [{"role": "dataset", "module": "openml-wilt-9914"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 5.819667802278931, "booster": "gbtree", "colsample_bylevel": 0.348795289173722, "colsample_bytree": 0.7500238830059764, "eta": 0.25818070033481905, "lambda": 5.241216216886798, "max_depth": 12, "min_child_weight": 13.3837927511113, "nrounds": 3625, "subsample": 0.500103261950426}}}], "metrics": 0.981194, "context": "openml-wilt-9914", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-wilt-9914-035", "modules": [{"role": "dataset", "module": "openml-wilt-9914"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.4190011520390199, "booster": "gbtree", "colsample_bylevel": 0.433862100588158, "colsample_bytree": 0.6751230910256515, "eta": 0.08082281819410404, "lambda": 0.0707914444226865, "max_depth": 4, "min_child_weight": 23.361804799693804, "nrounds": 877, "subsample": 0.717573560704477}}}], "metrics": 0.977475, "context": "openml-wilt-9914", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-phoneme-9952-065", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.7638181915293077, "booster": "gbtree", "colsample_bylevel": 0.637619949411601, "colsample_bytree": 0.8754316998481754, "eta": 0.020216020052907603, "lambda": 0.00400435629802911, "max_depth": 10, "min_child_weight": 4.231578754088378, "nrounds": 1882, "subsample": 0.548620000947267}}}], "metrics": 0.901184, "context": "openml-phoneme-9952", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-phoneme-9952-048", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.013509022872234598, "booster": "gbtree", "colsample_bylevel": 0.690700271632522, "colsample_bytree": 0.7706642373766756, "eta": 0.0268050467046099, "lambda": 7.9050627564002625, "max_depth": 10, "min_child_weight": 2.6868825973292387, "nrounds": 2403, "subsample": 0.895347124128602}}}], "metrics": 0.900629, "context": "openml-phoneme-9952", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-phoneme-9952-064", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.03873935047402841, "booster": "gbtree", "colsample_bylevel": 0.762635073624551, "colsample_bytree": 0.6146460898987948, "eta": 0.025925633217189704, "lambda": 14.653747001406115, "max_depth": 5, "min_child_weight": 19.56228844985581, "nrounds": 4482, "subsample": 0.872067330824211}}}], "metrics": 0.890266, "context": "openml-phoneme-9952", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-phoneme-9952-014", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.004248735525343562, "booster": "gbtree", "colsample_bylevel": 0.776700628688559, "colsample_bytree": 0.5165421980734908, "eta": 0.05501570135044731, "lambda": 0.023830729547910403, "max_depth": 8, "min_child_weight": 8.568370178378782, "nrounds": 482, "subsample": 0.853111796360463}}}], "metrics": 0.878238, "context": "openml-phoneme-9952", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-phoneme-9952-036", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 2.5278435574102307, "booster": "gbtree", "colsample_bylevel": 0.650631621479988, "colsample_bytree": 0.6047812601853162, "eta": 0.7627346838745862, "lambda": 0.4617868900369809, "max_depth": 11, "min_child_weight": 7.48349042888125, "nrounds": 2754, "subsample": 0.51376714524813}}}], "metrics": 0.878238, "context": "openml-phoneme-9952", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-monks-problems-1-3492-070", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 1.5437659015066592, "booster": "gbtree", "colsample_bylevel": 0.78483911161311, "colsample_bytree": 0.3505344953689717, "eta": 0.3144901314958091, "lambda": 0.0063791123459999285, "max_depth": 15, "min_child_weight": 5.0438201975849415, "nrounds": 2776, "subsample": 0.778182873292826}}}], "metrics": 1.0, "context": "openml-monks-problems-1-3492", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-monks-problems-1-3492-050", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.0028705379047549604, "booster": "gbtree", "colsample_bylevel": 0.615596573334187, "colsample_bytree": 0.7488787872087205, "eta": 0.09961533311007864, "lambda": 0.07122106328265883, "max_depth": 10, "min_child_weight": 2.2735882705970107, "nrounds": 2980, "subsample": 0.34304207507520895}}}], "metrics": 1.0, "context": "openml-monks-problems-1-3492", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-monks-problems-1-3492-041", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 3.0923934332555394, "booster": "gbtree", "colsample_bylevel": 0.336572330445051, "colsample_bytree": 0.9308760207448143, "eta": 0.15279210494452394, "lambda": 0.1256984101799929, "max_depth": 9, "min_child_weight": 2.6803479073273206, "nrounds": 4101, "subsample": 0.363212388497777}}}], "metrics": 0.996403, "context": "openml-monks-problems-1-3492", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-monks-problems-1-3492-014", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.0064859541660501, "booster": "gbtree", "colsample_bylevel": 0.344412589678541, "colsample_bytree": 0.6141068136155613, "eta": 0.0041941658960126605, "lambda": 0.002915606558418199, "max_depth": 3, "min_child_weight": 4.399666064482873, "nrounds": 3364, "subsample": 0.928215868095867}}}], "metrics": 0.935252, "context": "openml-monks-problems-1-3492", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-monks-problems-1-3492-065", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 3.9803661983212506, "booster": "gbtree", "colsample_bylevel": 0.435665573691949, "colsample_bytree": 0.6958455349620433, "eta": 0.15066777160187297, "lambda": 0.0017044061857305595, "max_depth": 14, "min_child_weight": 4.151258759415603, "nrounds": 641, "subsample": 0.574542618170381}}}], "metrics": 0.915468, "context": "openml-monks-problems-1-3492", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-monks-problems-2-3493-020", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.0039743258459308105, "booster": "gbtree", "colsample_bylevel": 0.792795626446605, "colsample_bytree": 0.9781016199219965, "eta": 0.26273691909456504, "lambda": 0.0010986291089621768, "max_depth": 9, "min_child_weight": 3.6788928998522317, "nrounds": 2992, "subsample": 0.60560626690276}}}], "metrics": 0.998336, "context": "openml-monks-problems-2-3493", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-monks-problems-2-3493-032", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.0026519776905424997, "booster": "gbtree", "colsample_bylevel": 0.760263120522723, "colsample_bytree": 0.382076623553783, "eta": 0.5108557088343368, "lambda": 23.012555591161988, "max_depth": 7, "min_child_weight": 3.205699072021002, "nrounds": 4187, "subsample": 0.722742949030362}}}], "metrics": 0.996672, "context": "openml-monks-problems-2-3493", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-monks-problems-2-3493-045", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.2803119309719101, "booster": "gbtree", "colsample_bylevel": 0.955776125891134, "colsample_bytree": 0.7055889339487994, "eta": 0.40145791776871, "lambda": 35.144316699593276, "max_depth": 14, "min_child_weight": 2.7669364890878114, "nrounds": 1432, "subsample": 0.832094726944342}}}], "metrics": 0.995008, "context": "openml-monks-problems-2-3493", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-monks-problems-2-3493-060", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.017751868953608696, "booster": "gbtree", "colsample_bylevel": 0.682298036525026, "colsample_bytree": 0.8485031232073901, "eta": 0.0493743190858661, "lambda": 2.03744163330705, "max_depth": 15, "min_child_weight": 8.119893180624853, "nrounds": 955, "subsample": 0.547116182744503}}}], "metrics": 0.793677, "context": "openml-monks-problems-2-3493", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-monks-problems-2-3493-016", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.0019046155694929508, "booster": "gbtree", "colsample_bylevel": 0.59044255129993, "colsample_bytree": 0.557593760250509, "eta": 0.01665645813582589, "lambda": 2.3461853973970195, "max_depth": 10, "min_child_weight": 1.0856543135796908, "nrounds": 1829, "subsample": 0.811817482439801}}}], "metrics": 0.788686, "context": "openml-monks-problems-2-3493", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-magictelescope-3954-070", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.0015360114652543293, "booster": "gbtree", "colsample_bylevel": 0.292094696313143, "colsample_bytree": 0.8011564798023549, "eta": 0.008956756026541553, "lambda": 0.30502255813064993, "max_depth": 6, "min_child_weight": 1.3955946467141203, "nrounds": 4539, "subsample": 0.3631351970369}}}], "metrics": 0.886172, "context": "openml-magictelescope-3954", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-magictelescope-3954-072", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.00126595080732348, "booster": "gbtree", "colsample_bylevel": 0.467078679939732, "colsample_bytree": 0.513464658458158, "eta": 0.01639177750582129, "lambda": 0.32739110648771297, "max_depth": 9, "min_child_weight": 3.428146876084351, "nrounds": 4188, "subsample": 0.406562245148234}}}], "metrics": 0.885752, "context": "openml-magictelescope-3954", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-magictelescope-3954-073", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.0036782410255423894, "booster": "gbtree", "colsample_bylevel": 0.852248253766447, "colsample_bytree": 0.6506674228537833, "eta": 0.012866160085731103, "lambda": 3.121337086584491, "max_depth": 9, "min_child_weight": 4.289040868685827, "nrounds": 2571, "subsample": 0.401575846760534}}}], "metrics": 0.884437, "context": "openml-magictelescope-3954", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-magictelescope-3954-075", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 5.295242139262362, "booster": "gbtree", "colsample_bylevel": 0.836961450986564, "colsample_bytree": 0.4257700892001392, "eta": 0.036000555972180125, "lambda": 1.32745558525658, "max_depth": 15, "min_child_weight": 2.0091690538764895, "nrounds": 3799, "subsample": 0.659558725217357}}}], "metrics": 0.884332, "context": "openml-magictelescope-3954", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-magictelescope-3954-068", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 1.2445263245024887, "booster": "gbtree", "colsample_bylevel": 0.922887159977108, "colsample_bytree": 0.4934949699625369, "eta": 0.038752649707182486, "lambda": 0.023013665709488908, "max_depth": 6, "min_child_weight": 1.5037207448165406, "nrounds": 3430, "subsample": 0.402183824544773}}}], "metrics": 0.883123, "context": "openml-magictelescope-3954", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-click-prediction-small-7295-071", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.002005979779025521, "booster": "gbtree", "colsample_bylevel": 0.586125797824934, "colsample_bytree": 0.9227260944269603, "eta": 0.008804476800752971, "lambda": 4.1089790274337, "max_depth": 5, "min_child_weight": 10.825008743766606, "nrounds": 3164, "subsample": 0.539869710826315}}}], "metrics": 0.837188, "context": "openml-click-prediction-small-7295", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-click-prediction-small-7295-074", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.00213907751348201, "booster": "gbtree", "colsample_bylevel": 0.414045373210683, "colsample_bytree": 0.9130223620984699, "eta": 0.0023109454118521587, "lambda": 0.16141263077542703, "max_depth": 9, "min_child_weight": 6.310662049759124, "nrounds": 3254, "subsample": 0.62122659557499}}}], "metrics": 0.837163, "context": "openml-click-prediction-small-7295", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-click-prediction-small-7295-060", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.08903156943870752, "booster": "gbtree", "colsample_bylevel": 0.71090942947194, "colsample_bytree": 0.25603907106667806, "eta": 0.03513645552279111, "lambda": 5.171116113705849, "max_depth": 5, "min_child_weight": 2.121966555791279, "nrounds": 2608, "subsample": 0.384208759432659}}}], "metrics": 0.836788, "context": "openml-click-prediction-small-7295", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-click-prediction-small-7295-070", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 24.343136424041898, "booster": "gbtree", "colsample_bylevel": 0.755560805322602, "colsample_bytree": 0.4762956818401813, "eta": 0.09871456667838775, "lambda": 0.24091343415181596, "max_depth": 5, "min_child_weight": 1.7432699023415097, "nrounds": 3150, "subsample": 0.590285751991905}}}], "metrics": 0.836537, "context": "openml-click-prediction-small-7295", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-click-prediction-small-7295-068", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.011926680522378703, "booster": "gbtree", "colsample_bylevel": 0.67510042572394, "colsample_bytree": 0.35526215069219513, "eta": 0.0326607187377423, "lambda": 1.00201798150172, "max_depth": 9, "min_child_weight": 98.60878650569403, "nrounds": 2661, "subsample": 0.429877504799515}}}], "metrics": 0.835486, "context": "openml-click-prediction-small-7295", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-tic-tac-toe-49-069", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.002603960827643579, "booster": "gbtree", "colsample_bylevel": 0.382702940842137, "colsample_bytree": 0.7463216007988901, "eta": 0.17699427353409897, "lambda": 2.166082881181581, "max_depth": 5, "min_child_weight": 5.297366069619215, "nrounds": 2384, "subsample": 0.418491745670326}}}], "metrics": 0.970772, "context": "openml-tic-tac-toe-49", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-tic-tac-toe-49-042", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.0273371051319551, "booster": "gbtree", "colsample_bylevel": 0.960104375146329, "colsample_bytree": 0.9652793956290932, "eta": 0.04113131372297749, "lambda": 5.190290080776234, "max_depth": 3, "min_child_weight": 12.433608871875888, "nrounds": 2966, "subsample": 0.470116829220206}}}], "metrics": 0.931106, "context": "openml-tic-tac-toe-49", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-tic-tac-toe-49-010", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 1.969841508343052, "booster": "gbtree", "colsample_bylevel": 0.412468777270988, "colsample_bytree": 0.8312927833128727, "eta": 0.30690288641169217, "lambda": 0.006528793159624181, "max_depth": 5, "min_child_weight": 13.434992620167607, "nrounds": 607, "subsample": 0.44537687485572}}}], "metrics": 0.9238, "context": "openml-tic-tac-toe-49", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-tic-tac-toe-49-068", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.0012354622246570999, "booster": "gbtree", "colsample_bylevel": 0.94088944606483, "colsample_bytree": 0.5470551298301669, "eta": 0.0034116745338443307, "lambda": 2.6504561883323876, "max_depth": 4, "min_child_weight": 1.1622340274255096, "nrounds": 3317, "subsample": 0.764468772965483}}}], "metrics": 0.909186, "context": "openml-tic-tac-toe-49", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-tic-tac-toe-49-033", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.009131652120313069, "booster": "gbtree", "colsample_bylevel": 0.291849835310131, "colsample_bytree": 0.5601477987900382, "eta": 0.002679617705207359, "lambda": 0.322554327844557, "max_depth": 10, "min_child_weight": 3.7390008413321985, "nrounds": 3438, "subsample": 0.908531895116903}}}], "metrics": 0.88309, "context": "openml-tic-tac-toe-49", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-bank-marketing-14965-062", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 19.168812044365897, "booster": "gbtree", "colsample_bylevel": 0.782732020365074, "colsample_bytree": 0.8765275796711438, "eta": 0.019433018430590997, "lambda": 0.03197797319257331, "max_depth": 8, "min_child_weight": 2.1482833834435104, "nrounds": 1864, "subsample": 0.518781493091956}}}], "metrics": 0.90896, "context": "openml-bank-marketing-14965", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-bank-marketing-14965-061", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 9.62352178861721, "booster": "gbtree", "colsample_bylevel": 0.581934942863882, "colsample_bytree": 0.8394317209556698, "eta": 0.09653354928243899, "lambda": 35.78556646229405, "max_depth": 10, "min_child_weight": 4.1040733338735285, "nrounds": 216, "subsample": 0.618067663931288}}}], "metrics": 0.908739, "context": "openml-bank-marketing-14965", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-bank-marketing-14965-045", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.04589848592779032, "booster": "gbtree", "colsample_bylevel": 0.612251700600609, "colsample_bytree": 0.5806135262198752, "eta": 0.028106658081255106, "lambda": 126.00783417667093, "max_depth": 9, "min_child_weight": 2.6695209959607302, "nrounds": 2252, "subsample": 0.300700055318885}}}], "metrics": 0.907788, "context": "openml-bank-marketing-14965", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-bank-marketing-14965-082", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 2.4383678092755203, "booster": "gbtree", "colsample_bylevel": 0.797875796910375, "colsample_bytree": 0.5591637880377467, "eta": 0.00281808439023746, "lambda": 24.0877318140115, "max_depth": 14, "min_child_weight": 4.217462452680808, "nrounds": 4121, "subsample": 0.725665916479193}}}], "metrics": 0.907788, "context": "openml-bank-marketing-14965", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-bank-marketing-14965-083", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 5.24561943962875, "booster": "gbtree", "colsample_bylevel": 0.763844408094883, "colsample_bytree": 0.7142213368158796, "eta": 0.010678842957750697, "lambda": 0.0011302848879811299, "max_depth": 14, "min_child_weight": 5.917287740300886, "nrounds": 4004, "subsample": 0.805185489729047}}}], "metrics": 0.90708, "context": "openml-bank-marketing-14965", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-eeg-eye-state-14951-086", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.0033470924134329913, "booster": "gbtree", "colsample_bylevel": 0.996396246599033, "colsample_bytree": 0.9582583996769033, "eta": 0.3512137142713511, "lambda": 28.600477820868715, "max_depth": 9, "min_child_weight": 1.4007379040950703, "nrounds": 3956, "subsample": 0.997209113324061}}}], "metrics": 0.954406, "context": "openml-eeg-eye-state-14951", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-eeg-eye-state-14951-071", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.23658137073921787, "booster": "gbtree", "colsample_bylevel": 0.218295002589002, "colsample_bytree": 0.9885779984131468, "eta": 0.049928029820597034, "lambda": 0.0034224418233151396, "max_depth": 13, "min_child_weight": 14.172061014781603, "nrounds": 1850, "subsample": 0.418183350097388}}}], "metrics": 0.932377, "context": "openml-eeg-eye-state-14951", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-eeg-eye-state-14951-072", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 6.773064157952582, "booster": "gbtree", "colsample_bylevel": 0.291071980493143, "colsample_bytree": 0.44222142028845823, "eta": 0.741184925880219, "lambda": 0.004563699344508289, "max_depth": 11, "min_child_weight": 1.5541479724870186, "nrounds": 4898, "subsample": 0.883547384268604}}}], "metrics": 0.917089, "context": "openml-eeg-eye-state-14951", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-eeg-eye-state-14951-080", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 12.64636160096159, "booster": "gbtree", "colsample_bylevel": 0.461212193360552, "colsample_bytree": 0.7756478983744984, "eta": 0.016766766777840607, "lambda": 0.056868272434329493, "max_depth": 10, "min_child_weight": 8.542043176178035, "nrounds": 2442, "subsample": 0.474594412557781}}}], "metrics": 0.907944, "context": "openml-eeg-eye-state-14951", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-eeg-eye-state-14951-069", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 2.487107953657649, "booster": "gbtree", "colsample_bylevel": 0.679319896735251, "colsample_bytree": 0.21622703893333706, "eta": 0.49406966725051715, "lambda": 16.228301947892806, "max_depth": 8, "min_child_weight": 47.706487076348026, "nrounds": 2454, "subsample": 0.793049090728164}}}], "metrics": 0.904473, "context": "openml-eeg-eye-state-14951", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-credit-g-31-042", "modules": [{"role": "dataset", "module": "openml-credit-g-31"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.03772737701749708, "booster": "gbtree", "colsample_bylevel": 0.461029773578048, "colsample_bytree": 0.9966655382256958, "eta": 0.004913620781179708, "lambda": 0.0018936447714247597, "max_depth": 10, "min_child_weight": 6.836768104846077, "nrounds": 1845, "subsample": 0.819516016589478}}}], "metrics": 0.766, "context": "openml-credit-g-31", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-credit-g-31-083", "modules": [{"role": "dataset", "module": "openml-credit-g-31"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.11610053936431193, "booster": "gbtree", "colsample_bylevel": 0.492663845652714, "colsample_bytree": 0.4751675777904689, "eta": 0.03166574017443191, "lambda": 35.8401365085389, "max_depth": 4, "min_child_weight": 6.932569988803825, "nrounds": 2288, "subsample": 0.76470084649045}}}], "metrics": 0.765, "context": "openml-credit-g-31", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-credit-g-31-028", "modules": [{"role": "dataset", "module": "openml-credit-g-31"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.01826272545109499, "booster": "gbtree", "colsample_bylevel": 0.261871548835188, "colsample_bytree": 0.3144522031605239, "eta": 0.007899917858796658, "lambda": 0.03297737833271949, "max_depth": 7, "min_child_weight": 4.812029107646558, "nrounds": 2925, "subsample": 0.278409302281216}}}], "metrics": 0.764, "context": "openml-credit-g-31", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-credit-g-31-037", "modules": [{"role": "dataset", "module": "openml-credit-g-31"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.013417571313116999, "booster": "gbtree", "colsample_bylevel": 0.682283690432087, "colsample_bytree": 0.5531534312129018, "eta": 0.43792099139041385, "lambda": 764.7343449721596, "max_depth": 13, "min_child_weight": 2.8415373410330322, "nrounds": 2799, "subsample": 0.412174034724012}}}], "metrics": 0.764, "context": "openml-credit-g-31", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-credit-g-31-086", "modules": [{"role": "dataset", "module": "openml-credit-g-31"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.5699694446183298, "booster": "gbtree", "colsample_bylevel": 0.21060974127613, "colsample_bytree": 0.5630186120349915, "eta": 0.0013978238593370998, "lambda": 0.005347067811551901, "max_depth": 7, "min_child_weight": 2.1764593568282904, "nrounds": 4517, "subsample": 0.274055549828336}}}], "metrics": 0.757, "context": "openml-credit-g-31", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-australian-125923-025", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.00156934710032502, "booster": "gbtree", "colsample_bylevel": 0.641734143951908, "colsample_bytree": 0.7747323219034816, "eta": 0.0793596276849303, "lambda": 0.5156480376602618, "max_depth": 14, "min_child_weight": 1.5958161163909892, "nrounds": 1769, "subsample": 0.946632027928717}}}], "metrics": 0.875362, "context": "openml-australian-125923", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-australian-125923-058", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 6.068385751453557, "booster": "gbtree", "colsample_bylevel": 0.956311105517671, "colsample_bytree": 0.9423524480614816, "eta": 0.04588784497546372, "lambda": 0.003162060978716789, "max_depth": 9, "min_child_weight": 1.4556827923879003, "nrounds": 3642, "subsample": 0.900513026840054}}}], "metrics": 0.873913, "context": "openml-australian-125923", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-australian-125923-030", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 11.647171142942609, "booster": "gblinear", "eta": 0.0012308545547454405, "lambda": 2.4011964892875306, "nrounds": 776, "subsample": 0.194270332274027}}}], "metrics": 0.873913, "context": "openml-australian-125923", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-australian-125923-024", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.003632123484876109, "booster": "gbtree", "colsample_bylevel": 0.724164266139269, "colsample_bytree": 0.4237784062813973, "eta": 0.009276603312470842, "lambda": 0.12934548591605796, "max_depth": 10, "min_child_weight": 5.550538074880406, "nrounds": 1337, "subsample": 0.562036123988219}}}], "metrics": 0.871014, "context": "openml-australian-125923", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-australian-125923-071", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.09107053667808174, "booster": "gbtree", "colsample_bylevel": 0.502826999407262, "colsample_bytree": 0.4146229738205667, "eta": 0.00128767190519662, "lambda": 6.575855921507169, "max_depth": 9, "min_child_weight": 1.9282912312695786, "nrounds": 3913, "subsample": 0.174314644397236}}}], "metrics": 0.869565, "context": "openml-australian-125923", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-kr-vs-kp-3-063", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 2.5735375246095313, "booster": "gbtree", "colsample_bylevel": 0.380757444771007, "colsample_bytree": 0.8381026421509681, "eta": 0.016394427072065204, "lambda": 0.26523282494766787, "max_depth": 7, "min_child_weight": 1.1375543251587292, "nrounds": 1737, "subsample": 0.370973052666523}}}], "metrics": 0.984355, "context": "openml-kr-vs-kp-3", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-kr-vs-kp-3-050", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.00992050597068936, "booster": "gblinear", "eta": 0.6149986258685771, "lambda": 0.013537148109787104, "nrounds": 2951, "subsample": 0.108093228121288}}}], "metrics": 0.969337, "context": "openml-kr-vs-kp-3", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-kr-vs-kp-3-090", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.045419828927767934, "booster": "gbtree", "colsample_bylevel": 0.776946167927235, "colsample_bytree": 0.7022696162410075, "eta": 0.0023757038830585406, "lambda": 19.513995413201012, "max_depth": 12, "min_child_weight": 7.625880710770496, "nrounds": 2551, "subsample": 0.774994043819606}}}], "metrics": 0.969024, "context": "openml-kr-vs-kp-3", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-kr-vs-kp-3-009", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.031846376726771194, "booster": "gbtree", "colsample_bylevel": 0.543454693397507, "colsample_bytree": 0.17930012446120394, "eta": 0.09156810239382833, "lambda": 0.002656724416506819, "max_depth": 8, "min_child_weight": 7.5008253926717865, "nrounds": 421, "subsample": 0.690730725345202}}}], "metrics": 0.965269, "context": "openml-kr-vs-kp-3", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-kr-vs-kp-3-043", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 16.7388979105274, "booster": "gbtree", "colsample_bylevel": 0.48656514310278, "colsample_bytree": 0.672011617042497, "eta": 0.7997971759073478, "lambda": 117.55069852690312, "max_depth": 11, "min_child_weight": 3.5183901050408477, "nrounds": 3335, "subsample": 0.646828697621822}}}], "metrics": 0.96433, "context": "openml-kr-vs-kp-3", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-pc4-3902-020", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.00226769099733653, "booster": "gblinear", "eta": 0.12888470660592297, "lambda": 1.2939701610613912, "nrounds": 3265, "subsample": 0.726508753723465}}}], "metrics": 0.91358, "context": "openml-pc4-3902", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-pc4-3902-091", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.20101315308658202, "booster": "gbtree", "colsample_bylevel": 0.739424327155575, "colsample_bytree": 0.4832050550565123, "eta": 0.022191088371091, "lambda": 0.43272967118434785, "max_depth": 5, "min_child_weight": 2.5773129674206308, "nrounds": 3228, "subsample": 0.680848344787955}}}], "metrics": 0.912894, "context": "openml-pc4-3902", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-pc4-3902-019", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.0013463412036204903, "booster": "gblinear", "eta": 0.22850906939573704, "lambda": 0.3895678149160848, "nrounds": 1338, "subsample": 0.649031047499739}}}], "metrics": 0.912894, "context": "openml-pc4-3902", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-pc4-3902-026", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.048229773455178114, "booster": "gblinear", "eta": 0.09869909373690937, "lambda": 0.5717105594587871, "nrounds": 3448, "subsample": 0.365934970835224}}}], "metrics": 0.912209, "context": "openml-pc4-3902", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-pc4-3902-084", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 1.1280604585124787, "booster": "gblinear", "eta": 0.280256818150395, "lambda": 26.098763750303203, "nrounds": 4400, "subsample": 0.126106453943066}}}], "metrics": 0.911523, "context": "openml-pc4-3902", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-qsar-biodeg-9957-028", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 2.533639192822499, "booster": "gbtree", "colsample_bylevel": 0.680048706708476, "colsample_bytree": 0.186814258044958, "eta": 0.050893276975467715, "lambda": 8.37759451925196, "max_depth": 7, "min_child_weight": 1.318030340425391, "nrounds": 4728, "subsample": 0.905142770847306}}}], "metrics": 0.876777, "context": "openml-qsar-biodeg-9957", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-qsar-biodeg-9957-085", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.030559329278146807, "booster": "gbtree", "colsample_bylevel": 0.495337036671117, "colsample_bytree": 0.41761739755272875, "eta": 0.009386537492077653, "lambda": 0.06387008344895631, "max_depth": 9, "min_child_weight": 2.6214940104535303, "nrounds": 3051, "subsample": 0.436657604272477}}}], "metrics": 0.872986, "context": "openml-qsar-biodeg-9957", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-qsar-biodeg-9957-083", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.16285213640320395, "booster": "gbtree", "colsample_bylevel": 0.538378939498216, "colsample_bytree": 0.8895092496484516, "eta": 0.0203147483662121, "lambda": 0.7857750803705943, "max_depth": 15, "min_child_weight": 5.7297873629927665, "nrounds": 881, "subsample": 0.599884665175341}}}], "metrics": 0.87109, "context": "openml-qsar-biodeg-9957", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-qsar-biodeg-9957-084", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 1.0039142135845498, "booster": "gbtree", "colsample_bylevel": 0.932097347453237, "colsample_bytree": 0.18280143610425298, "eta": 0.0256144349984194, "lambda": 0.013049743839562204, "max_depth": 9, "min_child_weight": 4.030828343148979, "nrounds": 2215, "subsample": 0.442717001936399}}}], "metrics": 0.870142, "context": "openml-qsar-biodeg-9957", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-qsar-biodeg-9957-090", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.0385403919617513, "booster": "gbtree", "colsample_bylevel": 0.438269004691392, "colsample_bytree": 0.1803065754309301, "eta": 0.004013058947216741, "lambda": 1.1772862283013492, "max_depth": 11, "min_child_weight": 1.808953077173589, "nrounds": 2833, "subsample": 0.807001672545448}}}], "metrics": 0.869194, "context": "openml-qsar-biodeg-9957", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-steel-plates-fault-9967-092", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.0055118732454551385, "booster": "gbtree", "colsample_bylevel": 0.859555108239874, "colsample_bytree": 0.9336191592108463, "eta": 0.23500538345349697, "lambda": 663.0614535203191, "max_depth": 10, "min_child_weight": 1.4204968532701097, "nrounds": 4537, "subsample": 0.637583491322584}}}], "metrics": 0.999485, "context": "openml-steel-plates-fault-9967", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-steel-plates-fault-9967-071", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.20749810954305387, "booster": "gbtree", "colsample_bylevel": 0.712474268861115, "colsample_bytree": 0.5566901987720279, "eta": 0.05062796162180368, "lambda": 0.18354459044635305, "max_depth": 5, "min_child_weight": 1.0419814853118008, "nrounds": 1911, "subsample": 0.645748317451216}}}], "metrics": 0.999485, "context": "openml-steel-plates-fault-9967", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-steel-plates-fault-9967-043", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.11057558556951305, "booster": "gblinear", "eta": 0.0483395556073428, "lambda": 0.04604886337629481, "nrounds": 1133, "subsample": 0.878401754866354}}}], "metrics": 0.999485, "context": "openml-steel-plates-fault-9967", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-steel-plates-fault-9967-028", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.5393097838583192, "booster": "gblinear", "eta": 0.007296647123690291, "lambda": 0.08325501702427204, "nrounds": 4447, "subsample": 0.417648193240166}}}], "metrics": 0.999485, "context": "openml-steel-plates-fault-9967", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-steel-plates-fault-9967-049", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.9126529824710391, "booster": "gbtree", "colsample_bylevel": 0.590937652159482, "colsample_bytree": 0.4068308639641847, "eta": 0.15300501409095893, "lambda": 0.4003616246266329, "max_depth": 1, "min_child_weight": 3.697288182279319, "nrounds": 3369, "subsample": 0.775979626341723}}}], "metrics": 0.999485, "context": "openml-steel-plates-fault-9967", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-eeg-eye-state-9983-090", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.30529792391468796, "booster": "gbtree", "colsample_bylevel": 0.719203668180853, "colsample_bytree": 0.8279847157489516, "eta": 0.0317833178045075, "lambda": 0.015427092487961102, "max_depth": 14, "min_child_weight": 3.136933894293288, "nrounds": 2005, "subsample": 0.818819764791988}}}], "metrics": 0.955607, "context": "openml-eeg-eye-state-9983", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-eeg-eye-state-9983-048", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.324757553895454, "booster": "gbtree", "colsample_bylevel": 0.353787096450105, "colsample_bytree": 0.9415038842078304, "eta": 0.09248922111299805, "lambda": 0.12450464322615294, "max_depth": 8, "min_child_weight": 12.881155164548998, "nrounds": 3623, "subsample": 0.82166205055546}}}], "metrics": 0.94466, "context": "openml-eeg-eye-state-9983", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-eeg-eye-state-9983-026", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 3.2380659148336735, "booster": "gbtree", "colsample_bylevel": 0.407982904696837, "colsample_bytree": 0.7275518953636295, "eta": 0.5274730611702031, "lambda": 51.27838590317318, "max_depth": 13, "min_child_weight": 8.979001632091276, "nrounds": 1629, "subsample": 0.628658038075082}}}], "metrics": 0.938385, "context": "openml-eeg-eye-state-9983", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-eeg-eye-state-9983-088", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.002257152763869319, "booster": "gbtree", "colsample_bylevel": 0.581344343489036, "colsample_bytree": 0.8836125372279445, "eta": 0.047466643497804606, "lambda": 0.03892930352924008, "max_depth": 9, "min_child_weight": 17.155051276913, "nrounds": 1676, "subsample": 0.5873217169893908}}}], "metrics": 0.938318, "context": "openml-eeg-eye-state-9983", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-eeg-eye-state-9983-065", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.7847182525281521, "booster": "gbtree", "colsample_bylevel": 0.744496963452548, "colsample_bytree": 0.48294034826792825, "eta": 0.17583784924377904, "lambda": 0.0169218150815381, "max_depth": 11, "min_child_weight": 13.564925625664799, "nrounds": 472, "subsample": 0.643167744670063}}}], "metrics": 0.934179, "context": "openml-eeg-eye-state-9983", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-kc1-3917-009", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.46665632737579393, "booster": "gblinear", "eta": 0.011260854874791205, "lambda": 0.09513243421201872, "nrounds": 1402, "subsample": 0.337876537605189}}}], "metrics": 0.862494, "context": "openml-kc1-3917", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-kc1-3917-013", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.00182654229756236, "booster": "gblinear", "eta": 0.00515843744270885, "lambda": 0.08734953913909065, "nrounds": 2751, "subsample": 0.561404404882342}}}], "metrics": 0.862494, "context": "openml-kc1-3917", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-kc1-3917-092", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.15741529502304896, "booster": "gbtree", "colsample_bylevel": 0.665942745516077, "colsample_bytree": 0.9500364153016366, "eta": 0.14619275780732602, "lambda": 470.09075660509205, "max_depth": 14, "min_child_weight": 2.6693183942929486, "nrounds": 4466, "subsample": 0.55077370875515}}}], "metrics": 0.862494, "context": "openml-kc1-3917", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-kc1-3917-059", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.0239912719929399, "booster": "gblinear", "eta": 0.014553255038681798, "lambda": 0.14471957801940297, "nrounds": 1134, "subsample": 0.630064751091413}}}], "metrics": 0.862494, "context": "openml-kc1-3917", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-kc1-3917-017", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.5863907676928503, "booster": "gblinear", "eta": 0.13727465846934203, "lambda": 121.22390175525905, "nrounds": 664, "subsample": 0.585144186555408}}}], "metrics": 0.861072, "context": "openml-kc1-3917", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-ozone-level-8hr-9978-070", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.12978223407813294, "booster": "gbtree", "colsample_bylevel": 0.131621553562582, "colsample_bytree": 0.4464406994473194, "eta": 0.106015830664345, "lambda": 0.045267619890671025, "max_depth": 9, "min_child_weight": 1.1587869415449088, "nrounds": 3177, "subsample": 0.893253343156539}}}], "metrics": 0.94633, "context": "openml-ozone-level-8hr-9978", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-ozone-level-8hr-9978-043", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 3.215973374782382, "booster": "gbtree", "colsample_bylevel": 0.887286017881706, "colsample_bytree": 0.37227401736415894, "eta": 0.2943904051663521, "lambda": 726.467179436072, "max_depth": 5, "min_child_weight": 14.425957412338285, "nrounds": 2735, "subsample": 0.838644810859114}}}], "metrics": 0.945935, "context": "openml-ozone-level-8hr-9978", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-ozone-level-8hr-9978-076", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 4.325873002249429, "booster": "gbtree", "colsample_bylevel": 0.143968381686136, "colsample_bytree": 0.7096768733415749, "eta": 0.4322827999665259, "lambda": 0.003494896294031251, "max_depth": 12, "min_child_weight": 6.222081474437483, "nrounds": 2730, "subsample": 0.979351750458591}}}], "metrics": 0.945935, "context": "openml-ozone-level-8hr-9978", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-ozone-level-8hr-9978-026", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.0016308982483165405, "booster": "gbtree", "colsample_bylevel": 0.693350369110703, "colsample_bytree": 0.2798679228242487, "eta": 0.022476126219097507, "lambda": 0.0040939723732695485, "max_depth": 12, "min_child_weight": 2.8167611639702517, "nrounds": 527, "subsample": 0.261353994300589}}}], "metrics": 0.945935, "context": "openml-ozone-level-8hr-9978", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-ozone-level-8hr-9978-059", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.04361922293398679, "booster": "gbtree", "colsample_bylevel": 0.0627333496231586, "colsample_bytree": 0.2700103057384489, "eta": 0.029119446547717802, "lambda": 0.05924677704020251, "max_depth": 7, "min_child_weight": 8.272953992270715, "nrounds": 3963, "subsample": 0.473246817104518}}}], "metrics": 0.944751, "context": "openml-ozone-level-8hr-9978", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-gina-agnostic-3891-069", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.013728788105443994, "booster": "gbtree", "colsample_bylevel": 0.158955389168113, "colsample_bytree": 0.4372392002794892, "eta": 0.0024823860566913205, "lambda": 0.03561493206248759, "max_depth": 6, "min_child_weight": 9.053827654272972, "nrounds": 3546, "subsample": 0.978356791310944}}}], "metrics": 0.94925, "context": "openml-gina-agnostic-3891", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-gina-agnostic-3891-098", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.025711699802504706, "booster": "gbtree", "colsample_bylevel": 0.858495340216905, "colsample_bytree": 0.8102171983871607, "eta": 0.001638894187658, "lambda": 0.047342305881502, "max_depth": 13, "min_child_weight": 1.3912824030643494, "nrounds": 3107, "subsample": 0.731465183873661}}}], "metrics": 0.948674, "context": "openml-gina-agnostic-3891", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-gina-agnostic-3891-048", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 5.279640694206429, "booster": "gbtree", "colsample_bylevel": 0.963933609658852, "colsample_bytree": 0.22010010684132592, "eta": 0.0285994021892966, "lambda": 0.0012964533563878905, "max_depth": 5, "min_child_weight": 5.7330939873403, "nrounds": 1370, "subsample": 0.906248615239747}}}], "metrics": 0.948674, "context": "openml-gina-agnostic-3891", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-gina-agnostic-3891-042", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.0019668819454154007, "booster": "gbtree", "colsample_bylevel": 0.687665317207575, "colsample_bytree": 0.0754054968081415, "eta": 0.016837917117610894, "lambda": 0.002149154550600871, "max_depth": 15, "min_child_weight": 6.116392102885171, "nrounds": 1832, "subsample": 0.528249442391098}}}], "metrics": 0.947232, "context": "openml-gina-agnostic-3891", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-gina-agnostic-3891-055", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.2195879314640279, "booster": "gbtree", "colsample_bylevel": 0.48389476747252, "colsample_bytree": 0.20041545357778703, "eta": 0.0026511542075871304, "lambda": 0.08315625263928066, "max_depth": 14, "min_child_weight": 7.300575629422995, "nrounds": 1601, "subsample": 0.90430139687378}}}], "metrics": 0.944637, "context": "openml-gina-agnostic-3891", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-wilt-9889-087", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.019645933617742396, "booster": "gbtree", "colsample_bylevel": 0.791225395398214, "colsample_bytree": 0.9592072052717204, "eta": 0.27448594608941107, "lambda": 110.69071145555102, "max_depth": 10, "min_child_weight": 11.609601924909803, "nrounds": 880, "subsample": 0.908761015278287}}}], "metrics": 0.984088, "context": "openml-wilt-9889", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-wilt-9889-059", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 1.8563513086707275, "booster": "gbtree", "colsample_bylevel": 0.856054452480748, "colsample_bytree": 0.9979806760627775, "eta": 0.2115777414274409, "lambda": 0.007054733883940629, "max_depth": 5, "min_child_weight": 12.62593315132799, "nrounds": 2062, "subsample": 0.865944417612627}}}], "metrics": 0.983674, "context": "openml-wilt-9889", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-wilt-9889-068", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.16922126432294896, "booster": "gbtree", "colsample_bylevel": 0.734106219606474, "colsample_bytree": 0.5274945501539856, "eta": 0.149821558381841, "lambda": 1.8718774199901713, "max_depth": 7, "min_child_weight": 8.614857372054157, "nrounds": 2361, "subsample": 0.923829327942803}}}], "metrics": 0.983674, "context": "openml-wilt-9889", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-wilt-9889-072", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.0887486502991941, "booster": "gbtree", "colsample_bylevel": 0.950483019696549, "colsample_bytree": 0.47960572357513026, "eta": 0.03318983678499481, "lambda": 0.19664422722132094, "max_depth": 5, "min_child_weight": 5.000313234700498, "nrounds": 1844, "subsample": 0.318628505105153}}}], "metrics": 0.983261, "context": "openml-wilt-9889", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-wilt-9889-008", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.00110351796337152, "booster": "gbtree", "colsample_bylevel": 0.878167688613757, "colsample_bytree": 0.45897490920722467, "eta": 0.17698271615577793, "lambda": 0.0012010364008812205, "max_depth": 8, "min_child_weight": 4.412908119624422, "nrounds": 568, "subsample": 0.682949580415152}}}], "metrics": 0.982641, "context": "openml-wilt-9889", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-monks-problems-3-3494-098", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.23569232869099607, "booster": "gbtree", "colsample_bylevel": 0.964990551350638, "colsample_bytree": 0.5592727478895338, "eta": 0.004818164176996411, "lambda": 2.3836428979051703, "max_depth": 13, "min_child_weight": 1.7213978385728297, "nrounds": 3473, "subsample": 0.875061537954025}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-monks-problems-3-3494-072", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.024603714549896, "booster": "gbtree", "colsample_bylevel": 0.99936268129386, "colsample_bytree": 0.9970461488071827, "eta": 0.587726500954524, "lambda": 0.08605365496027426, "max_depth": 14, "min_child_weight": 2.6022401407193523, "nrounds": 4708, "subsample": 0.749953023856506}}}], "metrics": 0.987365, "context": "openml-monks-problems-3-3494", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-monks-problems-3-3494-075", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 4.830806450271533, "booster": "gbtree", "colsample_bylevel": 0.464290518313646, "colsample_bytree": 0.9221733211841427, "eta": 0.28847379473436685, "lambda": 0.010464613775354601, "max_depth": 11, "min_child_weight": 1.8115899333743912, "nrounds": 1703, "subsample": 0.816196149890311}}}], "metrics": 0.983755, "context": "openml-monks-problems-3-3494", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-monks-problems-3-3494-109", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.18929002629702196, "booster": "gbtree", "colsample_bylevel": 0.292096439749002, "colsample_bytree": 0.8315444604329763, "eta": 0.0250135236814867, "lambda": 0.24236323875735, "max_depth": 13, "min_child_weight": 4.3650241404666215, "nrounds": 2346, "subsample": 0.821325435419567}}}], "metrics": 0.976534, "context": "openml-monks-problems-3-3494", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-monks-problems-3-3494-146", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.0024391493769767496, "booster": "gbtree", "colsample_bylevel": 0.743491229834035, "colsample_bytree": 0.9210827438462532, "eta": 0.035970663731395514, "lambda": 6.96107729451525, "max_depth": 12, "min_child_weight": 3.8153102338520015, "nrounds": 3211, "subsample": 0.560734787629917}}}], "metrics": 0.972924, "context": "openml-monks-problems-3-3494", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-diabetes-37-012", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.001923871622211431, "booster": "gblinear", "eta": 0.10611944958489597, "lambda": 0.0328977574205693, "nrounds": 1369, "subsample": 0.498716102028266}}}], "metrics": 0.779948, "context": "openml-diabetes-37", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-diabetes-37-118", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.9372306523931021, "booster": "gblinear", "eta": 0.027714510320110897, "lambda": 13.217005803934402, "nrounds": 4316, "subsample": 0.346896798349917}}}], "metrics": 0.777344, "context": "openml-diabetes-37", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-diabetes-37-144", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.002174077164625781, "booster": "gblinear", "eta": 0.135226324716128, "lambda": 0.006533232793638622, "nrounds": 2001, "subsample": 0.845361991575919}}}], "metrics": 0.776042, "context": "openml-diabetes-37", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-diabetes-37-034", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.07247249359341193, "booster": "gblinear", "eta": 0.227493772500104, "lambda": 0.028790884279075696, "nrounds": 4395, "subsample": 0.365501356334425}}}], "metrics": 0.776042, "context": "openml-diabetes-37", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-diabetes-37-076", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.10140172409467897, "booster": "gblinear", "eta": 0.3282525461790379, "lambda": 0.16376122668992998, "nrounds": 4284, "subsample": 0.173468217602931}}}], "metrics": 0.776042, "context": "openml-diabetes-37", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-ada-agnostic-3896-077", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.0025834246680695705, "booster": "gbtree", "colsample_bylevel": 0.149227689020336, "colsample_bytree": 0.4800358965829011, "eta": 0.005872239926756973, "lambda": 2.1031335060842107, "max_depth": 7, "min_child_weight": 1.7327361233014698, "nrounds": 2163, "subsample": 0.827655210020021}}}], "metrics": 0.855984, "context": "openml-ada-agnostic-3896", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-ada-agnostic-3896-184", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 1.2765773255046895, "booster": "gbtree", "colsample_bylevel": 0.513664929196239, "colsample_bytree": 0.320355910977721, "eta": 0.006480247908201518, "lambda": 15.40286237808629, "max_depth": 4, "min_child_weight": 1.1190474740336112, "nrounds": 3978, "subsample": 0.534818493085913}}}], "metrics": 0.855327, "context": "openml-ada-agnostic-3896", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-ada-agnostic-3896-148", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.04634541359137841, "booster": "gbtree", "colsample_bylevel": 0.702233196469024, "colsample_bytree": 0.511914597761258, "eta": 0.013989748026350498, "lambda": 0.22110739248166394, "max_depth": 14, "min_child_weight": 1.7233339488271984, "nrounds": 245, "subsample": 0.639630007580854}}}], "metrics": 0.853135, "context": "openml-ada-agnostic-3896", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-ada-agnostic-3896-027", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 10.755251750518203, "booster": "gbtree", "colsample_bylevel": 0.497375167673454, "colsample_bytree": 0.576200340811536, "eta": 0.15477169951257103, "lambda": 0.0012318327426661003, "max_depth": 8, "min_child_weight": 7.414210734955297, "nrounds": 498, "subsample": 0.404649597313255}}}], "metrics": 0.851162, "context": "openml-ada-agnostic-3896", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-xgboost-5906-openml-ada-agnostic-3896-006", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5906", "config": {"alpha": 0.007560669809348313, "booster": "gbtree", "colsample_bylevel": 0.487400314072147, "colsample_bytree": 0.113724359946698, "eta": 0.013443756325055694, "lambda": 0.9788371465036999, "max_depth": 11, "min_child_weight": 1.4042785662806891, "nrounds": 1016, "subsample": 0.202171710995026}}}], "metrics": 0.850943, "context": "openml-ada-agnostic-3896", "schema": "xgboost-5906", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-musk-3950-001", "modules": [{"role": "dataset", "module": "openml-musk-3950"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 30, "num.trees": 14, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.335174921550788}}}], "metrics": 1.0, "context": "openml-musk-3950", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-musk-3950-340", "modules": [{"role": "dataset", "module": "openml-musk-3950"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 120, "num.trees": 1496, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.883394121169113}}}], "metrics": 1.0, "context": "openml-musk-3950", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-musk-3950-330", "modules": [{"role": "dataset", "module": "openml-musk-3950"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 72, "num.trees": 1913, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.343879867251962}}}], "metrics": 1.0, "context": "openml-musk-3950", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-musk-3950-332", "modules": [{"role": "dataset", "module": "openml-musk-3950"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 37, "num.trees": 1494, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.426777447015047}}}], "metrics": 1.0, "context": "openml-musk-3950", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-musk-3950-334", "modules": [{"role": "dataset", "module": "openml-musk-3950"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 145, "num.trees": 1760, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.275613462529145}}}], "metrics": 1.0, "context": "openml-musk-3950", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-credit-g-146803-149", "modules": [{"role": "dataset", "module": "openml-credit-g-146803"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 3, "mtry": 16, "num.trees": 590, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.316219836566597}}}], "metrics": 0.779, "context": "openml-credit-g-146803", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-credit-g-146803-415", "modules": [{"role": "dataset", "module": "openml-credit-g-146803"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 4, "mtry": 10, "num.trees": 245, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.509764854796231}}}], "metrics": 0.779, "context": "openml-credit-g-146803", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-credit-g-146803-1187", "modules": [{"role": "dataset", "module": "openml-credit-g-146803"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 16, "num.trees": 908, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.44548615727108}}}], "metrics": 0.778, "context": "openml-credit-g-146803", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-credit-g-146803-229", "modules": [{"role": "dataset", "module": "openml-credit-g-146803"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 11, "mtry": 14, "num.trees": 1169, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.6857152972836051}}}], "metrics": 0.778, "context": "openml-credit-g-146803", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-credit-g-146803-550", "modules": [{"role": "dataset", "module": "openml-credit-g-146803"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 5, "mtry": 11, "num.trees": 1039, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.545695233065635}}}], "metrics": 0.778, "context": "openml-credit-g-146803", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-click-prediction-small-14971-1065", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 26, "mtry": 3, "num.trees": 103, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.468667794298381}}}], "metrics": 0.835311, "context": "openml-click-prediction-small-14971", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-click-prediction-small-14971-138", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 2, "num.trees": 76, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.423065428365953}}}], "metrics": 0.835086, "context": "openml-click-prediction-small-14971", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-click-prediction-small-14971-1519", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 2, "num.trees": 196, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.303168110479601}}}], "metrics": 0.835036, "context": "openml-click-prediction-small-14971", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-click-prediction-small-14971-2282", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 34, "mtry": 5, "num.trees": 178, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.571676405426115}}}], "metrics": 0.835036, "context": "openml-click-prediction-small-14971", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-click-prediction-small-14971-084", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 2, "num.trees": 68, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.482109892857261}}}], "metrics": 0.83496, "context": "openml-click-prediction-small-14971", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-bioresponse-14966-3046", "modules": [{"role": "dataset", "module": "openml-bioresponse-14966"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 9, "mtry": 230, "num.trees": 566, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.8991114056203511}}}], "metrics": 0.816049, "context": "openml-bioresponse-14966", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-bioresponse-14966-2879", "modules": [{"role": "dataset", "module": "openml-bioresponse-14966"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 4, "mtry": 82, "num.trees": 1280, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.6643571164691822}}}], "metrics": 0.814716, "context": "openml-bioresponse-14966", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-bioresponse-14966-2905", "modules": [{"role": "dataset", "module": "openml-bioresponse-14966"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 324, "num.trees": 804, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.709204626223072}}}], "metrics": 0.814716, "context": "openml-bioresponse-14966", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-bioresponse-14966-3568", "modules": [{"role": "dataset", "module": "openml-bioresponse-14966"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 349, "num.trees": 788, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.79444946157746}}}], "metrics": 0.814449, "context": "openml-bioresponse-14966", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-bioresponse-14966-3461", "modules": [{"role": "dataset", "module": "openml-bioresponse-14966"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 316, "num.trees": 619, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.8555788435973231}}}], "metrics": 0.814183, "context": "openml-bioresponse-14966", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-click-prediction-small-7295-1058", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 31, "mtry": 5, "num.trees": 214, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.346099227992818}}}], "metrics": 0.835111, "context": "openml-click-prediction-small-7295", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-click-prediction-small-7295-142", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 2, "num.trees": 193, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.742491129483096}}}], "metrics": 0.835086, "context": "openml-click-prediction-small-7295", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-click-prediction-small-7295-1010", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 11, "mtry": 4, "num.trees": 148, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.270815173955634}}}], "metrics": 0.835086, "context": "openml-click-prediction-small-7295", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-click-prediction-small-7295-1610", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 64, "mtry": 4, "num.trees": 93, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.805228310986422}}}], "metrics": 0.835061, "context": "openml-click-prediction-small-7295", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-click-prediction-small-7295-2893", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 14, "mtry": 3, "num.trees": 255, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.436616997723468}}}], "metrics": 0.835036, "context": "openml-click-prediction-small-7295", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-bioresponse-145677-2465", "modules": [{"role": "dataset", "module": "openml-bioresponse-145677"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 4, "mtry": 164, "num.trees": 625, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.483285928354599}}}], "metrics": 0.814449, "context": "openml-bioresponse-145677", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-bioresponse-145677-3736", "modules": [{"role": "dataset", "module": "openml-bioresponse-145677"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 3, "mtry": 227, "num.trees": 1143, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.684756563045084}}}], "metrics": 0.814183, "context": "openml-bioresponse-145677", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-bioresponse-145677-3681", "modules": [{"role": "dataset", "module": "openml-bioresponse-145677"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 307, "num.trees": 1184, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.65068074350711}}}], "metrics": 0.813916, "context": "openml-bioresponse-145677", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-bioresponse-145677-2745", "modules": [{"role": "dataset", "module": "openml-bioresponse-145677"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 16, "mtry": 187, "num.trees": 1645, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.720697599742562}}}], "metrics": 0.81365, "context": "openml-bioresponse-145677", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-bioresponse-145677-3621", "modules": [{"role": "dataset", "module": "openml-bioresponse-145677"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 4, "mtry": 148, "num.trees": 1000, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.905055132182315}}}], "metrics": 0.81365, "context": "openml-bioresponse-145677", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-bioresponse-9910-3921", "modules": [{"role": "dataset", "module": "openml-bioresponse-9910"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 117, "num.trees": 687, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.49456538609229}}}], "metrics": 0.816316, "context": "openml-bioresponse-9910", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-bioresponse-9910-2340", "modules": [{"role": "dataset", "module": "openml-bioresponse-9910"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 13, "mtry": 248, "num.trees": 195, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.786936636036262}}}], "metrics": 0.814983, "context": "openml-bioresponse-9910", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-bioresponse-9910-3914", "modules": [{"role": "dataset", "module": "openml-bioresponse-9910"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 9, "mtry": 100, "num.trees": 162, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.974316285876557}}}], "metrics": 0.814183, "context": "openml-bioresponse-9910", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-bioresponse-9910-3994", "modules": [{"role": "dataset", "module": "openml-bioresponse-9910"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 4, "mtry": 187, "num.trees": 80, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.7383225058205432}}}], "metrics": 0.813916, "context": "openml-bioresponse-9910", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-bioresponse-9910-1781", "modules": [{"role": "dataset", "module": "openml-bioresponse-9910"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 7, "mtry": 685, "num.trees": 274, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.8688510334352031}}}], "metrics": 0.813383, "context": "openml-bioresponse-9910", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-electricity-146012-2712", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 6, "num.trees": 54, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.8659904022002591}}}], "metrics": 0.933329, "context": "openml-electricity-146012", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-electricity-146012-944", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 7, "num.trees": 92, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.9467644842108711}}}], "metrics": 0.930901, "context": "openml-electricity-146012", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-electricity-146012-2283", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 7, "num.trees": 60, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.98795369095169}}}], "metrics": 0.930283, "context": "openml-electricity-146012", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-electricity-146012-2450", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 6, "num.trees": 42, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.6710330330766741}}}], "metrics": 0.929401, "context": "openml-electricity-146012", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-electricity-146012-400", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 8, "num.trees": 64, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.8342464291723442}}}], "metrics": 0.929379, "context": "openml-electricity-146012", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-electricity-219-2178", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 6, "num.trees": 90, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.7236674540909012}}}], "metrics": 0.931806, "context": "openml-electricity-219", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-electricity-219-1956", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 5, "num.trees": 117, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.650774134043604}}}], "metrics": 0.930217, "context": "openml-electricity-219", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-electricity-219-402", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 4, "mtry": 7, "num.trees": 112, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.740720197209157}}}], "metrics": 0.929334, "context": "openml-electricity-219", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-electricity-219-1061", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 4, "num.trees": 56, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.8804178647231311}}}], "metrics": 0.92918, "context": "openml-electricity-219", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-electricity-219-3498", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 73, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.9162919013062492}}}], "metrics": 0.92907, "context": "openml-electricity-219", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-nomao-9977-416", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 7, "num.trees": 99, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.91228400231339}}}], "metrics": 0.97055, "context": "openml-nomao-9977", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-nomao-9977-2584", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 4, "mtry": 15, "num.trees": 149, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.95864635896869}}}], "metrics": 0.969999, "context": "openml-nomao-9977", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-nomao-9977-3664", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 138, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.893957886751741}}}], "metrics": 0.969766, "context": "openml-nomao-9977", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-nomao-9977-3294", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 48, "num.trees": 199, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.7578002098016441}}}], "metrics": 0.969737, "context": "openml-nomao-9977", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-nomao-9977-4650", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 5, "mtry": 34, "num.trees": 455, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.7566626801388341}}}], "metrics": 0.969563, "context": "openml-nomao-9977", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-eeg-eye-state-9983-3778", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 5, "num.trees": 187, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.941200428106822}}}], "metrics": 0.941656, "context": "openml-eeg-eye-state-9983", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-eeg-eye-state-9983-2645", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 4, "mtry": 4, "num.trees": 179, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.958220252976753}}}], "metrics": 0.941121, "context": "openml-eeg-eye-state-9983", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-eeg-eye-state-9983-1807", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 4, "mtry": 5, "num.trees": 192, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.9389807387953621}}}], "metrics": 0.93972, "context": "openml-eeg-eye-state-9983", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-eeg-eye-state-9983-3380", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 3, "num.trees": 82, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.942872517835349}}}], "metrics": 0.93972, "context": "openml-eeg-eye-state-9983", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-eeg-eye-state-9983-2545", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 3, "mtry": 7, "num.trees": 131, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.953477944829501}}}], "metrics": 0.938451, "context": "openml-eeg-eye-state-9983", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-bank-marketing-145833-3868", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 7, "mtry": 14, "num.trees": 455, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.225654075830244}}}], "metrics": 0.908297, "context": "openml-bank-marketing-145833", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-bank-marketing-145833-1411", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 44, "mtry": 6, "num.trees": 89, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.526886312337592}}}], "metrics": 0.90823, "context": "openml-bank-marketing-145833", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-bank-marketing-145833-4024", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 48, "mtry": 14, "num.trees": 535, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.819092912785709}}}], "metrics": 0.908186, "context": "openml-bank-marketing-145833", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-bank-marketing-145833-2164", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 19, "mtry": 5, "num.trees": 141, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.442330009886064}}}], "metrics": 0.90812, "context": "openml-bank-marketing-145833", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-bank-marketing-145833-3138", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 5, "mtry": 5, "num.trees": 468, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.180589384678751}}}], "metrics": 0.90812, "context": "openml-bank-marketing-145833", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-madelon-145853-4007", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 157, "num.trees": 960, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.969635049742646}}}], "metrics": 0.871923, "context": "openml-madelon-145853", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-madelon-145853-2989", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 117, "num.trees": 1746, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.9936261315597221}}}], "metrics": 0.871154, "context": "openml-madelon-145853", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-madelon-145853-5123", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 170, "num.trees": 1453, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.9555408118758351}}}], "metrics": 0.870385, "context": "openml-madelon-145853", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-madelon-145853-3889", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 4, "mtry": 129, "num.trees": 1733, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.9479379986412821}}}], "metrics": 0.87, "context": "openml-madelon-145853", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-madelon-145853-2704", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 168, "num.trees": 1545, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.9772857684874912}}}], "metrics": 0.869615, "context": "openml-madelon-145853", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-nomao-145854-4525", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 5, "mtry": 8, "num.trees": 218, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.958738346584141}}}], "metrics": 0.970405, "context": "openml-nomao-145854", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-nomao-145854-3542", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 43, "num.trees": 300, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.908308252529241}}}], "metrics": 0.970144, "context": "openml-nomao-145854", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-nomao-145854-4044", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 4, "mtry": 33, "num.trees": 138, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.924735584342852}}}], "metrics": 0.970028, "context": "openml-nomao-145854", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-nomao-145854-3760", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 22, "num.trees": 259, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.827416079351678}}}], "metrics": 0.970028, "context": "openml-nomao-145854", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-nomao-145854-3803", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 6, "mtry": 11, "num.trees": 234, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.9488207987044011}}}], "metrics": 0.970028, "context": "openml-nomao-145854", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-eeg-eye-state-14951-747", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 213, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.936557590099983}}}], "metrics": 0.942256, "context": "openml-eeg-eye-state-14951", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-eeg-eye-state-14951-3470", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 3, "mtry": 4, "num.trees": 240, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.9616790710948411}}}], "metrics": 0.941188, "context": "openml-eeg-eye-state-14951", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-eeg-eye-state-14951-4906", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 4, "mtry": 4, "num.trees": 212, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.849717562063597}}}], "metrics": 0.939252, "context": "openml-eeg-eye-state-14951", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-eeg-eye-state-14951-4869", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 3, "num.trees": 139, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.796455837739632}}}], "metrics": 0.938451, "context": "openml-eeg-eye-state-14951", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-eeg-eye-state-14951-2734", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 4, "num.trees": 252, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.8093519177520652}}}], "metrics": 0.937784, "context": "openml-eeg-eye-state-14951", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-bank-marketing-14965-232", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 10, "num.trees": 396, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.244662942038849}}}], "metrics": 0.908606, "context": "openml-bank-marketing-14965", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-bank-marketing-14965-212", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 5, "num.trees": 735, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.153496468742378}}}], "metrics": 0.908252, "context": "openml-bank-marketing-14965", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-bank-marketing-14965-022", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 7, "num.trees": 323, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.301680381968617}}}], "metrics": 0.908142, "context": "openml-bank-marketing-14965", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-bank-marketing-14965-5337", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 41, "mtry": 5, "num.trees": 98, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.764513199147768}}}], "metrics": 0.908142, "context": "openml-bank-marketing-14965", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-bank-marketing-14965-4456", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 30, "mtry": 12, "num.trees": 271, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.434885877394117}}}], "metrics": 0.908075, "context": "openml-bank-marketing-14965", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-gina-agnostic-3891-479", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 40, "num.trees": 189, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.978043308760971}}}], "metrics": 0.946943, "context": "openml-gina-agnostic-3891", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-gina-agnostic-3891-5293", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 71, "num.trees": 1419, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.8604854010045531}}}], "metrics": 0.946655, "context": "openml-gina-agnostic-3891", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-gina-agnostic-3891-4444", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 6, "mtry": 31, "num.trees": 1419, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.97709038045723}}}], "metrics": 0.946367, "context": "openml-gina-agnostic-3891", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-gina-agnostic-3891-3152", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 3, "mtry": 131, "num.trees": 1322, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.9942036199616271}}}], "metrics": 0.946367, "context": "openml-gina-agnostic-3891", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-gina-agnostic-3891-1842", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 6, "mtry": 88, "num.trees": 61, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.942809198005125}}}], "metrics": 0.946078, "context": "openml-gina-agnostic-3891", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-madelon-9976-4706", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 163, "num.trees": 1552, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.947363157453947}}}], "metrics": 0.871538, "context": "openml-madelon-9976", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-madelon-9976-5742", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 31, "mtry": 151, "num.trees": 1787, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.99751933447551}}}], "metrics": 0.871154, "context": "openml-madelon-9976", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-madelon-9976-5328", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 158, "num.trees": 792, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.884260226786137}}}], "metrics": 0.870769, "context": "openml-madelon-9976", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-madelon-9976-3572", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 15, "mtry": 165, "num.trees": 1479, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.973964292253368}}}], "metrics": 0.870769, "context": "openml-madelon-9976", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-madelon-9976-4184", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 3, "mtry": 151, "num.trees": 1298, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.921950044273399}}}], "metrics": 0.869615, "context": "openml-madelon-9976", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-sylva-agnostic-3889-4254", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 130, "num.trees": 213, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.8668679759372031}}}], "metrics": 0.994651, "context": "openml-sylva-agnostic-3889", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-sylva-agnostic-3889-1825", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 77, "num.trees": 253, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.929929718561471}}}], "metrics": 0.994512, "context": "openml-sylva-agnostic-3889", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-sylva-agnostic-3889-2540", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 80, "num.trees": 231, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.8633760340046142}}}], "metrics": 0.994512, "context": "openml-sylva-agnostic-3889", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-sylva-agnostic-3889-4042", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 3, "mtry": 44, "num.trees": 479, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.620060349302366}}}], "metrics": 0.994512, "context": "openml-sylva-agnostic-3889", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-sylva-agnostic-3889-5881", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 98, "num.trees": 498, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.9251012945314872}}}], "metrics": 0.994512, "context": "openml-sylva-agnostic-3889", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-banknote-authentication-145834-4708", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 4, "mtry": 3, "num.trees": 145, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.9935823838924991}}}], "metrics": 0.995627, "context": "openml-banknote-authentication-145834", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-banknote-authentication-145834-4736", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 4, "mtry": 3, "num.trees": 137, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.929290052154101}}}], "metrics": 0.995627, "context": "openml-banknote-authentication-145834", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-banknote-authentication-145834-6014", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 3, "mtry": 3, "num.trees": 1135, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.9803267776500431}}}], "metrics": 0.995627, "context": "openml-banknote-authentication-145834", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-banknote-authentication-145834-6353", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 5, "mtry": 3, "num.trees": 641, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.929859838634729}}}], "metrics": 0.994898, "context": "openml-banknote-authentication-145834", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-banknote-authentication-145834-4707", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 3, "num.trees": 345, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.6793595618335531}}}], "metrics": 0.994898, "context": "openml-banknote-authentication-145834", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-spambase-43-2237", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 6, "num.trees": 516, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.9818891945760702}}}], "metrics": 0.956531, "context": "openml-spambase-43", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-spambase-43-3161", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 10, "num.trees": 268, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.9517495737643911}}}], "metrics": 0.956097, "context": "openml-spambase-43", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-spambase-43-3308", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 3, "mtry": 6, "num.trees": 805, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.9475600915262481}}}], "metrics": 0.955444, "context": "openml-spambase-43", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-spambase-43-949", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 8, "num.trees": 757, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.818237945670262}}}], "metrics": 0.955444, "context": "openml-spambase-43", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-spambase-43-5195", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 3, "mtry": 7, "num.trees": 241, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.865516136307269}}}], "metrics": 0.955444, "context": "openml-spambase-43", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-kr-vs-kp-145953-6538", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 33, "num.trees": 1052, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.865915597695857}}}], "metrics": 0.997184, "context": "openml-kr-vs-kp-145953", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-kr-vs-kp-145953-5150", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 33, "num.trees": 1626, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.986330966860987}}}], "metrics": 0.997184, "context": "openml-kr-vs-kp-145953", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-kr-vs-kp-145953-5510", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 30, "num.trees": 743, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.84041217349004}}}], "metrics": 0.997184, "context": "openml-kr-vs-kp-145953", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-kr-vs-kp-145953-5109", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 35, "num.trees": 1622, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.9795240582898261}}}], "metrics": 0.997184, "context": "openml-kr-vs-kp-145953", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-kr-vs-kp-145953-7048", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 32, "num.trees": 1241, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.977367731975392}}}], "metrics": 0.997184, "context": "openml-kr-vs-kp-145953", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-banknote-authentication-10093-7105", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 4, "mtry": 3, "num.trees": 1890, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.9893719990737742}}}], "metrics": 0.995627, "context": "openml-banknote-authentication-10093", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-banknote-authentication-10093-5461", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 5, "mtry": 3, "num.trees": 315, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.901747926138341}}}], "metrics": 0.994898, "context": "openml-banknote-authentication-10093", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-banknote-authentication-10093-7065", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 3, "num.trees": 2000, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.913758849096485}}}], "metrics": 0.994898, "context": "openml-banknote-authentication-10093", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-banknote-authentication-10093-4368", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 10, "mtry": 1, "num.trees": 331, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.96826116151642}}}], "metrics": 0.994898, "context": "openml-banknote-authentication-10093", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-banknote-authentication-10093-7110", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 5, "mtry": 3, "num.trees": 203, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.9238363544922321}}}], "metrics": 0.994898, "context": "openml-banknote-authentication-10093", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-magictelescope-3954-3953", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 7, "mtry": 3, "num.trees": 159, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.914422520226799}}}], "metrics": 0.883281, "context": "openml-magictelescope-3954", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-magictelescope-3954-6930", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 3, "num.trees": 219, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.8867227985057982}}}], "metrics": 0.88307, "context": "openml-magictelescope-3954", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-magictelescope-3954-6421", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 4, "mtry": 3, "num.trees": 145, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.863030467415228}}}], "metrics": 0.882702, "context": "openml-magictelescope-3954", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-magictelescope-3954-2122", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 4, "mtry": 2, "num.trees": 171, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.905258528701961}}}], "metrics": 0.88265, "context": "openml-magictelescope-3954", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-magictelescope-3954-6104", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 3, "mtry": 3, "num.trees": 225, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.7218799654627222}}}], "metrics": 0.88244, "context": "openml-magictelescope-3954", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-hill-valley-145847-2337", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 4, "mtry": 83, "num.trees": 214, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.5810482943430542}}}], "metrics": 0.607261, "context": "openml-hill-valley-145847", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-hill-valley-145847-3579", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 6, "mtry": 68, "num.trees": 126, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.433751236763783}}}], "metrics": 0.607261, "context": "openml-hill-valley-145847", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-hill-valley-145847-1042", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 54, "num.trees": 140, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.9347010498866442}}}], "metrics": 0.607261, "context": "openml-hill-valley-145847", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-hill-valley-145847-6177", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 3, "mtry": 22, "num.trees": 453, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.823529679188505}}}], "metrics": 0.606436, "context": "openml-hill-valley-145847", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-hill-valley-145847-5242", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 6, "num.trees": 851, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.9871898422483361}}}], "metrics": 0.605611, "context": "openml-hill-valley-145847", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-monks-problems-3-146066-001", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 5, "num.trees": 1483, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.5629993073409421}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-monks-problems-3-146066-3037", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 6, "mtry": 6, "num.trees": 107, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.7933057341258971}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-monks-problems-3-146066-3091", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 7, "mtry": 5, "num.trees": 1255, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.413223874592222}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-monks-problems-3-146066-3088", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 20, "mtry": 4, "num.trees": 16, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.704714067070745}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-monks-problems-3-146066-3086", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 9, "mtry": 4, "num.trees": 1912, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.988131878688}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-ada-agnostic-3896-1985", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 5, "mtry": 4, "num.trees": 95, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.34470186079852294}}}], "metrics": 0.856203, "context": "openml-ada-agnostic-3896", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-ada-agnostic-3896-6912", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 20, "mtry": 10, "num.trees": 1246, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.512245363998227}}}], "metrics": 0.856203, "context": "openml-ada-agnostic-3896", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-ada-agnostic-3896-3928", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 27, "mtry": 12, "num.trees": 916, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.531715915491805}}}], "metrics": 0.855984, "context": "openml-ada-agnostic-3896", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-ada-agnostic-3896-1161", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 6, "num.trees": 281, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.6384202726418151}}}], "metrics": 0.855984, "context": "openml-ada-agnostic-3896", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-ada-agnostic-3896-1153", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 18, "num.trees": 1287, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.194362003682181}}}], "metrics": 0.855765, "context": "openml-ada-agnostic-3896", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-monks-problems-2-146065-2485", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-146065"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 4, "mtry": 6, "num.trees": 1190, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.886180723225698}}}], "metrics": 1.0, "context": "openml-monks-problems-2-146065", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-monks-problems-2-146065-4758", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-146065"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 3, "mtry": 4, "num.trees": 1038, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.8479594991542401}}}], "metrics": 1.0, "context": "openml-monks-problems-2-146065", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-monks-problems-2-146065-4425", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-146065"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 4, "mtry": 6, "num.trees": 1482, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.947653720527887}}}], "metrics": 1.0, "context": "openml-monks-problems-2-146065", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-monks-problems-2-146065-4447", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-146065"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 3, "num.trees": 1185, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.928266446804628}}}], "metrics": 1.0, "context": "openml-monks-problems-2-146065", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-monks-problems-2-146065-4461", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-146065"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 4, "num.trees": 1383, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.978239354980178}}}], "metrics": 1.0, "context": "openml-monks-problems-2-146065", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-climate-model-simulation-crashes-145839-2310", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 31, "mtry": 11, "num.trees": 956, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.7045250750612471}}}], "metrics": 0.925926, "context": "openml-climate-model-simulation-crashes-145839", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-climate-model-simulation-crashes-145839-5262", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 10, "num.trees": 1510, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.6910831933841111}}}], "metrics": 0.924074, "context": "openml-climate-model-simulation-crashes-145839", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-climate-model-simulation-crashes-145839-4443", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 6, "mtry": 8, "num.trees": 136, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.792607809300534}}}], "metrics": 0.924074, "context": "openml-climate-model-simulation-crashes-145839", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-climate-model-simulation-crashes-145839-042", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 11, "num.trees": 473, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.683248610259034}}}], "metrics": 0.924074, "context": "openml-climate-model-simulation-crashes-145839", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-climate-model-simulation-crashes-145839-070", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 13, "num.trees": 1351, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.640451723895967}}}], "metrics": 0.924074, "context": "openml-climate-model-simulation-crashes-145839", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-tic-tac-toe-145804-2428", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-145804"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 4, "num.trees": 943, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.75110748433508}}}], "metrics": 0.993737, "context": "openml-tic-tac-toe-145804", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-tic-tac-toe-145804-1937", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-145804"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 1223, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.8841190363513312}}}], "metrics": 0.993737, "context": "openml-tic-tac-toe-145804", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-tic-tac-toe-145804-2417", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-145804"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 2, "num.trees": 1051, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.9304095173487441}}}], "metrics": 0.993737, "context": "openml-tic-tac-toe-145804", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-tic-tac-toe-145804-388", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-145804"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 4, "num.trees": 809, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.9557833319762721}}}], "metrics": 0.993737, "context": "openml-tic-tac-toe-145804", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-tic-tac-toe-145804-2321", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-145804"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 3, "num.trees": 485, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.6875591007759791}}}], "metrics": 0.993737, "context": "openml-tic-tac-toe-145804", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-spambase-145979-1987", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 10, "num.trees": 487, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.7832355061080312}}}], "metrics": 0.955662, "context": "openml-spambase-145979", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-spambase-145979-7413", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 213, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.988414934300818}}}], "metrics": 0.955662, "context": "openml-spambase-145979", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-spambase-145979-793", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 112, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.9467176587088031}}}], "metrics": 0.955444, "context": "openml-spambase-145979", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-spambase-145979-2328", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 3, "mtry": 11, "num.trees": 692, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.947223151382059}}}], "metrics": 0.955444, "context": "openml-spambase-145979", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-spambase-145979-6277", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 7, "mtry": 6, "num.trees": 731, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.9872199267847461}}}], "metrics": 0.95501, "context": "openml-spambase-145979", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-phishingwebsites-14952-2857", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-14952"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 15, "num.trees": 394, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.844842005334794}}}], "metrics": 0.973587, "context": "openml-phishingwebsites-14952", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-phishingwebsites-14952-6955", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-14952"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 15, "num.trees": 896, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.8572298434097321}}}], "metrics": 0.973496, "context": "openml-phishingwebsites-14952", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-phishingwebsites-14952-1029", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-14952"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 8, "num.trees": 99, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.944587674620561}}}], "metrics": 0.973225, "context": "openml-phishingwebsites-14952", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-phishingwebsites-14952-3598", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-14952"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 17, "num.trees": 239, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.768385663558729}}}], "metrics": 0.973134, "context": "openml-phishingwebsites-14952", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-phishingwebsites-14952-5993", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-14952"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 10, "num.trees": 366, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.929088887944818}}}], "metrics": 0.973134, "context": "openml-phishingwebsites-14952", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-credit-g-31-2660", "modules": [{"role": "dataset", "module": "openml-credit-g-31"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 3, "mtry": 16, "num.trees": 607, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.399462193134241}}}], "metrics": 0.781, "context": "openml-credit-g-31", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-credit-g-31-1600", "modules": [{"role": "dataset", "module": "openml-credit-g-31"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 10, "num.trees": 310, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.7641348364762961}}}], "metrics": 0.781, "context": "openml-credit-g-31", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-credit-g-31-911", "modules": [{"role": "dataset", "module": "openml-credit-g-31"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 13, "num.trees": 31, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.7987690265523271}}}], "metrics": 0.78, "context": "openml-credit-g-31", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-credit-g-31-6866", "modules": [{"role": "dataset", "module": "openml-credit-g-31"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 17, "mtry": 8, "num.trees": 1479, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.7858636763645341}}}], "metrics": 0.779, "context": "openml-credit-g-31", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-credit-g-31-3920", "modules": [{"role": "dataset", "module": "openml-credit-g-31"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 3, "mtry": 9, "num.trees": 108, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.43503059996292}}}], "metrics": 0.779, "context": "openml-credit-g-31", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-mozilla4-3899-6461", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 4, "num.trees": 425, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.991491831419989}}}], "metrics": 0.955484, "context": "openml-mozilla4-3899", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-mozilla4-3899-6188", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 3, "mtry": 5, "num.trees": 591, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.8962324083782731}}}], "metrics": 0.95542, "context": "openml-mozilla4-3899", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-mozilla4-3899-7737", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 649, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.90205964136403}}}], "metrics": 0.95542, "context": "openml-mozilla4-3899", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-mozilla4-3899-6858", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 388, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.8463504539104181}}}], "metrics": 0.955355, "context": "openml-mozilla4-3899", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-mozilla4-3899-6053", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 5, "num.trees": 795, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.891319688595831}}}], "metrics": 0.955355, "context": "openml-mozilla4-3899", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-scene-3485-7746", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 4, "mtry": 299, "num.trees": 1792, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.557092375238426}}}], "metrics": 0.96801, "context": "openml-scene-3485", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-scene-3485-5449", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 282, "num.trees": 650, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.581974654528312}}}], "metrics": 0.96801, "context": "openml-scene-3485", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-scene-3485-5152", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 10, "mtry": 264, "num.trees": 1486, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.619504565000534}}}], "metrics": 0.967595, "context": "openml-scene-3485", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-scene-3485-6274", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 292, "num.trees": 152, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.9970660533057532}}}], "metrics": 0.967595, "context": "openml-scene-3485", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-scene-3485-7717", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 16, "mtry": 274, "num.trees": 690, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.588226730353199}}}], "metrics": 0.967595, "context": "openml-scene-3485", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-hill-valley-9970-2191", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 24, "num.trees": 179, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.95540354878176}}}], "metrics": 0.607261, "context": "openml-hill-valley-9970", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-hill-valley-9970-2830", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 93, "num.trees": 1017, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.428062803274952}}}], "metrics": 0.605611, "context": "openml-hill-valley-9970", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-hill-valley-9970-2513", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 64, "num.trees": 234, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.966090916842222}}}], "metrics": 0.604785, "context": "openml-hill-valley-9970", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-hill-valley-9970-5683", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 24, "num.trees": 162, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.7745562107069421}}}], "metrics": 0.604785, "context": "openml-hill-valley-9970", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-hill-valley-9970-1073", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 39, "num.trees": 138, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.839427475468256}}}], "metrics": 0.60396, "context": "openml-hill-valley-9970", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-monks-problems-3-3494-3986", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 15, "mtry": 5, "num.trees": 107, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.8911974578164521}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-monks-problems-3-3494-3367", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 5, "mtry": 5, "num.trees": 862, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.96516313739121}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-monks-problems-3-3494-6305", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 3, "num.trees": 703, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.8348017683951181}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-monks-problems-3-3494-3368", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 17, "mtry": 6, "num.trees": 1344, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.666222273698077}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-monks-problems-3-3494-6303", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 6, "mtry": 6, "num.trees": 736, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.774186341208406}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-monks-problems-2-3493-5663", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 4, "num.trees": 1357, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.7829203052679081}}}], "metrics": 1.0, "context": "openml-monks-problems-2-3493", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-monks-problems-2-3493-6977", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 3, "mtry": 6, "num.trees": 1305, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.7255042890785262}}}], "metrics": 1.0, "context": "openml-monks-problems-2-3493", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-monks-problems-2-3493-3486", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 3, "mtry": 6, "num.trees": 1670, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.849920495483093}}}], "metrics": 1.0, "context": "openml-monks-problems-2-3493", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-monks-problems-2-3493-617", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 3, "num.trees": 606, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.982584352954291}}}], "metrics": 1.0, "context": "openml-monks-problems-2-3493", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-monks-problems-2-3493-4868", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 1357, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.8497689324431121}}}], "metrics": 1.0, "context": "openml-monks-problems-2-3493", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-ilpd-145848-7593", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 1, "num.trees": 166, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.947121218009852}}}], "metrics": 0.734134, "context": "openml-ilpd-145848", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-ilpd-145848-665", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 3, "mtry": 1, "num.trees": 399, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.920037387637421}}}], "metrics": 0.734134, "context": "openml-ilpd-145848", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-ilpd-145848-6950", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 4, "mtry": 1, "num.trees": 52, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.388855660147965}}}], "metrics": 0.732419, "context": "openml-ilpd-145848", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-ilpd-145848-4081", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 3, "mtry": 1, "num.trees": 1342, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.547083771391772}}}], "metrics": 0.732419, "context": "openml-ilpd-145848", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-ilpd-145848-3533", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 7, "mtry": 1, "num.trees": 1062, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.605385565524921}}}], "metrics": 0.732419, "context": "openml-ilpd-145848", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-phoneme-145857-6622", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 2, "num.trees": 837, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.808876255224459}}}], "metrics": 0.916543, "context": "openml-phoneme-145857", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-phoneme-145857-7555", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 1, "num.trees": 293, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.865484840166755}}}], "metrics": 0.915248, "context": "openml-phoneme-145857", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-phoneme-145857-7928", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 831, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.7648953118827191}}}], "metrics": 0.914878, "context": "openml-phoneme-145857", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-phoneme-145857-8214", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 2, "num.trees": 502, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.772740384540521}}}], "metrics": 0.914878, "context": "openml-phoneme-145857", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-phoneme-145857-6301", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 3, "num.trees": 507, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.9214575481601062}}}], "metrics": 0.914878, "context": "openml-phoneme-145857", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-steel-plates-fault-145872-8326", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 30, "num.trees": 1975, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.8295202916022391}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-steel-plates-fault-145872-3605", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 267, "mtry": 19, "num.trees": 1277, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.849113363469951}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-steel-plates-fault-145872-3594", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 5, "mtry": 23, "num.trees": 611, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.900814136653207}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-steel-plates-fault-145872-3595", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 123, "mtry": 22, "num.trees": 1042, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.6169567870441821}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-steel-plates-fault-145872-3596", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 194, "mtry": 28, "num.trees": 834, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.654172866279259}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-amazon-employee-access-34539-8369", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-34539"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 4, "mtry": 4, "num.trees": 329, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.580189191387035}}}], "metrics": 0.952394, "context": "openml-amazon-employee-access-34539", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-amazon-employee-access-34539-315", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-34539"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 3, "num.trees": 140, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.9622949963901191}}}], "metrics": 0.952394, "context": "openml-amazon-employee-access-34539", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-amazon-employee-access-34539-7300", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-34539"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 4, "num.trees": 204, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.794575724680908}}}], "metrics": 0.952394, "context": "openml-amazon-employee-access-34539", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-amazon-employee-access-34539-7482", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-34539"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 6, "mtry": 6, "num.trees": 283, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.781993436091579}}}], "metrics": 0.952302, "context": "openml-amazon-employee-access-34539", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-amazon-employee-access-34539-3916", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-34539"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 3, "mtry": 4, "num.trees": 155, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.5785542125348}}}], "metrics": 0.952272, "context": "openml-amazon-employee-access-34539", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-kc1-3917-4635", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 3, "mtry": 9, "num.trees": 721, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.5566335381241521}}}], "metrics": 0.871029, "context": "openml-kc1-3917", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-kc1-3917-3104", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 8, "num.trees": 1389, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.453165316651575}}}], "metrics": 0.869606, "context": "openml-kc1-3917", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-kc1-3917-4970", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 9, "num.trees": 1740, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.336396089405753}}}], "metrics": 0.869606, "context": "openml-kc1-3917", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-kc1-3917-3451", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 3, "mtry": 5, "num.trees": 261, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.466098750196397}}}], "metrics": 0.8691322901849218, "context": "openml-kc1-3917", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-kc1-3917-6334", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 14, "num.trees": 1728, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.435786343575455}}}], "metrics": 0.869132, "context": "openml-kc1-3917", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-amazon-employee-access-9911-6474", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-9911"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 6, "mtry": 5, "num.trees": 298, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.8444731934228911}}}], "metrics": 0.952486, "context": "openml-amazon-employee-access-9911", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-amazon-employee-access-9911-7529", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-9911"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 5, "num.trees": 211, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.825418231775984}}}], "metrics": 0.952302, "context": "openml-amazon-employee-access-9911", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-amazon-employee-access-9911-7796", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-9911"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 3, "num.trees": 230, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.644600718398578}}}], "metrics": 0.952302, "context": "openml-amazon-employee-access-9911", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-amazon-employee-access-9911-3454", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-9911"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 4, "mtry": 5, "num.trees": 161, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.6741180415730921}}}], "metrics": 0.952302, "context": "openml-amazon-employee-access-9911", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-amazon-employee-access-9911-216", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-9911"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 3, "num.trees": 372, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.9549937305040661}}}], "metrics": 0.952272, "context": "openml-amazon-employee-access-9911", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-kc2-3913-1612", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 13, "num.trees": 61, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.521710508293472}}}], "metrics": 0.85249, "context": "openml-kc2-3913", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-kc2-3913-7202", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 33, "mtry": 10, "num.trees": 780, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.6278909009415661}}}], "metrics": 0.85249, "context": "openml-kc2-3913", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-kc2-3913-6772", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 7, "mtry": 16, "num.trees": 1783, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.301013068691827}}}], "metrics": 0.85249, "context": "openml-kc2-3913", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-kc2-3913-2388", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 3, "mtry": 18, "num.trees": 32, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.539493137481622}}}], "metrics": 0.85249, "context": "openml-kc2-3913", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-kc2-3913-031", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 21, "num.trees": 791, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.240623217378743}}}], "metrics": 0.85249, "context": "openml-kc2-3913", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-diabetes-145976-6612", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 7, "mtry": 7, "num.trees": 273, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.13877020960208}}}], "metrics": 0.782552, "context": "openml-diabetes-145976", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-diabetes-145976-8675", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 3, "num.trees": 202, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.438885248429142}}}], "metrics": 0.782552, "context": "openml-diabetes-145976", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-diabetes-145976-6603", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 7, "num.trees": 177, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.6423488291678952}}}], "metrics": 0.782552, "context": "openml-diabetes-145976", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-diabetes-145976-7971", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 3, "mtry": 2, "num.trees": 1390, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.614977639284916}}}], "metrics": 0.78125, "context": "openml-diabetes-145976", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-diabetes-145976-6132", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 7, "mtry": 6, "num.trees": 246, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.9920139902504161}}}], "metrics": 0.78125, "context": "openml-diabetes-145976", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-phoneme-9952-8771", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 2, "num.trees": 620, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.8400106296176091}}}], "metrics": 0.916358, "context": "openml-phoneme-9952", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-phoneme-9952-8303", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 1, "num.trees": 636, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.9026580964680762}}}], "metrics": 0.916358, "context": "openml-phoneme-9952", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-phoneme-9952-7857", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 4, "mtry": 1, "num.trees": 139, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.9995283035794271}}}], "metrics": 0.915618, "context": "openml-phoneme-9952", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-phoneme-9952-6589", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 1, "num.trees": 285, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.934581545949914}}}], "metrics": 0.915063, "context": "openml-phoneme-9952", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-phoneme-9952-8858", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 2, "num.trees": 443, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.928225386375561}}}], "metrics": 0.914878, "context": "openml-phoneme-9952", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-phishingwebsites-34537-7300", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-34537"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 12, "num.trees": 484, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.9982312642037872}}}], "metrics": 0.974039, "context": "openml-phishingwebsites-34537", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-phishingwebsites-34537-834", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-34537"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 13, "num.trees": 309, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.892976565798745}}}], "metrics": 0.973587, "context": "openml-phishingwebsites-34537", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-phishingwebsites-34537-7710", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-34537"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 13, "num.trees": 530, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.9659770369529721}}}], "metrics": 0.973406, "context": "openml-phishingwebsites-34537", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-phishingwebsites-34537-7796", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-34537"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 3, "mtry": 11, "num.trees": 238, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.867157308966853}}}], "metrics": 0.973406, "context": "openml-phishingwebsites-34537", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-phishingwebsites-34537-8447", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-34537"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 15, "num.trees": 232, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.857485094154254}}}], "metrics": 0.973315, "context": "openml-phishingwebsites-34537", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-credit-g-145972-6765", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 5, "mtry": 29, "num.trees": 819, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.565295556955971}}}], "metrics": 0.781, "context": "openml-credit-g-145972", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-credit-g-145972-5648", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 9, "mtry": 17, "num.trees": 449, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.536864356603473}}}], "metrics": 0.781, "context": "openml-credit-g-145972", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-credit-g-145972-6648", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 7, "mtry": 18, "num.trees": 339, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.530652914568782}}}], "metrics": 0.78, "context": "openml-credit-g-145972", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-credit-g-145972-5167", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 4, "mtry": 19, "num.trees": 425, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.411192458751611}}}], "metrics": 0.779, "context": "openml-credit-g-145972", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-credit-g-145972-3327", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 5, "mtry": 20, "num.trees": 171, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.319246935751289}}}], "metrics": 0.779, "context": "openml-credit-g-145972", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-qsar-biodeg-9957-7720", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 28, "num.trees": 1272, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.525337688461877}}}], "metrics": 0.874882, "context": "openml-qsar-biodeg-9957", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-qsar-biodeg-9957-7788", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 4, "mtry": 21, "num.trees": 752, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.9867862925864761}}}], "metrics": 0.874882, "context": "openml-qsar-biodeg-9957", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-qsar-biodeg-9957-7531", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 11, "mtry": 39, "num.trees": 407, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.437691794079728}}}], "metrics": 0.873934, "context": "openml-qsar-biodeg-9957", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-qsar-biodeg-9957-4529", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 18, "num.trees": 412, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.940113818296231}}}], "metrics": 0.873934, "context": "openml-qsar-biodeg-9957", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-qsar-biodeg-9957-3493", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 3, "mtry": 17, "num.trees": 117, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.9862102923914791}}}], "metrics": 0.873934, "context": "openml-qsar-biodeg-9957", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-pc4-3902-2225", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 35, "num.trees": 1684, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.827110022329725}}}], "metrics": 0.915638, "context": "openml-pc4-3902", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-pc4-3902-8715", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 3, "mtry": 14, "num.trees": 673, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.9142648383975032}}}], "metrics": 0.915638, "context": "openml-pc4-3902", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-pc4-3902-4314", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 37, "num.trees": 1971, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.8178271783515811}}}], "metrics": 0.914952, "context": "openml-pc4-3902", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-pc4-3902-7663", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 20, "num.trees": 1824, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.7598146168747921}}}], "metrics": 0.914952, "context": "openml-pc4-3902", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-pc4-3902-3383", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 30, "num.trees": 771, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.8919583726441491}}}], "metrics": 0.914952, "context": "openml-pc4-3902", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-pc1-3918-4651", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 16, "mtry": 9, "num.trees": 1831, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.435507167526521}}}], "metrics": 0.943192, "context": "openml-pc1-3918", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-pc1-3918-1890", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 25, "mtry": 6, "num.trees": 141, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.429881459171884}}}], "metrics": 0.943192, "context": "openml-pc1-3918", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-pc1-3918-6162", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 17, "mtry": 10, "num.trees": 1883, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.400036845728755}}}], "metrics": 0.94229, "context": "openml-pc1-3918", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-pc1-3918-117", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 11, "num.trees": 1756, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.249703549547121}}}], "metrics": 0.94229, "context": "openml-pc1-3918", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-pc1-3918-1014", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 16, "num.trees": 781, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.330068144993857}}}], "metrics": 0.94229, "context": "openml-pc1-3918", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-ozone-level-8hr-145855-1439", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 11, "mtry": 53, "num.trees": 484, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.7524746791925281}}}], "metrics": 0.94633, "context": "openml-ozone-level-8hr-145855", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-ozone-level-8hr-145855-6288", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 48, "num.trees": 82, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.662036492279731}}}], "metrics": 0.94633, "context": "openml-ozone-level-8hr-145855", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-ozone-level-8hr-145855-9043", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 57, "num.trees": 106, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.570868046721444}}}], "metrics": 0.94633, "context": "openml-ozone-level-8hr-145855", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-ozone-level-8hr-145855-7307", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 59, "num.trees": 117, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.510590297915042}}}], "metrics": 0.945935, "context": "openml-ozone-level-8hr-145855", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-ozone-level-8hr-145855-6177", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 13, "num.trees": 74, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.625528041808866}}}], "metrics": 0.945541, "context": "openml-ozone-level-8hr-145855", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-monks-problems-1-146064-9734", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-146064"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 3, "num.trees": 1178, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.56815602411516}}}], "metrics": 1.0, "context": "openml-monks-problems-1-146064", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-monks-problems-1-146064-4824", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-146064"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 11, "mtry": 6, "num.trees": 1133, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.685371334152296}}}], "metrics": 1.0, "context": "openml-monks-problems-1-146064", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-monks-problems-1-146064-4878", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-146064"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 6, "mtry": 3, "num.trees": 221, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.870831829914823}}}], "metrics": 1.0, "context": "openml-monks-problems-1-146064", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-monks-problems-1-146064-4877", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-146064"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 5, "num.trees": 1878, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.815340952482074}}}], "metrics": 1.0, "context": "openml-monks-problems-1-146064", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-monks-problems-1-146064-4873", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-146064"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 6, "num.trees": 1613, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.8802603304153311}}}], "metrics": 1.0, "context": "openml-monks-problems-1-146064", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-wdbc-145878-7606", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 7, "num.trees": 1839, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.8731064271880311}}}], "metrics": 0.970123, "context": "openml-wdbc-145878", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-wdbc-145878-6295", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 7, "num.trees": 175, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.936247572838329}}}], "metrics": 0.970123, "context": "openml-wdbc-145878", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-wdbc-145878-8375", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 4, "mtry": 3, "num.trees": 1138, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.9257442631991581}}}], "metrics": 0.968366, "context": "openml-wdbc-145878", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-wdbc-145878-7742", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 21, "num.trees": 229, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.879089176957496}}}], "metrics": 0.968366, "context": "openml-wdbc-145878", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-wdbc-145878-9247", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 7, "mtry": 12, "num.trees": 546, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.9774557593511422}}}], "metrics": 0.968366, "context": "openml-wdbc-145878", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-australian-125923-9276", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 4, "num.trees": 17, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.7276798309059811}}}], "metrics": 0.87971, "context": "openml-australian-125923", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-australian-125923-7406", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 6, "mtry": 2, "num.trees": 46, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.9914852396817881}}}], "metrics": 0.87971, "context": "openml-australian-125923", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-australian-125923-7525", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 17, "mtry": 4, "num.trees": 44, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.363372555770911}}}], "metrics": 0.878261, "context": "openml-australian-125923", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-australian-125923-7728", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 5, "mtry": 12, "num.trees": 27, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.167426815046929}}}], "metrics": 0.878261, "context": "openml-australian-125923", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-australian-125923-2412", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 5, "num.trees": 44, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.472372465371154}}}], "metrics": 0.876812, "context": "openml-australian-125923", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-kr-vs-kp-3-8510", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 32, "num.trees": 978, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.99431764674373}}}], "metrics": 0.997184, "context": "openml-kr-vs-kp-3", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-kr-vs-kp-3-8406", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 2, "mtry": 33, "num.trees": 1596, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.98318869152572}}}], "metrics": 0.997184, "context": "openml-kr-vs-kp-3", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-kr-vs-kp-3-8923", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 26, "num.trees": 1602, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.997444531647488}}}], "metrics": 0.997184, "context": "openml-kr-vs-kp-3", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-kr-vs-kp-3-5411", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 36, "num.trees": 1399, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.9466032476164401}}}], "metrics": 0.996871, "context": "openml-kr-vs-kp-3", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-ranger-5965-openml-kr-vs-kp-3-3745", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5965", "config": {"min.node.size": 1, "mtry": 33, "num.trees": 902, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.8101284560281781}}}], "metrics": 0.996871, "context": "openml-kr-vs-kp-3", "schema": "ranger-5965", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-banknote-authentication-145834-144", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.949372094357386, "lambda": 0.00192432260153673}}}], "metrics": 0.983965, "context": "openml-banknote-authentication-145834", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-banknote-authentication-145834-047", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.828285421710461, "lambda": 0.00155609729372454}}}], "metrics": 0.983965, "context": "openml-banknote-authentication-145834", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-banknote-authentication-145834-158", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.879993628244847, "lambda": 0.00214254945606924}}}], "metrics": 0.981778, "context": "openml-banknote-authentication-145834", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-banknote-authentication-145834-060", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.499214767245576, "lambda": 0.0010033575643366}}}], "metrics": 0.981778, "context": "openml-banknote-authentication-145834", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-banknote-authentication-145834-020", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.884549982147291, "lambda": 0.00250302518657503}}}], "metrics": 0.981778, "context": "openml-banknote-authentication-145834", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-madelon-145853-153", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.928065786371008, "lambda": 0.0374513303630034}}}], "metrics": 0.618462, "context": "openml-madelon-145853", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-madelon-145853-003", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.931708315387368, "lambda": 0.0347519744880447}}}], "metrics": 0.618077, "context": "openml-madelon-145853", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-madelon-145853-100", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.616072565084323, "lambda": 0.0590428840122568}}}], "metrics": 0.618077, "context": "openml-madelon-145853", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-madelon-145853-064", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.604896825505421, "lambda": 0.045847209241803}}}], "metrics": 0.618077, "context": "openml-madelon-145853", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-madelon-145853-037", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.589737937320024, "lambda": 0.0620816377646072}}}], "metrics": 0.617692, "context": "openml-madelon-145853", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-climate-model-simulation-crashes-145839-388", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.229047984117642, "lambda": 0.217822962894198}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-145839", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-climate-model-simulation-crashes-145839-170", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.702481821645051, "lambda": 0.378887942971882}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-145839", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-climate-model-simulation-crashes-145839-163", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.925015562213957, "lambda": 0.145136467222015}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-145839", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-climate-model-simulation-crashes-145839-164", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.373475652886555, "lambda": 1.4135733535545}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-145839", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-climate-model-simulation-crashes-145839-165", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.565069195348769, "lambda": 23.410200808535}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-145839", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-blood-transfusion-service-center-145836-414", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.396819674409926, "lambda": 0.0329241886276756}}}], "metrics": 0.775401, "context": "openml-blood-transfusion-service-center-145836", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-blood-transfusion-service-center-145836-381", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.363498685881495, "lambda": 0.0347308198023233}}}], "metrics": 0.775401, "context": "openml-blood-transfusion-service-center-145836", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-blood-transfusion-service-center-145836-276", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.772381655871868, "lambda": 0.0213088610388148}}}], "metrics": 0.775401, "context": "openml-blood-transfusion-service-center-145836", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-blood-transfusion-service-center-145836-106", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.701344711706042, "lambda": 0.0183733783371737}}}], "metrics": 0.774064, "context": "openml-blood-transfusion-service-center-145836", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-blood-transfusion-service-center-145836-202", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.743560060625896, "lambda": 0.0138452042220124}}}], "metrics": 0.774064, "context": "openml-blood-transfusion-service-center-145836", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-steel-plates-fault-145872-292", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.853568377904594, "lambda": 0.0128118689112331}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-steel-plates-fault-145872-296", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.49615078815259, "lambda": 0.0158718876219137}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-steel-plates-fault-145872-392", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.51793379872106, "lambda": 0.0416487116070019}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-steel-plates-fault-145872-246", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.665431456174701, "lambda": 0.0452982469978839}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-steel-plates-fault-145872-394", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.589536684099585, "lambda": 0.0542161985696841}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-kr-vs-kp-145953-108", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.903483555885032, "lambda": 0.00108180815834888}}}], "metrics": 0.969962, "context": "openml-kr-vs-kp-145953", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-kr-vs-kp-145953-486", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.809300444088876, "lambda": 0.00101778829662883}}}], "metrics": 0.969337, "context": "openml-kr-vs-kp-145953", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-kr-vs-kp-145953-257", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.90335765411146, "lambda": 0.00110077224402643}}}], "metrics": 0.969024, "context": "openml-kr-vs-kp-145953", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-kr-vs-kp-145953-133", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.578381422674283, "lambda": 0.0011978673101168}}}], "metrics": 0.968398, "context": "openml-kr-vs-kp-145953", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-kr-vs-kp-145953-440", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.288397365715355, "lambda": 0.00108307913062547}}}], "metrics": 0.967772, "context": "openml-kr-vs-kp-145953", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-spambase-43-046", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.9356228786055, "lambda": 0.00103610154587838}}}], "metrics": 0.925016, "context": "openml-spambase-43", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-spambase-43-159", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.925662097753957, "lambda": 0.00169632093861474}}}], "metrics": 0.924799, "context": "openml-spambase-43", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-spambase-43-136", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.113351782318205, "lambda": 0.0010477622783057}}}], "metrics": 0.924582, "context": "openml-spambase-43", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-spambase-43-364", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.0497632136102766, "lambda": 0.00110526564499104}}}], "metrics": 0.924147, "context": "openml-spambase-43", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-spambase-43-252", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.162884045159444, "lambda": 0.001}}}], "metrics": 0.92393, "context": "openml-spambase-43", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-phoneme-145857-463", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.763862604973838, "lambda": 0.00108077138277392}}}], "metrics": 0.749075, "context": "openml-phoneme-145857", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-phoneme-145857-398", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.174157085362822, "lambda": 0.00123004298169233}}}], "metrics": 0.749075, "context": "openml-phoneme-145857", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-phoneme-145857-178", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.366524597164243, "lambda": 0.00110186782873452}}}], "metrics": 0.749075, "context": "openml-phoneme-145857", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-phoneme-145857-433", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.239641414955258, "lambda": 0.00151395122443946}}}], "metrics": 0.74889, "context": "openml-phoneme-145857", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-phoneme-145857-286", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.618686001515016, "lambda": 0.00134818464550015}}}], "metrics": 0.74889, "context": "openml-phoneme-145857", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-musk-3950-084", "modules": [{"role": "dataset", "module": "openml-musk-3950"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.137460829690099, "lambda": 0.00921129217620523}}}], "metrics": 0.999697, "context": "openml-musk-3950", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-musk-3950-060", "modules": [{"role": "dataset", "module": "openml-musk-3950"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.342604425968602, "lambda": 0.00233268208706031}}}], "metrics": 0.999697, "context": "openml-musk-3950", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-musk-3950-051", "modules": [{"role": "dataset", "module": "openml-musk-3950"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.0570002247113734, "lambda": 0.017997322517422}}}], "metrics": 0.999697, "context": "openml-musk-3950", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-musk-3950-247", "modules": [{"role": "dataset", "module": "openml-musk-3950"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.942899432498962, "lambda": 0.00218473086369112}}}], "metrics": 0.999697, "context": "openml-musk-3950", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-musk-3950-253", "modules": [{"role": "dataset", "module": "openml-musk-3950"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.199610359035432, "lambda": 0.00348367274888371}}}], "metrics": 0.999697, "context": "openml-musk-3950", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-bioresponse-145677-372", "modules": [{"role": "dataset", "module": "openml-bioresponse-145677"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.562990426784381, "lambda": 0.0141879578761054}}}], "metrics": 0.779525, "context": "openml-bioresponse-145677", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-bioresponse-145677-205", "modules": [{"role": "dataset", "module": "openml-bioresponse-145677"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.574391512200236, "lambda": 0.0144372498904573}}}], "metrics": 0.779259, "context": "openml-bioresponse-145677", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-bioresponse-145677-280", "modules": [{"role": "dataset", "module": "openml-bioresponse-145677"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.895461443345994, "lambda": 0.00859097401307845}}}], "metrics": 0.779259, "context": "openml-bioresponse-145677", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-bioresponse-145677-306", "modules": [{"role": "dataset", "module": "openml-bioresponse-145677"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.673961147200316, "lambda": 0.0111063105218315}}}], "metrics": 0.778992, "context": "openml-bioresponse-145677", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-bioresponse-145677-308", "modules": [{"role": "dataset", "module": "openml-bioresponse-145677"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.770092487102374, "lambda": 0.00990092667658299}}}], "metrics": 0.778726, "context": "openml-bioresponse-145677", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-bank-marketing-145833-436", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.842400756897405, "lambda": 0.00101208385387395}}}], "metrics": 0.901484, "context": "openml-bank-marketing-145833", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-bank-marketing-145833-039", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.248892011353746, "lambda": 0.00181647613688011}}}], "metrics": 0.901484, "context": "openml-bank-marketing-145833", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-bank-marketing-145833-234", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.453193940222263, "lambda": 0.00103176851917468}}}], "metrics": 0.901462, "context": "openml-bank-marketing-145833", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-bank-marketing-145833-402", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.469499152386561, "lambda": 0.00120783596590024}}}], "metrics": 0.901462, "context": "openml-bank-marketing-145833", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-bank-marketing-145833-348", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.503672600025311, "lambda": 0.00125484066619518}}}], "metrics": 0.901462, "context": "openml-bank-marketing-145833", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-bioresponse-9910-446", "modules": [{"role": "dataset", "module": "openml-bioresponse-9910"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.716125681763515, "lambda": 0.0101486422769179}}}], "metrics": 0.779792, "context": "openml-bioresponse-9910", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-bioresponse-9910-177", "modules": [{"role": "dataset", "module": "openml-bioresponse-9910"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.413795347558334, "lambda": 0.017303041938914}}}], "metrics": 0.779792, "context": "openml-bioresponse-9910", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-bioresponse-9910-397", "modules": [{"role": "dataset", "module": "openml-bioresponse-9910"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.35280653112568, "lambda": 0.0213785836716101}}}], "metrics": 0.779525, "context": "openml-bioresponse-9910", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-bioresponse-9910-434", "modules": [{"role": "dataset", "module": "openml-bioresponse-9910"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.168023103382438, "lambda": 0.0198922217638789}}}], "metrics": 0.779259, "context": "openml-bioresponse-9910", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-bioresponse-9910-125", "modules": [{"role": "dataset", "module": "openml-bioresponse-9910"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.172428290592507, "lambda": 0.021174527088012}}}], "metrics": 0.778726, "context": "openml-bioresponse-9910", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-bioresponse-14966-119", "modules": [{"role": "dataset", "module": "openml-bioresponse-14966"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.413497818866745, "lambda": 0.018660207462677}}}], "metrics": 0.780325, "context": "openml-bioresponse-14966", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-bioresponse-14966-370", "modules": [{"role": "dataset", "module": "openml-bioresponse-14966"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.734818551922217, "lambda": 0.0114056376202035}}}], "metrics": 0.779792, "context": "openml-bioresponse-14966", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-bioresponse-14966-120", "modules": [{"role": "dataset", "module": "openml-bioresponse-14966"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.502956530777737, "lambda": 0.0158672711403559}}}], "metrics": 0.779792, "context": "openml-bioresponse-14966", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-bioresponse-14966-216", "modules": [{"role": "dataset", "module": "openml-bioresponse-14966"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.556860788026825, "lambda": 0.0154476658684905}}}], "metrics": 0.779525, "context": "openml-bioresponse-14966", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-bioresponse-14966-076", "modules": [{"role": "dataset", "module": "openml-bioresponse-14966"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.643914320273325, "lambda": 0.0124784092470643}}}], "metrics": 0.779525, "context": "openml-bioresponse-14966", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-ada-agnostic-3896-090", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.356445478508249, "lambda": 0.00465953720560218}}}], "metrics": 0.843051, "context": "openml-ada-agnostic-3896", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-ada-agnostic-3896-324", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.971440502908081, "lambda": 0.00814926938000166}}}], "metrics": 0.843051, "context": "openml-ada-agnostic-3896", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-ada-agnostic-3896-347", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.821605670033023, "lambda": 0.0102860986756351}}}], "metrics": 0.843051, "context": "openml-ada-agnostic-3896", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-ada-agnostic-3896-122", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.352677318034694, "lambda": 0.00422694231632098}}}], "metrics": 0.842832, "context": "openml-ada-agnostic-3896", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-ada-agnostic-3896-219", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.961008145241067, "lambda": 0.00183266098167684}}}], "metrics": 0.842832, "context": "openml-ada-agnostic-3896", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-nomao-9977-497", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.142453325446695, "lambda": 0.00135850569992425}}}], "metrics": 0.947222, "context": "openml-nomao-9977", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-nomao-9977-311", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.856652155052871, "lambda": 0.00101745182973177}}}], "metrics": 0.946554, "context": "openml-nomao-9977", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-nomao-9977-213", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.930913726566359, "lambda": 0.001}}}], "metrics": 0.946496, "context": "openml-nomao-9977", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-nomao-9977-423", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.677037165267393, "lambda": 0.00115398743499704}}}], "metrics": 0.946438, "context": "openml-nomao-9977", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-nomao-9977-380", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.365202035289258, "lambda": 0.00172343596789731}}}], "metrics": 0.94638, "context": "openml-nomao-9977", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-pc1-3918-508", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.96636328776367, "lambda": 0.00247420111058431}}}], "metrics": 0.932372, "context": "openml-pc1-3918", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-pc1-3918-141", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.848931353073567, "lambda": 0.00267717377226403}}}], "metrics": 0.9323715058611362, "context": "openml-pc1-3918", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-pc1-3918-408", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.795903716702014, "lambda": 0.00122163532296833}}}], "metrics": 0.9323715058611362, "context": "openml-pc1-3918", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-pc1-3918-380", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.974533974891528, "lambda": 0.00242893597058443}}}], "metrics": 0.9323715058611362, "context": "openml-pc1-3918", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-pc1-3918-111", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.113644811557606, "lambda": 0.00441226892799659}}}], "metrics": 0.9323715058611362, "context": "openml-pc1-3918", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-magictelescope-3954-277", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.737581541761756, "lambda": 0.00101224711163966}}}], "metrics": 0.790641, "context": "openml-magictelescope-3954", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-magictelescope-3954-408", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.34190418664366, "lambda": 0.00219106236609392}}}], "metrics": 0.790589, "context": "openml-magictelescope-3954", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-magictelescope-3954-631", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.853430614806712, "lambda": 0.0020073739732143}}}], "metrics": 0.790536, "context": "openml-magictelescope-3954", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-magictelescope-3954-590", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.502443270757794, "lambda": 0.00164185499120533}}}], "metrics": 0.790536, "context": "openml-magictelescope-3954", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-magictelescope-3954-306", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.445697843562812, "lambda": 0.00117143895513387}}}], "metrics": 0.790536, "context": "openml-magictelescope-3954", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-scene-3485-253", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.772774001816288, "lambda": 0.00186299996891132}}}], "metrics": 0.989614, "context": "openml-scene-3485", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-scene-3485-099", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.750040397979319, "lambda": 0.00187433031539504}}}], "metrics": 0.989614, "context": "openml-scene-3485", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-scene-3485-244", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.705361770233139, "lambda": 0.00198196156037664}}}], "metrics": 0.989614, "context": "openml-scene-3485", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-scene-3485-531", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.745966913411394, "lambda": 0.00191435868814357}}}], "metrics": 0.989614, "context": "openml-scene-3485", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-scene-3485-270", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.252644720021635, "lambda": 0.00559199139793231}}}], "metrics": 0.989614, "context": "openml-scene-3485", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-phishingwebsites-14952-578", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-14952"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.0328565665986389, "lambda": 0.00327926402812549}}}], "metrics": 0.940027, "context": "openml-phishingwebsites-14952", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-phishingwebsites-14952-372", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-14952"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.0577455763705075, "lambda": 0.00313683216427385}}}], "metrics": 0.939937, "context": "openml-phishingwebsites-14952", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-phishingwebsites-14952-794", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-14952"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.01723338291049, "lambda": 0.00302209429453936}}}], "metrics": 0.939937, "context": "openml-phishingwebsites-14952", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-phishingwebsites-14952-615", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-14952"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.0432404056191444, "lambda": 0.00213616623253358}}}], "metrics": 0.939756, "context": "openml-phishingwebsites-14952", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-phishingwebsites-14952-161", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-14952"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.128954975632951, "lambda": 0.00293840350268925}}}], "metrics": 0.939756, "context": "openml-phishingwebsites-14952", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-qsar-biodeg-145862-078", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.521156735951081, "lambda": 0.00205343513242447}}}], "metrics": 0.875829, "context": "openml-qsar-biodeg-145862", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-qsar-biodeg-145862-770", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.840260591823608, "lambda": 0.00164780058969817}}}], "metrics": 0.874882, "context": "openml-qsar-biodeg-145862", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-qsar-biodeg-145862-514", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.377070039045066, "lambda": 0.00193364902244567}}}], "metrics": 0.874882, "context": "openml-qsar-biodeg-145862", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-qsar-biodeg-145862-011", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.94912736560218, "lambda": 0.00185991662537798}}}], "metrics": 0.874882, "context": "openml-qsar-biodeg-145862", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-qsar-biodeg-145862-656", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.60336639592424, "lambda": 0.00188370503642861}}}], "metrics": 0.874882, "context": "openml-qsar-biodeg-145862", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-electricity-146012-733", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.896789844613522, "lambda": 0.00155606854940199}}}], "metrics": 0.760483, "context": "openml-electricity-146012", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-electricity-146012-796", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.682371939532459, "lambda": 0.00203554695631131}}}], "metrics": 0.760328, "context": "openml-electricity-146012", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-electricity-146012-540", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.492129537044093, "lambda": 0.00224846566657275}}}], "metrics": 0.760306, "context": "openml-electricity-146012", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-electricity-146012-168", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.450426308205351, "lambda": 0.00258133849224145}}}], "metrics": 0.760064, "context": "openml-electricity-146012", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-electricity-146012-063", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.972637090599164, "lambda": 0.00256418912775865}}}], "metrics": 0.759975, "context": "openml-electricity-146012", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-nomao-145854-882", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.0550491600297391, "lambda": 0.001}}}], "metrics": 0.947831, "context": "openml-nomao-145854", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-nomao-145854-191", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.0316674367059022, "lambda": 0.0012352769218347}}}], "metrics": 0.947802, "context": "openml-nomao-145854", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-nomao-145854-782", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.0686662001535296, "lambda": 0.00114715652397162}}}], "metrics": 0.947657, "context": "openml-nomao-145854", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-nomao-145854-792", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.100795466918498, "lambda": 0.0012321984886998}}}], "metrics": 0.947628, "context": "openml-nomao-145854", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-nomao-145854-178", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.151449177414179, "lambda": 0.00110637420816618}}}], "metrics": 0.947599, "context": "openml-nomao-145854", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-qsar-biodeg-9957-721", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.531026746612042, "lambda": 0.00187793221084485}}}], "metrics": 0.875829, "context": "openml-qsar-biodeg-9957", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-qsar-biodeg-9957-818", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.431261918274686, "lambda": 0.00224479208702024}}}], "metrics": 0.874882, "context": "openml-qsar-biodeg-9957", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-qsar-biodeg-9957-815", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.963852570159361, "lambda": 0.00177723571557084}}}], "metrics": 0.874882, "context": "openml-qsar-biodeg-9957", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-qsar-biodeg-9957-492", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.668553900439292, "lambda": 0.00180141413716922}}}], "metrics": 0.874882, "context": "openml-qsar-biodeg-9957", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-qsar-biodeg-9957-659", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.484379487810656, "lambda": 0.00211628625359975}}}], "metrics": 0.874882, "context": "openml-qsar-biodeg-9957", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-hill-valley-145847-200", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.140835765749216, "lambda": 0.00102915029111553}}}], "metrics": 0.706271, "context": "openml-hill-valley-145847", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-hill-valley-145847-339", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.0847903015092015, "lambda": 0.00111951321241107}}}], "metrics": 0.702145, "context": "openml-hill-valley-145847", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-hill-valley-145847-186", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.23275915440172, "lambda": 0.00105659215802571}}}], "metrics": 0.70132, "context": "openml-hill-valley-145847", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-hill-valley-145847-818", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.0448322473093867, "lambda": 0.00126417258161873}}}], "metrics": 0.69967, "context": "openml-hill-valley-145847", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-hill-valley-145847-411", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.4569022199139, "lambda": 0.00100896095945869}}}], "metrics": 0.698845, "context": "openml-hill-valley-145847", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-diabetes-145976-418", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.100010556401685, "lambda": 0.00171795363370125}}}], "metrics": 0.778646, "context": "openml-diabetes-145976", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-diabetes-145976-481", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.138952489709482, "lambda": 0.00148332735033895}}}], "metrics": 0.778646, "context": "openml-diabetes-145976", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-diabetes-145976-196", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.589998133247718, "lambda": 0.00104430398794857}}}], "metrics": 0.778646, "context": "openml-diabetes-145976", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-diabetes-145976-554", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.0226141370367259, "lambda": 0.00208523795767713}}}], "metrics": 0.778646, "context": "openml-diabetes-145976", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-diabetes-145976-761", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.0289163691923022, "lambda": 0.00227660025966004}}}], "metrics": 0.778646, "context": "openml-diabetes-145976", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-monks-problems-1-146064-994", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-146064"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.935346915386617, "lambda": 0.15029924023006003}}}], "metrics": 0.746403, "context": "openml-monks-problems-1-146064", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-monks-problems-1-146064-465", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-146064"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.542257134104148, "lambda": 0.223841701228514}}}], "metrics": 0.746403, "context": "openml-monks-problems-1-146064", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-monks-problems-1-146064-473", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-146064"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.618595252046362, "lambda": 0.0436429526872996}}}], "metrics": 0.746403, "context": "openml-monks-problems-1-146064", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-monks-problems-1-146064-472", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-146064"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.00772639759816229, "lambda": 0.00269317639118778}}}], "metrics": 0.746403, "context": "openml-monks-problems-1-146064", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-monks-problems-1-146064-471", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-146064"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.268392754485831, "lambda": 0.00579866575062105}}}], "metrics": 0.746403, "context": "openml-monks-problems-1-146064", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-sylva-agnostic-3889-922", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.0508400541730225, "lambda": 0.0721176678397562}}}], "metrics": 0.98694, "context": "openml-sylva-agnostic-3889", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-sylva-agnostic-3889-044", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.0185991735197604, "lambda": 0.107881345621799}}}], "metrics": 0.986176, "context": "openml-sylva-agnostic-3889", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-sylva-agnostic-3889-247", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.0610796948894858, "lambda": 0.0800977896827457}}}], "metrics": 0.986176, "context": "openml-sylva-agnostic-3889", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-sylva-agnostic-3889-316", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.179434102261439, "lambda": 0.0575421701504415}}}], "metrics": 0.985273, "context": "openml-sylva-agnostic-3889", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-sylva-agnostic-3889-123", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.0846055559813976, "lambda": 0.07983349939136}}}], "metrics": 0.985134, "context": "openml-sylva-agnostic-3889", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-wilt-9914-166", "modules": [{"role": "dataset", "module": "openml-wilt-9914"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.796885686228052, "lambda": 0.00132737910678047}}}], "metrics": 0.95185, "context": "openml-wilt-9914", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-wilt-9914-1205", "modules": [{"role": "dataset", "module": "openml-wilt-9914"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.885316737927496, "lambda": 0.00177206798664417}}}], "metrics": 0.951643, "context": "openml-wilt-9914", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-wilt-9914-131", "modules": [{"role": "dataset", "module": "openml-wilt-9914"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.738917434355244, "lambda": 0.00133383276249368}}}], "metrics": 0.95123, "context": "openml-wilt-9914", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-wilt-9914-235", "modules": [{"role": "dataset", "module": "openml-wilt-9914"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.694155456032604, "lambda": 0.00124359811677048}}}], "metrics": 0.951023, "context": "openml-wilt-9914", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-wilt-9914-549", "modules": [{"role": "dataset", "module": "openml-wilt-9914"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.778337638126686, "lambda": 0.00135881737739568}}}], "metrics": 0.950816, "context": "openml-wilt-9914", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-monks-problems-2-3493-1400", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.485058546066284, "lambda": 0.0259522097612328}}}], "metrics": 0.657238, "context": "openml-monks-problems-2-3493", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-monks-problems-2-3493-520", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.00603013811632991, "lambda": 31.2706786501488}}}], "metrics": 0.657238, "context": "openml-monks-problems-2-3493", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-monks-problems-2-3493-512", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.385014427127317, "lambda": 23.1993736136937}}}], "metrics": 0.657238, "context": "openml-monks-problems-2-3493", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-monks-problems-2-3493-513", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.595574837876484, "lambda": 159.265485036055}}}], "metrics": 0.657238, "context": "openml-monks-problems-2-3493", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-monks-problems-2-3493-514", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.225368711398914, "lambda": 0.547481970869169}}}], "metrics": 0.657238, "context": "openml-monks-problems-2-3493", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-pc4-3902-1282", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.248792382190004, "lambda": 0.00186569237386324}}}], "metrics": 0.910837, "context": "openml-pc4-3902", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-pc4-3902-1026", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.0766260325908661, "lambda": 0.00450973080874992}}}], "metrics": 0.910837, "context": "openml-pc4-3902", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-pc4-3902-253", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.270028252154589, "lambda": 0.00187190872047833}}}], "metrics": 0.910837, "context": "openml-pc4-3902", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-pc4-3902-559", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.0352928922511637, "lambda": 0.00481816853699838}}}], "metrics": 0.910837, "context": "openml-pc4-3902", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-pc4-3902-1203", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.19699262175709, "lambda": 0.00184031242550997}}}], "metrics": 0.910837, "context": "openml-pc4-3902", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-bank-marketing-14965-908", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.374762722756714, "lambda": 0.00105905173247743}}}], "metrics": 0.901551, "context": "openml-bank-marketing-14965", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-bank-marketing-14965-216", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.45096995565109, "lambda": 0.001}}}], "metrics": 0.901506, "context": "openml-bank-marketing-14965", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-bank-marketing-14965-292", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.99879904021509, "lambda": 0.00389559114050623}}}], "metrics": 0.901484, "context": "openml-bank-marketing-14965", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-bank-marketing-14965-581", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.865584657993168, "lambda": 0.00423934857910017}}}], "metrics": 0.901484, "context": "openml-bank-marketing-14965", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-bank-marketing-14965-222", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.272035656031221, "lambda": 0.00145602982146316}}}], "metrics": 0.901484, "context": "openml-bank-marketing-14965", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-ozone-level-8hr-145855-590", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.106366502819583, "lambda": 0.00179531886238585}}}], "metrics": 0.945146, "context": "openml-ozone-level-8hr-145855", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-ozone-level-8hr-145855-104", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.143425705842674, "lambda": 0.00154303507461108}}}], "metrics": 0.945146, "context": "openml-ozone-level-8hr-145855", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-ozone-level-8hr-145855-1155", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.311693141004071, "lambda": 0.00133160207647888}}}], "metrics": 0.944751, "context": "openml-ozone-level-8hr-145855", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-ozone-level-8hr-145855-422", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.102382283192128, "lambda": 0.00156053904704669}}}], "metrics": 0.944751, "context": "openml-ozone-level-8hr-145855", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-ozone-level-8hr-145855-1062", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.130060771713033, "lambda": 0.00161385612503655}}}], "metrics": 0.944751, "context": "openml-ozone-level-8hr-145855", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-wdbc-145878-1221", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.546109674731269, "lambda": 0.00866769240769949}}}], "metrics": 0.980668, "context": "openml-wdbc-145878", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-wdbc-145878-346", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.399284986546263, "lambda": 0.00780252938031672}}}], "metrics": 0.980668, "context": "openml-wdbc-145878", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-wdbc-145878-226", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.505797336110845, "lambda": 0.0154555030177557}}}], "metrics": 0.980668, "context": "openml-wdbc-145878", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-wdbc-145878-1191", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.268098059576005, "lambda": 0.013879182947156}}}], "metrics": 0.980668, "context": "openml-wdbc-145878", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-wdbc-145878-1131", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.325748485745862, "lambda": 0.0147369162374649}}}], "metrics": 0.980668, "context": "openml-wdbc-145878", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-click-prediction-small-7295-636", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.353966925293207, "lambda": 0.00103261221512183}}}], "metrics": 0.832057, "context": "openml-click-prediction-small-7295", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-click-prediction-small-7295-928", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.144468675367534, "lambda": 0.00103526262098836}}}], "metrics": 0.832032, "context": "openml-click-prediction-small-7295", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-click-prediction-small-7295-1406", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.0290736937895417, "lambda": 0.001}}}], "metrics": 0.832032, "context": "openml-click-prediction-small-7295", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-click-prediction-small-7295-1402", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.73093789210543, "lambda": 0.00100731877455058}}}], "metrics": 0.832032, "context": "openml-click-prediction-small-7295", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-click-prediction-small-7295-376", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.0672955368645489, "lambda": 0.00103357231310545}}}], "metrics": 0.832032, "context": "openml-click-prediction-small-7295", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-steel-plates-fault-9967-1697", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.670252652605996, "lambda": 0.00756025064169852}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-steel-plates-fault-9967-644", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.699652247363701, "lambda": 0.0554113683070439}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-steel-plates-fault-9967-1277", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.705943487817422, "lambda": 0.0279798369932993}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-steel-plates-fault-9967-1444", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.7732696486637, "lambda": 0.00599705187446981}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-steel-plates-fault-9967-1061", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.845226235687733, "lambda": 0.00572671783700164}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-credit-g-31-547", "modules": [{"role": "dataset", "module": "openml-credit-g-31"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.0626035062596202, "lambda": 0.0181644448031338}}}], "metrics": 0.764, "context": "openml-credit-g-31", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-credit-g-31-1357", "modules": [{"role": "dataset", "module": "openml-credit-g-31"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.0680296600330621, "lambda": 0.0174654531054788}}}], "metrics": 0.764, "context": "openml-credit-g-31", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-credit-g-31-1057", "modules": [{"role": "dataset", "module": "openml-credit-g-31"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.100544249871746, "lambda": 0.0192894949384351}}}], "metrics": 0.763, "context": "openml-credit-g-31", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-credit-g-31-742", "modules": [{"role": "dataset", "module": "openml-credit-g-31"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.00329751335084438, "lambda": 0.0237661361356674}}}], "metrics": 0.763, "context": "openml-credit-g-31", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-credit-g-31-930", "modules": [{"role": "dataset", "module": "openml-credit-g-31"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.0580136380158365, "lambda": 0.0241358735362407}}}], "metrics": 0.763, "context": "openml-credit-g-31", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-australian-125923-303", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.338176711928099, "lambda": 0.0432255762559472}}}], "metrics": 0.875362, "context": "openml-australian-125923", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-australian-125923-801", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.245910628931597, "lambda": 0.11454394965888}}}], "metrics": 0.875362, "context": "openml-australian-125923", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-australian-125923-031", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.399103636154905, "lambda": 0.0432959256964034}}}], "metrics": 0.875362, "context": "openml-australian-125923", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-australian-125923-1392", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.385679163970053, "lambda": 0.0400046565926901}}}], "metrics": 0.875362, "context": "openml-australian-125923", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-australian-125923-038", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.408592677675188, "lambda": 0.0353622340640061}}}], "metrics": 0.875362, "context": "openml-australian-125923", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-kc1-3917-1092", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.306887106504291, "lambda": 0.0107773154600062}}}], "metrics": 0.861546, "context": "openml-kc1-3917", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-kc1-3917-1597", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.491820781491697, "lambda": 0.00874866768072819}}}], "metrics": 0.861546, "context": "openml-kc1-3917", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-kc1-3917-597", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.0157917006872594, "lambda": 0.0106489282728957}}}], "metrics": 0.861546, "context": "openml-kc1-3917", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-kc1-3917-1414", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.00622538686729968, "lambda": 0.0171086884993289}}}], "metrics": 0.861546, "context": "openml-kc1-3917", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-kc1-3917-1137", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.285557520808652, "lambda": 0.0112072619881276}}}], "metrics": 0.861546, "context": "openml-kc1-3917", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-hill-valley-9970-819", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.0688281571492553, "lambda": 0.00101858853454169}}}], "metrics": 0.705446, "context": "openml-hill-valley-9970", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-hill-valley-9970-186", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.116069301497191, "lambda": 0.001}}}], "metrics": 0.705446, "context": "openml-hill-valley-9970", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-hill-valley-9970-1573", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.0859172539785504, "lambda": 0.00100175379673197}}}], "metrics": 0.70462, "context": "openml-hill-valley-9970", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-hill-valley-9970-1210", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.037192618008703, "lambda": 0.0011229816291711}}}], "metrics": 0.703795, "context": "openml-hill-valley-9970", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-hill-valley-9970-1334", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.257879190146923, "lambda": 0.001}}}], "metrics": 0.703795, "context": "openml-hill-valley-9970", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-kc2-3913-955", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.202424599789083, "lambda": 0.0616978633483786}}}], "metrics": 0.85249, "context": "openml-kc2-3913", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-kc2-3913-1888", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.243585920892656, "lambda": 0.05902285562781}}}], "metrics": 0.850575, "context": "openml-kc2-3913", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-kc2-3913-705", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.128100933739915, "lambda": 0.0613568279373124}}}], "metrics": 0.850575, "context": "openml-kc2-3913", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-kc2-3913-785", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.0078149326145649, "lambda": 0.15955489384925903}}}], "metrics": 0.850575, "context": "openml-kc2-3913", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-kc2-3913-1037", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.0976889037992805, "lambda": 0.0869090463639692}}}], "metrics": 0.850575, "context": "openml-kc2-3913", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-eeg-eye-state-9983-1734", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.247854490531608, "lambda": 0.00102781331582036}}}], "metrics": 0.587784, "context": "openml-eeg-eye-state-9983", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-eeg-eye-state-9983-978", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.255111430771649, "lambda": 0.00108838446142912}}}], "metrics": 0.587717, "context": "openml-eeg-eye-state-9983", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-eeg-eye-state-9983-940", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.0482751184608787, "lambda": 0.001}}}], "metrics": 0.587717, "context": "openml-eeg-eye-state-9983", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-eeg-eye-state-9983-675", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.0201210791710764, "lambda": 0.00142074523047257}}}], "metrics": 0.587717, "context": "openml-eeg-eye-state-9983", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-eeg-eye-state-9983-1237", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.0197369509842247, "lambda": 0.00144912071513273}}}], "metrics": 0.587583, "context": "openml-eeg-eye-state-9983", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-blood-transfusion-service-center-10101-1095", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.683751152129844, "lambda": 0.0218786759640387}}}], "metrics": 0.775401, "context": "openml-blood-transfusion-service-center-10101", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-blood-transfusion-service-center-10101-1777", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.628367241937667, "lambda": 0.0248142556151689}}}], "metrics": 0.775401, "context": "openml-blood-transfusion-service-center-10101", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-blood-transfusion-service-center-10101-163", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.801140748662874, "lambda": 0.0179322769303373}}}], "metrics": 0.775401, "context": "openml-blood-transfusion-service-center-10101", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-blood-transfusion-service-center-10101-538", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.841869191266596, "lambda": 0.017895960158481}}}], "metrics": 0.775401, "context": "openml-blood-transfusion-service-center-10101", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-blood-transfusion-service-center-10101-076", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.734499267302454, "lambda": 0.0238512439173539}}}], "metrics": 0.775401, "context": "openml-blood-transfusion-service-center-10101", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-credit-g-145972-118", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.080445398343727, "lambda": 0.0176180430042076}}}], "metrics": 0.765, "context": "openml-credit-g-145972", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-credit-g-145972-599", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.177694492973387, "lambda": 0.0114664284392123}}}], "metrics": 0.765, "context": "openml-credit-g-145972", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-credit-g-145972-316", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.100300042657182, "lambda": 0.016617225789834}}}], "metrics": 0.764, "context": "openml-credit-g-145972", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-credit-g-145972-294", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.153464457020164, "lambda": 0.0126129432512143}}}], "metrics": 0.764, "context": "openml-credit-g-145972", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-credit-g-145972-1032", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.22369313496165, "lambda": 0.00981319961535503}}}], "metrics": 0.764, "context": "openml-credit-g-145972", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-spambase-145979-1294", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.984251966001466, "lambda": 0.00152342890131663}}}], "metrics": 0.924799, "context": "openml-spambase-145979", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-spambase-145979-665", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.956629132386297, "lambda": 0.00166144031473242}}}], "metrics": 0.924582, "context": "openml-spambase-145979", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-spambase-145979-1687", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.998656014446169, "lambda": 0.00124136029737853}}}], "metrics": 0.924364, "context": "openml-spambase-145979", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-spambase-145979-243", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.498563634930179, "lambda": 0.001}}}], "metrics": 0.924364, "context": "openml-spambase-145979", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-spambase-145979-034", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.0953148470725864, "lambda": 0.00100970080410315}}}], "metrics": 0.924364, "context": "openml-spambase-145979", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-phishingwebsites-34537-976", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-34537"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.0575969279743731, "lambda": 0.00313627609825784}}}], "metrics": 0.939937, "context": "openml-phishingwebsites-34537", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-phishingwebsites-34537-1462", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-34537"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.0438777871895581, "lambda": 0.0033169037184691}}}], "metrics": 0.939937, "context": "openml-phishingwebsites-34537", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-phishingwebsites-34537-1122", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-34537"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.00812279526144266, "lambda": 0.00270716990700492}}}], "metrics": 0.939846, "context": "openml-phishingwebsites-34537", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-phishingwebsites-34537-866", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-34537"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.00127575872465968, "lambda": 0.00320118838692542}}}], "metrics": 0.939846, "context": "openml-phishingwebsites-34537", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-phishingwebsites-34537-1835", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-34537"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.0501892340835184, "lambda": 0.00336724211942126}}}], "metrics": 0.939846, "context": "openml-phishingwebsites-34537", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-ilpd-145848-1016", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.890297938836738, "lambda": 0.00144510467876386}}}], "metrics": 0.735849, "context": "openml-ilpd-145848", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-ilpd-145848-122", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.677962876856327, "lambda": 0.00147879771276438}}}], "metrics": 0.735849, "context": "openml-ilpd-145848", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-ilpd-145848-1503", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.856078745331615, "lambda": 0.00140869854298264}}}], "metrics": 0.735849, "context": "openml-ilpd-145848", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-ilpd-145848-1826", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.856719993054867, "lambda": 0.00129186163945422}}}], "metrics": 0.734134, "context": "openml-ilpd-145848", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-ilpd-145848-1175", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.943981505464762, "lambda": 0.00115593963337328}}}], "metrics": 0.734134, "context": "openml-ilpd-145848", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-ozone-level-8hr-9978-1397", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.247735826764256, "lambda": 0.00136724879488678}}}], "metrics": 0.945146, "context": "openml-ozone-level-8hr-9978", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-ozone-level-8hr-9978-756", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.171601421199739, "lambda": 0.00145673324281591}}}], "metrics": 0.945146, "context": "openml-ozone-level-8hr-9978", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-ozone-level-8hr-9978-116", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.151842655614018, "lambda": 0.00150285954602314}}}], "metrics": 0.945146, "context": "openml-ozone-level-8hr-9978", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-ozone-level-8hr-9978-658", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.0779553845059127, "lambda": 0.00136014518845664}}}], "metrics": 0.944751, "context": "openml-ozone-level-8hr-9978", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-ozone-level-8hr-9978-2145", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.149218473117799, "lambda": 0.00182307641657791}}}], "metrics": 0.944751, "context": "openml-ozone-level-8hr-9978", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-gina-agnostic-3891-1586", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.727720938622952, "lambda": 0.0124156558328442}}}], "metrics": 0.876874, "context": "openml-gina-agnostic-3891", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-gina-agnostic-3891-1339", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.457828189479187, "lambda": 0.0193883826908651}}}], "metrics": 0.876874, "context": "openml-gina-agnostic-3891", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-gina-agnostic-3891-710", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.170066779246554, "lambda": 0.0259170561360456}}}], "metrics": 0.876874, "context": "openml-gina-agnostic-3891", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-gina-agnostic-3891-062", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.2896058333572, "lambda": 0.0135482218078997}}}], "metrics": 0.876586, "context": "openml-gina-agnostic-3891", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-gina-agnostic-3891-1265", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.268520361511037, "lambda": 0.0145583831207466}}}], "metrics": 0.876586, "context": "openml-gina-agnostic-3891", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-madelon-9976-705", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.468461432261392, "lambda": 0.0970309241231514}}}], "metrics": 0.620385, "context": "openml-madelon-9976", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-madelon-9976-2151", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.978282659081742, "lambda": 0.0473139724057985}}}], "metrics": 0.620385, "context": "openml-madelon-9976", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-madelon-9976-1996", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.756218077149242, "lambda": 0.0613989293862124}}}], "metrics": 0.62, "context": "openml-madelon-9976", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-madelon-9976-022", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.846060921670869, "lambda": 0.0352979760367461}}}], "metrics": 0.62, "context": "openml-madelon-9976", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-madelon-9976-748", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.843146696919575, "lambda": 0.0332522513034426}}}], "metrics": 0.62, "context": "openml-madelon-9976", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-mozilla4-3899-2250", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.997908888151869, "lambda": 0.0301448371883592}}}], "metrics": 0.859569, "context": "openml-mozilla4-3899", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-mozilla4-3899-1833", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.986556600779295, "lambda": 0.0281444495057417}}}], "metrics": 0.858797, "context": "openml-mozilla4-3899", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-mozilla4-3899-881", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.974814522080123, "lambda": 0.0279473401171265}}}], "metrics": 0.858475, "context": "openml-mozilla4-3899", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-mozilla4-3899-1854", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.965654642088339, "lambda": 0.0303392070704927}}}], "metrics": 0.857896, "context": "openml-mozilla4-3899", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-mozilla4-3899-1779", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.946277117356658, "lambda": 0.0244326670158174}}}], "metrics": 0.857703, "context": "openml-mozilla4-3899", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-pc3-3903-983", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.265504540409893, "lambda": 0.00143418575354796}}}], "metrics": 0.899552, "context": "openml-pc3-3903", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-pc3-3903-1505", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.815790364285931, "lambda": 0.00109554347023734}}}], "metrics": 0.899552, "context": "openml-pc3-3903", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-pc3-3903-170", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.746397789334878, "lambda": 0.00102061590786441}}}], "metrics": 0.899552, "context": "openml-pc3-3903", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-pc3-3903-050", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.686100484104827, "lambda": 0.00110816831398546}}}], "metrics": 0.899552, "context": "openml-pc3-3903", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-pc3-3903-2374", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.541680865222588, "lambda": 0.00112233652574378}}}], "metrics": 0.899552, "context": "openml-pc3-3903", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-monks-problems-2-146065-2388", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-146065"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.585009365808219, "lambda": 106.290542513874}}}], "metrics": 0.657238, "context": "openml-monks-problems-2-146065", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-monks-problems-2-146065-861", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-146065"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.0444427779875696, "lambda": 5.49791101446857}}}], "metrics": 0.657238, "context": "openml-monks-problems-2-146065", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-monks-problems-2-146065-863", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-146065"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.321712786797434, "lambda": 969.857169947141}}}], "metrics": 0.657238, "context": "openml-monks-problems-2-146065", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-monks-problems-2-146065-864", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-146065"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.135958343744278, "lambda": 875.731799868265}}}], "metrics": 0.657238, "context": "openml-monks-problems-2-146065", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-monks-problems-2-146065-867", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-146065"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.594246932538226, "lambda": 230.293092566477}}}], "metrics": 0.657238, "context": "openml-monks-problems-2-146065", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-click-prediction-small-14971-659", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.454464742448181, "lambda": 0.00100503954637607}}}], "metrics": 0.832057, "context": "openml-click-prediction-small-14971", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-click-prediction-small-14971-2241", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.75214309245348, "lambda": 0.001}}}], "metrics": 0.832057, "context": "openml-click-prediction-small-14971", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-click-prediction-small-14971-1710", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.740339090814814, "lambda": 0.001}}}], "metrics": 0.832032, "context": "openml-click-prediction-small-14971", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-click-prediction-small-14971-1158", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.125216769054532, "lambda": 0.00108033348924171}}}], "metrics": 0.832032, "context": "openml-click-prediction-small-14971", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-glmnet-5970-openml-click-prediction-small-14971-1618", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-5970", "config": {"alpha": 0.127896587597206, "lambda": 0.001}}}], "metrics": 0.832032, "context": "openml-click-prediction-small-14971", "schema": "glmnet-5970", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-credit-g-145972-011", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 1.1464964043949495, "booster": "gbtree", "colsample_bylevel": 0.101195101859048, "colsample_bytree": 0.333393105771393, "eta": 0.0190703499729629, "lambda": 1.26549414701504, "max_depth": 15, "min_child_weight": 2.7798880343923886, "nrounds": 2643, "subsample": 0.509576955786906}}}], "metrics": 0.772, "context": "openml-credit-g-145972", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-credit-g-145972-041", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.00640394904005575, "booster": "gblinear", "eta": 0.00932264263517455, "lambda": 0.0036532807415064782, "nrounds": 718, "subsample": 0.895665101893246}}}], "metrics": 0.761, "context": "openml-credit-g-145972", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-credit-g-145972-091", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.006512714528286183, "booster": "gblinear", "eta": 0.005658396552750762, "lambda": 0.12394456575636999, "nrounds": 3422, "subsample": 0.527365944115445}}}], "metrics": 0.76, "context": "openml-credit-g-145972", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-credit-g-145972-033", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.004195966598765881, "booster": "gblinear", "eta": 0.506231909784101, "lambda": 0.620289523924049, "nrounds": 1564, "subsample": 0.845544837764464}}}], "metrics": 0.758, "context": "openml-credit-g-145972", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-credit-g-145972-004", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.031441043668520297, "booster": "gbtree", "colsample_bylevel": 0.533789060777053, "colsample_bytree": 0.634213926270604, "eta": 0.00782966661551562, "lambda": 1.1365085829308097, "max_depth": 7, "min_child_weight": 1.0995221951463796, "nrounds": 381, "subsample": 0.268695614440367}}}], "metrics": 0.758, "context": "openml-credit-g-145972", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-monks-problems-2-146065-179", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-146065"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.04665628149984429, "booster": "gbtree", "colsample_bylevel": 0.704026817344129, "colsample_bytree": 0.983829276869074, "eta": 0.1782600911656461, "lambda": 2.5224786265703707, "max_depth": 5, "min_child_weight": 3.532514874465647, "nrounds": 2904, "subsample": 0.975298507674597}}}], "metrics": 0.998336, "context": "openml-monks-problems-2-146065", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-monks-problems-2-146065-081", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-146065"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.1252085235860469, "booster": "gbtree", "colsample_bylevel": 0.676835053833202, "colsample_bytree": 0.842004936188459, "eta": 0.7842896723960241, "lambda": 0.6630592730582222, "max_depth": 5, "min_child_weight": 7.571371214046208, "nrounds": 1541, "subsample": 0.498290412197821}}}], "metrics": 0.97005, "context": "openml-monks-problems-2-146065", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-monks-problems-2-146065-135", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-146065"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.14391565135626105, "booster": "gbtree", "colsample_bylevel": 0.945365568157285, "colsample_bytree": 0.340732974931598, "eta": 0.11731712539824303, "lambda": 5.380935779125656, "max_depth": 6, "min_child_weight": 3.7047099106524306, "nrounds": 3893, "subsample": 0.338404069445096}}}], "metrics": 0.948419, "context": "openml-monks-problems-2-146065", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-monks-problems-2-146065-144", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-146065"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0012876158401032103, "booster": "gbtree", "colsample_bylevel": 0.230065474053845, "colsample_bytree": 0.674262650543824, "eta": 0.196445196099896, "lambda": 69.27674910221525, "max_depth": 7, "min_child_weight": 1.2254639391076598, "nrounds": 2808, "subsample": 0.831061615259387}}}], "metrics": 0.890183, "context": "openml-monks-problems-2-146065", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-monks-problems-2-146065-174", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-146065"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 2.341929986318037, "booster": "gbtree", "colsample_bylevel": 0.329557150835171, "colsample_bytree": 0.460658787284046, "eta": 0.9538471009935222, "lambda": 57.87706793626544, "max_depth": 6, "min_child_weight": 2.196178174869989, "nrounds": 2730, "subsample": 0.851236674305983}}}], "metrics": 0.885191, "context": "openml-monks-problems-2-146065", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-qsar-biodeg-145862-156", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.31481861321837196, "booster": "gbtree", "colsample_bylevel": 0.142715314868838, "colsample_bytree": 0.857943574199453, "eta": 0.013095407248643698, "lambda": 0.21309181675255587, "max_depth": 11, "min_child_weight": 3.339373279911803, "nrounds": 4358, "subsample": 0.831344204838388}}}], "metrics": 0.880569, "context": "openml-qsar-biodeg-145862", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-qsar-biodeg-145862-144", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0183549143678104, "booster": "gbtree", "colsample_bylevel": 0.407801565015689, "colsample_bytree": 0.7532206508331, "eta": 0.012900265154507397, "lambda": 5.929646462326091, "max_depth": 3, "min_child_weight": 4.654721765093463, "nrounds": 4394, "subsample": 0.965655908221379}}}], "metrics": 0.879621, "context": "openml-qsar-biodeg-145862", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-qsar-biodeg-145862-196", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0015474403967926, "booster": "gbtree", "colsample_bylevel": 0.729276683181524, "colsample_bytree": 0.199102036422119, "eta": 0.7774321847537891, "lambda": 822.8642736313426, "max_depth": 9, "min_child_weight": 1.9011940213197298, "nrounds": 3206, "subsample": 0.904379664151929}}}], "metrics": 0.877725, "context": "openml-qsar-biodeg-145862", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-qsar-biodeg-145862-106", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.00899249143417735, "booster": "gbtree", "colsample_bylevel": 0.748384365579113, "colsample_bytree": 0.569925393443555, "eta": 0.019011404002412198, "lambda": 21.222838192269993, "max_depth": 4, "min_child_weight": 4.338543681993427, "nrounds": 3946, "subsample": 0.813378228223883}}}], "metrics": 0.876777, "context": "openml-qsar-biodeg-145862", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-qsar-biodeg-145862-151", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.9218171552340809, "booster": "gbtree", "colsample_bylevel": 0.791949198348448, "colsample_bytree": 0.815745339496061, "eta": 0.004948424904214198, "lambda": 0.013643261871725498, "max_depth": 3, "min_child_weight": 2.497617086651002, "nrounds": 2785, "subsample": 0.724707799777389}}}], "metrics": 0.874882, "context": "openml-qsar-biodeg-145862", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-madelon-145853-196", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.009018790841736268, "booster": "gbtree", "colsample_bylevel": 0.987796926405281, "colsample_bytree": 0.732490790775046, "eta": 0.005725426831273072, "lambda": 0.0192287896499084, "max_depth": 9, "min_child_weight": 3.6939180257170436, "nrounds": 1963, "subsample": 0.93457378577441}}}], "metrics": 0.845385, "context": "openml-madelon-145853", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-madelon-145853-067", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 4.9726729609847045, "booster": "gbtree", "colsample_bylevel": 0.844164072535932, "colsample_bytree": 0.8876734059304, "eta": 0.03168902119439291, "lambda": 0.33048225341525705, "max_depth": 7, "min_child_weight": 3.8662236606668725, "nrounds": 3300, "subsample": 0.824412663234398}}}], "metrics": 0.824615, "context": "openml-madelon-145853", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-madelon-145853-187", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0117228656177895, "booster": "gbtree", "colsample_bylevel": 0.52008635760285, "colsample_bytree": 0.969480579253286, "eta": 0.00255688369261912, "lambda": 13.473358496634587, "max_depth": 6, "min_child_weight": 9.550285988886385, "nrounds": 1776, "subsample": 0.779431246500462}}}], "metrics": 0.820769, "context": "openml-madelon-145853", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-madelon-145853-166", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 2.871515555292181, "booster": "gbtree", "colsample_bylevel": 0.75170111656189, "colsample_bytree": 0.480761028127745, "eta": 0.0963386763426621, "lambda": 5.002345695821709, "max_depth": 12, "min_child_weight": 3.871178100785168, "nrounds": 872, "subsample": 0.801249773381278}}}], "metrics": 0.801154, "context": "openml-madelon-145853", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-madelon-145853-242", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 12.749343827014204, "booster": "gbtree", "colsample_bylevel": 0.558055194793269, "colsample_bytree": 0.978012438630685, "eta": 0.0026486202330781006, "lambda": 50.21540708128219, "max_depth": 12, "min_child_weight": 10.017222288202099, "nrounds": 4231, "subsample": 0.871075512166135}}}], "metrics": 0.798846, "context": "openml-madelon-145853", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-blood-transfusion-service-center-145836-054", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 5.448876604089319, "booster": "gbtree", "colsample_bylevel": 0.822592198848724, "colsample_bytree": 0.941581166815013, "eta": 0.005714612035310482, "lambda": 0.0021481580689656304, "max_depth": 15, "min_child_weight": 2.7699040080921686, "nrounds": 1833, "subsample": 0.746519687981345}}}], "metrics": 0.787433, "context": "openml-blood-transfusion-service-center-145836", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-blood-transfusion-service-center-145836-221", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.463932527231414, "booster": "gbtree", "colsample_bylevel": 0.590341354487464, "colsample_bytree": 0.746430101804435, "eta": 0.0266217054069377, "lambda": 82.93071157680534, "max_depth": 10, "min_child_weight": 3.1829925505004413, "nrounds": 3144, "subsample": 0.25490402111318}}}], "metrics": 0.786096, "context": "openml-blood-transfusion-service-center-145836", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-blood-transfusion-service-center-145836-094", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 2.7761084445195867, "booster": "gbtree", "colsample_bylevel": 0.635655437130481, "colsample_bytree": 0.666669593658298, "eta": 0.006705691553912639, "lambda": 0.18199386609953003, "max_depth": 2, "min_child_weight": 16.821885664996184, "nrounds": 1621, "subsample": 0.56149718479719}}}], "metrics": 0.784759, "context": "openml-blood-transfusion-service-center-145836", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-blood-transfusion-service-center-145836-207", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 3.067800572832871, "booster": "gbtree", "colsample_bylevel": 0.425929707475007, "colsample_bytree": 0.779678933788091, "eta": 0.005376998375701621, "lambda": 16.153879150212695, "max_depth": 7, "min_child_weight": 2.1625787620955, "nrounds": 4887, "subsample": 0.837351695052348}}}], "metrics": 0.783422, "context": "openml-blood-transfusion-service-center-145836", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-blood-transfusion-service-center-145836-289", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0019024452248911806, "booster": "gbtree", "colsample_bylevel": 0.857294589281082, "colsample_bytree": 0.936074993573129, "eta": 0.00124801608835741, "lambda": 0.017923688003987796, "max_depth": 5, "min_child_weight": 1.05934319219963, "nrounds": 2329, "subsample": 0.611546531738713}}}], "metrics": 0.782086, "context": "openml-blood-transfusion-service-center-145836", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-phoneme-145857-341", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.06404653751081649, "booster": "gbtree", "colsample_bylevel": 0.532550724688917, "colsample_bytree": 0.989668275695294, "eta": 0.04432132070906398, "lambda": 0.8398395752543013, "max_depth": 12, "min_child_weight": 1.3443144475333901, "nrounds": 3477, "subsample": 0.958094134251587}}}], "metrics": 0.906551, "context": "openml-phoneme-145857", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-phoneme-145857-227", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 3.058712009517633, "booster": "gbtree", "colsample_bylevel": 0.84292671806179, "colsample_bytree": 0.728525905637071, "eta": 0.11284903910260094, "lambda": 0.0014494331636188199, "max_depth": 7, "min_child_weight": 2.1165705953571883, "nrounds": 3369, "subsample": 0.951741053140722}}}], "metrics": 0.899704, "context": "openml-phoneme-145857", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-phoneme-145857-139", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0036485655996747984, "booster": "gbtree", "colsample_bylevel": 0.483836288098246, "colsample_bytree": 0.787859689909965, "eta": 0.0130669925280334, "lambda": 0.030179547756105398, "max_depth": 12, "min_child_weight": 1.8083361626126415, "nrounds": 1362, "subsample": 0.572065786947496}}}], "metrics": 0.899519, "context": "openml-phoneme-145857", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-phoneme-145857-355", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0013556183405656198, "booster": "gbtree", "colsample_bylevel": 0.7248390968889, "colsample_bytree": 0.6578054651618, "eta": 0.12253011085111502, "lambda": 0.0020710093636566503, "max_depth": 14, "min_child_weight": 1.8396620144798093, "nrounds": 4128, "subsample": 0.767892395472154}}}], "metrics": 0.898779, "context": "openml-phoneme-145857", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-phoneme-145857-352", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.2050975168525861, "booster": "gbtree", "colsample_bylevel": 0.510762848658487, "colsample_bytree": 0.900728756794706, "eta": 0.07717938096801488, "lambda": 0.006681846555228842, "max_depth": 5, "min_child_weight": 3.5393919314123568, "nrounds": 3961, "subsample": 0.264836392388679}}}], "metrics": 0.893597, "context": "openml-phoneme-145857", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-diabetes-37-295", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.07293361232019055, "booster": "gblinear", "eta": 0.0396828501409091, "lambda": 0.150820814295352, "nrounds": 4184, "subsample": 0.312250493909232}}}], "metrics": 0.7799479166666667, "context": "openml-diabetes-37", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-diabetes-37-335", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.2508539600114859, "booster": "gblinear", "eta": 0.060166006471942694, "lambda": 0.055052537176692895, "nrounds": 2909, "subsample": 0.346780034247786}}}], "metrics": 0.7786458333333333, "context": "openml-diabetes-37", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-diabetes-37-265", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.017425035748584308, "booster": "gblinear", "eta": 0.021129888599894803, "lambda": 0.0623020605704439, "nrounds": 3494, "subsample": 0.663694841973484}}}], "metrics": 0.77734375, "context": "openml-diabetes-37", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-diabetes-37-354", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0012103145568068197, "booster": "gblinear", "eta": 0.07649966207117934, "lambda": 0.23104032787726997, "nrounds": 1705, "subsample": 0.422309258743189}}}], "metrics": 0.77734375, "context": "openml-diabetes-37", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-diabetes-37-283", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.003705238500447589, "booster": "gblinear", "eta": 0.12556798838589692, "lambda": 0.0032820742629110513, "nrounds": 1918, "subsample": 0.999704954912886}}}], "metrics": 0.77734375, "context": "openml-diabetes-37", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-ozone-level-8hr-145855-252", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0183861414505785, "booster": "gbtree", "colsample_bylevel": 0.552714104531333, "colsample_bytree": 0.738658565329388, "eta": 0.0167420980517653, "lambda": 0.0019460265864426707, "max_depth": 10, "min_child_weight": 2.2288167631061397, "nrounds": 1210, "subsample": 0.23192418783437496}}}], "metrics": 0.948303, "context": "openml-ozone-level-8hr-145855", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-ozone-level-8hr-145855-148", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.052575547565808727, "booster": "gbtree", "colsample_bylevel": 0.134584391722456, "colsample_bytree": 0.943139674607664, "eta": 0.028729712744152695, "lambda": 3.718212208034042, "max_depth": 13, "min_child_weight": 1.5924899968575013, "nrounds": 1529, "subsample": 0.235086603835225}}}], "metrics": 0.947908, "context": "openml-ozone-level-8hr-145855", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-ozone-level-8hr-145855-376", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.12949534813984204, "booster": "gbtree", "colsample_bylevel": 0.58737764088437, "colsample_bytree": 0.783764645922929, "eta": 0.012608871897893205, "lambda": 36.02727031062699, "max_depth": 11, "min_child_weight": 2.4449594665214796, "nrounds": 4100, "subsample": 0.508573351544328}}}], "metrics": 0.947119, "context": "openml-ozone-level-8hr-145855", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-ozone-level-8hr-145855-167", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 1.01562226376873, "booster": "gbtree", "colsample_bylevel": 0.560748708667234, "colsample_bytree": 0.669049900490791, "eta": 0.0234698610459157, "lambda": 66.10963179689664, "max_depth": 14, "min_child_weight": 1.2338198579712703, "nrounds": 4185, "subsample": 0.3181498255115}}}], "metrics": 0.946725, "context": "openml-ozone-level-8hr-145855", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-ozone-level-8hr-145855-028", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 11.120407451506809, "booster": "gbtree", "colsample_bylevel": 0.268574755638838, "colsample_bytree": 0.365121275419369, "eta": 0.11446420645884893, "lambda": 0.09640627123399408, "max_depth": 9, "min_child_weight": 13.608600048589112, "nrounds": 1315, "subsample": 0.848791885841638}}}], "metrics": 0.945541, "context": "openml-ozone-level-8hr-145855", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-kc1-3917-298", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.016737854276853693, "booster": "gblinear", "eta": 0.004141182381423281, "lambda": 0.0223468556190703, "nrounds": 3508, "subsample": 0.407868899195455}}}], "metrics": 0.863442, "context": "openml-kc1-3917", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-kc1-3917-264", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.205211578856861, "booster": "gbtree", "colsample_bylevel": 0.593794575892389, "colsample_bytree": 0.582023784518242, "eta": 0.009973660175718598, "lambda": 0.18043204338063, "max_depth": 10, "min_child_weight": 1.2377754046772411, "nrounds": 433, "subsample": 0.447270012553781}}}], "metrics": 0.862968, "context": "openml-kc1-3917", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-kc1-3917-022", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 2.3773545253483306, "booster": "gbtree", "colsample_bylevel": 0.950460343854502, "colsample_bytree": 0.751567963743582, "eta": 0.035603780502903484, "lambda": 0.013618151998152899, "max_depth": 12, "min_child_weight": 3.579820372471561, "nrounds": 652, "subsample": 0.829769528540783}}}], "metrics": 0.862494, "context": "openml-kc1-3917", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-kc1-3917-343", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.036578941868883316, "booster": "gblinear", "eta": 0.00394639112392298, "lambda": 0.5442569819390761, "nrounds": 4540, "subsample": 0.482340998691507}}}], "metrics": 0.86202, "context": "openml-kc1-3917", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-kc1-3917-288", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0240508886626181, "booster": "gbtree", "colsample_bylevel": 0.892520361114293, "colsample_bytree": 0.381847794866189, "eta": 0.019510799144145705, "lambda": 9.877346832094567, "max_depth": 3, "min_child_weight": 1.7232593066041593, "nrounds": 4852, "subsample": 0.777368611632846}}}], "metrics": 0.86202, "context": "openml-kc1-3917", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-monks-problems-1-3492-195", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0227225881871483, "booster": "gbtree", "colsample_bylevel": 0.474215213442221, "colsample_bytree": 0.671894747763872, "eta": 0.04938660427085398, "lambda": 1.2433588245352, "max_depth": 3, "min_child_weight": 2.367988478329502, "nrounds": 1145, "subsample": 0.478167947079055}}}], "metrics": 1.0, "context": "openml-monks-problems-1-3492", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-monks-problems-1-3492-360", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.21056626277489593, "booster": "gbtree", "colsample_bylevel": 0.756948421476409, "colsample_bytree": 0.382764199748635, "eta": 0.13345028339905005, "lambda": 52.00263948272703, "max_depth": 10, "min_child_weight": 2.212552809965991, "nrounds": 3905, "subsample": 0.693188006198034}}}], "metrics": 1.0, "context": "openml-monks-problems-1-3492", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-monks-problems-1-3492-305", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.005631831588566021, "booster": "gbtree", "colsample_bylevel": 0.882651336258277, "colsample_bytree": 0.202760488493368, "eta": 0.0334341105402662, "lambda": 0.7204634789346498, "max_depth": 10, "min_child_weight": 1.0825430319408595, "nrounds": 2127, "subsample": 0.157476129103452}}}], "metrics": 1.0, "context": "openml-monks-problems-1-3492", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-monks-problems-1-3492-143", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0239941493774961, "booster": "gbtree", "colsample_bylevel": 0.693652742542326, "colsample_bytree": 0.673685708781704, "eta": 0.6076740679911922, "lambda": 70.60585092539813, "max_depth": 11, "min_child_weight": 3.281444472797512, "nrounds": 162, "subsample": 0.696515262173489}}}], "metrics": 1.0, "context": "openml-monks-problems-1-3492", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-monks-problems-1-3492-400", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.58033940371094, "booster": "gbtree", "colsample_bylevel": 0.322864670539275, "colsample_bytree": 0.895717513514683, "eta": 0.15358635108429808, "lambda": 4.382399447297389, "max_depth": 4, "min_child_weight": 3.280281741587769, "nrounds": 2297, "subsample": 0.291083298320882}}}], "metrics": 1.0, "context": "openml-monks-problems-1-3492", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-tic-tac-toe-49-457", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.060169859592897876, "booster": "gbtree", "colsample_bylevel": 0.581280484329909, "colsample_bytree": 0.668470817618072, "eta": 0.11076023986880301, "lambda": 1.2746595384467507, "max_depth": 7, "min_child_weight": 1.3506720168187007, "nrounds": 4690, "subsample": 0.952287472551689}}}], "metrics": 0.996868, "context": "openml-tic-tac-toe-49", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-tic-tac-toe-49-173", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.18316270144923494, "booster": "gbtree", "colsample_bylevel": 0.916201935615391, "colsample_bytree": 0.347943220287561, "eta": 0.3778545397062109, "lambda": 6.035396235167915, "max_depth": 14, "min_child_weight": 1.7443790299276394, "nrounds": 1481, "subsample": 0.797039446188137}}}], "metrics": 0.996868, "context": "openml-tic-tac-toe-49", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-tic-tac-toe-49-010", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.06566766281186932, "booster": "gbtree", "colsample_bylevel": 0.772843304323032, "colsample_bytree": 0.441858702106401, "eta": 0.37230703753048416, "lambda": 0.10206460586507794, "max_depth": 15, "min_child_weight": 1.336548211328799, "nrounds": 981, "subsample": 0.887263190909289}}}], "metrics": 0.993737, "context": "openml-tic-tac-toe-49", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-tic-tac-toe-49-065", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.022417451582027906, "booster": "gbtree", "colsample_bylevel": 0.910191658418626, "colsample_bytree": 0.596154023660347, "eta": 0.010225168838903302, "lambda": 0.14604415231752696, "max_depth": 3, "min_child_weight": 4.551263077245862, "nrounds": 4360, "subsample": 0.929830183042213}}}], "metrics": 0.993737, "context": "openml-tic-tac-toe-49", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-tic-tac-toe-49-051", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.044013444522113324, "booster": "gbtree", "colsample_bylevel": 0.218663372565061, "colsample_bytree": 0.918232210446149, "eta": 0.04239938155453037, "lambda": 0.008805378954982608, "max_depth": 12, "min_child_weight": 1.6178505815728603, "nrounds": 1765, "subsample": 0.5910077402135361}}}], "metrics": 0.992693, "context": "openml-tic-tac-toe-49", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-bank-marketing-145833-425", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 28.885837180075228, "booster": "gbtree", "colsample_bylevel": 0.304956812178716, "colsample_bytree": 0.741886130301282, "eta": 0.10921293369430905, "lambda": 1.3201487104168697, "max_depth": 14, "min_child_weight": 3.774788308314001, "nrounds": 4424, "subsample": 0.561533142323606}}}], "metrics": 0.909712, "context": "openml-bank-marketing-145833", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-bank-marketing-145833-445", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.37277989721984095, "booster": "gbtree", "colsample_bylevel": 0.22163922060281, "colsample_bytree": 0.993010436417535, "eta": 0.0038972469695326, "lambda": 0.0023728817991150995, "max_depth": 13, "min_child_weight": 7.824631587547864, "nrounds": 3777, "subsample": 0.854269901500084}}}], "metrics": 0.909557, "context": "openml-bank-marketing-145833", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-bank-marketing-145833-368", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0019978282376426804, "booster": "gbtree", "colsample_bylevel": 0.589300907216966, "colsample_bytree": 0.367734584026039, "eta": 0.0238022433334006, "lambda": 0.020580398609066596, "max_depth": 4, "min_child_weight": 9.491473682454318, "nrounds": 2854, "subsample": 0.648198329517618}}}], "metrics": 0.909557, "context": "openml-bank-marketing-145833", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-bank-marketing-145833-072", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 20.162902221125417, "booster": "gbtree", "colsample_bylevel": 0.371366783510894, "colsample_bytree": 0.381213882239535, "eta": 0.11700174249308495, "lambda": 0.008854626677418188, "max_depth": 12, "min_child_weight": 1.2721285235929503, "nrounds": 937, "subsample": 0.932765381783247}}}], "metrics": 0.909226, "context": "openml-bank-marketing-145833", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-bank-marketing-145833-398", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.007495973751918338, "booster": "gbtree", "colsample_bylevel": 0.727875645970926, "colsample_bytree": 0.265829327981919, "eta": 0.017494015864545406, "lambda": 0.14674463737990698, "max_depth": 7, "min_child_weight": 5.175638899893672, "nrounds": 3141, "subsample": 0.921060142433271}}}], "metrics": 0.909004, "context": "openml-bank-marketing-145833", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-spambase-145979-471", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.007351262913272771, "booster": "gbtree", "colsample_bylevel": 0.619184499839321, "colsample_bytree": 0.902568853693083, "eta": 0.018418598782211495, "lambda": 21.595241993248198, "max_depth": 13, "min_child_weight": 1.7668741907622485, "nrounds": 2692, "subsample": 0.766690246574581}}}], "metrics": 0.955879, "context": "openml-spambase-145979", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-spambase-145979-287", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.2529644432700999, "booster": "gbtree", "colsample_bylevel": 0.127622178057209, "colsample_bytree": 0.729782280512154, "eta": 0.016734544342469397, "lambda": 0.20927011896200098, "max_depth": 7, "min_child_weight": 2.4573782157953503, "nrounds": 3449, "subsample": 0.707680497621186}}}], "metrics": 0.955662, "context": "openml-spambase-145979", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-spambase-145979-474", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.14228021161520304, "booster": "gbtree", "colsample_bylevel": 0.96606678259559, "colsample_bytree": 0.560365134384483, "eta": 0.008487941314813948, "lambda": 0.020057043627016696, "max_depth": 11, "min_child_weight": 1.10351932697855, "nrounds": 3200, "subsample": 0.920049199834466}}}], "metrics": 0.955444, "context": "openml-spambase-145979", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-spambase-145979-072", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0037441911709029897, "booster": "gbtree", "colsample_bylevel": 0.401006101630628, "colsample_bytree": 0.24110517045483, "eta": 0.15735087836865203, "lambda": 0.05026934661219391, "max_depth": 7, "min_child_weight": 2.1185253582533794, "nrounds": 262, "subsample": 0.597232829453424}}}], "metrics": 0.955444, "context": "openml-spambase-145979", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-spambase-145979-475", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.010653760807372003, "booster": "gbtree", "colsample_bylevel": 0.446920089656487, "colsample_bytree": 0.618641672423109, "eta": 0.0033194877515409786, "lambda": 0.4011716212603001, "max_depth": 15, "min_child_weight": 2.3735524144982714, "nrounds": 4848, "subsample": 0.603297814284451}}}], "metrics": 0.954792, "context": "openml-spambase-145979", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-steel-plates-fault-145872-321", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 1.0321491212934901, "booster": "gbtree", "colsample_bylevel": 0.790840549394488, "colsample_bytree": 0.970330622745678, "eta": 0.011196691749342704, "lambda": 0.3776497248617421, "max_depth": 5, "min_child_weight": 3.67914560198245, "nrounds": 1333, "subsample": 0.538555825920776}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-steel-plates-fault-145872-283", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.008869601035026873, "booster": "gblinear", "eta": 0.181432505169584, "lambda": 0.00154736526944336, "nrounds": 999, "subsample": 0.741255110152997}}}], "metrics": 0.999485, "context": "openml-steel-plates-fault-145872", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-steel-plates-fault-145872-273", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.018915281448924695, "booster": "gbtree", "colsample_bylevel": 0.587189025944099, "colsample_bytree": 0.719390236074105, "eta": 0.004903730810519392, "lambda": 11.575775060360614, "max_depth": 3, "min_child_weight": 2.0821003091437915, "nrounds": 2001, "subsample": 0.869002311490476}}}], "metrics": 0.999485, "context": "openml-steel-plates-fault-145872", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-steel-plates-fault-145872-461", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.13829253236595995, "booster": "gblinear", "eta": 0.04472869180701698, "lambda": 0.08096623936875293, "nrounds": 2120, "subsample": 0.854532783967443}}}], "metrics": 0.999485, "context": "openml-steel-plates-fault-145872", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-steel-plates-fault-145872-261", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.00136834921106891, "booster": "gblinear", "eta": 0.002032844776913271, "lambda": 1.8935469904522593, "nrounds": 3517, "subsample": 0.5676339367404581}}}], "metrics": 0.999485, "context": "openml-steel-plates-fault-145872", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-madelon-9976-476", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.09653574524893517, "booster": "gbtree", "colsample_bylevel": 0.318099030060694, "colsample_bytree": 0.689695453038439, "eta": 0.00209016480226845, "lambda": 0.09638351196952846, "max_depth": 14, "min_child_weight": 1.683866561735851, "nrounds": 2876, "subsample": 0.951229339418933}}}], "metrics": 0.856538, "context": "openml-madelon-9976", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-madelon-9976-487", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 7.556773832036052, "booster": "gbtree", "colsample_bylevel": 0.868631105637178, "colsample_bytree": 0.946155822137371, "eta": 0.0012274071386208802, "lambda": 0.04809033495138142, "max_depth": 5, "min_child_weight": 5.267849945198758, "nrounds": 4060, "subsample": 0.759334245184436}}}], "metrics": 0.821923, "context": "openml-madelon-9976", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-madelon-9976-267", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 2.4185527176193413, "booster": "gbtree", "colsample_bylevel": 0.812177132815123, "colsample_bytree": 0.324331776006147, "eta": 0.0101564614564528, "lambda": 0.013858881660812198, "max_depth": 15, "min_child_weight": 10.403536229385004, "nrounds": 559, "subsample": 0.960004996741191}}}], "metrics": 0.818846, "context": "openml-madelon-9976", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-madelon-9976-287", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.5457099912762521, "booster": "gbtree", "colsample_bylevel": 0.927230502711609, "colsample_bytree": 0.393289588857442, "eta": 0.020086909460803, "lambda": 0.10383878417848304, "max_depth": 6, "min_child_weight": 1.6939808064692496, "nrounds": 785, "subsample": 0.665265521151014}}}], "metrics": 0.815, "context": "openml-madelon-9976", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-madelon-9976-489", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.00225073098975246, "booster": "gbtree", "colsample_bylevel": 0.622267700033262, "colsample_bytree": 0.988397437846288, "eta": 0.0013341918618435596, "lambda": 82.52399196282701, "max_depth": 13, "min_child_weight": 3.9325242029389416, "nrounds": 4421, "subsample": 0.905169802485034}}}], "metrics": 0.811538, "context": "openml-madelon-9976", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-bioresponse-14966-139", "modules": [{"role": "dataset", "module": "openml-bioresponse-14966"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0011335700479095806, "booster": "gbtree", "colsample_bylevel": 0.042791563551873, "colsample_bytree": 0.2503181619104, "eta": 0.032625994569807006, "lambda": 2.4008293968884633, "max_depth": 10, "min_child_weight": 4.5097051483552075, "nrounds": 1479, "subsample": 0.685588077805005}}}], "metrics": 0.812317, "context": "openml-bioresponse-14966", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-bioresponse-14966-476", "modules": [{"role": "dataset", "module": "openml-bioresponse-14966"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0360623100411432, "booster": "gbtree", "colsample_bylevel": 0.74182243202813, "colsample_bytree": 0.509914037771523, "eta": 0.013724675627722595, "lambda": 0.822388692902431, "max_depth": 6, "min_child_weight": 1.5995569832058594, "nrounds": 1755, "subsample": 0.472803439572454}}}], "metrics": 0.810984, "context": "openml-bioresponse-14966", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-bioresponse-14966-254", "modules": [{"role": "dataset", "module": "openml-bioresponse-14966"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.004614778746177611, "booster": "gbtree", "colsample_bylevel": 0.295205799397081, "colsample_bytree": 0.496387653285637, "eta": 0.0036615700474309817, "lambda": 0.3389057088608491, "max_depth": 14, "min_child_weight": 4.125392906656079, "nrounds": 4759, "subsample": 0.371086471970193}}}], "metrics": 0.807785, "context": "openml-bioresponse-14966", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-bioresponse-14966-429", "modules": [{"role": "dataset", "module": "openml-bioresponse-14966"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.05216017317490257, "booster": "gbtree", "colsample_bylevel": 0.482694817939773, "colsample_bytree": 0.304865312296897, "eta": 0.00461501901555992, "lambda": 0.0022778066582805896, "max_depth": 5, "min_child_weight": 2.6779042272121814, "nrounds": 3305, "subsample": 0.500056390976533}}}], "metrics": 0.807518, "context": "openml-bioresponse-14966", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-bioresponse-14966-019", "modules": [{"role": "dataset", "module": "openml-bioresponse-14966"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.00297244814534233, "booster": "gbtree", "colsample_bylevel": 0.17318450473249, "colsample_bytree": 0.225771248340607, "eta": 0.08033406477052214, "lambda": 2.2611209341511302, "max_depth": 14, "min_child_weight": 2.4516781004272, "nrounds": 2641, "subsample": 0.879060422838666}}}], "metrics": 0.807251, "context": "openml-bioresponse-14966", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-bank-marketing-14965-346", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 4.09876978515237, "booster": "gbtree", "colsample_bylevel": 0.856098169460893, "colsample_bytree": 0.458119057118893, "eta": 0.0228469078457804, "lambda": 576.1716384027924, "max_depth": 5, "min_child_weight": 3.7763231904860675, "nrounds": 4400, "subsample": 0.850144393090159}}}], "metrics": 0.909801, "context": "openml-bank-marketing-14965", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-bank-marketing-14965-541", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 12.050243572680209, "booster": "gbtree", "colsample_bylevel": 0.560641767224297, "colsample_bytree": 0.996631969930604, "eta": 0.002861150873277139, "lambda": 0.013824104458030303, "max_depth": 15, "min_child_weight": 3.62942634348847, "nrounds": 4555, "subsample": 0.468603067984805}}}], "metrics": 0.909204, "context": "openml-bank-marketing-14965", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-bank-marketing-14965-375", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.023302320151033503, "booster": "gbtree", "colsample_bylevel": 0.283462066436186, "colsample_bytree": 0.557398543460295, "eta": 0.012455036631255105, "lambda": 0.9495337585740357, "max_depth": 11, "min_child_weight": 12.11403035191369, "nrounds": 880, "subsample": 0.681589746964164}}}], "metrics": 0.909115, "context": "openml-bank-marketing-14965", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-bank-marketing-14965-401", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 1.5570557541239207, "booster": "gbtree", "colsample_bylevel": 0.402754479087889, "colsample_bytree": 0.684707422740757, "eta": 0.010742943275051799, "lambda": 75.8965979605453, "max_depth": 12, "min_child_weight": 4.4760963541956515, "nrounds": 3408, "subsample": 0.67003096586559}}}], "metrics": 0.908783, "context": "openml-bank-marketing-14965", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-bank-marketing-14965-536", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.003932347042177119, "booster": "gbtree", "colsample_bylevel": 0.6286436105147, "colsample_bytree": 0.63184614549391, "eta": 0.012947848773391894, "lambda": 167.1575846816931, "max_depth": 13, "min_child_weight": 32.22016380644693, "nrounds": 2126, "subsample": 0.856673707067966}}}], "metrics": 0.908783, "context": "openml-bank-marketing-14965", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-hill-valley-145847-138", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 516.3673891182117, "booster": "gblinear", "eta": 0.22924870430274297, "lambda": 0.8189400759885097, "nrounds": 4711, "subsample": 0.621557743824087}}}], "metrics": 0.764026, "context": "openml-hill-valley-145847", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-hill-valley-145847-459", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 10.630901178264292, "booster": "gblinear", "eta": 0.16305253664807692, "lambda": 0.13625938458716497, "nrounds": 4987, "subsample": 0.245667528221384}}}], "metrics": 0.762376, "context": "openml-hill-valley-145847", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-hill-valley-145847-199", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.18224828550308408, "booster": "gblinear", "eta": 0.16888349862377094, "lambda": 38.71748659417933, "nrounds": 4861, "subsample": 0.161270968918689}}}], "metrics": 0.762376, "context": "openml-hill-valley-145847", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-hill-valley-145847-587", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 59.347128796751846, "booster": "gblinear", "eta": 0.21119751485809998, "lambda": 0.004712327392308091, "nrounds": 4745, "subsample": 0.198534569144249}}}], "metrics": 0.761551, "context": "openml-hill-valley-145847", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-hill-valley-145847-582", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.011774856443762602, "booster": "gblinear", "eta": 0.22079004837087907, "lambda": 0.134588105840608, "nrounds": 4698, "subsample": 0.936933878879063}}}], "metrics": 0.760726, "context": "openml-hill-valley-145847", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-banknote-authentication-145834-006", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.08294510438446351, "booster": "gbtree", "colsample_bylevel": 0.952521001221612, "colsample_bytree": 0.956188352778554, "eta": 0.022871724248665404, "lambda": 0.16976452097145198, "max_depth": 13, "min_child_weight": 1.25847014905351, "nrounds": 1897, "subsample": 0.611238821176812}}}], "metrics": 0.997085, "context": "openml-banknote-authentication-145834", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-banknote-authentication-145834-055", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.013364822409899599, "booster": "gbtree", "colsample_bylevel": 0.801569697447121, "colsample_bytree": 0.820616718148813, "eta": 0.005605106031750002, "lambda": 0.008279420958425411, "max_depth": 2, "min_child_weight": 5.623065093654284, "nrounds": 3785, "subsample": 0.6854654553812}}}], "metrics": 0.996356, "context": "openml-banknote-authentication-145834", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-banknote-authentication-145834-380", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0021404580563120896, "booster": "gbtree", "colsample_bylevel": 0.900690469658002, "colsample_bytree": 0.627592125209048, "eta": 0.3236562649203091, "lambda": 8.49051519571365, "max_depth": 4, "min_child_weight": 1.1618804559566294, "nrounds": 2394, "subsample": 0.92769165339414}}}], "metrics": 0.996356, "context": "openml-banknote-authentication-145834", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-banknote-authentication-145834-082", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.11870591745636705, "booster": "gbtree", "colsample_bylevel": 0.871699787909165, "colsample_bytree": 0.593222844880074, "eta": 0.01691852677105339, "lambda": 11.779344177093206, "max_depth": 3, "min_child_weight": 1.3498961659964506, "nrounds": 3873, "subsample": 0.727490161219612}}}], "metrics": 0.995627, "context": "openml-banknote-authentication-145834", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-banknote-authentication-145834-615", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.207206460589652, "booster": "gbtree", "colsample_bylevel": 0.902756747091189, "colsample_bytree": 0.993409947259352, "eta": 0.9743767630460617, "lambda": 0.04688644484062253, "max_depth": 10, "min_child_weight": 1.5065285231689194, "nrounds": 3135, "subsample": 0.373455164278857}}}], "metrics": 0.994898, "context": "openml-banknote-authentication-145834", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-mozilla4-3899-388", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.10123914031132004, "booster": "gbtree", "colsample_bylevel": 0.553984377766028, "colsample_bytree": 0.402115067699924, "eta": 0.10452578144338, "lambda": 0.4015634101099219, "max_depth": 4, "min_child_weight": 1.194797454341189, "nrounds": 3401, "subsample": 0.760434118309058}}}], "metrics": 0.958057, "context": "openml-mozilla4-3899", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-mozilla4-3899-313", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.9401649033663683, "booster": "gbtree", "colsample_bylevel": 0.397640609648079, "colsample_bytree": 0.73133816360496, "eta": 0.9281336729695661, "lambda": 3.5465296785971003, "max_depth": 8, "min_child_weight": 1.6202563845609916, "nrounds": 4478, "subsample": 0.493928698613308}}}], "metrics": 0.95632, "context": "openml-mozilla4-3899", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-mozilla4-3899-606", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.006656303123148593, "booster": "gbtree", "colsample_bylevel": 0.338247424224392, "colsample_bytree": 0.636804523644969, "eta": 0.034409382596539105, "lambda": 1.5850158993290784, "max_depth": 14, "min_child_weight": 1.9921458579155096, "nrounds": 3625, "subsample": 0.813930362206884}}}], "metrics": 0.956256, "context": "openml-mozilla4-3899", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-mozilla4-3899-556", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.006656229628288228, "booster": "gbtree", "colsample_bylevel": 0.813342805486172, "colsample_bytree": 0.873374854214489, "eta": 0.08396925079734731, "lambda": 0.15882445507731094, "max_depth": 9, "min_child_weight": 2.7741482224093987, "nrounds": 568, "subsample": 0.737946320348419}}}], "metrics": 0.955999, "context": "openml-mozilla4-3899", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-mozilla4-3899-332", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0015529268822301993, "booster": "gbtree", "colsample_bylevel": 0.769673849921674, "colsample_bytree": 0.799263346241787, "eta": 0.3884057341153891, "lambda": 149.33460103290196, "max_depth": 10, "min_child_weight": 2.9877416378223325, "nrounds": 4594, "subsample": 0.497810878278688}}}], "metrics": 0.955291, "context": "openml-mozilla4-3899", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-wilt-9889-594", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.005997270871587802, "booster": "gbtree", "colsample_bylevel": 0.946249773958698, "colsample_bytree": 0.961914318380877, "eta": 0.4212502489532978, "lambda": 513.6077707897815, "max_depth": 10, "min_child_weight": 2.672003246967711, "nrounds": 4568, "subsample": 0.921559670544229}}}], "metrics": 0.986981, "context": "openml-wilt-9889", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-wilt-9889-566", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.06857398201740374, "booster": "gbtree", "colsample_bylevel": 0.815073641715571, "colsample_bytree": 0.905920987715945, "eta": 0.05968816872994782, "lambda": 20.485124423511206, "max_depth": 15, "min_child_weight": 4.240270355339452, "nrounds": 1693, "subsample": 0.423643617494963}}}], "metrics": 0.986361, "context": "openml-wilt-9889", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-wilt-9889-604", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.11160504304618095, "booster": "gbtree", "colsample_bylevel": 0.995928895426914, "colsample_bytree": 0.984168099006638, "eta": 0.03951660829496141, "lambda": 7.475352961337709, "max_depth": 10, "min_child_weight": 5.154515659819423, "nrounds": 2819, "subsample": 0.770759194740094}}}], "metrics": 0.985741, "context": "openml-wilt-9889", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-wilt-9889-645", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 2.099987309459409, "booster": "gbtree", "colsample_bylevel": 0.994745789561421, "colsample_bytree": 0.786121805664152, "eta": 0.8907186072949201, "lambda": 991.4111274146768, "max_depth": 3, "min_child_weight": 1.1949658703017392, "nrounds": 4858, "subsample": 0.5588774316478521}}}], "metrics": 0.985121, "context": "openml-wilt-9889", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-wilt-9889-529", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.001848322112519989, "booster": "gbtree", "colsample_bylevel": 0.92094178753905, "colsample_bytree": 0.602264607790858, "eta": 0.9073448422309498, "lambda": 33.285813842835616, "max_depth": 12, "min_child_weight": 1.4462548092936012, "nrounds": 4039, "subsample": 0.589123934088275}}}], "metrics": 0.984914, "context": "openml-wilt-9889", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-scene-3485-443", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 1.8937727632052694, "booster": "gblinear", "eta": 0.008684851651811319, "lambda": 0.7881124676222606, "nrounds": 4336, "subsample": 0.797151291789487}}}], "metrics": 0.989198, "context": "openml-scene-3485", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-scene-3485-426", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 10.7594717557068, "booster": "gblinear", "eta": 0.3215907919858449, "lambda": 4.848830160931928, "nrounds": 1971, "subsample": 0.328129180916585}}}], "metrics": 0.989198, "context": "openml-scene-3485", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-scene-3485-391", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 2.4313721267907176, "booster": "gblinear", "eta": 0.050348880395304704, "lambda": 0.3272823604305161, "nrounds": 2962, "subsample": 0.802599701937288}}}], "metrics": 0.989198, "context": "openml-scene-3485", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-scene-3485-536", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 2.2349457006431908, "booster": "gblinear", "eta": 0.7612376720246818, "lambda": 4.961667559369266, "nrounds": 3131, "subsample": 0.727821798971854}}}], "metrics": 0.989198, "context": "openml-scene-3485", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-scene-3485-530", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 2.7072554886688893, "booster": "gblinear", "eta": 0.5764220801764351, "lambda": 0.031208217984511406, "nrounds": 2094, "subsample": 0.408625346468762}}}], "metrics": 0.989198, "context": "openml-scene-3485", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-pc4-3902-672", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.014465676184828202, "booster": "gbtree", "colsample_bylevel": 0.378157202387229, "colsample_bytree": 0.599064499372616, "eta": 0.1057485306895, "lambda": 296.43105421052974, "max_depth": 11, "min_child_weight": 1.5805713379290802, "nrounds": 4962, "subsample": 0.523658656002954}}}], "metrics": 0.918381, "context": "openml-pc4-3902", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-pc4-3902-457", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 3.1381515287541815, "booster": "gbtree", "colsample_bylevel": 0.465165451634675, "colsample_bytree": 0.973441044334322, "eta": 0.03342273623124502, "lambda": 0.3001336673705181, "max_depth": 12, "min_child_weight": 1.8750087393429296, "nrounds": 2454, "subsample": 0.736500391969457}}}], "metrics": 0.917695, "context": "openml-pc4-3902", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-pc4-3902-475", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 2.044196985806123, "booster": "gbtree", "colsample_bylevel": 0.788066232344136, "colsample_bytree": 0.637809886597097, "eta": 0.7933664644966583, "lambda": 0.11675382211774593, "max_depth": 10, "min_child_weight": 2.140863641909302, "nrounds": 778, "subsample": 0.887065313872881}}}], "metrics": 0.91701, "context": "openml-pc4-3902", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-pc4-3902-671", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.14711241749104992, "booster": "gbtree", "colsample_bylevel": 0.454756635706872, "colsample_bytree": 0.386966078076512, "eta": 0.014900288012862497, "lambda": 3.6658273399181716, "max_depth": 4, "min_child_weight": 1.668982282391971, "nrounds": 4327, "subsample": 0.952837647055276}}}], "metrics": 0.91701, "context": "openml-pc4-3902", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-pc4-3902-044", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 2.350414797660629, "booster": "gbtree", "colsample_bylevel": 0.344582185149193, "colsample_bytree": 0.839226244715974, "eta": 0.08500591949993329, "lambda": 0.7426010573317468, "max_depth": 6, "min_child_weight": 1.0310619499731193, "nrounds": 1995, "subsample": 0.677476538368501}}}], "metrics": 0.916324, "context": "openml-pc4-3902", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-bioresponse-9910-011", "modules": [{"role": "dataset", "module": "openml-bioresponse-9910"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.030755492061494496, "booster": "gbtree", "colsample_bylevel": 0.339249458862469, "colsample_bytree": 0.671085081761703, "eta": 0.009262702510929111, "lambda": 0.14168394729504308, "max_depth": 13, "min_child_weight": 1.4554564652184614, "nrounds": 142, "subsample": 0.5575056386878711}}}], "metrics": 0.810451, "context": "openml-bioresponse-9910", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-bioresponse-9910-697", "modules": [{"role": "dataset", "module": "openml-bioresponse-9910"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.031000494467032104, "booster": "gbtree", "colsample_bylevel": 0.42551729013212, "colsample_bytree": 0.647584830643609, "eta": 0.025175336784996793, "lambda": 0.139445515235561, "max_depth": 12, "min_child_weight": 9.180267106415068, "nrounds": 1121, "subsample": 0.760958321066573}}}], "metrics": 0.810184, "context": "openml-bioresponse-9910", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-bioresponse-9910-714", "modules": [{"role": "dataset", "module": "openml-bioresponse-9910"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.015399001461824597, "booster": "gbtree", "colsample_bylevel": 0.749717902159318, "colsample_bytree": 0.0916205586399883, "eta": 0.0271360074433548, "lambda": 5.673581759146016, "max_depth": 7, "min_child_weight": 1.8225704769218292, "nrounds": 4035, "subsample": 0.23204921984579396}}}], "metrics": 0.809917, "context": "openml-bioresponse-9910", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-bioresponse-9910-467", "modules": [{"role": "dataset", "module": "openml-bioresponse-9910"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.137753658026672, "booster": "gbtree", "colsample_bylevel": 0.37132822861895, "colsample_bytree": 0.732680928660557, "eta": 0.1504198550295309, "lambda": 89.53307810706217, "max_depth": 7, "min_child_weight": 3.91442318212212, "nrounds": 4526, "subsample": 0.663871643762104}}}], "metrics": 0.809384, "context": "openml-bioresponse-9910", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-bioresponse-9910-470", "modules": [{"role": "dataset", "module": "openml-bioresponse-9910"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.12516214110615698, "booster": "gbtree", "colsample_bylevel": 0.607618406647816, "colsample_bytree": 0.756966042332351, "eta": 0.24741080477314187, "lambda": 113.67878256990313, "max_depth": 14, "min_child_weight": 1.756408222880499, "nrounds": 3150, "subsample": 0.442556005902588}}}], "metrics": 0.808318, "context": "openml-bioresponse-9910", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-diabetes-145976-027", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.17449949103083096, "booster": "gblinear", "eta": 0.057109724165145606, "lambda": 0.00938776873911737, "nrounds": 2643, "subsample": 0.787868047156371}}}], "metrics": 0.779948, "context": "openml-diabetes-145976", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-diabetes-145976-770", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.016753928906950603, "booster": "gblinear", "eta": 0.10492089569295698, "lambda": 0.44300831001730795, "nrounds": 1404, "subsample": 0.399841713975184}}}], "metrics": 0.778646, "context": "openml-diabetes-145976", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-diabetes-145976-504", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.017241161000776307, "booster": "gblinear", "eta": 0.0687441663960794, "lambda": 0.0015822287408546393, "nrounds": 2043, "subsample": 0.527969832788222}}}], "metrics": 0.778646, "context": "openml-diabetes-145976", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-diabetes-145976-090", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.00406172439703689, "booster": "gblinear", "eta": 0.08410729563601152, "lambda": 0.00974553668523999, "nrounds": 2154, "subsample": 0.174907515477389}}}], "metrics": 0.778646, "context": "openml-diabetes-145976", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-diabetes-145976-201", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.31704227108605904, "booster": "gblinear", "eta": 0.2684592980246789, "lambda": 0.014908607929994105, "nrounds": 477, "subsample": 0.141939833201468}}}], "metrics": 0.778646, "context": "openml-diabetes-145976", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-ilpd-145848-703", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0015327125577979704, "booster": "gblinear", "eta": 0.30150763323369417, "lambda": 2.69518507837599, "nrounds": 4342, "subsample": 0.309674781165086}}}], "metrics": 0.737564, "context": "openml-ilpd-145848", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-ilpd-145848-465", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.18596390803799603, "booster": "gblinear", "eta": 0.8664155307862297, "lambda": 2.577669283695043, "nrounds": 4037, "subsample": 0.3445560343330731}}}], "metrics": 0.737564, "context": "openml-ilpd-145848", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-ilpd-145848-780", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.00266180947844588, "booster": "gblinear", "eta": 0.34820589916286016, "lambda": 1.5969383949350495, "nrounds": 3792, "subsample": 0.806408947729506}}}], "metrics": 0.735849, "context": "openml-ilpd-145848", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-ilpd-145848-220", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 1.2123764560478014, "booster": "gblinear", "eta": 0.18088673294303403, "lambda": 0.0017681285643758597, "nrounds": 4037, "subsample": 0.72487936434336}}}], "metrics": 0.735849, "context": "openml-ilpd-145848", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-ilpd-145848-078", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.26420129968923506, "booster": "gblinear", "eta": 0.19064945724085294, "lambda": 0.010348439883942295, "nrounds": 4153, "subsample": 0.689928565267473}}}], "metrics": 0.735849, "context": "openml-ilpd-145848", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-wilt-9914-236", "modules": [{"role": "dataset", "module": "openml-wilt-9914"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 1.3026467430180504, "booster": "gbtree", "colsample_bylevel": 0.743859705282375, "colsample_bytree": 0.612557107582688, "eta": 0.08634472011662801, "lambda": 1.5640849667122296, "max_depth": 3, "min_child_weight": 2.6652686340982212, "nrounds": 4768, "subsample": 0.549803957343102}}}], "metrics": 0.985948, "context": "openml-wilt-9914", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-wilt-9914-356", "modules": [{"role": "dataset", "module": "openml-wilt-9914"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.030306273800207707, "booster": "gbtree", "colsample_bylevel": 0.668750914279372, "colsample_bytree": 0.65428317245096, "eta": 0.009411649312647206, "lambda": 0.00198024213419448, "max_depth": 7, "min_child_weight": 3.185079980843001, "nrounds": 4917, "subsample": 0.606907549826428}}}], "metrics": 0.985741, "context": "openml-wilt-9914", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-wilt-9914-828", "modules": [{"role": "dataset", "module": "openml-wilt-9914"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.7689263733466941, "booster": "gbtree", "colsample_bylevel": 0.566287694964558, "colsample_bytree": 0.850153124891222, "eta": 0.045571316108726376, "lambda": 0.007362478070661379, "max_depth": 5, "min_child_weight": 1.0739143649687193, "nrounds": 3080, "subsample": 0.474299124605022}}}], "metrics": 0.985534, "context": "openml-wilt-9914", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-wilt-9914-345", "modules": [{"role": "dataset", "module": "openml-wilt-9914"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.8683847260964738, "booster": "gbtree", "colsample_bylevel": 0.786872402997687, "colsample_bytree": 0.884772634366527, "eta": 0.4392638745095809, "lambda": 1000.0, "max_depth": 13, "min_child_weight": 1.9685174964627103, "nrounds": 3324, "subsample": 0.541405824082904}}}], "metrics": 0.985534, "context": "openml-wilt-9914", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-wilt-9914-348", "modules": [{"role": "dataset", "module": "openml-wilt-9914"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0022891304189043694, "booster": "gbtree", "colsample_bylevel": 0.717398148961365, "colsample_bytree": 0.929784752195701, "eta": 0.7519867311088959, "lambda": 19.185529750958203, "max_depth": 9, "min_child_weight": 1.3258712715029901, "nrounds": 4625, "subsample": 0.791156121715903}}}], "metrics": 0.985328, "context": "openml-wilt-9914", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-electricity-146012-764", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.08544786001851784, "booster": "gbtree", "colsample_bylevel": 0.835386091610417, "colsample_bytree": 0.710951566928998, "eta": 0.031361124443934, "lambda": 0.00995710606420469, "max_depth": 12, "min_child_weight": 1.1569472532320888, "nrounds": 789, "subsample": 0.993785393168218}}}], "metrics": 0.945577, "context": "openml-electricity-146012", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-electricity-146012-830", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.09786941623584204, "booster": "gbtree", "colsample_bylevel": 0.97348449844867, "colsample_bytree": 0.847847668454051, "eta": 0.051815536905633494, "lambda": 0.0039957467075316605, "max_depth": 15, "min_child_weight": 3.24898452163723, "nrounds": 2400, "subsample": 0.749400228331797}}}], "metrics": 0.944628, "context": "openml-electricity-146012", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-electricity-146012-407", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0013163048701354103, "booster": "gbtree", "colsample_bylevel": 0.849112053867429, "colsample_bytree": 0.959161933977157, "eta": 0.0237186960268582, "lambda": 0.05009383239841239, "max_depth": 15, "min_child_weight": 1.0316288957153994, "nrounds": 1286, "subsample": 0.5622497944161301}}}], "metrics": 0.944408, "context": "openml-electricity-146012", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-electricity-146012-827", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.002163188570938419, "booster": "gbtree", "colsample_bylevel": 0.453277950175107, "colsample_bytree": 0.737142349826172, "eta": 0.0612002360444187, "lambda": 0.25769616714769206, "max_depth": 8, "min_child_weight": 1.2996544070567209, "nrounds": 4345, "subsample": 0.724024176364765}}}], "metrics": 0.939332, "context": "openml-electricity-146012", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-electricity-146012-762", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0212733387314749, "booster": "gbtree", "colsample_bylevel": 0.381427021929994, "colsample_bytree": 0.956339951604605, "eta": 0.07012544590342254, "lambda": 0.0013114007088199204, "max_depth": 13, "min_child_weight": 1.0210535745704297, "nrounds": 1092, "subsample": 0.812686131964438}}}], "metrics": 0.938934, "context": "openml-electricity-146012", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-electricity-219-411", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.012539923149039, "booster": "gbtree", "colsample_bylevel": 0.977349798893556, "colsample_bytree": 0.991227695252746, "eta": 0.010850487695761102, "lambda": 0.0013215667623664403, "max_depth": 9, "min_child_weight": 3.4322330312880722, "nrounds": 4876, "subsample": 0.849397866427898}}}], "metrics": 0.943128, "context": "openml-electricity-219", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-electricity-219-738", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.05885002656437083, "booster": "gbtree", "colsample_bylevel": 0.988715327810496, "colsample_bytree": 0.949765247525647, "eta": 0.21131913199811594, "lambda": 0.09679887364545055, "max_depth": 12, "min_child_weight": 5.4218264809960415, "nrounds": 622, "subsample": 0.939847702090628}}}], "metrics": 0.942642, "context": "openml-electricity-219", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-electricity-219-839", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 1.00980802261632, "booster": "gbtree", "colsample_bylevel": 0.78539809351787, "colsample_bytree": 0.92117123818025, "eta": 0.08827986916331304, "lambda": 0.12063636090808007, "max_depth": 12, "min_child_weight": 4.878613724766328, "nrounds": 4574, "subsample": 0.839268294116482}}}], "metrics": 0.942642, "context": "openml-electricity-219", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-electricity-219-705", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 1.8137637359785501, "booster": "gbtree", "colsample_bylevel": 0.812864234205335, "colsample_bytree": 0.712812630925328, "eta": 0.13759014775261802, "lambda": 0.0237458333597431, "max_depth": 7, "min_child_weight": 2.0487037653814792, "nrounds": 851, "subsample": 0.87972171434667}}}], "metrics": 0.939575, "context": "openml-electricity-219", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-electricity-219-812", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0189566052922433, "booster": "gbtree", "colsample_bylevel": 0.512183825252578, "colsample_bytree": 0.593162631615996, "eta": 0.03587682401550569, "lambda": 0.0016510624814646498, "max_depth": 15, "min_child_weight": 2.884247185704458, "nrounds": 1841, "subsample": 0.796025868318975}}}], "metrics": 0.93889, "context": "openml-electricity-219", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-pc1-3918-884", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0014663471354177005, "booster": "gbtree", "colsample_bylevel": 0.753789710812271, "colsample_bytree": 0.600318610202521, "eta": 0.0349365163932051, "lambda": 97.67932220211496, "max_depth": 3, "min_child_weight": 1.5727544942894303, "nrounds": 3598, "subsample": 0.850082706054673}}}], "metrics": 0.938683, "context": "openml-pc1-3918", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-pc1-3918-545", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0013465649256753005, "booster": "gbtree", "colsample_bylevel": 0.382586096646264, "colsample_bytree": 0.955661182058975, "eta": 0.005177405976129671, "lambda": 6.334450578693206, "max_depth": 2, "min_child_weight": 1.0704337698578292, "nrounds": 3658, "subsample": 0.862922645756043}}}], "metrics": 0.935978, "context": "openml-pc1-3918", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-pc1-3918-793", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.020611884182854697, "booster": "gbtree", "colsample_bylevel": 0.992094488814473, "colsample_bytree": 0.68390936194919, "eta": 0.029256309910475505, "lambda": 450.38215865184657, "max_depth": 4, "min_child_weight": 3.2010745939944827, "nrounds": 2077, "subsample": 0.844598442106508}}}], "metrics": 0.935978, "context": "openml-pc1-3918", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-pc1-3918-487", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.03756621780503629, "booster": "gbtree", "colsample_bylevel": 0.226148429792374, "colsample_bytree": 0.567636268679053, "eta": 0.014368648995082299, "lambda": 8.44432374493364, "max_depth": 6, "min_child_weight": 1.3810223020973411, "nrounds": 2481, "subsample": 0.461781768524088}}}], "metrics": 0.935077, "context": "openml-pc1-3918", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-pc1-3918-218", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.024714772070223996, "booster": "gbtree", "colsample_bylevel": 0.131083802087232, "colsample_bytree": 0.698404886759818, "eta": 0.00639500052981374, "lambda": 0.038222264745947386, "max_depth": 10, "min_child_weight": 2.151643841745132, "nrounds": 4565, "subsample": 0.999734391109087}}}], "metrics": 0.935077, "context": "openml-pc1-3918", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-blood-transfusion-service-center-10101-495", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.012848956764436894, "booster": "gbtree", "colsample_bylevel": 0.839087148662657, "colsample_bytree": 0.803072008304298, "eta": 0.010898826573870897, "lambda": 63.158877985567145, "max_depth": 7, "min_child_weight": 2.45835946612463, "nrounds": 1483, "subsample": 0.635296704666689}}}], "metrics": 0.792781, "context": "openml-blood-transfusion-service-center-10101", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-blood-transfusion-service-center-10101-802", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 5.984557977921596, "booster": "gbtree", "colsample_bylevel": 0.835536093683913, "colsample_bytree": 0.99776165978983, "eta": 0.0329926276002849, "lambda": 1.02923199449704, "max_depth": 12, "min_child_weight": 26.11474358035177, "nrounds": 4929, "subsample": 0.855926275369711}}}], "metrics": 0.78877, "context": "openml-blood-transfusion-service-center-10101", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-blood-transfusion-service-center-10101-098", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.11146013262177197, "booster": "gbtree", "colsample_bylevel": 0.707270475104451, "colsample_bytree": 0.923050681129098, "eta": 0.050818337745916105, "lambda": 172.80951711413286, "max_depth": 10, "min_child_weight": 3.1991247406081724, "nrounds": 3692, "subsample": 0.536672858824022}}}], "metrics": 0.787433, "context": "openml-blood-transfusion-service-center-10101", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-blood-transfusion-service-center-10101-487", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.198866005972096, "booster": "gbtree", "colsample_bylevel": 0.45865064766258, "colsample_bytree": 0.81762444623746, "eta": 0.00504314812774782, "lambda": 0.043231946892365425, "max_depth": 6, "min_child_weight": 10.075171677408694, "nrounds": 1534, "subsample": 0.307856027409434}}}], "metrics": 0.787433, "context": "openml-blood-transfusion-service-center-10101", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-blood-transfusion-service-center-10101-760", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.9132152060428039, "booster": "gbtree", "colsample_bylevel": 0.631517131114379, "colsample_bytree": 0.752722946926951, "eta": 0.011515270140439704, "lambda": 1.1296057024093895, "max_depth": 11, "min_child_weight": 11.669710132577087, "nrounds": 3065, "subsample": 0.5527345043374231}}}], "metrics": 0.787433, "context": "openml-blood-transfusion-service-center-10101", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-phishingwebsites-34537-947", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-34537"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.007344616100289139, "booster": "gbtree", "colsample_bylevel": 0.744739182991907, "colsample_bytree": 0.966367393033579, "eta": 0.03339368361526228, "lambda": 7.548967197270212, "max_depth": 7, "min_child_weight": 1.6774252899416113, "nrounds": 3811, "subsample": 0.902482439856976}}}], "metrics": 0.974491, "context": "openml-phishingwebsites-34537", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-phishingwebsites-34537-928", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-34537"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.4583480636167719, "booster": "gbtree", "colsample_bylevel": 0.337186956778169, "colsample_bytree": 0.866216577822343, "eta": 0.0408189066121443, "lambda": 0.6503327634370459, "max_depth": 11, "min_child_weight": 1.389014423412611, "nrounds": 3594, "subsample": 0.801465941616334}}}], "metrics": 0.97431, "context": "openml-phishingwebsites-34537", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-phishingwebsites-34537-455", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-34537"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0827230497851965, "booster": "gbtree", "colsample_bylevel": 0.279376015299931, "colsample_bytree": 0.617528794566169, "eta": 0.0142832392394319, "lambda": 0.7826164873197601, "max_depth": 14, "min_child_weight": 1.204454873490491, "nrounds": 2065, "subsample": 0.797265757573768}}}], "metrics": 0.97431, "context": "openml-phishingwebsites-34537", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-phishingwebsites-34537-918", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-34537"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 1.072276135986669, "booster": "gbtree", "colsample_bylevel": 0.938417248195037, "colsample_bytree": 0.945687294239178, "eta": 0.07614382835599717, "lambda": 0.3621558972615652, "max_depth": 6, "min_child_weight": 1.05155728947403, "nrounds": 1431, "subsample": 0.657074153306894}}}], "metrics": 0.97422, "context": "openml-phishingwebsites-34537", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-phishingwebsites-34537-756", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-34537"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.006025233033569811, "booster": "gbtree", "colsample_bylevel": 0.970701494021341, "colsample_bytree": 0.298101444030181, "eta": 0.34155254828997095, "lambda": 0.0037999120162917517, "max_depth": 8, "min_child_weight": 1.5208514734847296, "nrounds": 1789, "subsample": 0.806325988681056}}}], "metrics": 0.974039, "context": "openml-phishingwebsites-34537", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-ozone-level-8hr-9978-613", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.6661939186387351, "booster": "gbtree", "colsample_bylevel": 0.501996345352381, "colsample_bytree": 0.52928988263011, "eta": 0.011563035827874905, "lambda": 0.012317123799292598, "max_depth": 8, "min_child_weight": 1.6491653116984304, "nrounds": 1878, "subsample": 0.809738875227049}}}], "metrics": 0.947514, "context": "openml-ozone-level-8hr-9978", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-ozone-level-8hr-9978-252", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.09467179711319007, "booster": "gbtree", "colsample_bylevel": 0.95249142171815, "colsample_bytree": 0.382440847344697, "eta": 0.0102573763023772, "lambda": 0.0032176636032385706, "max_depth": 14, "min_child_weight": 3.2174705099732397, "nrounds": 1707, "subsample": 0.663704438204877}}}], "metrics": 0.947514, "context": "openml-ozone-level-8hr-9978", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-ozone-level-8hr-9978-672", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.020666867760815198, "booster": "gbtree", "colsample_bylevel": 0.854787400225177, "colsample_bytree": 0.430208075093105, "eta": 0.015948028867300398, "lambda": 0.004730785286421642, "max_depth": 9, "min_child_weight": 1.0744896860189093, "nrounds": 1308, "subsample": 0.258670123363845}}}], "metrics": 0.947119, "context": "openml-ozone-level-8hr-9978", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-ozone-level-8hr-9978-359", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.5479865905273792, "booster": "gbtree", "colsample_bylevel": 0.641298493603244, "colsample_bytree": 0.255413118517026, "eta": 0.00832329954084377, "lambda": 0.5066975167130631, "max_depth": 13, "min_child_weight": 1.5311338693569114, "nrounds": 2064, "subsample": 0.251766134123318}}}], "metrics": 0.946725, "context": "openml-ozone-level-8hr-9978", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-ozone-level-8hr-9978-871", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 5.780655762430044, "booster": "gbtree", "colsample_bylevel": 0.365969478152692, "colsample_bytree": 0.643339968286455, "eta": 0.10326767056501, "lambda": 16.513138780614593, "max_depth": 15, "min_child_weight": 4.604406929412785, "nrounds": 2357, "subsample": 0.67434509685263}}}], "metrics": 0.94633, "context": "openml-ozone-level-8hr-9978", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-bioresponse-145677-746", "modules": [{"role": "dataset", "module": "openml-bioresponse-145677"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 6.980625198933049, "booster": "gbtree", "colsample_bylevel": 0.698084082454443, "colsample_bytree": 0.0918317285832018, "eta": 0.0213288136688379, "lambda": 2.9829110424491962, "max_depth": 13, "min_child_weight": 1.09631804840271, "nrounds": 3393, "subsample": 0.827199234906584}}}], "metrics": 0.81125, "context": "openml-bioresponse-145677", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-bioresponse-145677-682", "modules": [{"role": "dataset", "module": "openml-bioresponse-145677"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.286355708393464, "booster": "gbtree", "colsample_bylevel": 0.0772214275784791, "colsample_bytree": 0.958572712959722, "eta": 0.018024355325786796, "lambda": 2.1960975587457496, "max_depth": 14, "min_child_weight": 2.350610667410691, "nrounds": 3378, "subsample": 0.565730497473851}}}], "metrics": 0.81125, "context": "openml-bioresponse-145677", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-bioresponse-145677-439", "modules": [{"role": "dataset", "module": "openml-bioresponse-145677"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 1.3965428524115306, "booster": "gbtree", "colsample_bylevel": 0.366466466803104, "colsample_bytree": 0.181876151356846, "eta": 0.0779441333509965, "lambda": 32.446367129715036, "max_depth": 15, "min_child_weight": 1.32768765768733, "nrounds": 4499, "subsample": 0.460160717880353}}}], "metrics": 0.810717, "context": "openml-bioresponse-145677", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-bioresponse-145677-205", "modules": [{"role": "dataset", "module": "openml-bioresponse-145677"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.00184213054377475, "booster": "gbtree", "colsample_bylevel": 0.056070325197652, "colsample_bytree": 0.954329098574817, "eta": 0.012526974406845498, "lambda": 0.1847593687581009, "max_depth": 13, "min_child_weight": 2.5254715758986417, "nrounds": 881, "subsample": 0.555167507426813}}}], "metrics": 0.810451, "context": "openml-bioresponse-145677", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-bioresponse-145677-797", "modules": [{"role": "dataset", "module": "openml-bioresponse-145677"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.00120853882361954, "booster": "gbtree", "colsample_bylevel": 0.562983981100842, "colsample_bytree": 0.269262606510893, "eta": 0.0119961754810332, "lambda": 5.715898791501194, "max_depth": 12, "min_child_weight": 4.547478828433234, "nrounds": 2284, "subsample": 0.784212430962361}}}], "metrics": 0.810184, "context": "openml-bioresponse-145677", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-pc3-3903-308", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.005867780045942189, "booster": "gbtree", "colsample_bylevel": 0.772534593706951, "colsample_bytree": 0.437900391407311, "eta": 0.00633287433844855, "lambda": 0.030723396226085498, "max_depth": 8, "min_child_weight": 1.22432493493008, "nrounds": 1978, "subsample": 0.542184816789813}}}], "metrics": 0.902751, "context": "openml-pc3-3903", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-pc3-3903-726", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 5.214572555337504, "booster": "gblinear", "eta": 0.15839397007817904, "lambda": 0.005487067973763232, "nrounds": 2342, "subsample": 0.598346540681087}}}], "metrics": 0.902111, "context": "openml-pc3-3903", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-pc3-3903-221", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 3.4466206663841983, "booster": "gblinear", "eta": 0.05788136833396424, "lambda": 0.301965850401507, "nrounds": 3930, "subsample": 0.472619111044332}}}], "metrics": 0.902111, "context": "openml-pc3-3903", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-pc3-3903-210", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 1.08819035403712, "booster": "gblinear", "eta": 0.6480689159277271, "lambda": 152.89798363411887, "nrounds": 168, "subsample": 0.895609637792222}}}], "metrics": 0.902111, "context": "openml-pc3-3903", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-pc3-3903-585", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.026919651171830702, "booster": "gblinear", "eta": 0.415395482437309, "lambda": 332.2072989253688, "nrounds": 3631, "subsample": 0.968408053740859}}}], "metrics": 0.902111, "context": "openml-pc3-3903", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-climate-model-simulation-crashes-9980-001", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 34.4960525889976, "booster": "gbtree", "colsample_bylevel": 0.810284987557679, "colsample_bytree": 0.918635408394039, "eta": 0.025540253072346603, "lambda": 0.375677327673787, "max_depth": 8, "min_child_weight": 2.2644827020961396, "nrounds": 587, "subsample": 0.441066739102826}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-9980", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-climate-model-simulation-crashes-9980-589", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 31.519991839950485, "booster": "gblinear", "eta": 0.07058735016046426, "lambda": 56.37772211258065, "nrounds": 1948, "subsample": 0.175839882763103}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-9980", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-climate-model-simulation-crashes-9980-186", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 6.533746055595065, "booster": "gblinear", "eta": 0.0251736536130443, "lambda": 10.75826772627849, "nrounds": 724, "subsample": 0.677223617793061}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-9980", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-climate-model-simulation-crashes-9980-598", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.5018820536790911, "booster": "gbtree", "colsample_bylevel": 0.650356459664181, "colsample_bytree": 0.126513714669272, "eta": 0.012644100408277199, "lambda": 16.504906017729812, "max_depth": 13, "min_child_weight": 15.792002685459899, "nrounds": 2354, "subsample": 0.709540762961842}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-9980", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-climate-model-simulation-crashes-9980-596", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0028764066459524705, "booster": "gblinear", "eta": 0.14021634180022197, "lambda": 3.516777793041439, "nrounds": 4683, "subsample": 0.415129284653813}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-9980", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-gina-agnostic-3891-672", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.6535004371177321, "booster": "gbtree", "colsample_bylevel": 0.802578345872462, "colsample_bytree": 0.0494087971746922, "eta": 0.027607202009288904, "lambda": 0.002085276057265059, "max_depth": 12, "min_child_weight": 2.639628520132501, "nrounds": 2850, "subsample": 0.926192427636124}}}], "metrics": 0.956459, "context": "openml-gina-agnostic-3891", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-gina-agnostic-3891-497", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.6457678105568289, "booster": "gbtree", "colsample_bylevel": 0.878391343168914, "colsample_bytree": 0.4210048627574, "eta": 0.008859440628548577, "lambda": 7.441568409696352, "max_depth": 14, "min_child_weight": 1.0922545376536712, "nrounds": 4097, "subsample": 0.950860299100168}}}], "metrics": 0.956459, "context": "openml-gina-agnostic-3891", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-gina-agnostic-3891-477", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.008575036489334328, "booster": "gbtree", "colsample_bylevel": 0.870364907663316, "colsample_bytree": 0.24834321718663, "eta": 0.018405314717060195, "lambda": 0.19606417135536305, "max_depth": 14, "min_child_weight": 1.9456362642889387, "nrounds": 4319, "subsample": 0.64411213286221}}}], "metrics": 0.956171, "context": "openml-gina-agnostic-3891", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-gina-agnostic-3891-895", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0205462715043752, "booster": "gbtree", "colsample_bylevel": 0.978931397432461, "colsample_bytree": 0.278201771667227, "eta": 0.0037276927243949805, "lambda": 0.0033196018169462096, "max_depth": 15, "min_child_weight": 3.7149024151809495, "nrounds": 3254, "subsample": 0.930443230830133}}}], "metrics": 0.956171, "context": "openml-gina-agnostic-3891", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-gina-agnostic-3891-759", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.06919973245294642, "booster": "gbtree", "colsample_bylevel": 0.58233857434243, "colsample_bytree": 0.716170164290816, "eta": 0.04568038047221191, "lambda": 0.021411938639663095, "max_depth": 15, "min_child_weight": 2.53257979766949, "nrounds": 1460, "subsample": 0.658681394765154}}}], "metrics": 0.954441, "context": "openml-gina-agnostic-3891", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-kc2-3913-641", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.035036751758640905, "booster": "gbtree", "colsample_bylevel": 0.841678087366745, "colsample_bytree": 0.803312515607104, "eta": 0.007261873395766488, "lambda": 60.04147964007211, "max_depth": 5, "min_child_weight": 2.53050402276305, "nrounds": 2442, "subsample": 0.963901826296933}}}], "metrics": 0.858238, "context": "openml-kc2-3913", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-kc2-3913-406", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 6.144328160674557, "booster": "gbtree", "colsample_bylevel": 0.555864443769678, "colsample_bytree": 0.412591391708702, "eta": 0.11372520866920201, "lambda": 0.21866794681500198, "max_depth": 5, "min_child_weight": 2.683661773312541, "nrounds": 3655, "subsample": 0.941723982943222}}}], "metrics": 0.856322, "context": "openml-kc2-3913", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-kc2-3913-696", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.07370136843136264, "booster": "gbtree", "colsample_bylevel": 0.570621372899041, "colsample_bytree": 0.551681311335415, "eta": 0.0011489777579108897, "lambda": 0.188815630022264, "max_depth": 10, "min_child_weight": 4.077614333667022, "nrounds": 4029, "subsample": 0.6897618311923}}}], "metrics": 0.854406, "context": "openml-kc2-3913", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-kc2-3913-1117", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.009322957884639866, "booster": "gbtree", "colsample_bylevel": 0.390202605631202, "colsample_bytree": 0.698659226763994, "eta": 0.008408372993849453, "lambda": 41.92448010835803, "max_depth": 3, "min_child_weight": 7.38566279305799, "nrounds": 2038, "subsample": 0.826784373656847}}}], "metrics": 0.854406, "context": "openml-kc2-3913", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-kc2-3913-226", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 1.0791713426735285, "booster": "gbtree", "colsample_bylevel": 0.50694845430553, "colsample_bytree": 0.531358138658106, "eta": 0.0012871976827268702, "lambda": 5.581900308259227, "max_depth": 14, "min_child_weight": 1.31694384366788, "nrounds": 4403, "subsample": 0.748585747275502}}}], "metrics": 0.854406, "context": "openml-kc2-3913", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-australian-125923-1012", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.05618463473469571, "booster": "gbtree", "colsample_bylevel": 0.621744592674077, "colsample_bytree": 0.776244127191603, "eta": 0.011961181384263402, "lambda": 0.07620767703588184, "max_depth": 11, "min_child_weight": 1.5811286105497395, "nrounds": 4596, "subsample": 0.902910762443207}}}], "metrics": 0.878261, "context": "openml-australian-125923", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-australian-125923-1245", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.09718117632004385, "booster": "gbtree", "colsample_bylevel": 0.705447941785678, "colsample_bytree": 0.652148719411343, "eta": 0.09268326186048029, "lambda": 2.3583692161789025, "max_depth": 10, "min_child_weight": 2.0064003700477016, "nrounds": 2556, "subsample": 0.322771790274419}}}], "metrics": 0.878261, "context": "openml-australian-125923", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-australian-125923-318", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0030688835534563703, "booster": "gbtree", "colsample_bylevel": 0.256280369358137, "colsample_bytree": 0.921641372144222, "eta": 0.061650941652911115, "lambda": 0.004410365144632489, "max_depth": 14, "min_child_weight": 1.655604731780669, "nrounds": 3577, "subsample": 0.940900298138149}}}], "metrics": 0.878261, "context": "openml-australian-125923", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-australian-125923-178", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.12206496751723299, "booster": "gbtree", "colsample_bylevel": 0.356032772921026, "colsample_bytree": 0.574948944849893, "eta": 0.11003008910683898, "lambda": 23.438873915601302, "max_depth": 14, "min_child_weight": 3.507858933649737, "nrounds": 984, "subsample": 0.984987899730913}}}], "metrics": 0.876812, "context": "openml-australian-125923", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-australian-125923-972", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 1.1387450993389898, "booster": "gbtree", "colsample_bylevel": 0.989616786362603, "colsample_bytree": 0.713639486348256, "eta": 0.8380061857434873, "lambda": 80.5557537212665, "max_depth": 6, "min_child_weight": 3.6700758938100977, "nrounds": 2976, "subsample": 0.792347900103778}}}], "metrics": 0.875362, "context": "openml-australian-125923", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-monks-problems-3-3494-566", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.009245299326772566, "booster": "gbtree", "colsample_bylevel": 0.916636927053332, "colsample_bytree": 0.313606678973883, "eta": 0.16748217400348894, "lambda": 393.1623625737925, "max_depth": 3, "min_child_weight": 1.4679561030103698, "nrounds": 4873, "subsample": 0.878151435405016}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-monks-problems-3-3494-1281", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.012315932612837694, "booster": "gbtree", "colsample_bylevel": 0.489984829444438, "colsample_bytree": 0.31767681799829, "eta": 0.19593909813870003, "lambda": 38.25535787298508, "max_depth": 15, "min_child_weight": 1.1161878179864704, "nrounds": 3995, "subsample": 0.680373667972162}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-monks-problems-3-3494-796", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.025539160651612804, "booster": "gbtree", "colsample_bylevel": 0.738022580742836, "colsample_bytree": 0.788094438845292, "eta": 0.022019335474969103, "lambda": 0.3462786136212221, "max_depth": 10, "min_child_weight": 2.7241521754202416, "nrounds": 1710, "subsample": 0.425987681886181}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-monks-problems-3-3494-124", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0035030924685633203, "booster": "gbtree", "colsample_bylevel": 0.663322317181155, "colsample_bytree": 0.968351433752105, "eta": 0.13554899562533798, "lambda": 64.45225526177916, "max_depth": 15, "min_child_weight": 2.2313693964320613, "nrounds": 152, "subsample": 0.936844779248349}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-monks-problems-3-3494-745", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0408986921199717, "booster": "gbtree", "colsample_bylevel": 0.86773515981622, "colsample_bytree": 0.727733787382022, "eta": 0.0012240046880821105, "lambda": 0.8356412028046066, "max_depth": 5, "min_child_weight": 1.9239886857050106, "nrounds": 2906, "subsample": 0.799950759857893}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-wdbc-145878-667", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.10358773410312895, "booster": "gbtree", "colsample_bylevel": 0.793826018460095, "colsample_bytree": 0.166589847998694, "eta": 0.0429540826727522, "lambda": 0.960163373057107, "max_depth": 14, "min_child_weight": 4.937159033622771, "nrounds": 2084, "subsample": 0.790398822422139}}}], "metrics": 0.973638, "context": "openml-wdbc-145878", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-wdbc-145878-1167", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.16703515884436296, "booster": "gbtree", "colsample_bylevel": 0.718934328760952, "colsample_bytree": 0.347546142758802, "eta": 0.0247367084039572, "lambda": 0.2635599460101049, "max_depth": 3, "min_child_weight": 1.066874235010099, "nrounds": 3160, "subsample": 0.6646195134148}}}], "metrics": 0.973638, "context": "openml-wdbc-145878", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-wdbc-145878-1320", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.06142173533194434, "booster": "gbtree", "colsample_bylevel": 0.837492007762194, "colsample_bytree": 0.36159752192907, "eta": 0.004072416103286771, "lambda": 0.009032337013330711, "max_depth": 9, "min_child_weight": 1.5342267992074394, "nrounds": 4861, "subsample": 0.278509035613388}}}], "metrics": 0.973638, "context": "openml-wdbc-145878", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-wdbc-145878-194", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.17868184746798602, "booster": "gbtree", "colsample_bylevel": 0.152841299306601, "colsample_bytree": 0.837904336629435, "eta": 0.0470048644140053, "lambda": 0.022713090365736207, "max_depth": 7, "min_child_weight": 1.0907903552125093, "nrounds": 4541, "subsample": 0.357965094153769}}}], "metrics": 0.973638, "context": "openml-wdbc-145878", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-wdbc-145878-918", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0023532475228365004, "booster": "gblinear", "eta": 0.07106227665333452, "lambda": 0.0016277526063879998, "nrounds": 1038, "subsample": 0.745560817536898}}}], "metrics": 0.97188, "context": "openml-wdbc-145878", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-wdbc-9946-663", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0013480577710528001, "booster": "gbtree", "colsample_bylevel": 0.291366472607478, "colsample_bytree": 0.664130115881562, "eta": 0.015962453122121, "lambda": 0.002112840211468299, "max_depth": 10, "min_child_weight": 2.9182860687089884, "nrounds": 4376, "subsample": 0.430983398645185}}}], "metrics": 0.975395, "context": "openml-wdbc-9946", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-wdbc-9946-756", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.17011452194572696, "booster": "gbtree", "colsample_bylevel": 0.311863522743806, "colsample_bytree": 0.403331597102806, "eta": 0.688464668089526, "lambda": 221.17278236738977, "max_depth": 13, "min_child_weight": 2.6094946862059607, "nrounds": 2814, "subsample": 0.836011706595309}}}], "metrics": 0.973638, "context": "openml-wdbc-9946", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-wdbc-9946-280", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0258091884743519, "booster": "gbtree", "colsample_bylevel": 0.854828934650868, "colsample_bytree": 0.328445237828419, "eta": 0.06178431432896128, "lambda": 0.014478645003753704, "max_depth": 3, "min_child_weight": 1.3854438286028499, "nrounds": 2149, "subsample": 0.334158348618075}}}], "metrics": 0.973638, "context": "openml-wdbc-9946", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-wdbc-9946-897", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0016279519563912595, "booster": "gbtree", "colsample_bylevel": 0.0374274998903275, "colsample_bytree": 0.972107284236699, "eta": 0.03530050436645931, "lambda": 0.0015662875039576098, "max_depth": 7, "min_child_weight": 2.3779726192440505, "nrounds": 463, "subsample": 0.655009409761988}}}], "metrics": 0.973638, "context": "openml-wdbc-9946", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-wdbc-9946-654", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.05249583905321963, "booster": "gbtree", "colsample_bylevel": 0.638242646353319, "colsample_bytree": 0.532373442780226, "eta": 0.6354487880846977, "lambda": 602.9020974691196, "max_depth": 9, "min_child_weight": 1.809995292461509, "nrounds": 2714, "subsample": 0.383307881071232}}}], "metrics": 0.973638, "context": "openml-wdbc-9946", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-ada-agnostic-3896-073", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.055837654638201395, "booster": "gbtree", "colsample_bylevel": 0.822655624477193, "colsample_bytree": 0.651075476547703, "eta": 0.011227846543603698, "lambda": 0.00694998775395707, "max_depth": 4, "min_child_weight": 2.131542836166171, "nrounds": 597, "subsample": 0.521033792197704}}}], "metrics": 0.857738, "context": "openml-ada-agnostic-3896", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-ada-agnostic-3896-929", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.06681103798897291, "booster": "gbtree", "colsample_bylevel": 0.993806692771614, "colsample_bytree": 0.966415100963786, "eta": 0.003251930735843169, "lambda": 62.176823833784425, "max_depth": 12, "min_child_weight": 2.2802599678480404, "nrounds": 1544, "subsample": 0.805956379021518}}}], "metrics": 0.856861, "context": "openml-ada-agnostic-3896", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-ada-agnostic-3896-789", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.17233198506131997, "booster": "gbtree", "colsample_bylevel": 0.509548631263897, "colsample_bytree": 0.759577802848071, "eta": 0.005016429809296969, "lambda": 0.00916773363644595, "max_depth": 4, "min_child_weight": 5.068186586526479, "nrounds": 1384, "subsample": 0.546712093707174}}}], "metrics": 0.856642, "context": "openml-ada-agnostic-3896", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-ada-agnostic-3896-178", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 10.29557657784591, "booster": "gbtree", "colsample_bylevel": 0.709781759651378, "colsample_bytree": 0.193543306319043, "eta": 0.0291383477343385, "lambda": 2.8834154152168696, "max_depth": 8, "min_child_weight": 12.01289034913431, "nrounds": 1923, "subsample": 0.786314381146804}}}], "metrics": 0.856642, "context": "openml-ada-agnostic-3896", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-ada-agnostic-3896-1018", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0025545041182179107, "booster": "gbtree", "colsample_bylevel": 0.121118025621399, "colsample_bytree": 0.973909138469025, "eta": 0.00232648522272969, "lambda": 0.015258565019188895, "max_depth": 7, "min_child_weight": 2.1885757892640285, "nrounds": 4377, "subsample": 0.859920150390826}}}], "metrics": 0.856423, "context": "openml-ada-agnostic-3896", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-qsar-biodeg-9957-460", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 2.947870745625351, "booster": "gbtree", "colsample_bylevel": 0.521543292095885, "colsample_bytree": 0.334863793803379, "eta": 0.03784117717994091, "lambda": 3.5980339929190586, "max_depth": 5, "min_child_weight": 2.86575119920563, "nrounds": 4655, "subsample": 0.680875571304932}}}], "metrics": 0.880569, "context": "openml-qsar-biodeg-9957", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-qsar-biodeg-9957-1343", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0013666944382886904, "booster": "gbtree", "colsample_bylevel": 0.599813789129257, "colsample_bytree": 0.976777820615098, "eta": 0.008451403864267727, "lambda": 0.0048130309322520015, "max_depth": 12, "min_child_weight": 4.246918801223689, "nrounds": 4530, "subsample": 0.988748907670379}}}], "metrics": 0.879621, "context": "openml-qsar-biodeg-9957", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-qsar-biodeg-9957-863", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.011658974682331796, "booster": "gbtree", "colsample_bylevel": 0.742970778606832, "colsample_bytree": 0.492157150292769, "eta": 0.0068422842377927895, "lambda": 0.012170493366244999, "max_depth": 5, "min_child_weight": 6.06309662136468, "nrounds": 2808, "subsample": 0.931682741222903}}}], "metrics": 0.878673, "context": "openml-qsar-biodeg-9957", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-qsar-biodeg-9957-875", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.13407257573854897, "booster": "gbtree", "colsample_bylevel": 0.804767236113548, "colsample_bytree": 0.961864944314584, "eta": 0.10720859384488597, "lambda": 4.712936414908419, "max_depth": 12, "min_child_weight": 1.5618833493849387, "nrounds": 2051, "subsample": 0.936621773475781}}}], "metrics": 0.878673, "context": "openml-qsar-biodeg-9957", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-qsar-biodeg-9957-367", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.6128473538024599, "booster": "gbtree", "colsample_bylevel": 0.286385449580848, "colsample_bytree": 0.810958883026615, "eta": 0.03308104439672511, "lambda": 15.482601677565613, "max_depth": 12, "min_child_weight": 3.342964611837222, "nrounds": 1787, "subsample": 0.596646298863925}}}], "metrics": 0.877725, "context": "openml-qsar-biodeg-9957", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-kr-vs-kp-3-1415", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 2.330790662390619, "booster": "gbtree", "colsample_bylevel": 0.972876270534471, "colsample_bytree": 0.889796345494688, "eta": 0.16110135451714802, "lambda": 15.619748135632786, "max_depth": 13, "min_child_weight": 1.6750424940500108, "nrounds": 3679, "subsample": 0.882111730636097}}}], "metrics": 0.993742, "context": "openml-kr-vs-kp-3", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-kr-vs-kp-3-668", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 1.9559001508055405, "booster": "gbtree", "colsample_bylevel": 0.470818697707728, "colsample_bytree": 0.567578621441498, "eta": 0.0384400411788756, "lambda": 5.7502445508955065, "max_depth": 15, "min_child_weight": 1.013766713085189, "nrounds": 3880, "subsample": 0.996678242553026}}}], "metrics": 0.993429, "context": "openml-kr-vs-kp-3", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-kr-vs-kp-3-098", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0017763451544364707, "booster": "gbtree", "colsample_bylevel": 0.633353541838005, "colsample_bytree": 0.343353725736961, "eta": 0.042121210036095605, "lambda": 0.0943539555247495, "max_depth": 4, "min_child_weight": 1.14065672235864, "nrounds": 1886, "subsample": 0.790277968160808}}}], "metrics": 0.993429, "context": "openml-kr-vs-kp-3", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-kr-vs-kp-3-418", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.047693580239093813, "booster": "gbtree", "colsample_bylevel": 0.328394385520369, "colsample_bytree": 0.458934127818793, "eta": 0.0028112377467022992, "lambda": 0.004409669457302619, "max_depth": 11, "min_child_weight": 1.03689515392805, "nrounds": 2161, "subsample": 0.920506813400425}}}], "metrics": 0.993116, "context": "openml-kr-vs-kp-3", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-kr-vs-kp-3-939", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.09215432295593834, "booster": "gbtree", "colsample_bylevel": 0.332695248303935, "colsample_bytree": 0.796131473500282, "eta": 0.02960245527377819, "lambda": 0.249518344581886, "max_depth": 15, "min_child_weight": 1.3775635308396204, "nrounds": 1369, "subsample": 0.585057464661077}}}], "metrics": 0.992804, "context": "openml-kr-vs-kp-3", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-click-prediction-small-7295-765", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 1.4868455315460596, "booster": "gbtree", "colsample_bylevel": 0.726700472645462, "colsample_bytree": 0.904503823490813, "eta": 0.0033824648139893303, "lambda": 0.006142839720043482, "max_depth": 9, "min_child_weight": 5.461510788516353, "nrounds": 2233, "subsample": 0.66415130700916}}}], "metrics": 0.837864, "context": "openml-click-prediction-small-7295", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-click-prediction-small-7295-764", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0199700241081502, "booster": "gbtree", "colsample_bylevel": 0.653097188798711, "colsample_bytree": 0.640489684883505, "eta": 0.005821208029551773, "lambda": 0.00743363400303192, "max_depth": 9, "min_child_weight": 1.1884608927860494, "nrounds": 3395, "subsample": 0.752888946374878}}}], "metrics": 0.837814, "context": "openml-click-prediction-small-7295", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-click-prediction-small-7295-735", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.005713170032073723, "booster": "gbtree", "colsample_bylevel": 0.949407497188076, "colsample_bytree": 0.90711916424334, "eta": 0.015294597751283006, "lambda": 0.4150748691438149, "max_depth": 4, "min_child_weight": 1.6709353907682207, "nrounds": 2123, "subsample": 0.971300596976653}}}], "metrics": 0.837789, "context": "openml-click-prediction-small-7295", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-click-prediction-small-7295-385", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.13890551669742296, "booster": "gbtree", "colsample_bylevel": 0.889124110108241, "colsample_bytree": 0.502154117682949, "eta": 0.015236283574016102, "lambda": 26.61732505784153, "max_depth": 6, "min_child_weight": 3.307590426842497, "nrounds": 4373, "subsample": 0.929100975696929}}}], "metrics": 0.837714, "context": "openml-click-prediction-small-7295", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-click-prediction-small-7295-992", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.09739687613832511, "booster": "gbtree", "colsample_bylevel": 0.187819362618029, "colsample_bytree": 0.796086573041975, "eta": 0.015358295166943698, "lambda": 3.9581427302992207, "max_depth": 8, "min_child_weight": 15.821920420223204, "nrounds": 3067, "subsample": 0.918492891220376}}}], "metrics": 0.837664, "context": "openml-click-prediction-small-7295", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-click-prediction-small-14971-753", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 3.0631103433629714, "booster": "gbtree", "colsample_bylevel": 0.659665473969653, "colsample_bytree": 0.474967492278665, "eta": 0.007004079662681362, "lambda": 0.12696077544023002, "max_depth": 9, "min_child_weight": 1.7255023271645287, "nrounds": 2404, "subsample": 0.45046765182633}}}], "metrics": 0.838265, "context": "openml-click-prediction-small-14971", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-click-prediction-small-14971-767", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.74449307692739, "booster": "gbtree", "colsample_bylevel": 0.675344854127616, "colsample_bytree": 0.492987614823505, "eta": 0.00309232409718054, "lambda": 0.00468950302888055, "max_depth": 10, "min_child_weight": 1.2068021056583609, "nrounds": 4461, "subsample": 0.418323335424066}}}], "metrics": 0.83824, "context": "openml-click-prediction-small-14971", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-click-prediction-small-14971-1088", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0028173467335642294, "booster": "gbtree", "colsample_bylevel": 0.377002995228395, "colsample_bytree": 0.461366639239714, "eta": 0.010487320089855702, "lambda": 4.6472180506788785, "max_depth": 13, "min_child_weight": 3.7776246313487825, "nrounds": 2015, "subsample": 0.587732272245921}}}], "metrics": 0.838165, "context": "openml-click-prediction-small-14971", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-click-prediction-small-14971-1097", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 1.1131261480801105, "booster": "gbtree", "colsample_bylevel": 0.628015297697857, "colsample_bytree": 0.87181902769953, "eta": 0.004828867858453581, "lambda": 0.008924028484265796, "max_depth": 8, "min_child_weight": 2.9582794123839085, "nrounds": 4160, "subsample": 0.686973219155334}}}], "metrics": 0.838064, "context": "openml-click-prediction-small-14971", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-click-prediction-small-14971-209", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0016305013249826006, "booster": "gbtree", "colsample_bylevel": 0.686255613109097, "colsample_bytree": 0.366493993671611, "eta": 0.027024662483586002, "lambda": 0.03940889690091788, "max_depth": 8, "min_child_weight": 3.267202821821319, "nrounds": 831, "subsample": 0.725130622158758}}}], "metrics": 0.837839, "context": "openml-click-prediction-small-14971", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-ilpd-9971-551", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.833182613778542, "booster": "gblinear", "eta": 0.125781219788694, "lambda": 0.009169563047184321, "nrounds": 4160, "subsample": 0.590621699090116}}}], "metrics": 0.737564, "context": "openml-ilpd-9971", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-ilpd-9971-1332", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.2870665140623708, "booster": "gblinear", "eta": 0.1817435437523, "lambda": 2.3785840519866923, "nrounds": 2799, "subsample": 0.220678165298887}}}], "metrics": 0.737564, "context": "openml-ilpd-9971", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-ilpd-9971-1005", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0014736386542479904, "booster": "gblinear", "eta": 0.6570459649539362, "lambda": 2.077043695088601, "nrounds": 1516, "subsample": 0.187899149395525}}}], "metrics": 0.737564, "context": "openml-ilpd-9971", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-ilpd-9971-144", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 1.4588607771046613, "booster": "gblinear", "eta": 0.35796361896802786, "lambda": 0.24872874367572612, "nrounds": 2967, "subsample": 0.65844535198994}}}], "metrics": 0.737564, "context": "openml-ilpd-9971", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-ilpd-9971-1360", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 1.2106926709677395, "booster": "gblinear", "eta": 0.12271078035138801, "lambda": 0.6711676273164302, "nrounds": 4476, "subsample": 0.897127466765232}}}], "metrics": 0.735849, "context": "openml-ilpd-9971", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-monks-problems-2-3493-126", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.06133803497389224, "booster": "gbtree", "colsample_bylevel": 0.889272439526394, "colsample_bytree": 0.718151607783511, "eta": 0.6597669473784828, "lambda": 22.346517253612873, "max_depth": 14, "min_child_weight": 5.130210428146705, "nrounds": 3810, "subsample": 0.585908276238479}}}], "metrics": 1.0, "context": "openml-monks-problems-2-3493", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-monks-problems-2-3493-1136", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.31331957306932595, "booster": "gbtree", "colsample_bylevel": 0.75585351139307, "colsample_bytree": 0.845053568249568, "eta": 0.136166161942219, "lambda": 0.007918389339431012, "max_depth": 8, "min_child_weight": 7.872399880736126, "nrounds": 4642, "subsample": 0.748644706001505}}}], "metrics": 1.0, "context": "openml-monks-problems-2-3493", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-monks-problems-2-3493-481", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.014592160691059002, "booster": "gbtree", "colsample_bylevel": 0.695744390133768, "colsample_bytree": 0.494877694174647, "eta": 0.254762349658433, "lambda": 0.0062482534986999716, "max_depth": 2, "min_child_weight": 2.8065687209094423, "nrounds": 2638, "subsample": 0.946600133110769}}}], "metrics": 1.0, "context": "openml-monks-problems-2-3493", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-monks-problems-2-3493-036", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0015286335480277904, "booster": "gbtree", "colsample_bylevel": 0.695396307157353, "colsample_bytree": 0.967438572552055, "eta": 0.133634675564934, "lambda": 5.591967019637805, "max_depth": 2, "min_child_weight": 9.279164686954863, "nrounds": 4801, "subsample": 0.742192390072159}}}], "metrics": 1.0, "context": "openml-monks-problems-2-3493", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-monks-problems-2-3493-608", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.5618678197131188, "booster": "gbtree", "colsample_bylevel": 0.81666531227529, "colsample_bytree": 0.334211710607633, "eta": 0.6513346994093492, "lambda": 0.00251099329301328, "max_depth": 10, "min_child_weight": 4.836644594531888, "nrounds": 4530, "subsample": 0.778604747261852}}}], "metrics": 0.998336, "context": "openml-monks-problems-2-3493", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-credit-g-31-1142", "modules": [{"role": "dataset", "module": "openml-credit-g-31"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.0511918333483725, "booster": "gbtree", "colsample_bylevel": 0.475514942314476, "colsample_bytree": 0.673374444013461, "eta": 0.015678334021381593, "lambda": 0.021452679045747797, "max_depth": 4, "min_child_weight": 1.9946712706038416, "nrounds": 466, "subsample": 0.498467986588366}}}], "metrics": 0.776, "context": "openml-credit-g-31", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-credit-g-31-320", "modules": [{"role": "dataset", "module": "openml-credit-g-31"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.002633270444370379, "booster": "gbtree", "colsample_bylevel": 0.416315622162074, "colsample_bytree": 0.366496084956452, "eta": 0.0016392008681228901, "lambda": 0.005643135138271758, "max_depth": 6, "min_child_weight": 1.12449814942677, "nrounds": 3229, "subsample": 0.6913686579559}}}], "metrics": 0.772, "context": "openml-credit-g-31", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-credit-g-31-879", "modules": [{"role": "dataset", "module": "openml-credit-g-31"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 2.54527076152457, "booster": "gbtree", "colsample_bylevel": 0.550130780087784, "colsample_bytree": 0.338768204441294, "eta": 0.003916572022626449, "lambda": 0.008869669054127697, "max_depth": 7, "min_child_weight": 1.1208001321423098, "nrounds": 2362, "subsample": 0.530522591271438}}}], "metrics": 0.772, "context": "openml-credit-g-31", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-credit-g-31-1214", "modules": [{"role": "dataset", "module": "openml-credit-g-31"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.008327872782935515, "booster": "gbtree", "colsample_bylevel": 0.195751245832071, "colsample_bytree": 0.595072037773207, "eta": 0.008201487308375312, "lambda": 0.9584489281777799, "max_depth": 7, "min_child_weight": 2.939749020056878, "nrounds": 1145, "subsample": 0.579042606544681}}}], "metrics": 0.771, "context": "openml-credit-g-31", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-credit-g-31-375", "modules": [{"role": "dataset", "module": "openml-credit-g-31"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 1.4714808593981803, "booster": "gbtree", "colsample_bylevel": 0.360558901680633, "colsample_bytree": 0.481951583176851, "eta": 0.050656612996753995, "lambda": 456.62923423810224, "max_depth": 14, "min_child_weight": 1.4155834990401208, "nrounds": 4935, "subsample": 0.404476732085459}}}], "metrics": 0.771, "context": "openml-credit-g-31", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-sylva-agnostic-3889-560", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.048083548364790715, "booster": "gblinear", "eta": 0.018054047149609002, "lambda": 0.6561463269239408, "nrounds": 2619, "subsample": 0.272310312069021}}}], "metrics": 0.995623, "context": "openml-sylva-agnostic-3889", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-sylva-agnostic-3889-351", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 1.132936753546701, "booster": "gbtree", "colsample_bylevel": 0.534955249866471, "colsample_bytree": 0.765234572114423, "eta": 0.34876235362664587, "lambda": 60.362372993420855, "max_depth": 8, "min_child_weight": 1.6787374497742897, "nrounds": 2917, "subsample": 0.946477009868249}}}], "metrics": 0.995485, "context": "openml-sylva-agnostic-3889", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-sylva-agnostic-3889-1320", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.03212192770012121, "booster": "gblinear", "eta": 0.06786700149243177, "lambda": 0.39814989749120305, "nrounds": 818, "subsample": 0.251487781805918}}}], "metrics": 0.995485, "context": "openml-sylva-agnostic-3889", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-sylva-agnostic-3889-862", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.7572277078179798, "booster": "gblinear", "eta": 0.09099421109653273, "lambda": 0.0202643884146613, "nrounds": 764, "subsample": 0.691337976208888}}}], "metrics": 0.995485, "context": "openml-sylva-agnostic-3889", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-xgboost-5971-openml-sylva-agnostic-3889-1630", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-5971", "config": {"alpha": 0.8091249851160247, "booster": "gblinear", "eta": 0.0150736574648721, "lambda": 0.003104584743154829, "nrounds": 4462, "subsample": 0.345830011530779}}}], "metrics": 0.995485, "context": "openml-sylva-agnostic-3889", "schema": "xgboost-5971", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-musk-146082-689", "modules": [{"role": "dataset", "module": "openml-musk-146082"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.999617090215907, "lambda": 0.00115338636914272}}}], "metrics": 0.999697, "context": "openml-musk-146082", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-musk-146082-234", "modules": [{"role": "dataset", "module": "openml-musk-146082"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.596233393065631, "lambda": 0.00194764556850316}}}], "metrics": 0.999697, "context": "openml-musk-146082", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-musk-146082-106", "modules": [{"role": "dataset", "module": "openml-musk-146082"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.213430135743693, "lambda": 0.0079577975041801}}}], "metrics": 0.999697, "context": "openml-musk-146082", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-musk-146082-107", "modules": [{"role": "dataset", "module": "openml-musk-146082"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.195484109222889, "lambda": 0.00637694386551741}}}], "metrics": 0.999697, "context": "openml-musk-146082", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-musk-146082-828", "modules": [{"role": "dataset", "module": "openml-musk-146082"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.708141525276005, "lambda": 0.00604455904002478}}}], "metrics": 0.999697, "context": "openml-musk-146082", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-ilpd-145848-548", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.754710267996415, "lambda": 0.00138836941471532}}}], "metrics": 0.737564, "context": "openml-ilpd-145848", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-ilpd-145848-946", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.765242315130308, "lambda": 0.00147619351966868}}}], "metrics": 0.735849, "context": "openml-ilpd-145848", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-ilpd-145848-056", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.829903102014214, "lambda": 0.00128595036501098}}}], "metrics": 0.735849, "context": "openml-ilpd-145848", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-ilpd-145848-969", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.461888146121055, "lambda": 0.00123932726260566}}}], "metrics": 0.734134, "context": "openml-ilpd-145848", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-ilpd-145848-022", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.452841105405241, "lambda": 0.00154362506074625}}}], "metrics": 0.734134, "context": "openml-ilpd-145848", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-madelon-9976-130", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.269698299700394, "lambda": 0.171698322828604}}}], "metrics": 0.620769, "context": "openml-madelon-9976", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-madelon-9976-385", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.8540828183759, "lambda": 0.0329800847322637}}}], "metrics": 0.62, "context": "openml-madelon-9976", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-madelon-9976-864", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.979587196139619, "lambda": 0.0291320733499147}}}], "metrics": 0.619615, "context": "openml-madelon-9976", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-madelon-9976-114", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.297186639625579, "lambda": 0.151069247292243}}}], "metrics": 0.619615, "context": "openml-madelon-9976", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-madelon-9976-375", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.901063558878377, "lambda": 0.0325620046752844}}}], "metrics": 0.619231, "context": "openml-madelon-9976", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-eeg-eye-state-14951-926", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.338438708567992, "lambda": 0.001}}}], "metrics": 0.587717, "context": "openml-eeg-eye-state-14951", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-eeg-eye-state-14951-913", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.193629854125902, "lambda": 0.00103860782899337}}}], "metrics": 0.587517, "context": "openml-eeg-eye-state-14951", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-eeg-eye-state-14951-1266", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.335886003449559, "lambda": 0.00107383214252931}}}], "metrics": 0.58745, "context": "openml-eeg-eye-state-14951", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-eeg-eye-state-14951-1494", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.159831390483305, "lambda": 0.00108132369623326}}}], "metrics": 0.58745, "context": "openml-eeg-eye-state-14951", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-eeg-eye-state-14951-1640", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.331784943817183, "lambda": 0.00101939758794635}}}], "metrics": 0.58745, "context": "openml-eeg-eye-state-14951", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-bank-marketing-145833-033", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.39087449060753, "lambda": 0.00108591997536219}}}], "metrics": 0.901528, "context": "openml-bank-marketing-145833", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-bank-marketing-145833-1651", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.260597337735817, "lambda": 0.00165458555317215}}}], "metrics": 0.901528, "context": "openml-bank-marketing-145833", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-bank-marketing-145833-1432", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.889480107231066, "lambda": 0.00421908418131862}}}], "metrics": 0.901528, "context": "openml-bank-marketing-145833", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-bank-marketing-145833-553", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.23485771054402, "lambda": 0.00184012857951352}}}], "metrics": 0.901506, "context": "openml-bank-marketing-145833", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-bank-marketing-145833-1908", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.278023668797687, "lambda": 0.00174179625406881}}}], "metrics": 0.901506, "context": "openml-bank-marketing-145833", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-nomao-145854-807", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.0291824010200799, "lambda": 0.00124670379049381}}}], "metrics": 0.947831, "context": "openml-nomao-145854", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-nomao-145854-754", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.0770597869995981, "lambda": 0.00106017783326182}}}], "metrics": 0.947802, "context": "openml-nomao-145854", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-nomao-145854-235", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.0665036209393293, "lambda": 0.00131579765878304}}}], "metrics": 0.947686, "context": "openml-nomao-145854", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-nomao-145854-904", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.112902814755216, "lambda": 0.00108310853831759}}}], "metrics": 0.947686, "context": "openml-nomao-145854", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-nomao-145854-1905", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.23149265977554, "lambda": 0.001}}}], "metrics": 0.947657, "context": "openml-nomao-145854", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-bank-marketing-14965-425", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.351422187173739, "lambda": 0.00111668971687925}}}], "metrics": 0.901573, "context": "openml-bank-marketing-14965", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-bank-marketing-14965-2235", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.384804701898247, "lambda": 0.0010509636354942}}}], "metrics": 0.901551, "context": "openml-bank-marketing-14965", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-bank-marketing-14965-2637", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.381029334617779, "lambda": 0.0010584057781158}}}], "metrics": 0.901551, "context": "openml-bank-marketing-14965", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-bank-marketing-14965-777", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.348677528556436, "lambda": 0.00112779120265743}}}], "metrics": 0.901528, "context": "openml-bank-marketing-14965", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-bank-marketing-14965-2730", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.284939605044201, "lambda": 0.00148885116383067}}}], "metrics": 0.901506, "context": "openml-bank-marketing-14965", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-hill-valley-9970-3329", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.126732554286718, "lambda": 0.00104704594999381}}}], "metrics": 0.705446, "context": "openml-hill-valley-9970", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-hill-valley-9970-2163", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.116879631765187, "lambda": 0.001}}}], "metrics": 0.705446, "context": "openml-hill-valley-9970", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-hill-valley-9970-777", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.148944365093485, "lambda": 0.0010261425963661}}}], "metrics": 0.70462, "context": "openml-hill-valley-9970", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-hill-valley-9970-1334", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.107980226865038, "lambda": 0.001}}}], "metrics": 0.703795, "context": "openml-hill-valley-9970", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-hill-valley-9970-294", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.0269010195042938, "lambda": 0.0010971936543607}}}], "metrics": 0.703795, "context": "openml-hill-valley-9970", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-monks-problems-3-146066-1171", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.978959234664217, "lambda": 0.00164578468334636}}}], "metrics": 0.980144, "context": "openml-monks-problems-3-146066", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-monks-problems-3-146066-2737", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.812787086237222, "lambda": 0.00108054359865307}}}], "metrics": 0.980144, "context": "openml-monks-problems-3-146066", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-monks-problems-3-146066-541", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.748216478852555, "lambda": 0.001}}}], "metrics": 0.980144, "context": "openml-monks-problems-3-146066", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-monks-problems-3-146066-2734", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.952265724539757, "lambda": 0.00131564338619056}}}], "metrics": 0.980144, "context": "openml-monks-problems-3-146066", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-monks-problems-3-146066-3795", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.883754541631788, "lambda": 0.00141622539549597}}}], "metrics": 0.980144, "context": "openml-monks-problems-3-146066", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-madelon-145853-2260", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.967558233998716, "lambda": 0.031038741471141}}}], "metrics": 0.620769, "context": "openml-madelon-145853", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-madelon-145853-814", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.680890754796565, "lambda": 0.0413477777734213}}}], "metrics": 0.620385, "context": "openml-madelon-145853", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-madelon-145853-4293", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.538236060878262, "lambda": 0.0865372451882959}}}], "metrics": 0.620385, "context": "openml-madelon-145853", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-madelon-145853-563", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.979228463023901, "lambda": 0.0301923404530092}}}], "metrics": 0.620385, "context": "openml-madelon-145853", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-madelon-145853-025", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.413721699267626, "lambda": 0.111261459645562}}}], "metrics": 0.620385, "context": "openml-madelon-145853", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-musk-3950-4976", "modules": [{"role": "dataset", "module": "openml-musk-3950"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.931607243139297, "lambda": 0.00414989368264667}}}], "metrics": 0.999697, "context": "openml-musk-3950", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-musk-3950-3401", "modules": [{"role": "dataset", "module": "openml-musk-3950"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.236633290536702, "lambda": 0.0148652271483682}}}], "metrics": 0.999697, "context": "openml-musk-3950", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-musk-3950-700", "modules": [{"role": "dataset", "module": "openml-musk-3950"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.759661857038736, "lambda": 0.00138355945600341}}}], "metrics": 0.999697, "context": "openml-musk-3950", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-musk-3950-699", "modules": [{"role": "dataset", "module": "openml-musk-3950"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.209614010062069, "lambda": 0.00473777177046752}}}], "metrics": 0.999697, "context": "openml-musk-3950", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-musk-3950-4796", "modules": [{"role": "dataset", "module": "openml-musk-3950"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.958130150102079, "lambda": 0.00400650754498089}}}], "metrics": 0.999697, "context": "openml-musk-3950", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-pc4-3902-270", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.0921626123599708, "lambda": 0.00459559491885638}}}], "metrics": 0.911523, "context": "openml-pc4-3902", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-pc4-3902-4259", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.109488248825073, "lambda": 0.00460140709784591}}}], "metrics": 0.911523, "context": "openml-pc4-3902", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-pc4-3902-3792", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.120583567535505, "lambda": 0.00461699830656253}}}], "metrics": 0.911523, "context": "openml-pc4-3902", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-pc4-3902-1502", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.0252085528336465, "lambda": 0.00506322133094543}}}], "metrics": 0.910837, "context": "openml-pc4-3902", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-pc4-3902-3197", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.0752798519097269, "lambda": 0.0045759166594889}}}], "metrics": 0.910837, "context": "openml-pc4-3902", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-ada-agnostic-3896-4064", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.978340785484761, "lambda": 0.00927972475995668}}}], "metrics": 0.843709, "context": "openml-ada-agnostic-3896", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-ada-agnostic-3896-3333", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.924721545772627, "lambda": 0.0102670797050116}}}], "metrics": 0.843709, "context": "openml-ada-agnostic-3896", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-ada-agnostic-3896-853", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.93237871536985, "lambda": 0.00876662985406823}}}], "metrics": 0.843709, "context": "openml-ada-agnostic-3896", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-ada-agnostic-3896-4525", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.899622538127005, "lambda": 0.00829732729206384}}}], "metrics": 0.84349, "context": "openml-ada-agnostic-3896", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-ada-agnostic-3896-2952", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.910352156264707, "lambda": 0.0105833576345504}}}], "metrics": 0.84349, "context": "openml-ada-agnostic-3896", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-scene-3485-5970", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.979456053115427, "lambda": 0.00145061968349281}}}], "metrics": 0.989614, "context": "openml-scene-3485", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-scene-3485-1949", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.564020358258858, "lambda": 0.00280324737725766}}}], "metrics": 0.989614, "context": "openml-scene-3485", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-scene-3485-4782", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.268902773037553, "lambda": 0.00519080605675644}}}], "metrics": 0.989614, "context": "openml-scene-3485", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-scene-3485-1928", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.469378472305834, "lambda": 0.0034386897584379097}}}], "metrics": 0.989614, "context": "openml-scene-3485", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-scene-3485-4748", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.371154888300225, "lambda": 0.00422014756900871}}}], "metrics": 0.989614, "context": "openml-scene-3485", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-electricity-146012-2549", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.741548548219725, "lambda": 0.00174505296445671}}}], "metrics": 0.760527, "context": "openml-electricity-146012", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-electricity-146012-1682", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.653687041718513, "lambda": 0.00193877435920185}}}], "metrics": 0.760505, "context": "openml-electricity-146012", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-electricity-146012-5099", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.639702174346894, "lambda": 0.00202197531342235}}}], "metrics": 0.760461, "context": "openml-electricity-146012", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-electricity-146012-4247", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.625097279902548, "lambda": 0.00200930337355149}}}], "metrics": 0.760461, "context": "openml-electricity-146012", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-electricity-146012-108", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.612130497815087, "lambda": 0.00202725589234487}}}], "metrics": 0.760461, "context": "openml-electricity-146012", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-banknote-authentication-145834-2630", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.986594318877906, "lambda": 0.001}}}], "metrics": 0.990525, "context": "openml-banknote-authentication-145834", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-banknote-authentication-145834-1136", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.974583183182403, "lambda": 0.00103071784194449}}}], "metrics": 0.989067, "context": "openml-banknote-authentication-145834", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-banknote-authentication-145834-3813", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.984975259983912, "lambda": 0.00113725722916001}}}], "metrics": 0.989067, "context": "openml-banknote-authentication-145834", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-banknote-authentication-145834-2094", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.977659910917282, "lambda": 0.00107152298961541}}}], "metrics": 0.989067, "context": "openml-banknote-authentication-145834", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-banknote-authentication-145834-1062", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.99395890138112, "lambda": 0.00109588285808516}}}], "metrics": 0.989067, "context": "openml-banknote-authentication-145834", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-monks-problems-3-3494-7117", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.891230364562944, "lambda": 0.00125822553564312}}}], "metrics": 0.980144, "context": "openml-monks-problems-3-3494", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-monks-problems-3-3494-2351", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.687930652173236, "lambda": 0.00122709599998874}}}], "metrics": 0.980144, "context": "openml-monks-problems-3-3494", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-monks-problems-3-3494-5118", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.924455126747489, "lambda": 0.00111713696687581}}}], "metrics": 0.980144, "context": "openml-monks-problems-3-3494", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-monks-problems-3-3494-3277", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.811696065822616, "lambda": 0.00169034809183388}}}], "metrics": 0.980144, "context": "openml-monks-problems-3-3494", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-monks-problems-3-3494-4405", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.786434767302126, "lambda": 0.00131509580873662}}}], "metrics": 0.980144, "context": "openml-monks-problems-3-3494", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-blood-transfusion-service-center-145836-9286", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.897365878568962, "lambda": 0.0200194169729823}}}], "metrics": 0.775401, "context": "openml-blood-transfusion-service-center-145836", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-blood-transfusion-service-center-145836-5519", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.595346356509253, "lambda": 0.0231900263062285}}}], "metrics": 0.775401, "context": "openml-blood-transfusion-service-center-145836", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-blood-transfusion-service-center-145836-9255", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.74923717463389, "lambda": 0.0225262192398498}}}], "metrics": 0.775401, "context": "openml-blood-transfusion-service-center-145836", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-blood-transfusion-service-center-145836-3152", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.366223201155663, "lambda": 0.0360693859898182}}}], "metrics": 0.775401, "context": "openml-blood-transfusion-service-center-145836", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-blood-transfusion-service-center-145836-3209", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.509103088639677, "lambda": 0.0257462762944352}}}], "metrics": 0.775401, "context": "openml-blood-transfusion-service-center-145836", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-climate-model-simulation-crashes-145839-9979", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.0328421625308692, "lambda": 27.5429344052667}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-145839", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-climate-model-simulation-crashes-145839-3850", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.139744902262464, "lambda": 0.561001072331582}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-145839", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-climate-model-simulation-crashes-145839-3831", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.0739278646651655, "lambda": 0.522600656923833}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-145839", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-climate-model-simulation-crashes-145839-3832", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.350067407591268, "lambda": 0.108006260427753}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-145839", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-climate-model-simulation-crashes-145839-3833", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.41499587870203, "lambda": 177.30672098265}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-145839", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-wdbc-145878-8210", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.312136171152815, "lambda": 0.00598956558836415}}}], "metrics": 0.982425, "context": "openml-wdbc-145878", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-wdbc-145878-4275", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.399326498154551, "lambda": 0.0095710322305227}}}], "metrics": 0.982425, "context": "openml-wdbc-145878", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-wdbc-145878-2208", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.279672931879759, "lambda": 0.00624536323897852}}}], "metrics": 0.982425, "context": "openml-wdbc-145878", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-wdbc-145878-7390", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.239604589529335, "lambda": 0.0063413024063044}}}], "metrics": 0.982425, "context": "openml-wdbc-145878", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-wdbc-145878-7936", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.283449547365308, "lambda": 0.00608853178715846}}}], "metrics": 0.982425, "context": "openml-wdbc-145878", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-wilt-9889-8564", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.824636534554884, "lambda": 0.00139318971429092}}}], "metrics": 0.952263, "context": "openml-wilt-9889", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-wilt-9889-4053", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.807373082032427, "lambda": 0.00136534439411078}}}], "metrics": 0.95185, "context": "openml-wilt-9889", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-wilt-9889-7801", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.864916085731238, "lambda": 0.00185266708419922}}}], "metrics": 0.951436, "context": "openml-wilt-9889", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-wilt-9889-6843", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.821766635635868, "lambda": 0.00162446676624092}}}], "metrics": 0.95123, "context": "openml-wilt-9889", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-wilt-9889-4221", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.587368376785889, "lambda": 0.00101530532177551}}}], "metrics": 0.95123, "context": "openml-wilt-9889", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-diabetes-145976-5622", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.400961189297959, "lambda": 0.001}}}], "metrics": 0.778646, "context": "openml-diabetes-145976", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-diabetes-145976-509", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.0147953913547099, "lambda": 0.00236426546334753}}}], "metrics": 0.778646, "context": "openml-diabetes-145976", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-diabetes-145976-6746", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.447233321145177, "lambda": 0.00108913626369628}}}], "metrics": 0.778646, "context": "openml-diabetes-145976", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-diabetes-145976-6045", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.41906958213076, "lambda": 0.00103161497573878}}}], "metrics": 0.778646, "context": "openml-diabetes-145976", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-diabetes-145976-1123", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.608262112131342, "lambda": 0.00106518361875872}}}], "metrics": 0.778646, "context": "openml-diabetes-145976", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-spambase-43-3318", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.990459996741265, "lambda": 0.00101887152131333}}}], "metrics": 0.925451, "context": "openml-spambase-43", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-spambase-43-4397", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.979410901432857, "lambda": 0.00101655122708693}}}], "metrics": 0.925234, "context": "openml-spambase-43", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-spambase-43-7337", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.933349872939289, "lambda": 0.00159108584576187}}}], "metrics": 0.924799, "context": "openml-spambase-43", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-spambase-43-4071", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.979298916179687, "lambda": 0.00165851059248514}}}], "metrics": 0.924799, "context": "openml-spambase-43", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-spambase-43-6262", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.985212825005874, "lambda": 0.00151548358444547}}}], "metrics": 0.924799, "context": "openml-spambase-43", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-ilpd-9971-7687", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.830337940948084, "lambda": 0.00139341995719381}}}], "metrics": 0.737564, "context": "openml-ilpd-9971", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-ilpd-9971-11757", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.864772439468652, "lambda": 0.00134398176788144}}}], "metrics": 0.737564, "context": "openml-ilpd-9971", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-ilpd-9971-371", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.776232567150146, "lambda": 0.00145761558150487}}}], "metrics": 0.735849, "context": "openml-ilpd-9971", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-ilpd-9971-2776", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.970536230597645, "lambda": 0.00142675283029688}}}], "metrics": 0.735849, "context": "openml-ilpd-9971", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-ilpd-9971-4662", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.749918932793662, "lambda": 0.00148702728631047}}}], "metrics": 0.735849, "context": "openml-ilpd-9971", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-kr-vs-kp-3-6374", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.952148175099865, "lambda": 0.00104095085913104}}}], "metrics": 0.970275, "context": "openml-kr-vs-kp-3", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-kr-vs-kp-3-11125", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.982510200701654, "lambda": 0.00108022707087903}}}], "metrics": 0.970275, "context": "openml-kr-vs-kp-3", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-kr-vs-kp-3-3181", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.938450392801315, "lambda": 0.00107986061097836}}}], "metrics": 0.970275, "context": "openml-kr-vs-kp-3", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-kr-vs-kp-3-12268", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.9843677978497, "lambda": 0.00108401347715312}}}], "metrics": 0.970275, "context": "openml-kr-vs-kp-3", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-kr-vs-kp-3-8890", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.912900969851762, "lambda": 0.00101552837718523}}}], "metrics": 0.970275, "context": "openml-kr-vs-kp-3", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-qsar-biodeg-145862-11079", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.441138816066086, "lambda": 0.00213717218629908}}}], "metrics": 0.876777, "context": "openml-qsar-biodeg-145862", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-qsar-biodeg-145862-7314", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.49167735921219, "lambda": 0.00216472629476512}}}], "metrics": 0.875829, "context": "openml-qsar-biodeg-145862", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-qsar-biodeg-145862-2441", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.534410734428093, "lambda": 0.00193344831973442}}}], "metrics": 0.875829, "context": "openml-qsar-biodeg-145862", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-qsar-biodeg-145862-12021", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.541866249172017, "lambda": 0.00211335652142033}}}], "metrics": 0.875829, "context": "openml-qsar-biodeg-145862", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-qsar-biodeg-145862-4732", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.474417632911354, "lambda": 0.00204107575413086}}}], "metrics": 0.875829, "context": "openml-qsar-biodeg-145862", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-spambase-145979-10371", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.953056395985186, "lambda": 0.001}}}], "metrics": 0.925451, "context": "openml-spambase-145979", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-spambase-145979-7668", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.998709307983518, "lambda": 0.00102587365274312}}}], "metrics": 0.925451, "context": "openml-spambase-145979", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-spambase-145979-9872", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.976924514397979, "lambda": 0.00100850299074145}}}], "metrics": 0.925234, "context": "openml-spambase-145979", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-spambase-145979-164", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.993056579725817, "lambda": 0.00107741711254748}}}], "metrics": 0.925234, "context": "openml-spambase-145979", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-spambase-145979-7051", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.925853809108958, "lambda": 0.0017437083817223}}}], "metrics": 0.925016, "context": "openml-spambase-145979", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-gina-agnostic-3891-13065", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.442106686765328, "lambda": 0.0199274969060114}}}], "metrics": 0.877163, "context": "openml-gina-agnostic-3891", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-gina-agnostic-3891-11237", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.461030699545518, "lambda": 0.0195812991294872}}}], "metrics": 0.877163, "context": "openml-gina-agnostic-3891", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-gina-agnostic-3891-4945", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.350084399105981, "lambda": 0.0106182517707173}}}], "metrics": 0.876874, "context": "openml-gina-agnostic-3891", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-gina-agnostic-3891-5506", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.704055278562009, "lambda": 0.0129372052940063}}}], "metrics": 0.876874, "context": "openml-gina-agnostic-3891", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-gina-agnostic-3891-9016", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.315369527321309, "lambda": 0.0118155486980357}}}], "metrics": 0.876874, "context": "openml-gina-agnostic-3891", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-ozone-level-8hr-145855-3394", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.171972858021036, "lambda": 0.00173245139839757}}}], "metrics": 0.945146, "context": "openml-ozone-level-8hr-145855", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-ozone-level-8hr-145855-5405", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.205616432474926, "lambda": 0.00146595193269444}}}], "metrics": 0.945146, "context": "openml-ozone-level-8hr-145855", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-ozone-level-8hr-145855-4823", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.342807019827887, "lambda": 0.00118897918766482}}}], "metrics": 0.945146, "context": "openml-ozone-level-8hr-145855", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-ozone-level-8hr-145855-4062", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.0517505712341517, "lambda": 0.0014181481981431}}}], "metrics": 0.945146, "context": "openml-ozone-level-8hr-145855", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-ozone-level-8hr-145855-13293", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.291999525390565, "lambda": 0.00129449844666688}}}], "metrics": 0.945146, "context": "openml-ozone-level-8hr-145855", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-sylva-agnostic-3889-8231", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.00603079679422081, "lambda": 0.0754522010058594}}}], "metrics": 0.988677, "context": "openml-sylva-agnostic-3889", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-sylva-agnostic-3889-689", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.00949837709777057, "lambda": 0.0760955051104349}}}], "metrics": 0.988329, "context": "openml-sylva-agnostic-3889", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-sylva-agnostic-3889-4813", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.00322707137092948, "lambda": 0.0842199861570334}}}], "metrics": 0.988051, "context": "openml-sylva-agnostic-3889", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-sylva-agnostic-3889-1869", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.00187682430259883, "lambda": 0.0903568984193644}}}], "metrics": 0.987774, "context": "openml-sylva-agnostic-3889", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-sylva-agnostic-3889-13792", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.0302862615790218, "lambda": 0.0687140782792761}}}], "metrics": 0.987774, "context": "openml-sylva-agnostic-3889", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-electricity-219-5999", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.818882711231709, "lambda": 0.00161160397705705}}}], "metrics": 0.760571, "context": "openml-electricity-219", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-electricity-219-11021", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.635849813465029, "lambda": 0.00197102096772813}}}], "metrics": 0.760549, "context": "openml-electricity-219", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-electricity-219-9857", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.653506019152701, "lambda": 0.00196391888660276}}}], "metrics": 0.760527, "context": "openml-electricity-219", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-electricity-219-393", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.648337173042819, "lambda": 0.00195860725651849}}}], "metrics": 0.760527, "context": "openml-electricity-219", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-electricity-219-12229", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.688700792845339, "lambda": 0.00187453912411279}}}], "metrics": 0.760505, "context": "openml-electricity-219", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-magictelescope-3954-2889", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.636364127742127, "lambda": 0.00103205784924795}}}], "metrics": 0.790694, "context": "openml-magictelescope-3954", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-magictelescope-3954-9275", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.774718694156036, "lambda": 0.001}}}], "metrics": 0.790694, "context": "openml-magictelescope-3954", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-magictelescope-3954-13166", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.676708998857066, "lambda": 0.001}}}], "metrics": 0.790694, "context": "openml-magictelescope-3954", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-magictelescope-3954-2771", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.658231914276257, "lambda": 0.00100587361895694}}}], "metrics": 0.790694, "context": "openml-magictelescope-3954", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-magictelescope-3954-3694", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.672736365580931, "lambda": 0.00100538022245563}}}], "metrics": 0.790694, "context": "openml-magictelescope-3954", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-mozilla4-3899-11719", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.990258214995265, "lambda": 0.0290436150939092}}}], "metrics": 0.859183, "context": "openml-mozilla4-3899", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-mozilla4-3899-1226", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.973998979432508, "lambda": 0.0256848269620696}}}], "metrics": 0.858926, "context": "openml-mozilla4-3899", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-mozilla4-3899-10524", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.95560551690869, "lambda": 0.0267360948695498}}}], "metrics": 0.858604, "context": "openml-mozilla4-3899", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-mozilla4-3899-7154", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.995798402233049, "lambda": 0.0252258770737569}}}], "metrics": 0.858604, "context": "openml-mozilla4-3899", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-mozilla4-3899-11666", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.987046181922778, "lambda": 0.0333245973315755}}}], "metrics": 0.85854, "context": "openml-mozilla4-3899", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-kc1-3917-7919", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.480935330269858, "lambda": 0.00824434486744311}}}], "metrics": 0.86202, "context": "openml-kc1-3917", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-kc1-3917-9578", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.206632427172735, "lambda": 0.0133586159931476}}}], "metrics": 0.861546, "context": "openml-kc1-3917", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-kc1-3917-15185", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.189805964473635, "lambda": 0.0136775727621565}}}], "metrics": 0.861546, "context": "openml-kc1-3917", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-kc1-3917-14115", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.118991125375032, "lambda": 0.0161159213072058}}}], "metrics": 0.861546, "context": "openml-kc1-3917", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-kc1-3917-1503", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.423699783394113, "lambda": 0.00908662095233348}}}], "metrics": 0.861546, "context": "openml-kc1-3917", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-monks-problems-1-3492-8484", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.396727586165071, "lambda": 0.00126225485760089}}}], "metrics": 0.746403, "context": "openml-monks-problems-1-3492", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-monks-problems-1-3492-3481", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.581326221115887, "lambda": 0.00695488554374393}}}], "metrics": 0.746403, "context": "openml-monks-problems-1-3492", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-monks-problems-1-3492-10189", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.45896978280507, "lambda": 0.00138537398977866}}}], "metrics": 0.746403, "context": "openml-monks-problems-1-3492", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-monks-problems-1-3492-10188", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.610342269996181, "lambda": 0.00137610844455353}}}], "metrics": 0.746403, "context": "openml-monks-problems-1-3492", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-monks-problems-1-3492-3507", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.042901384877041, "lambda": 3.66875498539773}}}], "metrics": 0.746403, "context": "openml-monks-problems-1-3492", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-click-prediction-small-7295-1096", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.519921718398109, "lambda": 0.001}}}], "metrics": 0.832057, "context": "openml-click-prediction-small-7295", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-click-prediction-small-7295-7535", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.417121225735173, "lambda": 0.001}}}], "metrics": 0.832057, "context": "openml-click-prediction-small-7295", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-click-prediction-small-7295-9180", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.506890010554343, "lambda": 0.0010312613456809}}}], "metrics": 0.832057, "context": "openml-click-prediction-small-7295", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-click-prediction-small-7295-11295", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.558040200732648, "lambda": 0.00100162956185412}}}], "metrics": 0.832057, "context": "openml-click-prediction-small-7295", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-click-prediction-small-7295-14594", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.633006101939827, "lambda": 0.001}}}], "metrics": 0.832057, "context": "openml-click-prediction-small-7295", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-steel-plates-fault-145872-8918", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.437560294289142, "lambda": 0.00583811075629773}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-steel-plates-fault-145872-12324", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.866731704911217, "lambda": 0.00221466796115783}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-steel-plates-fault-145872-12125", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.787351857405156, "lambda": 0.0030273647762608996}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-steel-plates-fault-145872-12126", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.507959023118019, "lambda": 0.0158419947843822}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-steel-plates-fault-145872-12131", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.861089756246656, "lambda": 0.0536570843062531}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-diabetes-37-11005", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.467334275366738, "lambda": 0.00122653000901361}}}], "metrics": 0.778646, "context": "openml-diabetes-37", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-diabetes-37-11655", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.536406573373824, "lambda": 0.00117982516833402}}}], "metrics": 0.778646, "context": "openml-diabetes-37", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-diabetes-37-13438", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.136732824379578, "lambda": 0.00172082594416935}}}], "metrics": 0.778646, "context": "openml-diabetes-37", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-diabetes-37-748", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.0452967633027583, "lambda": 0.00134917529378722}}}], "metrics": 0.778646, "context": "openml-diabetes-37", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-diabetes-37-8497", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.0485554724000394, "lambda": 0.00135460157453648}}}], "metrics": 0.778646, "context": "openml-diabetes-37", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-monks-problems-2-3493-19931", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.696224391227588, "lambda": 180.197008618342}}}], "metrics": 0.657238, "context": "openml-monks-problems-2-3493", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-monks-problems-2-3493-7372", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.0544988841284066, "lambda": 1.48532533495023}}}], "metrics": 0.657238, "context": "openml-monks-problems-2-3493", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-monks-problems-2-3493-7364", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.851849734317511, "lambda": 69.425681017292}}}], "metrics": 0.657238, "context": "openml-monks-problems-2-3493", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-monks-problems-2-3493-7365", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.380347514525056, "lambda": 1.48711637591363}}}], "metrics": 0.657238, "context": "openml-monks-problems-2-3493", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-monks-problems-2-3493-7366", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.522637750720605, "lambda": 0.111762225571297}}}], "metrics": 0.657238, "context": "openml-monks-problems-2-3493", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-ozone-level-8hr-9978-18502", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.163875727448612, "lambda": 0.00175590630635592}}}], "metrics": 0.945146, "context": "openml-ozone-level-8hr-9978", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-ozone-level-8hr-9978-17675", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.134180197492242, "lambda": 0.00178189711445398}}}], "metrics": 0.945146, "context": "openml-ozone-level-8hr-9978", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-ozone-level-8hr-9978-900", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.164599939482287, "lambda": 0.00179974829263356}}}], "metrics": 0.945146, "context": "openml-ozone-level-8hr-9978", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-ozone-level-8hr-9978-8358", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.176204662770033, "lambda": 0.00171382353107301}}}], "metrics": 0.945146, "context": "openml-ozone-level-8hr-9978", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-ozone-level-8hr-9978-10487", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.145973271690309, "lambda": 0.00173110189156247}}}], "metrics": 0.945146, "context": "openml-ozone-level-8hr-9978", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-credit-g-145972-5536", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.0935568711720407, "lambda": 0.0181715940504078}}}], "metrics": 0.766, "context": "openml-credit-g-145972", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-credit-g-145972-11228", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.206076587550342, "lambda": 0.0107805117013979}}}], "metrics": 0.765, "context": "openml-credit-g-145972", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-credit-g-145972-8663", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.208083472214639, "lambda": 0.0103431171481481}}}], "metrics": 0.765, "context": "openml-credit-g-145972", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-credit-g-145972-10166", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.115423269569874, "lambda": 0.0192424142100848}}}], "metrics": 0.765, "context": "openml-credit-g-145972", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-credit-g-145972-10873", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.134395123226568, "lambda": 0.013976152742902}}}], "metrics": 0.765, "context": "openml-credit-g-145972", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-pc1-3918-15812", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.924175456166267, "lambda": 0.00129853448889341}}}], "metrics": 0.933273, "context": "openml-pc1-3918", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-pc1-3918-771", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.903321639867499, "lambda": 0.00124550487081227}}}], "metrics": 0.933273, "context": "openml-pc1-3918", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-pc1-3918-7391", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.98760465439409, "lambda": 0.00118848102945825}}}], "metrics": 0.933273, "context": "openml-pc1-3918", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-pc1-3918-12778", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.857077426277101, "lambda": 0.00125934030395388}}}], "metrics": 0.933273, "context": "openml-pc1-3918", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-pc1-3918-13735", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.848387725651264, "lambda": 0.00192747760896617}}}], "metrics": 0.933273, "context": "openml-pc1-3918", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-steel-plates-fault-9967-15772", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.974308901233599, "lambda": 0.00171319998519255}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-steel-plates-fault-9967-8397", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.847632497316226, "lambda": 0.0162214217224377}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-steel-plates-fault-9967-8392", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.492144311545417, "lambda": 0.0516388995587687}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-steel-plates-fault-9967-18720", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.880965853109956, "lambda": 0.0268832959925215}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-steel-plates-fault-9967-8391", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.405165457865223, "lambda": 0.0114828525258235}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-kc2-3913-10920", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.172961400123313, "lambda": 0.0663155143570556}}}], "metrics": 0.85249, "context": "openml-kc2-3913", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-kc2-3913-21930", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.169781251111999, "lambda": 0.0645316226384517}}}], "metrics": 0.85249, "context": "openml-kc2-3913", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-kc2-3913-11561", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.174517274368554, "lambda": 0.0601730355506233}}}], "metrics": 0.85249, "context": "openml-kc2-3913", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-kc2-3913-20371", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.156096398597583, "lambda": 0.0652884777701419}}}], "metrics": 0.85249, "context": "openml-kc2-3913", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-kc2-3913-11817", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.243195477174595, "lambda": 0.0557335729132296}}}], "metrics": 0.85249, "context": "openml-kc2-3913", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-wdbc-9946-10728", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.317952851532027, "lambda": 0.00576730656650106}}}], "metrics": 0.982425, "context": "openml-wdbc-9946", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-wdbc-9946-3390", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.300114799989387, "lambda": 0.00588519973098064}}}], "metrics": 0.982425, "context": "openml-wdbc-9946", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-wdbc-9946-18567", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.313755558105186, "lambda": 0.0059779010393092}}}], "metrics": 0.982425, "context": "openml-wdbc-9946", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-wdbc-9946-23841", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.27447564760223, "lambda": 0.00615997566826888}}}], "metrics": 0.982425, "context": "openml-wdbc-9946", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-wdbc-9946-10188", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.409998050890863, "lambda": 0.00713841983493128}}}], "metrics": 0.982425, "context": "openml-wdbc-9946", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-phoneme-9952-8529", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.00525903678499162, "lambda": 0.001}}}], "metrics": 0.749445, "context": "openml-phoneme-9952", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-phoneme-9952-17217", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.0120157622732222, "lambda": 0.001}}}], "metrics": 0.749445, "context": "openml-phoneme-9952", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-phoneme-9952-10327", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.0152808816637844, "lambda": 0.00100710205697116}}}], "metrics": 0.749445, "context": "openml-phoneme-9952", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-phoneme-9952-9019", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.0392606558743864, "lambda": 0.00101358868908699}}}], "metrics": 0.74926, "context": "openml-phoneme-9952", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-phoneme-9952-22865", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.161899000871927, "lambda": 0.001}}}], "metrics": 0.74926, "context": "openml-phoneme-9952", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-qsar-biodeg-9957-17264", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.438409752678126, "lambda": 0.00213372527414705}}}], "metrics": 0.876777, "context": "openml-qsar-biodeg-9957", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-qsar-biodeg-9957-19276", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.473456029081717, "lambda": 0.00209684036714066}}}], "metrics": 0.875829, "context": "openml-qsar-biodeg-9957", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-qsar-biodeg-9957-18256", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.913826667238027, "lambda": 0.00182114820878506}}}], "metrics": 0.875829, "context": "openml-qsar-biodeg-9957", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-qsar-biodeg-9957-15160", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.957871187012643, "lambda": 0.00182921972985128}}}], "metrics": 0.875829, "context": "openml-qsar-biodeg-9957", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-qsar-biodeg-9957-10614", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.516084295231849, "lambda": 0.00187413832241356}}}], "metrics": 0.875829, "context": "openml-qsar-biodeg-9957", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-hill-valley-145847-15739", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.0158242562320083, "lambda": 0.00100697332029188}}}], "metrics": 0.707096, "context": "openml-hill-valley-145847", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-hill-valley-145847-14327", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.187050130916759, "lambda": 0.001}}}], "metrics": 0.706271, "context": "openml-hill-valley-145847", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-hill-valley-145847-7855", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.166838955599815, "lambda": 0.00103299261831446}}}], "metrics": 0.706271, "context": "openml-hill-valley-145847", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-hill-valley-145847-25086", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.00177745684050024, "lambda": 0.00110433608171681}}}], "metrics": 0.706271, "context": "openml-hill-valley-145847", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-glmnet-6766-openml-hill-valley-145847-26484", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "glmnet-6766", "config": {"alpha": 0.171529552899301, "lambda": 0.001}}}], "metrics": 0.706271, "context": "openml-hill-valley-145847", "schema": "glmnet-6766", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-haberman-272-006", "modules": [{"role": "dataset", "module": "openml-haberman-272"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00160914992520529, "booster": "gblinear", "eta": 0.0159274642549566, "lambda": 50.913948043841, "nrounds": 3356, "nthread": 0, "subsample": 0.186830151011236}}}], "metrics": 0.74, "context": "openml-haberman-272", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-haberman-272-005", "modules": [{"role": "dataset", "module": "openml-haberman-272"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00235298961142127, "booster": "gbtree", "colsample_bylevel": 0.991601191693917, "colsample_bytree": 0.996006388217211, "eta": 0.00425939357331107, "lambda": 1.06506539179449, "max_depth": 5, "min_child_weight": 4.98428392138307, "nrounds": 550, "nthread": 0, "subsample": 0.899001907370985}}}], "metrics": 0.74, "context": "openml-haberman-272", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-haberman-272-007", "modules": [{"role": "dataset", "module": "openml-haberman-272"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.201158593962047, "booster": "gblinear", "eta": 0.00828045771280908, "lambda": 720.614136507857, "nrounds": 4743, "nthread": 0, "subsample": 0.21608650824055103}}}], "metrics": 0.73, "context": "openml-haberman-272", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-haberman-272-004", "modules": [{"role": "dataset", "module": "openml-haberman-272"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 3.58872064006038, "booster": "gbtree", "colsample_bylevel": 0.310191081371158, "colsample_bytree": 0.475980486953631, "eta": 0.00306435858565976, "lambda": 1.12752724652931, "max_depth": 8, "min_child_weight": 4.73233123149239, "nrounds": 1619, "nthread": 0, "subsample": 0.236313604656607}}}], "metrics": 0.73, "context": "openml-haberman-272", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-haberman-272-003", "modules": [{"role": "dataset", "module": "openml-haberman-272"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 40.1549270999235, "booster": "gblinear", "eta": 0.405633707382808, "lambda": 220.292324514708, "nrounds": 1733, "nthread": 0, "subsample": 0.328345989529043}}}], "metrics": 0.73, "context": "openml-haberman-272", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-gina-agnostic-3891-094", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.814387649976429, "booster": "gbtree", "colsample_bylevel": 0.202985379612073, "colsample_bytree": 0.97661155438982, "eta": 0.145301458946022, "lambda": 0.136875172389387, "max_depth": 15, "min_child_weight": 6.70696949381567, "nrounds": 384, "nthread": 1, "subsample": 0.774709211452864}}}], "metrics": 0.95098, "context": "openml-gina-agnostic-3891", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-gina-agnostic-3891-081", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0258744468503825, "booster": "gbtree", "colsample_bylevel": 0.289936189539731, "colsample_bytree": 0.205113620497286, "eta": 0.0657110738983469, "lambda": 0.196514695443702, "max_depth": 5, "min_child_weight": 2.96318173178215, "nrounds": 546, "nthread": 1, "subsample": 0.499013545387425}}}], "metrics": 0.946655, "context": "openml-gina-agnostic-3891", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-gina-agnostic-3891-114", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 5.60068507534694, "booster": "gbtree", "colsample_bylevel": 0.526970982085913, "colsample_bytree": 0.39363714074716, "eta": 0.467057280340118, "lambda": 0.01934581903684, "max_depth": 7, "min_child_weight": 6.71358659260984, "nrounds": 487, "nthread": 1, "subsample": 0.980652486043982}}}], "metrics": 0.942907, "context": "openml-gina-agnostic-3891", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-gina-agnostic-3891-105", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.334853409910291, "booster": "gbtree", "colsample_bylevel": 0.37505819206126, "colsample_bytree": 0.265574414050207, "eta": 0.543442813812154, "lambda": 0.540611924250797, "max_depth": 15, "min_child_weight": 5.64350792594099, "nrounds": 322, "nthread": 1, "subsample": 0.814672638615593}}}], "metrics": 0.937716, "context": "openml-gina-agnostic-3891", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-gina-agnostic-3891-224", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0424353590699179, "booster": "gbtree", "colsample_bylevel": 0.686806278303266, "colsample_bytree": 0.481796472566202, "eta": 0.195350746516929, "lambda": 3.44123295122041, "max_depth": 2, "min_child_weight": 2.24188596457227, "nrounds": 465, "nthread": 1, "subsample": 0.765369013044983}}}], "metrics": 0.929931, "context": "openml-gina-agnostic-3891", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-bank-marketing-145833-019", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 13.0057844062661, "booster": "gbtree", "colsample_bylevel": 0.306499771308154, "colsample_bytree": 0.438679411541671, "eta": 0.100622602877102, "lambda": 0.182417340765419, "max_depth": 12, "min_child_weight": 2.21686621183155, "nrounds": 438, "nthread": 1, "subsample": 0.38864802531898}}}], "metrics": 0.908053, "context": "openml-bank-marketing-145833", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-bank-marketing-145833-123", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00222129569108017, "booster": "gbtree", "colsample_bylevel": 0.192558327224106, "colsample_bytree": 0.90813643601723, "eta": 0.0872693690535492, "lambda": 0.0905967259435628, "max_depth": 2, "min_child_weight": 1.0838101180739, "nrounds": 727, "nthread": 1, "subsample": 0.174440595693886}}}], "metrics": 0.906417, "context": "openml-bank-marketing-145833", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-bank-marketing-145833-056", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.466651528815458, "booster": "gbtree", "colsample_bylevel": 0.238625709200278, "colsample_bytree": 0.300778133329004, "eta": 0.337576270387683, "lambda": 0.199015876901552, "max_depth": 13, "min_child_weight": 71.8870730883108, "nrounds": 191, "nthread": 1, "subsample": 0.900540852872655}}}], "metrics": 0.905554, "context": "openml-bank-marketing-145833", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-bank-marketing-145833-057", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00253673467119198, "booster": "gbtree", "colsample_bylevel": 0.265322280814871, "colsample_bytree": 0.236726129194722, "eta": 0.07316928893711, "lambda": 10.2411564405444, "max_depth": 15, "min_child_weight": 8.70647657636395, "nrounds": 264, "nthread": 1, "subsample": 0.450009370641783}}}], "metrics": 0.9052, "context": "openml-bank-marketing-145833", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-bank-marketing-145833-181", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.331998422672998, "booster": "gbtree", "colsample_bylevel": 0.59076314070262, "colsample_bytree": 0.290584089234471, "eta": 0.0629696768981863, "lambda": 0.010151182044935, "max_depth": 2, "min_child_weight": 53.3642727326782, "nrounds": 481, "nthread": 1, "subsample": 0.979076325520873}}}], "metrics": 0.904293, "context": "openml-bank-marketing-145833", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-click-prediction-small-14971-663", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0428901139452703, "booster": "gbtree", "colsample_bylevel": 0.604731902480125, "colsample_bytree": 0.535434403689578, "eta": 0.00862955814068188, "lambda": 7.61598564435163, "max_depth": 7, "min_child_weight": 2.12587401952161, "nrounds": 4156, "nthread": 1, "subsample": 0.301831974345259}}}], "metrics": 0.838115, "context": "openml-click-prediction-small-14971", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-click-prediction-small-14971-420", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 1.01065957965817, "booster": "gbtree", "colsample_bylevel": 0.831254580290988, "colsample_bytree": 0.501360439695418, "eta": 0.00366769146513963, "lambda": 1.40312901190797, "max_depth": 12, "min_child_weight": 31.962400743712, "nrounds": 4255, "nthread": 1, "subsample": 0.834457908361219}}}], "metrics": 0.837739, "context": "openml-click-prediction-small-14971", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-click-prediction-small-14971-338", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.232489873323476, "booster": "gbtree", "colsample_bylevel": 0.339544442947954, "colsample_bytree": 0.689276218879968, "eta": 0.021688592503883, "lambda": 0.6121336094865, "max_depth": 13, "min_child_weight": 13.8830587702455, "nrounds": 601, "nthread": 1, "subsample": 0.782555874995887}}}], "metrics": 0.837714, "context": "openml-click-prediction-small-14971", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-click-prediction-small-14971-496", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0729578727169534, "booster": "gbtree", "colsample_bylevel": 0.600885031512007, "colsample_bytree": 0.829908354440704, "eta": 0.00467648585011912, "lambda": 0.128846445415239, "max_depth": 8, "min_child_weight": 3.2291290793654, "nrounds": 2779, "nthread": 1, "subsample": 0.214330215589143}}}], "metrics": 0.837689, "context": "openml-click-prediction-small-14971", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-click-prediction-small-14971-476", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00267451164857907, "booster": "gbtree", "colsample_bylevel": 0.419529014499858, "colsample_bytree": 0.622158566722646, "eta": 0.0127166955097663, "lambda": 0.0133731138224349, "max_depth": 5, "min_child_weight": 37.0119444700621, "nrounds": 4049, "nthread": 1, "subsample": 0.895176020986401}}}], "metrics": 0.837439, "context": "openml-click-prediction-small-14971", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-sylva-agnostic-3889-402", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00972444702916717, "booster": "gblinear", "eta": 0.0112160416250838, "lambda": 0.646408406622564, "nrounds": 4541, "nthread": 1, "subsample": 0.547959503415041}}}], "metrics": 0.995693, "context": "openml-sylva-agnostic-3889", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-sylva-agnostic-3889-162", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 1.03254656054498, "booster": "gblinear", "eta": 0.0932106967762917, "lambda": 0.00964530642777908, "nrounds": 516, "nthread": 1, "subsample": 0.644011696707457}}}], "metrics": 0.995554, "context": "openml-sylva-agnostic-3889", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-sylva-agnostic-3889-242", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 1.40476985079867, "booster": "gblinear", "eta": 0.125065360176796, "lambda": 0.212432587301859, "nrounds": 274, "nthread": 1, "subsample": 0.161460373736918}}}], "metrics": 0.995485, "context": "openml-sylva-agnostic-3889", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-sylva-agnostic-3889-394", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.602936604296133, "booster": "gblinear", "eta": 0.0240238405173435, "lambda": 0.158130746273998, "nrounds": 2447, "nthread": 1, "subsample": 0.677996637136675}}}], "metrics": 0.995485, "context": "openml-sylva-agnostic-3889", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-sylva-agnostic-3889-689", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 1.15119399871059, "booster": "gblinear", "eta": 0.018995433908057, "lambda": 0.491342720213165, "nrounds": 2769, "nthread": 1, "subsample": 0.461640713876113}}}], "metrics": 0.995485, "context": "openml-sylva-agnostic-3889", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-bank-marketing-14965-355", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00374420935967662, "booster": "gbtree", "colsample_bylevel": 0.878716196632013, "colsample_bytree": 0.844275380251929, "eta": 0.0118412362827649, "lambda": 97.8538865228208, "max_depth": 5, "min_child_weight": 4.52749856337331, "nrounds": 3971, "nthread": 1, "subsample": 0.975674145179801}}}], "metrics": 0.91042, "context": "openml-bank-marketing-14965", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-bank-marketing-14965-340", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0182803213410152, "booster": "gbtree", "colsample_bylevel": 0.213833244051784, "colsample_bytree": 0.845263700932264, "eta": 0.0268978811943336, "lambda": 93.8841705721908, "max_depth": 5, "min_child_weight": 7.35663447100062, "nrounds": 1940, "nthread": 1, "subsample": 0.974712856346741}}}], "metrics": 0.909889, "context": "openml-bank-marketing-14965", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-bank-marketing-14965-390", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0329891505503413, "booster": "gbtree", "colsample_bylevel": 0.544431853573769, "colsample_bytree": 0.962643061066046, "eta": 0.0757481973177453, "lambda": 0.00277952912963798, "max_depth": 3, "min_child_weight": 12.6834274136914, "nrounds": 1123, "nthread": 1, "subsample": 0.628698315634392}}}], "metrics": 0.909779, "context": "openml-bank-marketing-14965", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-bank-marketing-14965-941", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 7.44828162313408, "booster": "gbtree", "colsample_bylevel": 0.57986085372977, "colsample_bytree": 0.756986336549744, "eta": 0.0118814421605017, "lambda": 0.731470700615998, "max_depth": 5, "min_child_weight": 4.51264491332116, "nrounds": 4164, "nthread": 1, "subsample": 0.889379459898919}}}], "metrics": 0.909668, "context": "openml-bank-marketing-14965", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-bank-marketing-14965-695", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.834746941488657, "booster": "gbtree", "colsample_bylevel": 0.732263078913093, "colsample_bytree": 0.937241957522929, "eta": 0.428859210453369, "lambda": 632.519823308231, "max_depth": 13, "min_child_weight": 5.71628638581897, "nrounds": 119, "nthread": 1, "subsample": 0.394966105278581}}}], "metrics": 0.909602, "context": "openml-bank-marketing-14965", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-spambase-43-803", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.470945072005131, "booster": "gbtree", "colsample_bylevel": 0.210737332003191, "colsample_bytree": 0.401865524472669, "eta": 0.0116734264936609, "lambda": 5.5523936985901, "max_depth": 14, "min_child_weight": 1.87070551603822, "nrounds": 1986, "nthread": 1, "subsample": 0.816554921958595}}}], "metrics": 0.956749, "context": "openml-spambase-43", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-spambase-43-527", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 1.65388094969689, "booster": "gbtree", "colsample_bylevel": 0.658207347616553, "colsample_bytree": 0.855234693968669, "eta": 0.004885942505008369, "lambda": 0.495368690895507, "max_depth": 15, "min_child_weight": 1.12640948322662, "nrounds": 3777, "nthread": 1, "subsample": 0.639446527929977}}}], "metrics": 0.955879, "context": "openml-spambase-43", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-spambase-43-006", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00369961811668628, "booster": "gbtree", "colsample_bylevel": 0.580005168914795, "colsample_bytree": 0.496011469513178, "eta": 0.0353176042707346, "lambda": 0.0159306484065424, "max_depth": 11, "min_child_weight": 3.22063237571209, "nrounds": 404, "nthread": 1, "subsample": 0.63171674751211}}}], "metrics": 0.955662, "context": "openml-spambase-43", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-spambase-43-431", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.217180761679482, "booster": "gbtree", "colsample_bylevel": 0.299754853360355, "colsample_bytree": 0.339201389346272, "eta": 0.0599124909063726, "lambda": 3.12326796496007, "max_depth": 11, "min_child_weight": 1.90935126219286, "nrounds": 2234, "nthread": 1, "subsample": 0.979452721588314}}}], "metrics": 0.955662, "context": "openml-spambase-43", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-spambase-43-117", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.807939207984175, "booster": "gbtree", "colsample_bylevel": 0.707074321107939, "colsample_bytree": 0.800085102207959, "eta": 0.00467908317394926, "lambda": 0.00928852904987972, "max_depth": 15, "min_child_weight": 1.73026091526741, "nrounds": 3292, "nthread": 1, "subsample": 0.578137732320465}}}], "metrics": 0.954792, "context": "openml-spambase-43", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-click-prediction-small-7295-616", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.200856050544381, "booster": "gbtree", "colsample_bylevel": 0.848259449470788, "colsample_bytree": 0.347699639620259, "eta": 0.00419192623367018, "lambda": 0.00397279082639123, "max_depth": 15, "min_child_weight": 3.05094997287425, "nrounds": 1912, "nthread": 1, "subsample": 0.495138530363329}}}], "metrics": 0.83819, "context": "openml-click-prediction-small-7295", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-click-prediction-small-7295-1271", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0380355166164734, "booster": "gbtree", "colsample_bylevel": 0.950673815794289, "colsample_bytree": 0.417118737474084, "eta": 0.00289636827134038, "lambda": 0.0697114904397891, "max_depth": 13, "min_child_weight": 2.04428624265817, "nrounds": 3224, "nthread": 1, "subsample": 0.280858249845915}}}], "metrics": 0.838165, "context": "openml-click-prediction-small-7295", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-click-prediction-small-7295-1128", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.904561111267763, "booster": "gbtree", "colsample_bylevel": 0.671493262052536, "colsample_bytree": 0.487514647422358, "eta": 0.007068999243284649, "lambda": 0.00526912231767765, "max_depth": 8, "min_child_weight": 9.37439457217009, "nrounds": 2764, "nthread": 1, "subsample": 0.577408764488064}}}], "metrics": 0.83814, "context": "openml-click-prediction-small-7295", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-click-prediction-small-7295-075", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.937522414774629, "booster": "gbtree", "colsample_bylevel": 0.534482333576307, "colsample_bytree": 0.551454425323755, "eta": 0.0230599382678886, "lambda": 0.309279925801742, "max_depth": 15, "min_child_weight": 2.78960919336506, "nrounds": 523, "nthread": 1, "subsample": 0.321347283525392}}}], "metrics": 0.837789, "context": "openml-click-prediction-small-7295", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-click-prediction-small-7295-612", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00120236846934748, "booster": "gbtree", "colsample_bylevel": 0.843141743214801, "colsample_bytree": 0.387450239155442, "eta": 0.0210644589868597, "lambda": 0.21818771681717, "max_depth": 5, "min_child_weight": 2.8036582728169, "nrounds": 3332, "nthread": 1, "subsample": 0.444478694209829}}}], "metrics": 0.837714, "context": "openml-click-prediction-small-7295", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-wilt-9889-1127", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 2.06745024787372, "booster": "gbtree", "colsample_bylevel": 0.79950402257964, "colsample_bytree": 0.853282727533951, "eta": 0.300204784875211, "lambda": 0.0045615851639627, "max_depth": 3, "min_child_weight": 1.35152912176629, "nrounds": 4142, "nthread": 1, "subsample": 0.659522255766205}}}], "metrics": 0.987187, "context": "openml-wilt-9889", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-wilt-9889-953", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.011847600963420302, "booster": "gbtree", "colsample_bylevel": 0.928170062368736, "colsample_bytree": 0.999375343555585, "eta": 0.315101817676484, "lambda": 219.611015037471, "max_depth": 13, "min_child_weight": 1.57313835390639, "nrounds": 3962, "nthread": 1, "subsample": 0.280653377901763}}}], "metrics": 0.985741, "context": "openml-wilt-9889", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-wilt-9889-350", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0704557899858476, "booster": "gbtree", "colsample_bylevel": 0.888889778172597, "colsample_bytree": 0.905215117847547, "eta": 0.00956921194942662, "lambda": 0.020051010140142, "max_depth": 5, "min_child_weight": 1.71914099834029, "nrounds": 3472, "nthread": 1, "subsample": 0.24239538158290103}}}], "metrics": 0.985741, "context": "openml-wilt-9889", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-wilt-9889-024", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.571301768133743, "booster": "gbtree", "colsample_bylevel": 0.503916682675481, "colsample_bytree": 0.895389480981976, "eta": 0.0483013200258114, "lambda": 22.8564745533027, "max_depth": 6, "min_child_weight": 2.62598540697846, "nrounds": 1358, "nthread": 1, "subsample": 0.62921467020642}}}], "metrics": 0.985328, "context": "openml-wilt-9889", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-wilt-9889-1290", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 1.6441180288454, "booster": "gbtree", "colsample_bylevel": 0.708042748039588, "colsample_bytree": 0.947503517614678, "eta": 0.139359437376242, "lambda": 0.0685634658614648, "max_depth": 2, "min_child_weight": 6.07727844556976, "nrounds": 2729, "nthread": 1, "subsample": 0.67723873371724}}}], "metrics": 0.985121, "context": "openml-wilt-9889", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-nomao-9977-114", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.041654781711762, "booster": "gbtree", "colsample_bylevel": 0.932438890682533, "colsample_bytree": 0.232173703610897, "eta": 0.0199624714852524, "lambda": 0.00228030423921534, "max_depth": 8, "min_child_weight": 1.28415105739043, "nrounds": 2876, "nthread": 1, "subsample": 0.641868106694892}}}], "metrics": 0.975366, "context": "openml-nomao-9977", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-nomao-9977-1285", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00121846387565772, "booster": "gbtree", "colsample_bylevel": 0.301271411357448, "colsample_bytree": 0.340112632839009, "eta": 0.027797536885479, "lambda": 0.180097410792549, "max_depth": 13, "min_child_weight": 1.78828088188708, "nrounds": 3931, "nthread": 1, "subsample": 0.656147888256237}}}], "metrics": 0.975279, "context": "openml-nomao-9977", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-nomao-9977-1576", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.183334061315184, "booster": "gbtree", "colsample_bylevel": 0.30488775880076, "colsample_bytree": 0.95489092473872, "eta": 0.146896059428169, "lambda": 0.0130632431166141, "max_depth": 4, "min_child_weight": 1.04395355324038, "nrounds": 3441, "nthread": 1, "subsample": 0.614034095569514}}}], "metrics": 0.975134, "context": "openml-nomao-9977", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-nomao-9977-956", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.413856477578749, "booster": "gbtree", "colsample_bylevel": 0.317221196833998, "colsample_bytree": 0.390710223931819, "eta": 0.0586380903747398, "lambda": 0.390905160034849, "max_depth": 9, "min_child_weight": 1.77362218507283, "nrounds": 3724, "nthread": 1, "subsample": 0.826461446797475}}}], "metrics": 0.975076, "context": "openml-nomao-9977", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-nomao-9977-884", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00209622180817577, "booster": "gbtree", "colsample_bylevel": 0.121782839531079, "colsample_bytree": 0.555375803261995, "eta": 0.0568670422385874, "lambda": 0.0154556283817986, "max_depth": 6, "min_child_weight": 1.94921709646978, "nrounds": 3488, "nthread": 1, "subsample": 0.482976036611944}}}], "metrics": 0.97496, "context": "openml-nomao-9977", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-nomao-145854-1359", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.471646542879564, "booster": "gbtree", "colsample_bylevel": 0.86604400863871, "colsample_bytree": 0.173737798817456, "eta": 0.0718364836572113, "lambda": 0.0263035259077138, "max_depth": 5, "min_child_weight": 1.30731907730044, "nrounds": 4984, "nthread": 1, "subsample": 0.672967485804111}}}], "metrics": 0.975163, "context": "openml-nomao-145854", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-nomao-145854-862", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0538977276605123, "booster": "gbtree", "colsample_bylevel": 0.802080834750086, "colsample_bytree": 0.129845352377743, "eta": 0.253325724952421, "lambda": 0.0899639130242699, "max_depth": 9, "min_child_weight": 2.38686516788387, "nrounds": 2356, "nthread": 1, "subsample": 0.971231746766716}}}], "metrics": 0.974873, "context": "openml-nomao-145854", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-nomao-145854-1675", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00146788747737293, "booster": "gbtree", "colsample_bylevel": 0.567153497133404, "colsample_bytree": 0.23525426373817, "eta": 0.104995901059117, "lambda": 0.0448703408373444, "max_depth": 4, "min_child_weight": 1.95187105672818, "nrounds": 4821, "nthread": 1, "subsample": 0.821450972231105}}}], "metrics": 0.974786, "context": "openml-nomao-145854", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-nomao-145854-852", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00189381154112192, "booster": "gbtree", "colsample_bylevel": 0.900116314180195, "colsample_bytree": 0.213150403695181, "eta": 0.17351216726916, "lambda": 16.694230874577, "max_depth": 15, "min_child_weight": 3.7823334634463, "nrounds": 724, "nthread": 1, "subsample": 0.983086333819665}}}], "metrics": 0.974786, "context": "openml-nomao-145854", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-nomao-145854-1150", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00376201397894533, "booster": "gbtree", "colsample_bylevel": 0.114720569225028, "colsample_bytree": 0.640968576539308, "eta": 0.0541636477130217, "lambda": 0.305760606889281, "max_depth": 6, "min_child_weight": 1.22652774519901, "nrounds": 1500, "nthread": 1, "subsample": 0.566727282409556}}}], "metrics": 0.974757, "context": "openml-nomao-145854", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-pc4-3902-588", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00210198212516679, "booster": "gbtree", "colsample_bylevel": 0.596635356079787, "colsample_bytree": 0.768533876165748, "eta": 0.0032288761062492, "lambda": 0.698852997988521, "max_depth": 10, "min_child_weight": 1.6131702376304, "nrounds": 4533, "nthread": 1, "subsample": 0.72318395532202}}}], "metrics": 0.921125, "context": "openml-pc4-3902", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-pc4-3902-2531", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00749656365555367, "booster": "gbtree", "colsample_bylevel": 0.992761784233153, "colsample_bytree": 0.747038495028391, "eta": 0.0316256416707609, "lambda": 1.96065851218323, "max_depth": 4, "min_child_weight": 2.94639683997634, "nrounds": 1426, "nthread": 1, "subsample": 0.923800085368566}}}], "metrics": 0.917695, "context": "openml-pc4-3902", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-pc4-3902-089", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.001, "booster": "gbtree", "colsample_bylevel": 0.69840890634805, "colsample_bytree": 0.482145244488493, "eta": 0.393836391640725, "lambda": 431.438173354578, "max_depth": 10, "min_child_weight": 2.52026085464409, "nrounds": 4624, "nthread": 1, "subsample": 0.32924983529374}}}], "metrics": 0.91701, "context": "openml-pc4-3902", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-pc4-3902-1192", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0872106759325667, "booster": "gbtree", "colsample_bylevel": 0.222558809444308, "colsample_bytree": 0.749894303269684, "eta": 0.219020873716475, "lambda": 0.140893602516904, "max_depth": 6, "min_child_weight": 1.6423800340271, "nrounds": 264, "nthread": 1, "subsample": 0.771145135280676}}}], "metrics": 0.91701, "context": "openml-pc4-3902", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-pc4-3902-080", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.019703012288053, "booster": "gbtree", "colsample_bylevel": 0.689543009269983, "colsample_bytree": 0.366224377881736, "eta": 0.292146311250289, "lambda": 81.9659309426045, "max_depth": 10, "min_child_weight": 2.46838883523318, "nrounds": 1156, "nthread": 1, "subsample": 0.870946918264963}}}], "metrics": 0.91701, "context": "openml-pc4-3902", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-banknote-authentication-145834-2208", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.040820914502281, "booster": "gbtree", "colsample_bylevel": 0.855159325292334, "colsample_bytree": 0.848848002497107, "eta": 0.0571189861803908, "lambda": 0.31346134621722, "max_depth": 13, "min_child_weight": 1.36994084900593, "nrounds": 1107, "nthread": 1, "subsample": 0.179445685725659}}}], "metrics": 0.998542, "context": "openml-banknote-authentication-145834", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-banknote-authentication-145834-2565", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.549934882403567, "booster": "gbtree", "colsample_bylevel": 0.509561045793816, "colsample_bytree": 0.629446737468243, "eta": 0.254088078992433, "lambda": 0.00682355438502159, "max_depth": 2, "min_child_weight": 2.01949132456422, "nrounds": 699, "nthread": 1, "subsample": 0.869316658633761}}}], "metrics": 0.997813, "context": "openml-banknote-authentication-145834", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-banknote-authentication-145834-269", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0454986078425638, "booster": "gbtree", "colsample_bylevel": 0.659234029706568, "colsample_bytree": 0.861226733308285, "eta": 0.0575784369802536, "lambda": 1.25703629683195, "max_depth": 3, "min_child_weight": 1.99932587270194, "nrounds": 889, "nthread": 1, "subsample": 0.350562934880145}}}], "metrics": 0.997813, "context": "openml-banknote-authentication-145834", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-banknote-authentication-145834-1055", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00536830381337302, "booster": "gbtree", "colsample_bylevel": 0.686046555172652, "colsample_bytree": 0.802356880158186, "eta": 0.123543060430547, "lambda": 1.63477283147417, "max_depth": 15, "min_child_weight": 1.28202473244341, "nrounds": 3842, "nthread": 1, "subsample": 0.276020205905661}}}], "metrics": 0.997813, "context": "openml-banknote-authentication-145834", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-banknote-authentication-145834-010", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.5756373625126, "booster": "gbtree", "colsample_bylevel": 0.951743536628783, "colsample_bytree": 0.784188590710983, "eta": 0.250985776827051, "lambda": 3.88420683964855, "max_depth": 4, "min_child_weight": 1.41932302926052, "nrounds": 1691, "nthread": 1, "subsample": 0.655739164026454}}}], "metrics": 0.997813, "context": "openml-banknote-authentication-145834", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-electricity-146012-307", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.245361047264519, "booster": "gbtree", "colsample_bylevel": 0.912933584768325, "colsample_bytree": 0.823527257423848, "eta": 0.335952668837201, "lambda": 0.189021762101315, "max_depth": 10, "min_child_weight": 2.41145883867631, "nrounds": 289, "nthread": 1, "subsample": 0.976003102189861}}}], "metrics": 0.944209, "context": "openml-electricity-146012", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-electricity-146012-2562", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 1.10975575614756, "booster": "gbtree", "colsample_bylevel": 0.962995384354144, "colsample_bytree": 0.610855414532125, "eta": 0.262075234775975, "lambda": 0.00287386685170204, "max_depth": 7, "min_child_weight": 1.30506830379651, "nrounds": 4982, "nthread": 1, "subsample": 0.908722252747975}}}], "metrics": 0.942444, "context": "openml-electricity-146012", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-electricity-146012-1258", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.540743397251989, "booster": "gbtree", "colsample_bylevel": 0.349940155632794, "colsample_bytree": 0.928324862848967, "eta": 0.137089680642641, "lambda": 1.80217707356832, "max_depth": 10, "min_child_weight": 1.33827230127954, "nrounds": 3164, "nthread": 1, "subsample": 0.994650021474808}}}], "metrics": 0.940479, "context": "openml-electricity-146012", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-electricity-146012-3054", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.515943671011491, "booster": "gbtree", "colsample_bylevel": 0.73112879646942, "colsample_bytree": 0.66245500696823, "eta": 0.120907931151973, "lambda": 0.231588940397763, "max_depth": 10, "min_child_weight": 9.08525613271084, "nrounds": 4548, "nthread": 1, "subsample": 0.929810493532568}}}], "metrics": 0.938537, "context": "openml-electricity-146012", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-electricity-146012-3072", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0010655391170073, "booster": "gbtree", "colsample_bylevel": 0.722897934028879, "colsample_bytree": 0.807237407658249, "eta": 0.0343310851174236, "lambda": 2.20166460430276, "max_depth": 9, "min_child_weight": 5.08373451170101, "nrounds": 4298, "nthread": 1, "subsample": 0.749766747793183}}}], "metrics": 0.938449, "context": "openml-electricity-146012", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-electricity-219-594", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.009432215959976072, "booster": "gbtree", "colsample_bylevel": 0.697227717377245, "colsample_bytree": 0.818930426379666, "eta": 0.0923677165261241, "lambda": 0.0335674003911803, "max_depth": 10, "min_child_weight": 2.04179767032281, "nrounds": 305, "nthread": 1, "subsample": 0.940911597153172}}}], "metrics": 0.939729, "context": "openml-electricity-219", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-electricity-219-2074", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 2.3732030589826, "booster": "gbtree", "colsample_bylevel": 0.766731201205403, "colsample_bytree": 0.523531635990366, "eta": 0.632607587551226, "lambda": 0.00210006219244774, "max_depth": 6, "min_child_weight": 9.66670436618169, "nrounds": 612, "nthread": 1, "subsample": 0.864313476532698}}}], "metrics": 0.927481, "context": "openml-electricity-219", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-electricity-219-3169", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.198051373658986, "booster": "gbtree", "colsample_bylevel": 0.948302265023813, "colsample_bytree": 0.904974757460877, "eta": 0.068941160426532, "lambda": 0.0472657318350211, "max_depth": 8, "min_child_weight": 3.64378177422103, "nrounds": 268, "nthread": 1, "subsample": 0.984207250969484}}}], "metrics": 0.924545, "context": "openml-electricity-219", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-electricity-219-1095", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0187496537857111, "booster": "gbtree", "colsample_bylevel": 0.834619141416624, "colsample_bytree": 0.6850028433837, "eta": 0.337702002702286, "lambda": 0.017852305873345, "max_depth": 13, "min_child_weight": 17.4744149139018, "nrounds": 155, "nthread": 1, "subsample": 0.942605682043359}}}], "metrics": 0.92214, "context": "openml-electricity-219", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-electricity-219-1442", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00558447875925245, "booster": "gbtree", "colsample_bylevel": 0.45486402255483, "colsample_bytree": 0.575992892263457, "eta": 0.186212240685261, "lambda": 3.89677561461846, "max_depth": 8, "min_child_weight": 1.03957414284587, "nrounds": 408, "nthread": 1, "subsample": 0.712005006032996}}}], "metrics": 0.919712, "context": "openml-electricity-219", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-monks-problems-3-3494-1133", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 1.85339027091041, "booster": "gbtree", "colsample_bylevel": 0.255159043939784, "colsample_bytree": 0.708506802329794, "eta": 0.603940142190323, "lambda": 0.751914541222766, "max_depth": 14, "min_child_weight": 1.57964130608495, "nrounds": 2988, "nthread": 1, "subsample": 0.71638979059644}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-monks-problems-3-3494-3012", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.585878332069445, "booster": "gbtree", "colsample_bylevel": 0.36238316167146, "colsample_bytree": 0.913491994142532, "eta": 0.313539948446904, "lambda": 0.0018237743607257, "max_depth": 13, "min_child_weight": 3.30771489206513, "nrounds": 2583, "nthread": 1, "subsample": 0.728339058370329}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-monks-problems-3-3494-2614", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0738233820864486, "booster": "gbtree", "colsample_bylevel": 0.956090984633192, "colsample_bytree": 0.345298764063045, "eta": 0.00383872775326047, "lambda": 0.058787244412444, "max_depth": 3, "min_child_weight": 1.06020203555304, "nrounds": 4229, "nthread": 1, "subsample": 0.71289259090554}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-monks-problems-3-3494-1494", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 3.89399763945689, "booster": "gbtree", "colsample_bylevel": 0.789110295940191, "colsample_bytree": 0.853977401508018, "eta": 0.00415091187740964, "lambda": 8.56794714625483, "max_depth": 11, "min_child_weight": 1.29438237735364, "nrounds": 1520, "nthread": 1, "subsample": 0.964051836589351}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-monks-problems-3-3494-1619", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.996852187856723, "booster": "gbtree", "colsample_bylevel": 0.524004444945604, "colsample_bytree": 0.797991966828704, "eta": 0.234667890189602, "lambda": 0.234069372858121, "max_depth": 12, "min_child_weight": 1.9143703582858, "nrounds": 4048, "nthread": 1, "subsample": 0.46695278713014}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-madelon-9976-1955", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00195037989193369, "booster": "gbtree", "colsample_bylevel": 0.524658416863531, "colsample_bytree": 0.494975913316011, "eta": 0.00219717589336541, "lambda": 0.0129358734605128, "max_depth": 8, "min_child_weight": 3.19159113754506, "nrounds": 226, "nthread": 1, "subsample": 0.890067089861259}}}], "metrics": 0.853846, "context": "openml-madelon-9976", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-madelon-9976-1172", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0016412531216875, "booster": "gbtree", "colsample_bylevel": 0.446239963639528, "colsample_bytree": 0.508445462211967, "eta": 0.0129305085368182, "lambda": 0.126004639127777, "max_depth": 10, "min_child_weight": 4.14267724211127, "nrounds": 469, "nthread": 1, "subsample": 0.985373874427751}}}], "metrics": 0.846154, "context": "openml-madelon-9976", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-madelon-9976-1364", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0635897373455669, "booster": "gbtree", "colsample_bylevel": 0.168780500767753, "colsample_bytree": 0.703396411379799, "eta": 0.00104965520009998, "lambda": 0.0126940055884052, "max_depth": 15, "min_child_weight": 1.74710938823477, "nrounds": 224, "nthread": 1, "subsample": 0.997515636170283}}}], "metrics": 0.84, "context": "openml-madelon-9976", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-madelon-9976-863", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 4.89535609191973, "booster": "gbtree", "colsample_bylevel": 0.56034153397195, "colsample_bytree": 0.748455631081015, "eta": 0.0216700046801582, "lambda": 0.00124661011509845, "max_depth": 10, "min_child_weight": 1.02718627788018, "nrounds": 163, "nthread": 1, "subsample": 0.751708680950105}}}], "metrics": 0.835, "context": "openml-madelon-9976", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-madelon-9976-1789", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00143641953190433, "booster": "gbtree", "colsample_bylevel": 0.376034961314872, "colsample_bytree": 0.766589517472312, "eta": 0.0741360984178849, "lambda": 0.00540826700831711, "max_depth": 9, "min_child_weight": 1.12962201854093, "nrounds": 539, "nthread": 1, "subsample": 0.94195991277229}}}], "metrics": 0.831538, "context": "openml-madelon-9976", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-madelon-145853-3864", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00151614325617239, "booster": "gbtree", "colsample_bylevel": 0.506971101043746, "colsample_bytree": 0.772544690407813, "eta": 0.00101407562835255, "lambda": 0.00371228305232187, "max_depth": 9, "min_child_weight": 1.35698553286402, "nrounds": 3779, "nthread": 1, "subsample": 0.898201998253353}}}], "metrics": 0.868462, "context": "openml-madelon-145853", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-madelon-145853-1599", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00202761236288231, "booster": "gbtree", "colsample_bylevel": 0.80480789532885, "colsample_bytree": 0.584897823864594, "eta": 0.001554060644937, "lambda": 0.0244714544626609, "max_depth": 10, "min_child_weight": 1.64091334708531, "nrounds": 921, "nthread": 1, "subsample": 0.921186144649982}}}], "metrics": 0.863462, "context": "openml-madelon-145853", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-madelon-145853-1063", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00384927605134505, "booster": "gbtree", "colsample_bylevel": 0.506852737627923, "colsample_bytree": 0.801703049335629, "eta": 0.00134084990303344, "lambda": 0.851418524340032, "max_depth": 7, "min_child_weight": 2.61600102735234, "nrounds": 1380, "nthread": 1, "subsample": 0.977539017423987}}}], "metrics": 0.861923, "context": "openml-madelon-145853", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-madelon-145853-1481", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.339793496324604, "booster": "gbtree", "colsample_bylevel": 0.433057001791894, "colsample_bytree": 0.779030505567789, "eta": 0.00113905912838876, "lambda": 1.59896009959651, "max_depth": 15, "min_child_weight": 1.43770496915244, "nrounds": 886, "nthread": 1, "subsample": 0.923674871469848}}}], "metrics": 0.858077, "context": "openml-madelon-145853", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-madelon-145853-3248", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00386117221317466, "booster": "gbtree", "colsample_bylevel": 0.68755084881559, "colsample_bytree": 0.920953175518662, "eta": 0.00266534408635046, "lambda": 0.00529407109056753, "max_depth": 15, "min_child_weight": 2.13898017633302, "nrounds": 477, "nthread": 1, "subsample": 0.834295506053604}}}], "metrics": 0.856538, "context": "openml-madelon-145853", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-ilpd-9971-3451", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0124060610411093, "booster": "gblinear", "eta": 0.809857985041713, "lambda": 2.08756190020066, "nrounds": 769, "nthread": 1, "subsample": 0.560401061316952}}}], "metrics": 0.737564, "context": "openml-ilpd-9971", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-ilpd-9971-4612", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0733208870774282, "booster": "gblinear", "eta": 0.784606313022703, "lambda": 2.29202780138536, "nrounds": 4925, "nthread": 1, "subsample": 0.984900417178869}}}], "metrics": 0.737564, "context": "openml-ilpd-9971", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-ilpd-9971-1878", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00154045025504157, "booster": "gblinear", "eta": 0.511120964213567, "lambda": 2.50653905987218, "nrounds": 3927, "nthread": 1, "subsample": 0.417773525742814}}}], "metrics": 0.737564, "context": "openml-ilpd-9971", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-ilpd-9971-227", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0406009528134793, "booster": "gblinear", "eta": 0.955681127628295, "lambda": 2.21453309011375, "nrounds": 3129, "nthread": 1, "subsample": 0.994471998652443}}}], "metrics": 0.737564, "context": "openml-ilpd-9971", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-ilpd-9971-4183", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.66139349975806, "booster": "gblinear", "eta": 0.939699521509039, "lambda": 0.0134199830401377, "nrounds": 3053, "nthread": 1, "subsample": 0.399171911063604}}}], "metrics": 0.737564, "context": "openml-ilpd-9971", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-ozone-level-8hr-145855-2508", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 1.10516875246553, "booster": "gbtree", "colsample_bylevel": 0.3597895167768, "colsample_bytree": 0.567487676395103, "eta": 0.00967619392352242, "lambda": 0.706284836741259, "max_depth": 8, "min_child_weight": 1.01237410045617, "nrounds": 2150, "nthread": 1, "subsample": 0.362032531481236}}}], "metrics": 0.948698, "context": "openml-ozone-level-8hr-145855", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-ozone-level-8hr-145855-1863", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0724622092088877, "booster": "gbtree", "colsample_bylevel": 0.496994828106835, "colsample_bytree": 0.619881980121136, "eta": 0.0160206586820859, "lambda": 5.52253522695438, "max_depth": 7, "min_child_weight": 2.28496543782475, "nrounds": 1732, "nthread": 1, "subsample": 0.627235323586501}}}], "metrics": 0.948698, "context": "openml-ozone-level-8hr-145855", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-ozone-level-8hr-145855-2124", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0530513433055239, "booster": "gbtree", "colsample_bylevel": 0.611638177651912, "colsample_bytree": 0.61214289884083, "eta": 0.0180734533261467, "lambda": 3.20724742781982, "max_depth": 6, "min_child_weight": 2.19381118894145, "nrounds": 1600, "nthread": 1, "subsample": 0.68819378267508}}}], "metrics": 0.948303, "context": "openml-ozone-level-8hr-145855", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-ozone-level-8hr-145855-4506", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 2.79416265286334, "booster": "gbtree", "colsample_bylevel": 0.940083612920716, "colsample_bytree": 0.559959464706481, "eta": 0.152431650660745, "lambda": 0.156521714019879, "max_depth": 12, "min_child_weight": 2.8717725650735, "nrounds": 4062, "nthread": 1, "subsample": 0.574772493750788}}}], "metrics": 0.948303, "context": "openml-ozone-level-8hr-145855", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-ozone-level-8hr-145855-1468", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 2.18921350777999, "booster": "gbtree", "colsample_bylevel": 0.432311258045956, "colsample_bytree": 0.390317183919251, "eta": 0.0632578669816182, "lambda": 0.001, "max_depth": 14, "min_child_weight": 6.32113602302274, "nrounds": 308, "nthread": 1, "subsample": 0.955106304492801}}}], "metrics": 0.948303, "context": "openml-ozone-level-8hr-145855", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-hill-valley-9970-173", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 417.88061226885, "booster": "gblinear", "eta": 0.200700984900243, "lambda": 0.0842236188115443, "nrounds": 4770, "nthread": 1, "subsample": 0.740986509341747}}}], "metrics": 0.764026, "context": "openml-hill-valley-9970", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-hill-valley-9970-450", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 1.01490248290186, "booster": "gblinear", "eta": 0.229763442945992, "lambda": 0.467172821116499, "nrounds": 4920, "nthread": 1, "subsample": 0.376401297003031}}}], "metrics": 0.763201, "context": "openml-hill-valley-9970", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-hill-valley-9970-2337", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 127.894011723835, "booster": "gblinear", "eta": 0.155934159084034, "lambda": 0.0029548475848672805, "nrounds": 4873, "nthread": 1, "subsample": 0.35022836974822}}}], "metrics": 0.762376, "context": "openml-hill-valley-9970", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-hill-valley-9970-4330", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 379.919638139988, "booster": "gblinear", "eta": 0.166350724691271, "lambda": 0.0038149934277324805, "nrounds": 4665, "nthread": 1, "subsample": 0.927303867787123}}}], "metrics": 0.762376, "context": "openml-hill-valley-9970", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-hill-valley-9970-1467", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 2.8439228293056, "booster": "gblinear", "eta": 0.171391754433964, "lambda": 49.466392812933, "nrounds": 4840, "nthread": 1, "subsample": 0.889596498594619}}}], "metrics": 0.762376, "context": "openml-hill-valley-9970", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-ozone-level-8hr-9978-1040", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 6.03657082514018, "booster": "gbtree", "colsample_bylevel": 0.659766096388921, "colsample_bytree": 0.703429855406284, "eta": 0.119037559353244, "lambda": 0.0281839930452563, "max_depth": 13, "min_child_weight": 1.35919983985023, "nrounds": 1300, "nthread": 1, "subsample": 0.95171146732755}}}], "metrics": 0.950276, "context": "openml-ozone-level-8hr-9978", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-ozone-level-8hr-9978-3492", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.173389620179785, "booster": "gbtree", "colsample_bylevel": 0.591415227157995, "colsample_bytree": 0.972538957372308, "eta": 0.019024744521312, "lambda": 1.03867895761328, "max_depth": 10, "min_child_weight": 1.06478553849322, "nrounds": 1360, "nthread": 1, "subsample": 0.2222831643885}}}], "metrics": 0.949092, "context": "openml-ozone-level-8hr-9978", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-ozone-level-8hr-9978-2172", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00370524855175675, "booster": "gbtree", "colsample_bylevel": 0.487459322437644, "colsample_bytree": 0.40179970418103, "eta": 0.00517333322843916, "lambda": 1.64864519758612, "max_depth": 6, "min_child_weight": 1.47879798659613, "nrounds": 4153, "nthread": 1, "subsample": 0.6705711315386}}}], "metrics": 0.949092, "context": "openml-ozone-level-8hr-9978", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-ozone-level-8hr-9978-2427", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 2.86363102595322, "booster": "gbtree", "colsample_bylevel": 0.544205610407516, "colsample_bytree": 0.743338346248493, "eta": 0.0416509781635252, "lambda": 2.06333452943736, "max_depth": 14, "min_child_weight": 2.27264002162136, "nrounds": 994, "nthread": 1, "subsample": 0.876958403084427}}}], "metrics": 0.948698, "context": "openml-ozone-level-8hr-9978", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-ozone-level-8hr-9978-4797", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.577101608745705, "booster": "gbtree", "colsample_bylevel": 0.894278859719634, "colsample_bytree": 0.555980474222451, "eta": 0.0121625194496001, "lambda": 1.69501015088669, "max_depth": 10, "min_child_weight": 2.37676686269123, "nrounds": 1470, "nthread": 1, "subsample": 0.716644308972172}}}], "metrics": 0.948698, "context": "openml-ozone-level-8hr-9978", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-monks-problems-3-146066-5196", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00481483991502849, "booster": "gbtree", "colsample_bylevel": 0.701273431768641, "colsample_bytree": 0.693258830578998, "eta": 0.00144064377539198, "lambda": 0.197933506017279, "max_depth": 6, "min_child_weight": 3.14094096924707, "nrounds": 3356, "nthread": 1, "subsample": 0.775831428426318}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-monks-problems-3-146066-984", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.21823662249196, "booster": "gbtree", "colsample_bylevel": 0.940624194219708, "colsample_bytree": 0.896386699285358, "eta": 0.0307070627836884, "lambda": 16.0750582450701, "max_depth": 5, "min_child_weight": 3.48644834980809, "nrounds": 2604, "nthread": 1, "subsample": 0.784782546013594}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-monks-problems-3-146066-3244", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0770890373813917, "booster": "gbtree", "colsample_bylevel": 0.363904620520771, "colsample_bytree": 0.766575793270022, "eta": 0.297390907293067, "lambda": 1.80255005232074, "max_depth": 4, "min_child_weight": 3.05309169087892, "nrounds": 2239, "nthread": 1, "subsample": 0.51383021781221}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-monks-problems-3-146066-1028", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0036260212977707, "booster": "gbtree", "colsample_bylevel": 0.388981473864987, "colsample_bytree": 0.332136449636891, "eta": 0.969537553212836, "lambda": 21.2669655866638, "max_depth": 5, "min_child_weight": 1.80713104902534, "nrounds": 324, "nthread": 1, "subsample": 0.801750635472126}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-monks-problems-3-146066-3177", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.208098894384155, "booster": "gbtree", "colsample_bylevel": 0.113292190479115, "colsample_bytree": 0.88442312553525, "eta": 0.0419691585610011, "lambda": 0.2315138389097, "max_depth": 13, "min_child_weight": 1.54889493768097, "nrounds": 1319, "nthread": 1, "subsample": 0.627774639963172}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-magictelescope-3954-2196", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.294471063457746, "booster": "gbtree", "colsample_bylevel": 0.590500812511891, "colsample_bytree": 0.966231189668179, "eta": 0.0327776096202162, "lambda": 0.0105250226704468, "max_depth": 7, "min_child_weight": 1.04173270830483, "nrounds": 612, "nthread": 1, "subsample": 0.355417804652825}}}], "metrics": 0.886803, "context": "openml-magictelescope-3954", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-magictelescope-3954-081", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00104011687747794, "booster": "gbtree", "colsample_bylevel": 0.389790846733376, "colsample_bytree": 0.975316107738763, "eta": 0.0725009891388028, "lambda": 0.0675155689860969, "max_depth": 5, "min_child_weight": 1.71868584994714, "nrounds": 1018, "nthread": 1, "subsample": 0.664919609227218}}}], "metrics": 0.88654, "context": "openml-magictelescope-3954", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-magictelescope-3954-3892", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0197155575567075, "booster": "gbtree", "colsample_bylevel": 0.380179282510653, "colsample_bytree": 0.844821909908205, "eta": 0.0693135725340125, "lambda": 6.46442173440561, "max_depth": 11, "min_child_weight": 3.92111746800948, "nrounds": 322, "nthread": 1, "subsample": 0.973829530319199}}}], "metrics": 0.886278, "context": "openml-magictelescope-3954", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-magictelescope-3954-2386", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0203705063952224, "booster": "gbtree", "colsample_bylevel": 0.544701943872496, "colsample_bytree": 0.577377357287332, "eta": 0.0778164165133404, "lambda": 0.510236138704941, "max_depth": 4, "min_child_weight": 1.15935045470601, "nrounds": 2030, "nthread": 1, "subsample": 0.696446540416218}}}], "metrics": 0.885962, "context": "openml-magictelescope-3954", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-magictelescope-3954-3435", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 6.25774788185987, "booster": "gbtree", "colsample_bylevel": 0.92293512984179, "colsample_bytree": 0.989293757593259, "eta": 0.309548852876984, "lambda": 0.00302406524203899, "max_depth": 9, "min_child_weight": 3.64584068409082, "nrounds": 615, "nthread": 1, "subsample": 0.893523093755357}}}], "metrics": 0.885068, "context": "openml-magictelescope-3954", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-blood-transfusion-service-center-145836-2679", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 7.26811100011672, "booster": "gbtree", "colsample_bylevel": 0.868875643238425, "colsample_bytree": 0.77521712007001, "eta": 0.0766873798467554, "lambda": 44.8864128943999, "max_depth": 5, "min_child_weight": 6.59744614443898, "nrounds": 1359, "nthread": 1, "subsample": 0.427979684132151}}}], "metrics": 0.795455, "context": "openml-blood-transfusion-service-center-145836", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-blood-transfusion-service-center-145836-1845", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 6.86855171034154, "booster": "gbtree", "colsample_bylevel": 0.858270211843774, "colsample_bytree": 0.85496961302124, "eta": 0.030729088846829, "lambda": 0.00459497710957487, "max_depth": 8, "min_child_weight": 5.57647298252766, "nrounds": 1015, "nthread": 1, "subsample": 0.344032952026464}}}], "metrics": 0.794118, "context": "openml-blood-transfusion-service-center-145836", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-blood-transfusion-service-center-145836-5434", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0241491147357813, "booster": "gbtree", "colsample_bylevel": 0.573516698554158, "colsample_bytree": 0.962467487435788, "eta": 0.00121524953884215, "lambda": 0.00517551022019719, "max_depth": 4, "min_child_weight": 10.564340311767, "nrounds": 4693, "nthread": 1, "subsample": 0.413300969032571}}}], "metrics": 0.791444, "context": "openml-blood-transfusion-service-center-145836", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-blood-transfusion-service-center-145836-206", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00199197486065545, "booster": "gbtree", "colsample_bylevel": 0.709494923707098, "colsample_bytree": 0.509837756631896, "eta": 0.0664836393616602, "lambda": 112.103737196946, "max_depth": 1, "min_child_weight": 2.08556344483315, "nrounds": 1368, "nthread": 1, "subsample": 0.452138878637925}}}], "metrics": 0.791444, "context": "openml-blood-transfusion-service-center-145836", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-blood-transfusion-service-center-145836-6097", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00194018011147523, "booster": "gbtree", "colsample_bylevel": 0.507685871561989, "colsample_bytree": 0.737827750621364, "eta": 0.00176501348179715, "lambda": 0.848420448405802, "max_depth": 7, "min_child_weight": 5.42188920449609, "nrounds": 4618, "nthread": 1, "subsample": 0.252367706247605}}}], "metrics": 0.790107, "context": "openml-blood-transfusion-service-center-145836", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-climate-model-simulation-crashes-145839-651", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.474672801194148, "booster": "gblinear", "eta": 0.126690437639759, "lambda": 2.99506382375111, "nrounds": 1359, "nthread": 1, "subsample": 0.297252262546681}}}], "metrics": 0.916667, "context": "openml-climate-model-simulation-crashes-145839", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-climate-model-simulation-crashes-145839-8397", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0968682045906109, "booster": "gblinear", "eta": 0.0814268851504991, "lambda": 1.61873609597609, "nrounds": 758, "nthread": 1, "subsample": 0.967275154660456}}}], "metrics": 0.916667, "context": "openml-climate-model-simulation-crashes-145839", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-climate-model-simulation-crashes-145839-3720", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 2.51798386111923, "booster": "gbtree", "colsample_bylevel": 0.220364824868739, "colsample_bytree": 0.608764644246548, "eta": 0.194814232607942, "lambda": 0.00518787535677869, "max_depth": 5, "min_child_weight": 2.13144663823388, "nrounds": 3387, "nthread": 1, "subsample": 0.131521569914185}}}], "metrics": 0.916667, "context": "openml-climate-model-simulation-crashes-145839", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-climate-model-simulation-crashes-145839-3387", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.910396753452046, "booster": "gblinear", "eta": 0.209624527811461, "lambda": 1.62655926402033, "nrounds": 2961, "nthread": 1, "subsample": 0.862156620481983}}}], "metrics": 0.916667, "context": "openml-climate-model-simulation-crashes-145839", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-climate-model-simulation-crashes-145839-8879", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 153.679635493144, "booster": "gblinear", "eta": 0.00113436713950372, "lambda": 0.371485054302137, "nrounds": 4551, "nthread": 1, "subsample": 0.677628532866947}}}], "metrics": 0.914815, "context": "openml-climate-model-simulation-crashes-145839", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-ilpd-145848-7365", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.361937220554819, "booster": "gblinear", "eta": 0.661681662269133, "lambda": 1.46582568234347, "nrounds": 508, "nthread": 1, "subsample": 0.920181785407476}}}], "metrics": 0.73928, "context": "openml-ilpd-145848", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-ilpd-145848-2864", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.157191672316545, "booster": "gblinear", "eta": 0.699848735634893, "lambda": 3.03189289120141, "nrounds": 3335, "nthread": 1, "subsample": 0.89913081433624}}}], "metrics": 0.737564, "context": "openml-ilpd-145848", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-ilpd-145848-7504", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.108640343293849, "booster": "gblinear", "eta": 0.373498049258157, "lambda": 2.75715237687709, "nrounds": 3280, "nthread": 1, "subsample": 0.916208305442706}}}], "metrics": 0.737564, "context": "openml-ilpd-145848", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-ilpd-145848-2254", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.017885004348783, "booster": "gblinear", "eta": 0.953295608843049, "lambda": 2.46202814225477, "nrounds": 1492, "nthread": 1, "subsample": 0.432306332024746}}}], "metrics": 0.737564, "context": "openml-ilpd-145848", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-ilpd-145848-071", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.013107571874747401, "booster": "gblinear", "eta": 0.390217483434488, "lambda": 2.52112214836398, "nrounds": 4388, "nthread": 1, "subsample": 0.32931669647805395}}}], "metrics": 0.737564, "context": "openml-ilpd-145848", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-qsar-biodeg-9957-8271", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 1.96690411649404, "booster": "gbtree", "colsample_bylevel": 0.374777290737256, "colsample_bytree": 0.931264840764925, "eta": 0.0709121870427343, "lambda": 11.3295678978127, "max_depth": 7, "min_child_weight": 1.81194034998174, "nrounds": 1094, "nthread": 1, "subsample": 0.971111965808086}}}], "metrics": 0.88436, "context": "openml-qsar-biodeg-9957", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-qsar-biodeg-9957-4581", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0382525955604763, "booster": "gbtree", "colsample_bylevel": 0.0702219686936587, "colsample_bytree": 0.509465745417401, "eta": 0.0189265622633585, "lambda": 0.0105673531385219, "max_depth": 9, "min_child_weight": 3.08565990746942, "nrounds": 3793, "nthread": 1, "subsample": 0.793333495617844}}}], "metrics": 0.883412, "context": "openml-qsar-biodeg-9957", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-qsar-biodeg-9957-763", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.07527714002296, "booster": "gbtree", "colsample_bylevel": 0.698838407639414, "colsample_bytree": 0.440582623705268, "eta": 0.00999133732219018, "lambda": 0.0033634591467297803, "max_depth": 2, "min_child_weight": 2.09943116501897, "nrounds": 4116, "nthread": 1, "subsample": 0.870739296847023}}}], "metrics": 0.882464, "context": "openml-qsar-biodeg-9957", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-qsar-biodeg-9957-2748", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00134521672854338, "booster": "gbtree", "colsample_bylevel": 0.553519278299063, "colsample_bytree": 0.474821259267628, "eta": 0.0103941699379839, "lambda": 4.62814126651693, "max_depth": 9, "min_child_weight": 4.59342504017149, "nrounds": 3210, "nthread": 1, "subsample": 0.869980920059606}}}], "metrics": 0.882464, "context": "openml-qsar-biodeg-9957", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-qsar-biodeg-9957-7503", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00180188422175304, "booster": "gbtree", "colsample_bylevel": 0.873584639746696, "colsample_bytree": 0.914799886988476, "eta": 0.0323175448617431, "lambda": 4.74284396626963, "max_depth": 11, "min_child_weight": 1.90104993234551, "nrounds": 1115, "nthread": 1, "subsample": 0.745809084689245}}}], "metrics": 0.882464, "context": "openml-qsar-biodeg-9957", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-climate-model-simulation-crashes-9980-9351", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00191732109450003, "booster": "gbtree", "colsample_bylevel": 0.802794524468482, "colsample_bytree": 0.993397521553561, "eta": 0.111925051043034, "lambda": 0.0892244060390198, "max_depth": 3, "min_child_weight": 1.93310550772514, "nrounds": 49, "nthread": 1, "subsample": 0.9036939333193}}}], "metrics": 0.918519, "context": "openml-climate-model-simulation-crashes-9980", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-climate-model-simulation-crashes-9980-1943", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.97707718212998, "booster": "gblinear", "eta": 0.143282008486918, "lambda": 1.56876410903952, "nrounds": 2092, "nthread": 1, "subsample": 0.35229496108368}}}], "metrics": 0.916667, "context": "openml-climate-model-simulation-crashes-9980", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-climate-model-simulation-crashes-9980-1392", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 1.02776172321772, "booster": "gblinear", "eta": 0.0351647182915129, "lambda": 1.49425097020648, "nrounds": 3256, "nthread": 1, "subsample": 0.107848988263868}}}], "metrics": 0.916667, "context": "openml-climate-model-simulation-crashes-9980", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-climate-model-simulation-crashes-9980-7926", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00700212274038561, "booster": "gbtree", "colsample_bylevel": 0.794193190988153, "colsample_bytree": 0.713823797414079, "eta": 0.0014307383788284, "lambda": 0.0196747401693523, "max_depth": 3, "min_child_weight": 2.07369001903316, "nrounds": 4574, "nthread": 1, "subsample": 0.997266723401845}}}], "metrics": 0.916667, "context": "openml-climate-model-simulation-crashes-9980", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-climate-model-simulation-crashes-9980-6829", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00900527296074188, "booster": "gblinear", "eta": 0.0188419279489595, "lambda": 1.75926836649599, "nrounds": 3313, "nthread": 1, "subsample": 0.751933288713917}}}], "metrics": 0.916667, "context": "openml-climate-model-simulation-crashes-9980", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-mozilla4-3899-8300", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.008818205118790872, "booster": "gbtree", "colsample_bylevel": 0.634817532496527, "colsample_bytree": 0.488030132139102, "eta": 0.0585413579825676, "lambda": 0.244826068523886, "max_depth": 9, "min_child_weight": 2.00385864124052, "nrounds": 1657, "nthread": 1, "subsample": 0.981829958199523}}}], "metrics": 0.959537, "context": "openml-mozilla4-3899", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-mozilla4-3899-2148", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0508486439509948, "booster": "gbtree", "colsample_bylevel": 0.722497874870896, "colsample_bytree": 0.527683819178492, "eta": 0.113251957606924, "lambda": 0.892315527238208, "max_depth": 8, "min_child_weight": 1.08848919410605, "nrounds": 2057, "nthread": 1, "subsample": 0.712140010623261}}}], "metrics": 0.959087, "context": "openml-mozilla4-3899", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-mozilla4-3899-9984", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00840223243143122, "booster": "gbtree", "colsample_bylevel": 0.861097703920677, "colsample_bytree": 0.468882355373353, "eta": 0.0497533374773709, "lambda": 0.057725830790086, "max_depth": 14, "min_child_weight": 1.69935638751557, "nrounds": 1956, "nthread": 1, "subsample": 0.836356778233312}}}], "metrics": 0.959087, "context": "openml-mozilla4-3899", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-mozilla4-3899-9563", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00842223143109602, "booster": "gbtree", "colsample_bylevel": 0.670448518823832, "colsample_bytree": 0.746788254706189, "eta": 0.189733945976203, "lambda": 0.110544089478836, "max_depth": 10, "min_child_weight": 1.06477625342859, "nrounds": 3369, "nthread": 1, "subsample": 0.67870479375124}}}], "metrics": 0.958958, "context": "openml-mozilla4-3899", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-mozilla4-3899-8842", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.112091320314148, "booster": "gbtree", "colsample_bylevel": 0.926442203810439, "colsample_bytree": 0.527708791662008, "eta": 0.026354075788479, "lambda": 0.105959737293836, "max_depth": 14, "min_child_weight": 1.81575952446805, "nrounds": 3579, "nthread": 1, "subsample": 0.989594138157554}}}], "metrics": 0.958894, "context": "openml-mozilla4-3899", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-pc3-3903-2470", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.117444660224444, "booster": "gbtree", "colsample_bylevel": 0.910688609350473, "colsample_bytree": 0.404768952168524, "eta": 0.00126655874307371, "lambda": 0.1568483945546, "max_depth": 13, "min_child_weight": 1.90914680495618, "nrounds": 722, "nthread": 1, "subsample": 0.862098097824492}}}], "metrics": 0.904031, "context": "openml-pc3-3903", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-pc3-3903-2542", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 3.38017872609519, "booster": "gblinear", "eta": 0.0788766301110005, "lambda": 0.00393238585869779, "nrounds": 3895, "nthread": 1, "subsample": 0.489594397833571}}}], "metrics": 0.903391, "context": "openml-pc3-3903", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-pc3-3903-1975", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 3.96288328933331, "booster": "gblinear", "eta": 0.107809295327622, "lambda": 0.00206715669751818, "nrounds": 3612, "nthread": 1, "subsample": 0.250755558442324}}}], "metrics": 0.903391, "context": "openml-pc3-3903", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-pc3-3903-11685", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 22.9106523742437, "booster": "gblinear", "eta": 0.741776843094473, "lambda": 0.253567098183232, "nrounds": 261, "nthread": 1, "subsample": 0.636902821692638}}}], "metrics": 0.903391, "context": "openml-pc3-3903", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-pc3-3903-5180", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 2.613855594062, "booster": "gblinear", "eta": 0.101377337434745, "lambda": 0.0130604622444687, "nrounds": 3108, "nthread": 1, "subsample": 0.557672393508255}}}], "metrics": 0.903391, "context": "openml-pc3-3903", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-diabetes-37-9636", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.014752014997515602, "booster": "gblinear", "eta": 0.039015632299907, "lambda": 0.00492070325825203, "nrounds": 3854, "nthread": 1, "subsample": 0.28470437664073}}}], "metrics": 0.779948, "context": "openml-diabetes-37", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-diabetes-37-13257", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.010591010211552, "booster": "gblinear", "eta": 0.183840825584193, "lambda": 0.00141275943052667, "nrounds": 798, "nthread": 1, "subsample": 0.833319364697672}}}], "metrics": 0.779948, "context": "openml-diabetes-37", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-diabetes-37-1852", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.055402799262906, "booster": "gblinear", "eta": 0.0537913129714222, "lambda": 0.0617022127915547, "nrounds": 2924, "nthread": 1, "subsample": 0.914819939574227}}}], "metrics": 0.779948, "context": "openml-diabetes-37", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-diabetes-37-7506", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0228516250066498, "booster": "gblinear", "eta": 0.0420495903652948, "lambda": 0.0336164430761704, "nrounds": 3729, "nthread": 1, "subsample": 0.601118712034076}}}], "metrics": 0.779948, "context": "openml-diabetes-37", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-diabetes-37-6303", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0175993128658693, "booster": "gblinear", "eta": 0.05905711568109, "lambda": 0.0447092221331647, "nrounds": 2887, "nthread": 1, "subsample": 0.740513476845808}}}], "metrics": 0.779948, "context": "openml-diabetes-37", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-scene-3485-2707", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 34.2935751264937, "booster": "gblinear", "eta": 0.0780533143341359, "lambda": 0.0301196995717746, "nrounds": 463, "nthread": 1, "subsample": 0.512398350075819}}}], "metrics": 0.989198, "context": "openml-scene-3485", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-scene-3485-13807", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 4.34961853332867, "booster": "gblinear", "eta": 0.00833619501535015, "lambda": 0.0266590766377971, "nrounds": 3859, "nthread": 1, "subsample": 0.912199450284243}}}], "metrics": 0.989198, "context": "openml-scene-3485", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-scene-3485-13772", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 31.295016991294, "booster": "gblinear", "eta": 0.00239166005552926, "lambda": 0.00439140943151453, "nrounds": 4421, "nthread": 1, "subsample": 0.716609161766246}}}], "metrics": 0.989198, "context": "openml-scene-3485", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-scene-3485-10429", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 13.4424088198838, "booster": "gblinear", "eta": 0.655055912267919, "lambda": 6.81759611858454, "nrounds": 596, "nthread": 1, "subsample": 0.554835170623846}}}], "metrics": 0.989198, "context": "openml-scene-3485", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-scene-3485-8515", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 2.9838568102871, "booster": "gblinear", "eta": 0.0300060340272891, "lambda": 0.00228803276911392, "nrounds": 697, "nthread": 1, "subsample": 0.681556168640964}}}], "metrics": 0.989198, "context": "openml-scene-3485", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-tic-tac-toe-49-1423", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.145562059684604, "booster": "gbtree", "colsample_bylevel": 0.688694326439872, "colsample_bytree": 0.662008504848927, "eta": 0.0411389104440696, "lambda": 0.261930662136229, "max_depth": 3, "min_child_weight": 1.64558757516119, "nrounds": 3667, "nthread": 1, "subsample": 0.792567376676016}}}], "metrics": 0.998956, "context": "openml-tic-tac-toe-49", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-tic-tac-toe-49-5602", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.164254834885599, "booster": "gbtree", "colsample_bylevel": 0.790555448038504, "colsample_bytree": 0.163274479098618, "eta": 0.570676702620208, "lambda": 0.177267323391713, "max_depth": 2, "min_child_weight": 1.28486208035819, "nrounds": 1722, "nthread": 1, "subsample": 0.968202331871726}}}], "metrics": 0.997912, "context": "openml-tic-tac-toe-49", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-tic-tac-toe-49-16677", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0569392945907483, "booster": "gbtree", "colsample_bylevel": 0.424138485221192, "colsample_bytree": 0.96744817472063, "eta": 0.348502729728946, "lambda": 35.8193106375039, "max_depth": 4, "min_child_weight": 2.1835550041368, "nrounds": 4975, "nthread": 1, "subsample": 0.908655140735209}}}], "metrics": 0.997912, "context": "openml-tic-tac-toe-49", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-tic-tac-toe-49-2546", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00607206422701305, "booster": "gbtree", "colsample_bylevel": 0.363603033125401, "colsample_bytree": 0.851347974734381, "eta": 0.0586192830683408, "lambda": 0.00125272549525717, "max_depth": 3, "min_child_weight": 1.27802168702264, "nrounds": 4175, "nthread": 1, "subsample": 0.796665074140765}}}], "metrics": 0.997912, "context": "openml-tic-tac-toe-49", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-tic-tac-toe-49-14112", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0522829415078111, "booster": "gbtree", "colsample_bylevel": 0.268697541672736, "colsample_bytree": 0.8472512178123, "eta": 0.834588901793776, "lambda": 17.7369498303216, "max_depth": 3, "min_child_weight": 1.32144956684256, "nrounds": 4241, "nthread": 1, "subsample": 0.885476274555549}}}], "metrics": 0.996868, "context": "openml-tic-tac-toe-49", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-kc2-3913-9569", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.127562866489977, "booster": "gbtree", "colsample_bylevel": 0.441857469966635, "colsample_bytree": 0.83045409899205, "eta": 0.10635145956689, "lambda": 524.468435254559, "max_depth": 15, "min_child_weight": 3.60327398316517, "nrounds": 2363, "nthread": 1, "subsample": 0.756464469293132}}}], "metrics": 0.862069, "context": "openml-kc2-3913", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-kc2-3913-4584", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00436751083482846, "booster": "gbtree", "colsample_bylevel": 0.905115274712443, "colsample_bytree": 0.267526305979118, "eta": 0.349925060514239, "lambda": 116.728959000485, "max_depth": 3, "min_child_weight": 3.76677768835895, "nrounds": 272, "nthread": 1, "subsample": 0.541699438379146}}}], "metrics": 0.858238, "context": "openml-kc2-3913", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-kc2-3913-13902", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 4.07495230083064, "booster": "gbtree", "colsample_bylevel": 0.896558605367318, "colsample_bytree": 0.523979570483789, "eta": 0.0799843655114171, "lambda": 164.212034631434, "max_depth": 3, "min_child_weight": 1.99390263024787, "nrounds": 2828, "nthread": 1, "subsample": 0.748502200026996}}}], "metrics": 0.858238, "context": "openml-kc2-3913", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-kc2-3913-6644", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0988581143499305, "booster": "gbtree", "colsample_bylevel": 0.302735792472959, "colsample_bytree": 0.892622163984925, "eta": 0.00291395603186286, "lambda": 0.173369867799283, "max_depth": 8, "min_child_weight": 7.37565936188167, "nrounds": 2075, "nthread": 1, "subsample": 0.843561151414178}}}], "metrics": 0.858238, "context": "openml-kc2-3913", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-kc2-3913-2849", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0211255643422772, "booster": "gbtree", "colsample_bylevel": 0.479562838794664, "colsample_bytree": 0.675262282369658, "eta": 0.0184357241667017, "lambda": 26.9202673865662, "max_depth": 5, "min_child_weight": 1.67128219086379, "nrounds": 914, "nthread": 1, "subsample": 0.69381614162121}}}], "metrics": 0.858238, "context": "openml-kc2-3913", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-spambase-145979-11711", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0664140267472706, "booster": "gbtree", "colsample_bylevel": 0.0947320787236094, "colsample_bytree": 0.81356769031845, "eta": 0.012825661220596, "lambda": 0.00946493817350279, "max_depth": 15, "min_child_weight": 1.73917015286566, "nrounds": 1938, "nthread": 1, "subsample": 0.711648200778291}}}], "metrics": 0.958053, "context": "openml-spambase-145979", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-spambase-145979-10489", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0635242592610629, "booster": "gbtree", "colsample_bylevel": 0.42436146712862, "colsample_bytree": 0.528419391950592, "eta": 0.0165308903061177, "lambda": 0.203891772112747, "max_depth": 6, "min_child_weight": 1.26956361935989, "nrounds": 930, "nthread": 1, "subsample": 0.885716110770591}}}], "metrics": 0.956966, "context": "openml-spambase-145979", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-spambase-145979-8728", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00600112499712684, "booster": "gbtree", "colsample_bylevel": 0.65444625983946, "colsample_bytree": 0.330395376542583, "eta": 0.0318793803383626, "lambda": 0.0682601960722529, "max_depth": 9, "min_child_weight": 3.02542314230485, "nrounds": 431, "nthread": 1, "subsample": 0.809528881311417}}}], "metrics": 0.956966, "context": "openml-spambase-145979", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-spambase-145979-4742", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.165042204379407, "booster": "gbtree", "colsample_bylevel": 0.728628387441859, "colsample_bytree": 0.78205186361447, "eta": 0.121270826269019, "lambda": 16.7517817407704, "max_depth": 13, "min_child_weight": 1.26670824010202, "nrounds": 755, "nthread": 1, "subsample": 0.714609787636437}}}], "metrics": 0.956966, "context": "openml-spambase-145979", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-spambase-145979-16889", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 1.5080153666309, "booster": "gbtree", "colsample_bylevel": 0.766282454598695, "colsample_bytree": 0.794181034900248, "eta": 0.0594244818021888, "lambda": 0.00473366162163635, "max_depth": 14, "min_child_weight": 1.18177777042649, "nrounds": 2942, "nthread": 1, "subsample": 0.960680032894015}}}], "metrics": 0.956749, "context": "openml-spambase-145979", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-credit-g-145972-8333", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.17196047796733, "booster": "gbtree", "colsample_bylevel": 0.0286977828945965, "colsample_bytree": 0.597394386306405, "eta": 0.00881896742500636, "lambda": 0.30632625529001, "max_depth": 6, "min_child_weight": 1.09526600073188, "nrounds": 3936, "nthread": 1, "subsample": 0.719656586647034}}}], "metrics": 0.78, "context": "openml-credit-g-145972", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-credit-g-145972-6870", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.012051517601174101, "booster": "gbtree", "colsample_bylevel": 0.326749992091209, "colsample_bytree": 0.442777701187879, "eta": 0.00455650398244884, "lambda": 0.101445338350606, "max_depth": 10, "min_child_weight": 1.36413483447991, "nrounds": 1370, "nthread": 1, "subsample": 0.338639407930896}}}], "metrics": 0.776, "context": "openml-credit-g-145972", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-credit-g-145972-6952", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00631482123497608, "booster": "gbtree", "colsample_bylevel": 0.130979731911793, "colsample_bytree": 0.635029386496171, "eta": 0.00546158098550434, "lambda": 0.00445874861331597, "max_depth": 11, "min_child_weight": 1.27005577100403, "nrounds": 1689, "nthread": 1, "subsample": 0.56480878170114}}}], "metrics": 0.776, "context": "openml-credit-g-145972", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-credit-g-145972-021", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0650095483577214, "booster": "gbtree", "colsample_bylevel": 0.351769125787541, "colsample_bytree": 0.213388410396874, "eta": 0.00162320196693017, "lambda": 0.406623015587938, "max_depth": 9, "min_child_weight": 1.12257237368765, "nrounds": 4476, "nthread": 1, "subsample": 0.42110809974838}}}], "metrics": 0.775, "context": "openml-credit-g-145972", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-credit-g-145972-3437", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.067951021640836, "booster": "gbtree", "colsample_bylevel": 0.197363541927189, "colsample_bytree": 0.753832969116047, "eta": 0.0126548735180137, "lambda": 1.56757506620078, "max_depth": 9, "min_child_weight": 1.51592093737875, "nrounds": 409, "nthread": 1, "subsample": 0.604120383039117}}}], "metrics": 0.775, "context": "openml-credit-g-145972", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-wdbc-145878-16330", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.3390301814251, "booster": "gbtree", "colsample_bylevel": 0.755641168914735, "colsample_bytree": 0.649851178983226, "eta": 0.0714662931733613, "lambda": 0.101325360489594, "max_depth": 9, "min_child_weight": 1.33065847678741, "nrounds": 1937, "nthread": 1, "subsample": 0.148947089584544}}}], "metrics": 0.97891, "context": "openml-wdbc-145878", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-wdbc-145878-750", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0282059196961216, "booster": "gbtree", "colsample_bylevel": 0.159897731384262, "colsample_bytree": 0.542690251488239, "eta": 0.0235386463765944, "lambda": 0.0449305321988987, "max_depth": 4, "min_child_weight": 3.16894191458055, "nrounds": 2735, "nthread": 1, "subsample": 0.347408318659291}}}], "metrics": 0.977153, "context": "openml-wdbc-145878", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-wdbc-145878-14850", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0453116023229305, "booster": "gbtree", "colsample_bylevel": 0.291585484752432, "colsample_bytree": 0.404128527967259, "eta": 0.0513654227430265, "lambda": 0.842784154135056, "max_depth": 6, "min_child_weight": 1.04771851283783, "nrounds": 2879, "nthread": 1, "subsample": 0.451593037578277}}}], "metrics": 0.977153, "context": "openml-wdbc-145878", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-wdbc-145878-8795", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.025519746810484, "booster": "gbtree", "colsample_bylevel": 0.484238671138883, "colsample_bytree": 0.809075072407722, "eta": 0.298393668992724, "lambda": 1.74714941415874, "max_depth": 12, "min_child_weight": 1.20629048419795, "nrounds": 3977, "nthread": 1, "subsample": 0.853514637961052}}}], "metrics": 0.977153, "context": "openml-wdbc-145878", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-wdbc-145878-17634", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 2.87883527424599, "booster": "gbtree", "colsample_bylevel": 0.487471588887274, "colsample_bytree": 0.44645164324902, "eta": 0.636016466690406, "lambda": 18.9014811428271, "max_depth": 10, "min_child_weight": 4.08938408407873, "nrounds": 4706, "nthread": 1, "subsample": 0.660331829218194}}}], "metrics": 0.977153, "context": "openml-wdbc-145878", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-kr-vs-kp-145953-13208", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.545565385064018, "booster": "gbtree", "colsample_bylevel": 0.758854982908815, "colsample_bytree": 0.395643947413191, "eta": 0.0470031210913751, "lambda": 0.0464428577294426, "max_depth": 7, "min_child_weight": 1.19423552698308, "nrounds": 2947, "nthread": 1, "subsample": 0.985887580737472}}}], "metrics": 0.994681, "context": "openml-kr-vs-kp-145953", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-kr-vs-kp-145953-6118", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.190897266614894, "booster": "gbtree", "colsample_bylevel": 0.929048474412411, "colsample_bytree": 0.729120539268479, "eta": 0.136878595455737, "lambda": 1.85495942535575, "max_depth": 6, "min_child_weight": 1.05694197756502, "nrounds": 1201, "nthread": 1, "subsample": 0.894358369265683}}}], "metrics": 0.994681, "context": "openml-kr-vs-kp-145953", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-kr-vs-kp-145953-17334", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.282308395072967, "booster": "gbtree", "colsample_bylevel": 0.913624949753284, "colsample_bytree": 0.851761152269319, "eta": 0.0269153163633531, "lambda": 0.00778291121203419, "max_depth": 13, "min_child_weight": 1.01311842837783, "nrounds": 1694, "nthread": 1, "subsample": 0.859510561777279}}}], "metrics": 0.994368, "context": "openml-kr-vs-kp-145953", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-kr-vs-kp-145953-16504", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.169537434273015, "booster": "gbtree", "colsample_bylevel": 0.734640906332061, "colsample_bytree": 0.578242653748021, "eta": 0.287154110269381, "lambda": 8.21476418980956, "max_depth": 8, "min_child_weight": 1.06345232833475, "nrounds": 4093, "nthread": 1, "subsample": 0.980524078011513}}}], "metrics": 0.994368, "context": "openml-kr-vs-kp-145953", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-kr-vs-kp-145953-13628", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00665544298233067, "booster": "gbtree", "colsample_bylevel": 0.751269367290661, "colsample_bytree": 0.332953241188079, "eta": 0.0191688301618421, "lambda": 0.00138776830699029, "max_depth": 8, "min_child_weight": 1.05450984626708, "nrounds": 2175, "nthread": 1, "subsample": 0.890659088175744}}}], "metrics": 0.994055, "context": "openml-kr-vs-kp-145953", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-hill-valley-145847-9056", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 983.086029604001, "booster": "gblinear", "eta": 0.199328952483827, "lambda": 0.026688340224914, "nrounds": 4873, "nthread": 1, "subsample": 0.88625554072205}}}], "metrics": 0.764851, "context": "openml-hill-valley-145847", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-hill-valley-145847-810", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 291.042677756445, "booster": "gblinear", "eta": 0.187309017772191, "lambda": 0.945841421633694, "nrounds": 4983, "nthread": 1, "subsample": 0.138625898375176}}}], "metrics": 0.764851, "context": "openml-hill-valley-145847", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-hill-valley-145847-8660", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 2.63206288099577, "booster": "gblinear", "eta": 0.165602774829804, "lambda": 1.34810179399312, "nrounds": 4979, "nthread": 1, "subsample": 0.511609225533903}}}], "metrics": 0.763201, "context": "openml-hill-valley-145847", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-hill-valley-145847-9948", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 1000.0, "booster": "gblinear", "eta": 0.265123357260913, "lambda": 0.0060323420421381, "nrounds": 4596, "nthread": 1, "subsample": 0.462256892723963}}}], "metrics": 0.763201, "context": "openml-hill-valley-145847", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-hill-valley-145847-11908", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 24.187583110604, "booster": "gblinear", "eta": 0.230164229367656, "lambda": 0.615242288707238, "nrounds": 4998, "nthread": 1, "subsample": 0.351665704371408}}}], "metrics": 0.763201, "context": "openml-hill-valley-145847", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-eeg-eye-state-14951-18212", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00852228722160565, "booster": "gbtree", "colsample_bylevel": 0.557691948954016, "colsample_bytree": 0.95732907904312, "eta": 0.0589019207552629, "lambda": 2.0725168531843, "max_depth": 12, "min_child_weight": 2.28619475437707, "nrounds": 861, "nthread": 1, "subsample": 0.69203902517911}}}], "metrics": 0.956275, "context": "openml-eeg-eye-state-14951", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-eeg-eye-state-14951-17255", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.766000168846181, "booster": "gbtree", "colsample_bylevel": 0.483574294717982, "colsample_bytree": 0.875077947974205, "eta": 0.0588243818847307, "lambda": 0.0100556536063357, "max_depth": 13, "min_child_weight": 1.77840440633438, "nrounds": 2277, "nthread": 1, "subsample": 0.941560739092529}}}], "metrics": 0.955808, "context": "openml-eeg-eye-state-14951", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-eeg-eye-state-14951-17314", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00169779252323403, "booster": "gbtree", "colsample_bylevel": 0.914453723002225, "colsample_bytree": 0.673881717491895, "eta": 0.0630421111230286, "lambda": 0.00121754437451311, "max_depth": 13, "min_child_weight": 1.48624713878554, "nrounds": 3480, "nthread": 1, "subsample": 0.651354771107435}}}], "metrics": 0.955808, "context": "openml-eeg-eye-state-14951", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-eeg-eye-state-14951-18261", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00150742320245443, "booster": "gbtree", "colsample_bylevel": 0.75173207721673, "colsample_bytree": 0.976789291482419, "eta": 0.0262883730964857, "lambda": 23.5036669237731, "max_depth": 14, "min_child_weight": 1.27159355686978, "nrounds": 4675, "nthread": 1, "subsample": 0.957812187145464}}}], "metrics": 0.955541, "context": "openml-eeg-eye-state-14951", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-eeg-eye-state-14951-18490", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0126069352467588, "booster": "gbtree", "colsample_bylevel": 0.522402209695429, "colsample_bytree": 0.85081222676672, "eta": 0.0204248477900187, "lambda": 3.66846350152271, "max_depth": 11, "min_child_weight": 1.93816598940542, "nrounds": 4273, "nthread": 1, "subsample": 0.710113795334473}}}], "metrics": 0.95494, "context": "openml-eeg-eye-state-14951", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-phoneme-9952-14133", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00270883412996579, "booster": "gbtree", "colsample_bylevel": 0.663934695534408, "colsample_bytree": 0.88820463209413, "eta": 0.0283788166484735, "lambda": 0.00684532131798336, "max_depth": 15, "min_child_weight": 1.23321506126951, "nrounds": 546, "nthread": 1, "subsample": 0.781890748557635}}}], "metrics": 0.911177, "context": "openml-phoneme-9952", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-phoneme-9952-14193", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00141111695226835, "booster": "gbtree", "colsample_bylevel": 0.83969231066294, "colsample_bytree": 0.912956825224683, "eta": 0.0291191295482122, "lambda": 3.55000522862151, "max_depth": 12, "min_child_weight": 1.62754912806007, "nrounds": 2166, "nthread": 1, "subsample": 0.696483841980807}}}], "metrics": 0.909697, "context": "openml-phoneme-9952", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-phoneme-9952-15186", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0509926415517199, "booster": "gbtree", "colsample_bylevel": 0.741316969972104, "colsample_bytree": 0.857243960956112, "eta": 0.00278264051644568, "lambda": 0.00557360082327785, "max_depth": 14, "min_child_weight": 1.18692382096565, "nrounds": 2261, "nthread": 1, "subsample": 0.969941704184748}}}], "metrics": 0.909511, "context": "openml-phoneme-9952", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-phoneme-9952-2949", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.759249440387334, "booster": "gbtree", "colsample_bylevel": 0.896120588295162, "colsample_bytree": 0.815690696937963, "eta": 0.0399672349967479, "lambda": 0.00630635406954694, "max_depth": 13, "min_child_weight": 2.14260436218901, "nrounds": 1508, "nthread": 1, "subsample": 0.710676994477399}}}], "metrics": 0.907846, "context": "openml-phoneme-9952", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-phoneme-9952-18108", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 1.08376126774306, "booster": "gbtree", "colsample_bylevel": 0.348942972254008, "colsample_bytree": 0.996077249525115, "eta": 0.0207982486311691, "lambda": 0.0352319386911324, "max_depth": 14, "min_child_weight": 1.65545940186601, "nrounds": 919, "nthread": 1, "subsample": 0.79296912276186}}}], "metrics": 0.907291, "context": "openml-phoneme-9952", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-kr-vs-kp-3-5196", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.989308022794797, "booster": "gbtree", "colsample_bylevel": 0.640977100236341, "colsample_bytree": 0.391270995605737, "eta": 0.067618684835672, "lambda": 0.00797666886061232, "max_depth": 13, "min_child_weight": 1.05189878433137, "nrounds": 3511, "nthread": 1, "subsample": 0.917774253245443}}}], "metrics": 0.994368, "context": "openml-kr-vs-kp-3", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-kr-vs-kp-3-9028", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 1.10577394278002, "booster": "gbtree", "colsample_bylevel": 0.793843200895935, "colsample_bytree": 0.432235272368416, "eta": 0.496917471696134, "lambda": 0.0263283784695002, "max_depth": 5, "min_child_weight": 1.02140181240612, "nrounds": 1882, "nthread": 1, "subsample": 0.866927376389503}}}], "metrics": 0.994368, "context": "openml-kr-vs-kp-3", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-kr-vs-kp-3-13243", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00173477460746951, "booster": "gbtree", "colsample_bylevel": 0.188479451462626, "colsample_bytree": 0.769462911877781, "eta": 0.0257973734111776, "lambda": 0.889827313439899, "max_depth": 12, "min_child_weight": 1.14902305297388, "nrounds": 1463, "nthread": 1, "subsample": 0.754612824530341}}}], "metrics": 0.994055, "context": "openml-kr-vs-kp-3", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-kr-vs-kp-3-16255", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0119043734638462, "booster": "gbtree", "colsample_bylevel": 0.321129625895992, "colsample_bytree": 0.602631316520274, "eta": 0.32207825793555, "lambda": 2.2527423923254, "max_depth": 11, "min_child_weight": 1.43404221327782, "nrounds": 1801, "nthread": 1, "subsample": 0.73697985841427}}}], "metrics": 0.994055, "context": "openml-kr-vs-kp-3", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-kr-vs-kp-3-6579", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.087192829510308, "booster": "gbtree", "colsample_bylevel": 0.573098907247186, "colsample_bytree": 0.337805637856945, "eta": 0.0134037751810307, "lambda": 0.0221129652569497, "max_depth": 7, "min_child_weight": 1.07842241556501, "nrounds": 4481, "nthread": 1, "subsample": 0.715916687482968}}}], "metrics": 0.994055, "context": "openml-kr-vs-kp-3", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-ada-agnostic-3896-12884", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00109692135913209, "booster": "gbtree", "colsample_bylevel": 0.447942425962538, "colsample_bytree": 0.741632041987032, "eta": 0.00254535629041027, "lambda": 0.112608797118056, "max_depth": 6, "min_child_weight": 1.55116194674847, "nrounds": 2117, "nthread": 1, "subsample": 0.875988264637999}}}], "metrics": 0.861464, "context": "openml-ada-agnostic-3896", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-ada-agnostic-3896-19435", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0011357491753385, "booster": "gbtree", "colsample_bylevel": 0.790667006047443, "colsample_bytree": 0.50572271947749, "eta": 0.00128809213199955, "lambda": 0.517934427593283, "max_depth": 5, "min_child_weight": 1.78935122950636, "nrounds": 4971, "nthread": 1, "subsample": 0.650063262321055}}}], "metrics": 0.85993, "context": "openml-ada-agnostic-3896", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-ada-agnostic-3896-6715", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 3.2244860316628, "booster": "gbtree", "colsample_bylevel": 0.679412602446973, "colsample_bytree": 0.510911135002971, "eta": 0.00462007348775782, "lambda": 1.16959027474438, "max_depth": 5, "min_child_weight": 2.2816408258264, "nrounds": 1870, "nthread": 1, "subsample": 0.953632999141701}}}], "metrics": 0.858834, "context": "openml-ada-agnostic-3896", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-ada-agnostic-3896-6153", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0137519198786118, "booster": "gbtree", "colsample_bylevel": 0.483234825544059, "colsample_bytree": 0.989335847785696, "eta": 0.005814771775191059, "lambda": 0.01594151996424, "max_depth": 6, "min_child_weight": 1.26105722453602, "nrounds": 369, "nthread": 1, "subsample": 0.90162495020777}}}], "metrics": 0.858834, "context": "openml-ada-agnostic-3896", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-ada-agnostic-3896-8485", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.871468822422695, "booster": "gbtree", "colsample_bylevel": 0.622887794161215, "colsample_bytree": 0.67939186305739, "eta": 0.00280091674827255, "lambda": 3.45684134043767, "max_depth": 5, "min_child_weight": 2.97408723497696, "nrounds": 2579, "nthread": 1, "subsample": 0.770741392835043}}}], "metrics": 0.858615, "context": "openml-ada-agnostic-3896", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-steel-plates-fault-145872-718", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 1.97044776704345, "booster": "gbtree", "colsample_bylevel": 0.911736891372129, "colsample_bytree": 0.998921850929037, "eta": 0.0302296142669766, "lambda": 113.402081753682, "max_depth": 7, "min_child_weight": 1.32491088730069, "nrounds": 4802, "nthread": 1, "subsample": 0.912748359539546}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-steel-plates-fault-145872-7819", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 4.16671789327095, "booster": "gbtree", "colsample_bylevel": 0.902978142024949, "colsample_bytree": 0.625613016774878, "eta": 0.446608657788216, "lambda": 0.00103885132408805, "max_depth": 1, "min_child_weight": 3.26653381606188, "nrounds": 4891, "nthread": 1, "subsample": 0.786374134686776}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-steel-plates-fault-145872-16209", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.79174684355414, "booster": "gbtree", "colsample_bylevel": 0.661786352749914, "colsample_bytree": 0.872768432600424, "eta": 0.00138950194252374, "lambda": 0.00650264729972297, "max_depth": 15, "min_child_weight": 1.33250328951354, "nrounds": 4191, "nthread": 1, "subsample": 0.834650515485555}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-steel-plates-fault-145872-14153", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.682316910527941, "booster": "gbtree", "colsample_bylevel": 0.904022617032751, "colsample_bytree": 0.910587893798947, "eta": 0.0340035863453389, "lambda": 0.0158730918794764, "max_depth": 14, "min_child_weight": 2.4777685924458, "nrounds": 1760, "nthread": 1, "subsample": 0.842933886870742}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-steel-plates-fault-145872-9796", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.359853180871366, "booster": "gbtree", "colsample_bylevel": 0.919380911858752, "colsample_bytree": 0.952584780752659, "eta": 0.00532625187517145, "lambda": 0.0479414567652706, "max_depth": 11, "min_child_weight": 2.66343312235759, "nrounds": 546, "nthread": 1, "subsample": 0.905427287216298}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-banknote-authentication-10093-8752", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0190609107526474, "booster": "gbtree", "colsample_bylevel": 0.794970508664846, "colsample_bytree": 0.865085487719625, "eta": 0.177068367535244, "lambda": 0.999173397223635, "max_depth": 6, "min_child_weight": 1.05688668473365, "nrounds": 3298, "nthread": 1, "subsample": 0.452710574725643}}}], "metrics": 0.998542, "context": "openml-banknote-authentication-10093", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-banknote-authentication-10093-2655", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.213755087718173, "booster": "gbtree", "colsample_bylevel": 0.936974397627637, "colsample_bytree": 0.786537480540574, "eta": 0.977737400290701, "lambda": 368.967205405128, "max_depth": 12, "min_child_weight": 1.03725060110253, "nrounds": 4452, "nthread": 1, "subsample": 0.247465592087246}}}], "metrics": 0.998542, "context": "openml-banknote-authentication-10093", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-banknote-authentication-10093-20889", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0270453361993833, "booster": "gbtree", "colsample_bylevel": 0.853211362380534, "colsample_bytree": 0.934284980408847, "eta": 0.144960148541766, "lambda": 3.11246263857649, "max_depth": 2, "min_child_weight": 1.15818065613027, "nrounds": 3945, "nthread": 1, "subsample": 0.50695934840478}}}], "metrics": 0.998542, "context": "openml-banknote-authentication-10093", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-banknote-authentication-10093-693", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00592732089309534, "booster": "gbtree", "colsample_bylevel": 0.795953390188515, "colsample_bytree": 0.829666498117149, "eta": 0.0285624209219009, "lambda": 0.119010285762306, "max_depth": 2, "min_child_weight": 1.55028133091509, "nrounds": 2894, "nthread": 1, "subsample": 0.293436079681851}}}], "metrics": 0.998542, "context": "openml-banknote-authentication-10093", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-banknote-authentication-10093-10308", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0459264380045443, "booster": "gbtree", "colsample_bylevel": 0.499727340880781, "colsample_bytree": 0.936192221008241, "eta": 0.27998967715612, "lambda": 27.9739883328488, "max_depth": 10, "min_child_weight": 1.06532054976546, "nrounds": 4827, "nthread": 1, "subsample": 0.272413229057565}}}], "metrics": 0.998542, "context": "openml-banknote-authentication-10093", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-pc1-3918-4664", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.081097310748267, "booster": "gbtree", "colsample_bylevel": 0.732523558661342, "colsample_bytree": 0.917961107566953, "eta": 0.118249927060198, "lambda": 139.796471483366, "max_depth": 11, "min_child_weight": 1.01437711743232, "nrounds": 1376, "nthread": 1, "subsample": 0.539827667409554}}}], "metrics": 0.940487, "context": "openml-pc1-3918", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-pc1-3918-18113", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 1.33318213277933, "booster": "gbtree", "colsample_bylevel": 0.144908627728, "colsample_bytree": 0.824147892184556, "eta": 0.817675141605917, "lambda": 545.81858280976, "max_depth": 5, "min_child_weight": 2.20712983472486, "nrounds": 1853, "nthread": 1, "subsample": 0.837372303428128}}}], "metrics": 0.939585, "context": "openml-pc1-3918", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-pc1-3918-18007", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00329994535736909, "booster": "gbtree", "colsample_bylevel": 0.843487479956821, "colsample_bytree": 0.51510581956245, "eta": 0.0340961587374494, "lambda": 1.10295222856354, "max_depth": 1, "min_child_weight": 2.26042773412577, "nrounds": 1947, "nthread": 1, "subsample": 0.962512242747471}}}], "metrics": 0.939585, "context": "openml-pc1-3918", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-pc1-3918-7050", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 4.86501069554294, "booster": "gbtree", "colsample_bylevel": 0.654900128720328, "colsample_bytree": 0.976854744600132, "eta": 0.0657931329651737, "lambda": 0.871219113188109, "max_depth": 2, "min_child_weight": 1.48607495733879, "nrounds": 2618, "nthread": 1, "subsample": 0.781771006784402}}}], "metrics": 0.938683, "context": "openml-pc1-3918", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-pc1-3918-16549", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0502379704622644, "booster": "gbtree", "colsample_bylevel": 0.590910050552338, "colsample_bytree": 0.29945568763651, "eta": 0.00135143342699823, "lambda": 0.0364442784603879, "max_depth": 8, "min_child_weight": 3.55668975110674, "nrounds": 3362, "nthread": 1, "subsample": 0.981193662784062}}}], "metrics": 0.938683, "context": "openml-pc1-3918", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-wdbc-9946-2126", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00168330760198866, "booster": "gbtree", "colsample_bylevel": 0.0797803718596697, "colsample_bytree": 0.95108640496619, "eta": 0.0312060046716899, "lambda": 4.72944353809966, "max_depth": 14, "min_child_weight": 1.31416918755293, "nrounds": 3508, "nthread": 1, "subsample": 0.266869424888864}}}], "metrics": 0.977153, "context": "openml-wdbc-9946", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-wdbc-9946-7319", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.016468743578043, "booster": "gbtree", "colsample_bylevel": 0.890013886382803, "colsample_bytree": 0.391819888493046, "eta": 0.986263808174404, "lambda": 106.914012338179, "max_depth": 3, "min_child_weight": 1.01500388865468, "nrounds": 2862, "nthread": 1, "subsample": 0.359283793205395}}}], "metrics": 0.977153, "context": "openml-wdbc-9946", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-wdbc-9946-865", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0926770069276782, "booster": "gbtree", "colsample_bylevel": 0.27754671080038, "colsample_bytree": 0.645841691410169, "eta": 0.307966998716347, "lambda": 11.9248133623786, "max_depth": 6, "min_child_weight": 4.62849876439628, "nrounds": 1944, "nthread": 1, "subsample": 0.468842463521287}}}], "metrics": 0.977153, "context": "openml-wdbc-9946", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-wdbc-9946-5234", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.0585338323886804, "booster": "gbtree", "colsample_bylevel": 0.479595653479919, "colsample_bytree": 0.907085395650938, "eta": 0.199124933498236, "lambda": 1.11949131107352, "max_depth": 9, "min_child_weight": 1.51730318624036, "nrounds": 4759, "nthread": 1, "subsample": 0.589660533471033}}}], "metrics": 0.977153, "context": "openml-wdbc-9946", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-wdbc-9946-18310", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00181815917241954, "booster": "gbtree", "colsample_bylevel": 0.13886265270412, "colsample_bytree": 0.647026286227629, "eta": 0.349025394931416, "lambda": 4.15420181244914, "max_depth": 8, "min_child_weight": 1.11372604397951, "nrounds": 198, "nthread": 1, "subsample": 0.767356415721588}}}], "metrics": 0.977153, "context": "openml-wdbc-9946", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-diabetes-145976-3897", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.286945602019445, "booster": "gblinear", "eta": 0.143338929057099, "lambda": 0.0019250651535974, "nrounds": 1140, "nthread": 1, "subsample": 0.495793465455063}}}], "metrics": 0.779948, "context": "openml-diabetes-145976", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-diabetes-145976-11221", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00302151873817291, "booster": "gblinear", "eta": 0.196585900234737, "lambda": 0.0163248926899531, "nrounds": 732, "nthread": 1, "subsample": 0.720173264970072}}}], "metrics": 0.779948, "context": "openml-diabetes-145976", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-diabetes-145976-032", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00613129501500589, "booster": "gblinear", "eta": 0.038608506139289, "lambda": 0.0030868619701540506, "nrounds": 3959, "nthread": 1, "subsample": 0.725813779747114}}}], "metrics": 0.779948, "context": "openml-diabetes-145976", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-diabetes-145976-15243", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.00791339756153797, "booster": "gblinear", "eta": 0.0855952365314576, "lambda": 0.00322709343198689, "nrounds": 1710, "nthread": 1, "subsample": 0.868779134727083}}}], "metrics": 0.779948, "context": "openml-diabetes-145976", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-xgboost-6767-openml-diabetes-145976-25692", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "xgboost-6767", "config": {"alpha": 0.105697362444133, "booster": "gblinear", "eta": 0.039319591763411, "lambda": 0.00453311278572196, "nrounds": 3786, "nthread": 1, "subsample": 0.18602140925359}}}], "metrics": 0.779948, "context": "openml-diabetes-145976", "schema": "xgboost-6767", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-nomao-9977-492", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 2, "mtry": 23, "num.trees": 162, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.954550193506293}}}], "metrics": 0.970173, "context": "openml-nomao-9977", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-nomao-9977-019", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 21, "num.trees": 525, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.778999167773873}}}], "metrics": 0.969882, "context": "openml-nomao-9977", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-nomao-9977-381", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 3, "mtry": 23, "num.trees": 536, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.906412419211119}}}], "metrics": 0.969679, "context": "openml-nomao-9977", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-nomao-9977-317", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 4, "mtry": 10, "num.trees": 432, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.888704249612056}}}], "metrics": 0.96936, "context": "openml-nomao-9977", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-nomao-9977-057", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 3, "mtry": 7, "num.trees": 428, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.81156769732479}}}], "metrics": 0.96936, "context": "openml-nomao-9977", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-electricity-146012-790", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 4, "mtry": 13, "num.trees": 83, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.802406724332832}}}], "metrics": 0.928827, "context": "openml-electricity-146012", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-electricity-146012-757", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 2, "mtry": 14, "num.trees": 92, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.87409099151846}}}], "metrics": 0.926973, "context": "openml-electricity-146012", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-electricity-146012-369", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 6, "num.trees": 260, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.872448311164044}}}], "metrics": 0.926708, "context": "openml-electricity-146012", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-electricity-146012-516", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 6, "num.trees": 163, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.900563342357054}}}], "metrics": 0.926311, "context": "openml-electricity-146012", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-electricity-146012-428", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 5, "num.trees": 173, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.905878420732915}}}], "metrics": 0.925605, "context": "openml-electricity-146012", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-click-prediction-small-14971-1386", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 20, "mtry": 2, "num.trees": 405, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.863182388572022}}}], "metrics": 0.836913, "context": "openml-click-prediction-small-14971", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-click-prediction-small-14971-1431", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 4, "mtry": 6, "num.trees": 283, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.19837460576091}}}], "metrics": 0.836487, "context": "openml-click-prediction-small-14971", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-click-prediction-small-14971-1436", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 73, "mtry": 5, "num.trees": 303, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.726495711691678}}}], "metrics": 0.836387, "context": "openml-click-prediction-small-14971", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-click-prediction-small-14971-1477", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 5, "mtry": 2, "num.trees": 250, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.729298916622065}}}], "metrics": 0.836387, "context": "openml-click-prediction-small-14971", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-click-prediction-small-14971-1450", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 7, "mtry": 2, "num.trees": 443, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.256030804337934}}}], "metrics": 0.836362, "context": "openml-click-prediction-small-14971", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-musk-146082-1968", "modules": [{"role": "dataset", "module": "openml-musk-146082"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 156, "num.trees": 1659, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.941010980331339}}}], "metrics": 1.0, "context": "openml-musk-146082", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-musk-146082-1257", "modules": [{"role": "dataset", "module": "openml-musk-146082"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 37, "num.trees": 1366, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.323002381669357}}}], "metrics": 1.0, "context": "openml-musk-146082", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-musk-146082-523", "modules": [{"role": "dataset", "module": "openml-musk-146082"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 50, "num.trees": 626, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.4781353907193989}}}], "metrics": 1.0, "context": "openml-musk-146082", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-musk-146082-1252", "modules": [{"role": "dataset", "module": "openml-musk-146082"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 33, "num.trees": 39, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.688920515682548}}}], "metrics": 1.0, "context": "openml-musk-146082", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-musk-146082-524", "modules": [{"role": "dataset", "module": "openml-musk-146082"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 91, "num.trees": 951, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.292027946352027}}}], "metrics": 1.0, "context": "openml-musk-146082", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-spambase-145979-1646", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 2, "mtry": 5, "num.trees": 550, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.9235270494828}}}], "metrics": 0.956314, "context": "openml-spambase-145979", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-spambase-145979-1446", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 5, "mtry": 4, "num.trees": 1445, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.961838474147953}}}], "metrics": 0.956097, "context": "openml-spambase-145979", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-spambase-145979-1126", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 2, "mtry": 4, "num.trees": 955, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.997852105461061}}}], "metrics": 0.955879, "context": "openml-spambase-145979", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-spambase-145979-1670", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 8, "num.trees": 155, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.878694769437425}}}], "metrics": 0.955662, "context": "openml-spambase-145979", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-spambase-145979-1891", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 5, "num.trees": 1656, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.807384011382237}}}], "metrics": 0.955662, "context": "openml-spambase-145979", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-bank-marketing-14965-496", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 7, "num.trees": 435, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.446276245941408}}}], "metrics": 0.908805, "context": "openml-bank-marketing-14965", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-bank-marketing-14965-555", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 7, "num.trees": 297, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.26786691264715}}}], "metrics": 0.908451, "context": "openml-bank-marketing-14965", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-bank-marketing-14965-707", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 11, "num.trees": 404, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.164708715560846}}}], "metrics": 0.908363, "context": "openml-bank-marketing-14965", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-bank-marketing-14965-1309", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 8, "num.trees": 367, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.247321191173978}}}], "metrics": 0.908319, "context": "openml-bank-marketing-14965", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-bank-marketing-14965-1150", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 5, "num.trees": 179, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.794110599462874}}}], "metrics": 0.908297, "context": "openml-bank-marketing-14965", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-bank-marketing-145833-261", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 6, "num.trees": 266, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.417373052658513}}}], "metrics": 0.908739, "context": "openml-bank-marketing-145833", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-bank-marketing-145833-830", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 3, "mtry": 9, "num.trees": 1429, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.140254025231116}}}], "metrics": 0.908451, "context": "openml-bank-marketing-145833", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-bank-marketing-145833-975", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 2, "mtry": 6, "num.trees": 650, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.267450070334598}}}], "metrics": 0.908385, "context": "openml-bank-marketing-145833", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-bank-marketing-145833-1987", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 2, "mtry": 7, "num.trees": 1321, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.137802972760983}}}], "metrics": 0.908252, "context": "openml-bank-marketing-145833", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-bank-marketing-145833-658", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 23, "mtry": 10, "num.trees": 1552, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.22197445051278897}}}], "metrics": 0.90823, "context": "openml-bank-marketing-145833", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-magictelescope-3954-2122", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 2, "mtry": 2, "num.trees": 227, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.942471113521606}}}], "metrics": 0.883701, "context": "openml-magictelescope-3954", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-magictelescope-3954-1050", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 6, "mtry": 2, "num.trees": 373, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.810895702126436}}}], "metrics": 0.882387, "context": "openml-magictelescope-3954", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-magictelescope-3954-2330", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 2, "mtry": 3, "num.trees": 481, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.832004655431956}}}], "metrics": 0.882229, "context": "openml-magictelescope-3954", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-magictelescope-3954-2264", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 3, "num.trees": 237, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.5620606850599871}}}], "metrics": 0.882229, "context": "openml-magictelescope-3954", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-magictelescope-3954-2057", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 2, "mtry": 7, "num.trees": 642, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.867450586520135}}}], "metrics": 0.882229, "context": "openml-magictelescope-3954", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-sylva-agnostic-3889-2887", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 55, "num.trees": 108, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.962053071614355}}}], "metrics": 0.99472, "context": "openml-sylva-agnostic-3889", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-sylva-agnostic-3889-1293", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 41, "num.trees": 164, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.740079947630875}}}], "metrics": 0.99472, "context": "openml-sylva-agnostic-3889", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-sylva-agnostic-3889-2930", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 37, "num.trees": 604, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.846622079540975}}}], "metrics": 0.994651, "context": "openml-sylva-agnostic-3889", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-sylva-agnostic-3889-1434", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 134, "num.trees": 91, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.978725716797635}}}], "metrics": 0.994651, "context": "openml-sylva-agnostic-3889", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-sylva-agnostic-3889-290", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 51, "num.trees": 93, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.973826594767161}}}], "metrics": 0.994651, "context": "openml-sylva-agnostic-3889", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-electricity-219-3795", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 6, "num.trees": 41, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.843792382767424}}}], "metrics": 0.930879, "context": "openml-electricity-219", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-electricity-219-3412", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 4, "mtry": 4, "num.trees": 152, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.978910622210242}}}], "metrics": 0.929379, "context": "openml-electricity-219", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-electricity-219-3426", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 6, "num.trees": 161, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.645742746419273}}}], "metrics": 0.929092, "context": "openml-electricity-219", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-electricity-219-2559", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 6, "mtry": 5, "num.trees": 99, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.90114752643276}}}], "metrics": 0.928496, "context": "openml-electricity-219", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-electricity-219-2223", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 6, "num.trees": 223, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.948115215753205}}}], "metrics": 0.927812, "context": "openml-electricity-219", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-click-prediction-small-7295-3378", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 2, "mtry": 3, "num.trees": 361, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.359796890150756}}}], "metrics": 0.836537, "context": "openml-click-prediction-small-7295", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-click-prediction-small-7295-3329", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 8, "num.trees": 690, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.18521143598482}}}], "metrics": 0.836462, "context": "openml-click-prediction-small-7295", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-click-prediction-small-7295-3339", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 16, "mtry": 2, "num.trees": 407, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.462701526284218}}}], "metrics": 0.836462, "context": "openml-click-prediction-small-7295", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-click-prediction-small-7295-3399", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 7, "mtry": 2, "num.trees": 288, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.73720485761296}}}], "metrics": 0.836312, "context": "openml-click-prediction-small-7295", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-click-prediction-small-7295-3367", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 8, "mtry": 2, "num.trees": 636, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.246626106766053}}}], "metrics": 0.836287, "context": "openml-click-prediction-small-7295", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-monks-problems-3-146066-4451", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 1569, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.870526759023778}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-monks-problems-3-146066-1965", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 6, "num.trees": 1687, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.788542322441936}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-monks-problems-3-146066-1994", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 6, "num.trees": 821, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.946090037096292}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-monks-problems-3-146066-1990", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 1591, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.437737385137007}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-monks-problems-3-146066-1987", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 1186, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.687945711868815}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-banknote-authentication-145834-1938", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 3, "num.trees": 127, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.927868662634864}}}], "metrics": 0.995627, "context": "openml-banknote-authentication-145834", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-banknote-authentication-145834-3437", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 3, "num.trees": 114, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.961569014401175}}}], "metrics": 0.995627, "context": "openml-banknote-authentication-145834", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-banknote-authentication-145834-829", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 3, "num.trees": 147, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.944466862268746}}}], "metrics": 0.995627, "context": "openml-banknote-authentication-145834", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-banknote-authentication-145834-2114", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 3, "num.trees": 118, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.923309688502923}}}], "metrics": 0.995627, "context": "openml-banknote-authentication-145834", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-banknote-authentication-145834-4941", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 2, "mtry": 3, "num.trees": 857, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.974925860832445}}}], "metrics": 0.995627, "context": "openml-banknote-authentication-145834", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-monks-problems-3-3494-5523", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 2, "mtry": 4, "num.trees": 1603, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.383633052394725}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-monks-problems-3-3494-3226", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 1722, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.49465550601016695}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-monks-problems-3-3494-3246", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 1688, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.841653465875424}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-monks-problems-3-3494-3245", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 1727, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.621211344283074}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-monks-problems-3-3494-1218", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 1409, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.873681253497489}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-climate-model-simulation-crashes-9980-778", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 11, "num.trees": 130, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.651755265984684}}}], "metrics": 0.92963, "context": "openml-climate-model-simulation-crashes-9980", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-climate-model-simulation-crashes-9980-5018", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 35, "mtry": 9, "num.trees": 1638, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.762274557095952}}}], "metrics": 0.924074, "context": "openml-climate-model-simulation-crashes-9980", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-climate-model-simulation-crashes-9980-2273", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 12, "num.trees": 1174, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.598313281708397}}}], "metrics": 0.922222, "context": "openml-climate-model-simulation-crashes-9980", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-climate-model-simulation-crashes-9980-5106", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 24, "mtry": 15, "num.trees": 943, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.641427553026006}}}], "metrics": 0.922222, "context": "openml-climate-model-simulation-crashes-9980", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-climate-model-simulation-crashes-9980-2762", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 9, "num.trees": 1296, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.672690659412183}}}], "metrics": 0.922222, "context": "openml-climate-model-simulation-crashes-9980", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-wdbc-9946-4742", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 15, "num.trees": 35, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.562240067007951}}}], "metrics": 0.968366, "context": "openml-wdbc-9946", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-wdbc-9946-2826", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 7, "num.trees": 1269, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.974160914099775}}}], "metrics": 0.966608, "context": "openml-wdbc-9946", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-wdbc-9946-5110", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 7, "num.trees": 820, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.990465200203471}}}], "metrics": 0.966608, "context": "openml-wdbc-9946", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-wdbc-9946-2585", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 13, "num.trees": 542, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.919094503368251}}}], "metrics": 0.966608, "context": "openml-wdbc-9946", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-wdbc-9946-3986", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 7, "num.trees": 1310, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.973747042752802}}}], "metrics": 0.966608, "context": "openml-wdbc-9946", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-wilt-9889-4329", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 5, "num.trees": 41, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.6556477436563}}}], "metrics": 0.986361, "context": "openml-wilt-9889", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-wilt-9889-1319", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 924, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.731110333069228}}}], "metrics": 0.985741, "context": "openml-wilt-9889", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-wilt-9889-4261", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 799, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.733938300865702}}}], "metrics": 0.985741, "context": "openml-wilt-9889", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-wilt-9889-5379", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 5, "num.trees": 324, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.800650377199054}}}], "metrics": 0.985741, "context": "openml-wilt-9889", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-wilt-9889-2800", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 5, "num.trees": 381, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.795985643356107}}}], "metrics": 0.985741, "context": "openml-wilt-9889", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-eeg-eye-state-14951-6538", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 3, "num.trees": 169, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.959633365995251}}}], "metrics": 0.943591, "context": "openml-eeg-eye-state-14951", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-eeg-eye-state-14951-5622", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 2, "mtry": 6, "num.trees": 409, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.925791180273518}}}], "metrics": 0.942457, "context": "openml-eeg-eye-state-14951", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-eeg-eye-state-14951-6235", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 5, "mtry": 4, "num.trees": 404, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.97943458147347}}}], "metrics": 0.941722, "context": "openml-eeg-eye-state-14951", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-eeg-eye-state-14951-6730", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 2, "mtry": 6, "num.trees": 420, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.883485784195363}}}], "metrics": 0.941589, "context": "openml-eeg-eye-state-14951", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-eeg-eye-state-14951-5710", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 6, "num.trees": 495, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.883500470337458}}}], "metrics": 0.941255, "context": "openml-eeg-eye-state-14951", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-spambase-43-6171", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 8, "num.trees": 316, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.888209345168434}}}], "metrics": 0.956314, "context": "openml-spambase-43", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-spambase-43-5421", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 507, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.968603741633706}}}], "metrics": 0.956314, "context": "openml-spambase-43", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-spambase-43-1441", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 5, "num.trees": 203, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.913698213151656}}}], "metrics": 0.956314, "context": "openml-spambase-43", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-spambase-43-2576", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 2, "mtry": 5, "num.trees": 590, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.944666173867881}}}], "metrics": 0.956097, "context": "openml-spambase-43", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-spambase-43-1199", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 5, "num.trees": 1465, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.816649852669798}}}], "metrics": 0.956097, "context": "openml-spambase-43", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-phoneme-145857-8002", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 3, "mtry": 2, "num.trees": 1234, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.814922855398618}}}], "metrics": 0.915248, "context": "openml-phoneme-145857", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-phoneme-145857-8123", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 4, "mtry": 2, "num.trees": 1359, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.92029427641537}}}], "metrics": 0.914693, "context": "openml-phoneme-145857", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-phoneme-145857-8008", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 175, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.807162539078854}}}], "metrics": 0.913583, "context": "openml-phoneme-145857", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-phoneme-145857-8180", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 2, "mtry": 3, "num.trees": 1792, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.734370686369948}}}], "metrics": 0.913583, "context": "openml-phoneme-145857", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-phoneme-145857-8005", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 956, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.810481597553007}}}], "metrics": 0.913397, "context": "openml-phoneme-145857", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-pc3-3903-1688", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 3, "num.trees": 97, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.770461962395348}}}], "metrics": 0.90531, "context": "openml-pc3-3903", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-pc3-3903-308", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 6, "num.trees": 71, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.956039593159221}}}], "metrics": 0.90531, "context": "openml-pc3-3903", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-pc3-3903-1128", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 5, "num.trees": 95, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.911829138640314}}}], "metrics": 0.90531, "context": "openml-pc3-3903", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-pc3-3903-3718", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 7, "num.trees": 160, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.987017973209731}}}], "metrics": 0.90531, "context": "openml-pc3-3903", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-pc3-3903-5073", "modules": [{"role": "dataset", "module": "openml-pc3-3903"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 3, "num.trees": 58, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.796378029161133}}}], "metrics": 0.90531, "context": "openml-pc3-3903", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-madelon-9976-2908", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 154, "num.trees": 1637, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.990072580962442}}}], "metrics": 0.872692, "context": "openml-madelon-9976", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-madelon-9976-1927", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 124, "num.trees": 1490, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.999285916332155}}}], "metrics": 0.871538, "context": "openml-madelon-9976", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-madelon-9976-1917", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 153, "num.trees": 819, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.950434699794278}}}], "metrics": 0.871154, "context": "openml-madelon-9976", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-madelon-9976-2406", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 153, "num.trees": 1177, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.940594070754014}}}], "metrics": 0.871154, "context": "openml-madelon-9976", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-madelon-9976-2519", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 109, "num.trees": 405, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.988425220362842}}}], "metrics": 0.870769, "context": "openml-madelon-9976", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-gina-agnostic-3891-6580", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 32, "num.trees": 1246, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.955890265782364}}}], "metrics": 0.948674, "context": "openml-gina-agnostic-3891", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-gina-agnostic-3891-714", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 36, "num.trees": 1367, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.971962525509298}}}], "metrics": 0.948385, "context": "openml-gina-agnostic-3891", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-gina-agnostic-3891-4709", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 2, "mtry": 31, "num.trees": 337, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.979543757857755}}}], "metrics": 0.948385, "context": "openml-gina-agnostic-3891", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-gina-agnostic-3891-5882", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 3, "mtry": 34, "num.trees": 960, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.979487633681856}}}], "metrics": 0.948097, "context": "openml-gina-agnostic-3891", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-gina-agnostic-3891-472", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 2, "mtry": 29, "num.trees": 1997, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.94827170567587}}}], "metrics": 0.94752, "context": "openml-gina-agnostic-3891", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-wdbc-145878-9063", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 15, "num.trees": 236, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.913573631248437}}}], "metrics": 0.968366, "context": "openml-wdbc-145878", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-wdbc-145878-841", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 14, "num.trees": 363, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.938762362347916}}}], "metrics": 0.968366, "context": "openml-wdbc-145878", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-wdbc-145878-8677", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 8, "num.trees": 49, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.790926552074961}}}], "metrics": 0.968366, "context": "openml-wdbc-145878", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-wdbc-145878-5507", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 13, "num.trees": 15, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.959767535957508}}}], "metrics": 0.966608, "context": "openml-wdbc-145878", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-wdbc-145878-2487", "modules": [{"role": "dataset", "module": "openml-wdbc-145878"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 13, "num.trees": 1528, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.940596686745994}}}], "metrics": 0.966608, "context": "openml-wdbc-145878", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-monks-problems-2-3493-4184", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 6, "num.trees": 239, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.946895321528427}}}], "metrics": 0.985025, "context": "openml-monks-problems-2-3493", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-monks-problems-2-3493-1063", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 6, "num.trees": 308, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.980795469786972}}}], "metrics": 0.983361, "context": "openml-monks-problems-2-3493", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-monks-problems-2-3493-2085", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 6, "num.trees": 476, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.993531759292819}}}], "metrics": 0.983361, "context": "openml-monks-problems-2-3493", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-monks-problems-2-3493-8721", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 6, "num.trees": 426, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.971315373852849}}}], "metrics": 0.983361, "context": "openml-monks-problems-2-3493", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-monks-problems-2-3493-5810", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 6, "num.trees": 391, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.979117804416455}}}], "metrics": 0.983361, "context": "openml-monks-problems-2-3493", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-credit-g-145972-4878", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 15, "num.trees": 708, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.643781762663275}}}], "metrics": 0.78, "context": "openml-credit-g-145972", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-credit-g-145972-1354", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 19, "num.trees": 73, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.957666194089688}}}], "metrics": 0.78, "context": "openml-credit-g-145972", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-credit-g-145972-8477", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 9, "num.trees": 1118, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.788353137439117}}}], "metrics": 0.78, "context": "openml-credit-g-145972", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-credit-g-145972-1761", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 9, "num.trees": 1720, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.781776719051413}}}], "metrics": 0.78, "context": "openml-credit-g-145972", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-credit-g-145972-9428", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 18, "num.trees": 42, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.15427900783252}}}], "metrics": 0.78, "context": "openml-credit-g-145972", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-scene-3485-766", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 290, "num.trees": 41, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.63103429316543}}}], "metrics": 0.968841, "context": "openml-scene-3485", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-scene-3485-031", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 295, "num.trees": 43, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.539385365066119}}}], "metrics": 0.968841, "context": "openml-scene-3485", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-scene-3485-1980", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 284, "num.trees": 193, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.624793208320625}}}], "metrics": 0.968425, "context": "openml-scene-3485", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-scene-3485-3322", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 294, "num.trees": 50, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.965276165679097}}}], "metrics": 0.968425, "context": "openml-scene-3485", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-scene-3485-4833", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 291, "num.trees": 531, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.57525734200608}}}], "metrics": 0.968425, "context": "openml-scene-3485", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-climate-model-simulation-crashes-145839-4050", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 13, "num.trees": 44, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.702473189355805}}}], "metrics": 0.924074, "context": "openml-climate-model-simulation-crashes-145839", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-climate-model-simulation-crashes-145839-2752", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 9, "num.trees": 1319, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.671808459493332}}}], "metrics": 0.922222, "context": "openml-climate-model-simulation-crashes-145839", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-climate-model-simulation-crashes-145839-8295", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 9, "num.trees": 90, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.637665024399757}}}], "metrics": 0.922222, "context": "openml-climate-model-simulation-crashes-145839", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-climate-model-simulation-crashes-145839-6224", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 12, "num.trees": 790, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.592221925943159}}}], "metrics": 0.922222, "context": "openml-climate-model-simulation-crashes-145839", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-climate-model-simulation-crashes-145839-4635", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 10, "num.trees": 587, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.705318817612715}}}], "metrics": 0.922222, "context": "openml-climate-model-simulation-crashes-145839", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-banknote-authentication-10093-5918", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 3, "num.trees": 1068, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.976643081032671}}}], "metrics": 0.995627, "context": "openml-banknote-authentication-10093", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-banknote-authentication-10093-2191", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 3, "num.trees": 1071, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.972924531623721}}}], "metrics": 0.995627, "context": "openml-banknote-authentication-10093", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-banknote-authentication-10093-9817", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 3, "num.trees": 637, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.972193493880331}}}], "metrics": 0.995627, "context": "openml-banknote-authentication-10093", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-banknote-authentication-10093-946", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 3, "num.trees": 81, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.92953177136369}}}], "metrics": 0.995627, "context": "openml-banknote-authentication-10093", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-banknote-authentication-10093-1429", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 3, "num.trees": 1087, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.993491925974377}}}], "metrics": 0.995627, "context": "openml-banknote-authentication-10093", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-nomao-145854-6852", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 7, "num.trees": 409, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.816899658739567}}}], "metrics": 0.970811, "context": "openml-nomao-145854", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-nomao-145854-7111", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 2, "mtry": 4, "num.trees": 210, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.899038044689223}}}], "metrics": 0.970579, "context": "openml-nomao-145854", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-nomao-145854-8164", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 17, "num.trees": 421, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.825334458006546}}}], "metrics": 0.97055, "context": "openml-nomao-145854", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-nomao-145854-6880", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 2, "mtry": 8, "num.trees": 286, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.812099333573133}}}], "metrics": 0.970521, "context": "openml-nomao-145854", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-nomao-145854-9368", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 15, "num.trees": 204, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.955933072580956}}}], "metrics": 0.970521, "context": "openml-nomao-145854", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-eeg-eye-state-9983-5688", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 3, "num.trees": 575, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.995055746030994}}}], "metrics": 0.937784, "context": "openml-eeg-eye-state-9983", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-eeg-eye-state-9983-6146", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 3, "num.trees": 465, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.984893154469319}}}], "metrics": 0.937183, "context": "openml-eeg-eye-state-9983", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-eeg-eye-state-9983-3120", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 621, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.95508839529939}}}], "metrics": 0.936849, "context": "openml-eeg-eye-state-9983", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-eeg-eye-state-9983-8608", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 664, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.979027666687034}}}], "metrics": 0.936782, "context": "openml-eeg-eye-state-9983", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-eeg-eye-state-9983-3007", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 3, "num.trees": 545, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.980035100411624}}}], "metrics": 0.936782, "context": "openml-eeg-eye-state-9983", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-diabetes-145976-3350", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 2, "num.trees": 239, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.597033431311138}}}], "metrics": 0.785156, "context": "openml-diabetes-145976", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-diabetes-145976-7724", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 2, "num.trees": 289, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.962713366933167}}}], "metrics": 0.785156, "context": "openml-diabetes-145976", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-diabetes-145976-7089", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 94, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.536930733104236}}}], "metrics": 0.783854, "context": "openml-diabetes-145976", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-diabetes-145976-4513", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 2, "num.trees": 866, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.597002630960196}}}], "metrics": 0.783854, "context": "openml-diabetes-145976", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-diabetes-145976-2044", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 2, "num.trees": 74, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.577974871522747}}}], "metrics": 0.783854, "context": "openml-diabetes-145976", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-phoneme-9952-743", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 2, "num.trees": 223, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.960927816829644}}}], "metrics": 0.912287, "context": "openml-phoneme-9952", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-phoneme-9952-10742", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 2, "num.trees": 1382, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.998150558420457}}}], "metrics": 0.911732, "context": "openml-phoneme-9952", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-phoneme-9952-8745", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 2, "num.trees": 1148, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.999009449104779}}}], "metrics": 0.911732, "context": "openml-phoneme-9952", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-phoneme-9952-10386", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 2, "num.trees": 963, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.999855456594378}}}], "metrics": 0.911732, "context": "openml-phoneme-9952", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-phoneme-9952-5061", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 2, "num.trees": 328, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.933519098022953}}}], "metrics": 0.911732, "context": "openml-phoneme-9952", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-monks-problems-1-3492-6883", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 6, "num.trees": 1310, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.548192398995161}}}], "metrics": 1.0, "context": "openml-monks-problems-1-3492", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-monks-problems-1-3492-10694", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 3, "num.trees": 882, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.927615690301172}}}], "metrics": 1.0, "context": "openml-monks-problems-1-3492", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-monks-problems-1-3492-1900", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 6, "num.trees": 1391, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.426440651249141}}}], "metrics": 1.0, "context": "openml-monks-problems-1-3492", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-monks-problems-1-3492-1899", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 5, "num.trees": 1656, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.528633953817189}}}], "metrics": 1.0, "context": "openml-monks-problems-1-3492", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-monks-problems-1-3492-8191", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 3, "num.trees": 1687, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.939214607304893}}}], "metrics": 1.0, "context": "openml-monks-problems-1-3492", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-madelon-145853-869", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 135, "num.trees": 701, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.992681471374817}}}], "metrics": 0.871154, "context": "openml-madelon-145853", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-madelon-145853-3417", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 142, "num.trees": 897, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.978742319671437}}}], "metrics": 0.870769, "context": "openml-madelon-145853", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-madelon-145853-4445", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 147, "num.trees": 1962, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.972311780345626}}}], "metrics": 0.870385, "context": "openml-madelon-145853", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-madelon-145853-914", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 152, "num.trees": 1262, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.940867385966703}}}], "metrics": 0.870385, "context": "openml-madelon-145853", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-madelon-145853-2038", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 148, "num.trees": 1473, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.977561486372724}}}], "metrics": 0.870385, "context": "openml-madelon-145853", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-mozilla4-3899-15939", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 2, "mtry": 5, "num.trees": 480, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.81788296494633}}}], "metrics": 0.955677, "context": "openml-mozilla4-3899", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-mozilla4-3899-15305", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 2, "mtry": 4, "num.trees": 1269, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.928751689009368}}}], "metrics": 0.955484, "context": "openml-mozilla4-3899", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-mozilla4-3899-15529", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 5, "num.trees": 617, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.795790319866501}}}], "metrics": 0.955355, "context": "openml-mozilla4-3899", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-mozilla4-3899-15172", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 2, "mtry": 4, "num.trees": 851, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.902734581124969}}}], "metrics": 0.955355, "context": "openml-mozilla4-3899", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-mozilla4-3899-15683", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 3, "mtry": 4, "num.trees": 358, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.656996314343996}}}], "metrics": 0.955227, "context": "openml-mozilla4-3899", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-hill-valley-9970-15556", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 2, "mtry": 18, "num.trees": 569, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.865386508079246}}}], "metrics": 0.605611, "context": "openml-hill-valley-9970", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-hill-valley-9970-16582", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 20, "num.trees": 110, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.733557553961873}}}], "metrics": 0.605611, "context": "openml-hill-valley-9970", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-hill-valley-9970-12653", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 2, "mtry": 15, "num.trees": 1056, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.933792560757138}}}], "metrics": 0.604785, "context": "openml-hill-valley-9970", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-hill-valley-9970-14217", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 2, "mtry": 16, "num.trees": 1344, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.969659417611547}}}], "metrics": 0.60396, "context": "openml-hill-valley-9970", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-hill-valley-9970-14994", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 2, "mtry": 19, "num.trees": 273, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.914240803499706}}}], "metrics": 0.60396, "context": "openml-hill-valley-9970", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-ada-agnostic-3896-17814", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 27, "mtry": 7, "num.trees": 116, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.749860036908649}}}], "metrics": 0.857519, "context": "openml-ada-agnostic-3896", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-ada-agnostic-3896-14022", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 45, "mtry": 7, "num.trees": 120, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.654339544824325}}}], "metrics": 0.856861, "context": "openml-ada-agnostic-3896", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-ada-agnostic-3896-3180", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 6, "num.trees": 99, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.636681368248537}}}], "metrics": 0.856861, "context": "openml-ada-agnostic-3896", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-ada-agnostic-3896-17193", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 29, "mtry": 9, "num.trees": 86, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.691676897415891}}}], "metrics": 0.856642, "context": "openml-ada-agnostic-3896", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-ada-agnostic-3896-11030", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 19, "num.trees": 1118, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.209477306553163}}}], "metrics": 0.856642, "context": "openml-ada-agnostic-3896", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-blood-transfusion-service-center-145836-5228", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 44, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.191562787909061}}}], "metrics": 0.802139, "context": "openml-blood-transfusion-service-center-145836", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-blood-transfusion-service-center-145836-16513", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 2, "num.trees": 55, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.13237202106975}}}], "metrics": 0.802139, "context": "openml-blood-transfusion-service-center-145836", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-blood-transfusion-service-center-145836-15241", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 3, "num.trees": 119, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.130589772388339}}}], "metrics": 0.799465, "context": "openml-blood-transfusion-service-center-145836", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-blood-transfusion-service-center-145836-10641", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 3, "num.trees": 55, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.104432780388743}}}], "metrics": 0.799465, "context": "openml-blood-transfusion-service-center-145836", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-blood-transfusion-service-center-145836-5370", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 3, "num.trees": 450, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.109995688591152}}}], "metrics": 0.799465, "context": "openml-blood-transfusion-service-center-145836", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-ozone-level-8hr-9978-14606", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 40, "num.trees": 44, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.396120427665301}}}], "metrics": 0.946725, "context": "openml-ozone-level-8hr-9978", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-ozone-level-8hr-9978-14417", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 53, "num.trees": 49, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.995261376537383}}}], "metrics": 0.946725, "context": "openml-ozone-level-8hr-9978", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-ozone-level-8hr-9978-9355", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 16, "num.trees": 102, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.667192753916606}}}], "metrics": 0.94633, "context": "openml-ozone-level-8hr-9978", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-ozone-level-8hr-9978-6686", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 12, "num.trees": 64, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.902238505519927}}}], "metrics": 0.94633, "context": "openml-ozone-level-8hr-9978", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-ozone-level-8hr-9978-6933", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 51, "num.trees": 41, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.859026625263505}}}], "metrics": 0.94633, "context": "openml-ozone-level-8hr-9978", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-steel-plates-fault-9967-20036", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 19, "num.trees": 1540, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.621030155406334}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-steel-plates-fault-9967-7792", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 23, "num.trees": 617, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.16908303280361}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-steel-plates-fault-9967-8297", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 33, "num.trees": 1251, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.604244788922369}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-steel-plates-fault-9967-8296", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 28, "num.trees": 1450, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.34495043430943}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-steel-plates-fault-9967-8295", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-9967"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 18, "num.trees": 624, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.283264417434111}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-9967", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-musk-3950-15042", "modules": [{"role": "dataset", "module": "openml-musk-3950"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 152, "num.trees": 1858, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.45040621457155794}}}], "metrics": 1.0, "context": "openml-musk-3950", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-musk-3950-13491", "modules": [{"role": "dataset", "module": "openml-musk-3950"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 151, "num.trees": 328, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.849354894086719}}}], "metrics": 1.0, "context": "openml-musk-3950", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-musk-3950-4980", "modules": [{"role": "dataset", "module": "openml-musk-3950"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 120, "num.trees": 543, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.230710468348116}}}], "metrics": 1.0, "context": "openml-musk-3950", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-musk-3950-4983", "modules": [{"role": "dataset", "module": "openml-musk-3950"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 82, "num.trees": 732, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.280581503082067}}}], "metrics": 1.0, "context": "openml-musk-3950", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-musk-3950-13516", "modules": [{"role": "dataset", "module": "openml-musk-3950"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 29, "num.trees": 1807, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.118341794540174}}}], "metrics": 1.0, "context": "openml-musk-3950", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-ilpd-9971-10113", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 1, "num.trees": 18, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.709991654241458}}}], "metrics": 0.735849, "context": "openml-ilpd-9971", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-ilpd-9971-20484", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 1, "num.trees": 76, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.807545935292728}}}], "metrics": 0.735849, "context": "openml-ilpd-9971", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-ilpd-9971-7361", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 62, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.172979549085721}}}], "metrics": 0.735849, "context": "openml-ilpd-9971", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-ilpd-9971-9278", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 1, "num.trees": 404, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.5739548235898841}}}], "metrics": 0.734134, "context": "openml-ilpd-9971", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-ilpd-9971-18117", "modules": [{"role": "dataset", "module": "openml-ilpd-9971"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 1, "num.trees": 759, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.677246367116459}}}], "metrics": 0.734134, "context": "openml-ilpd-9971", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-steel-plates-fault-145872-25557", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 10, "mtry": 18, "num.trees": 1674, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.591702645667829}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-steel-plates-fault-145872-9084", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 13, "num.trees": 1973, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.671298256400041}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-steel-plates-fault-145872-9109", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 15, "num.trees": 498, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.340373756340705}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-steel-plates-fault-145872-9108", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 14, "num.trees": 941, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.874656875384971}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-steel-plates-fault-145872-9106", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 28, "num.trees": 1883, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.286590139521286}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-diabetes-37-9324", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 3, "num.trees": 131, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.685412741382606}}}], "metrics": 0.78776, "context": "openml-diabetes-37", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-diabetes-37-5713", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 2, "num.trees": 298, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.962783910287544}}}], "metrics": 0.786458, "context": "openml-diabetes-37", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-diabetes-37-770", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 2, "num.trees": 193, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.733017857046798}}}], "metrics": 0.783854, "context": "openml-diabetes-37", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-diabetes-37-1937", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 2, "num.trees": 142, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.67719971134793}}}], "metrics": 0.783854, "context": "openml-diabetes-37", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-diabetes-37-6394", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 2, "num.trees": 131, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.62899750682991}}}], "metrics": 0.783854, "context": "openml-diabetes-37", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-kc2-3913-11676", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 3, "num.trees": 992, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.42165966858156}}}], "metrics": 0.858238, "context": "openml-kc2-3913", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-kc2-3913-7962", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 15, "num.trees": 1240, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.292035432858393}}}], "metrics": 0.854406, "context": "openml-kc2-3913", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-kc2-3913-4739", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 13, "num.trees": 1725, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.290168880671263}}}], "metrics": 0.854406, "context": "openml-kc2-3913", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-kc2-3913-10552", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 1, "num.trees": 1643, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.448371329251677}}}], "metrics": 0.854406, "context": "openml-kc2-3913", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-kc2-3913-19644", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 13, "num.trees": 604, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.309557101340033}}}], "metrics": 0.854406, "context": "openml-kc2-3913", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-australian-125923-30174", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 14, "num.trees": 19, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.500674122781493}}}], "metrics": 0.882609, "context": "openml-australian-125923", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-australian-125923-7782", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 2, "num.trees": 15, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.963369482406415}}}], "metrics": 0.881159, "context": "openml-australian-125923", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-australian-125923-12289", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 13, "num.trees": 38, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.148476401506923}}}], "metrics": 0.881159, "context": "openml-australian-125923", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-australian-125923-9990", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 9, "num.trees": 54, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.343353777937591}}}], "metrics": 0.881159, "context": "openml-australian-125923", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-australian-125923-383", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 27, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.317753566219471}}}], "metrics": 0.87971, "context": "openml-australian-125923", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-pc4-3902-25361", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 32, "num.trees": 1660, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.973081026575528}}}], "metrics": 0.91701, "context": "openml-pc4-3902", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-pc4-3902-32452", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 2, "mtry": 14, "num.trees": 1214, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.95481123845093}}}], "metrics": 0.916324, "context": "openml-pc4-3902", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-pc4-3902-30457", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 3, "mtry": 9, "num.trees": 267, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.971692553418688}}}], "metrics": 0.915638, "context": "openml-pc4-3902", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-pc4-3902-24441", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 11, "num.trees": 674, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.920733811473474}}}], "metrics": 0.915638, "context": "openml-pc4-3902", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-pc4-3902-24956", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 2, "mtry": 20, "num.trees": 867, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.928255048464052}}}], "metrics": 0.915638, "context": "openml-pc4-3902", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-pc1-3918-27611", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 6, "num.trees": 19, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.42794475045520797}}}], "metrics": 0.944995, "context": "openml-pc1-3918", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-pc1-3918-18448", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 12, "num.trees": 144, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.44930024151690295}}}], "metrics": 0.943192, "context": "openml-pc1-3918", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-pc1-3918-3193", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 8, "num.trees": 110, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.44807462957687694}}}], "metrics": 0.943192, "context": "openml-pc1-3918", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-pc1-3918-2035", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 6, "num.trees": 11, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.410181860439479}}}], "metrics": 0.943192, "context": "openml-pc1-3918", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-6794-openml-pc1-3918-13644", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-6794", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 12, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.599502351903357}}}], "metrics": 0.943192, "context": "openml-pc1-3918", "schema": "ranger-6794", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-magictelescope-3954-038", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 3, "num.trees": 820, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.686326361913234}}}], "metrics": 0.882597, "context": "openml-magictelescope-3954", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-magictelescope-3954-089", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 4, "mtry": 5, "num.trees": 784, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.758920558867976}}}], "metrics": 0.881861, "context": "openml-magictelescope-3954", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-magictelescope-3954-092", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 4, "num.trees": 1895, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.798386362497695}}}], "metrics": 0.881861, "context": "openml-magictelescope-3954", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-magictelescope-3954-076", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 10, "mtry": 4, "num.trees": 222, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.921171128470451}}}], "metrics": 0.881546, "context": "openml-magictelescope-3954", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-magictelescope-3954-059", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 1, "mtry": 5, "num.trees": 924, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.835428815009072}}}], "metrics": 0.88081, "context": "openml-magictelescope-3954", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-electricity-219-081", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 7, "num.trees": 768, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.882862425618805}}}], "metrics": 0.931762, "context": "openml-electricity-219", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-electricity-219-031", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 7, "num.trees": 1176, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.623432750836946}}}], "metrics": 0.928959, "context": "openml-electricity-219", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-electricity-219-051", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 1231, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.808810784807429}}}], "metrics": 0.928937, "context": "openml-electricity-219", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-electricity-219-092", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 1, "mtry": 5, "num.trees": 1287, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.500572948809713}}}], "metrics": 0.916424, "context": "openml-electricity-219", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-electricity-219-091", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 9, "mtry": 5, "num.trees": 1336, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.725471169664525}}}], "metrics": 0.916203, "context": "openml-electricity-219", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-pc4-3902-080", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 15, "num.trees": 668, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.986720060254447}}}], "metrics": 0.914952, "context": "openml-pc4-3902", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-pc4-3902-091", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 1, "mtry": 36, "num.trees": 539, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.816935044410638}}}], "metrics": 0.91358, "context": "openml-pc4-3902", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-pc4-3902-023", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 4, "mtry": 31, "num.trees": 1986, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.961711096251383}}}], "metrics": 0.912209, "context": "openml-pc4-3902", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-pc4-3902-056", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 1, "mtry": 7, "num.trees": 1754, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.880540059879422}}}], "metrics": 0.910151, "context": "openml-pc4-3902", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-pc4-3902-051", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 1, "mtry": 31, "num.trees": 1271, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.783761882921681}}}], "metrics": 0.909465, "context": "openml-pc4-3902", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-kr-vs-kp-145953-045", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 4, "mtry": 21, "num.trees": 1576, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.996950044622645}}}], "metrics": 0.996245, "context": "openml-kr-vs-kp-145953", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-kr-vs-kp-145953-002", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 7, "mtry": 27, "num.trees": 143, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.902410115976818}}}], "metrics": 0.996245, "context": "openml-kr-vs-kp-145953", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-kr-vs-kp-145953-088", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 24, "num.trees": 675, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.626757932291366}}}], "metrics": 0.99562, "context": "openml-kr-vs-kp-145953", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-kr-vs-kp-145953-022", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 30, "num.trees": 467, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.462845486518927}}}], "metrics": 0.99562, "context": "openml-kr-vs-kp-145953", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-kr-vs-kp-145953-016", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 31, "num.trees": 1415, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.595103020127863}}}], "metrics": 0.995307, "context": "openml-kr-vs-kp-145953", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-pc1-3918-024", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 29, "mtry": 12, "num.trees": 325, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.761041242186911}}}], "metrics": 0.941389, "context": "openml-pc1-3918", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-pc1-3918-092", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 11, "mtry": 11, "num.trees": 1948, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.447774148406461}}}], "metrics": 0.941389, "context": "openml-pc1-3918", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-pc1-3918-017", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 10, "num.trees": 1135, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.241286286897957}}}], "metrics": 0.940487, "context": "openml-pc1-3918", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-pc1-3918-009", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 10, "mtry": 13, "num.trees": 1319, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.282987099443562}}}], "metrics": 0.940487, "context": "openml-pc1-3918", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-pc1-3918-012", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 8, "num.trees": 1177, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.370159316761419}}}], "metrics": 0.939585, "context": "openml-pc1-3918", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-wilt-9889-052", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 5, "num.trees": 1900, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.780821501440369}}}], "metrics": 0.985328, "context": "openml-wilt-9889", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-wilt-9889-049", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 4, "num.trees": 1976, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.680114940204658}}}], "metrics": 0.985328, "context": "openml-wilt-9889", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-wilt-9889-070", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 18, "mtry": 5, "num.trees": 1485, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.925891235680319}}}], "metrics": 0.984914, "context": "openml-wilt-9889", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-wilt-9889-096", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 13, "mtry": 4, "num.trees": 1871, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.985642797942273}}}], "metrics": 0.984914, "context": "openml-wilt-9889", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-wilt-9889-013", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 9, "mtry": 4, "num.trees": 476, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.997755380813032}}}], "metrics": 0.984914, "context": "openml-wilt-9889", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-climate-model-simulation-crashes-145839-033", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 22, "mtry": 13, "num.trees": 407, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.561498418194242}}}], "metrics": 0.918519, "context": "openml-climate-model-simulation-crashes-145839", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-climate-model-simulation-crashes-145839-086", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 14, "mtry": 14, "num.trees": 796, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.504224124690518}}}], "metrics": 0.916667, "context": "openml-climate-model-simulation-crashes-145839", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-climate-model-simulation-crashes-145839-072", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 18, "mtry": 12, "num.trees": 278, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.491627381718718}}}], "metrics": 0.916667, "context": "openml-climate-model-simulation-crashes-145839", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-climate-model-simulation-crashes-145839-005", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 1, "mtry": 15, "num.trees": 1331, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.574692660314031}}}], "metrics": 0.916667, "context": "openml-climate-model-simulation-crashes-145839", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-climate-model-simulation-crashes-145839-064", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-145839"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 14, "num.trees": 960, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.502722557447851}}}], "metrics": 0.916667, "context": "openml-climate-model-simulation-crashes-145839", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-scene-3485-075", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 27, "mtry": 298, "num.trees": 1112, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.809736222983338}}}], "metrics": 0.966764, "context": "openml-scene-3485", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-scene-3485-014", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 10, "mtry": 237, "num.trees": 408, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.916069168155082}}}], "metrics": 0.965933, "context": "openml-scene-3485", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-scene-3485-032", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 270, "num.trees": 898, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.884068320808001}}}], "metrics": 0.965933, "context": "openml-scene-3485", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-scene-3485-029", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 15, "mtry": 240, "num.trees": 1129, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.874102999223396}}}], "metrics": 0.965933, "context": "openml-scene-3485", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-scene-3485-068", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 5, "mtry": 266, "num.trees": 928, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.465117158088833}}}], "metrics": 0.965933, "context": "openml-scene-3485", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-madelon-145853-016", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 12, "mtry": 191, "num.trees": 1134, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.831742939725518}}}], "metrics": 0.865385, "context": "openml-madelon-145853", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-madelon-145853-137", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 13, "mtry": 109, "num.trees": 1896, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.931035835156217}}}], "metrics": 0.865, "context": "openml-madelon-145853", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-madelon-145853-121", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 10, "mtry": 192, "num.trees": 1123, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.810731126391329}}}], "metrics": 0.863462, "context": "openml-madelon-145853", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-madelon-145853-014", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 217, "num.trees": 832, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.754708871920593}}}], "metrics": 0.862692, "context": "openml-madelon-145853", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-madelon-145853-108", "modules": [{"role": "dataset", "module": "openml-madelon-145853"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 236, "num.trees": 269, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.966429666639306}}}], "metrics": 0.861538, "context": "openml-madelon-145853", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-nomao-145854-028", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 31, "num.trees": 655, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.667675263411365}}}], "metrics": 0.969389, "context": "openml-nomao-145854", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-nomao-145854-114", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 5, "num.trees": 1123, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.824622215423733}}}], "metrics": 0.968838, "context": "openml-nomao-145854", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-nomao-145854-123", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 4, "mtry": 5, "num.trees": 1107, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.612931966665201}}}], "metrics": 0.968751, "context": "openml-nomao-145854", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-nomao-145854-017", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 6, "mtry": 28, "num.trees": 1781, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.662429482419975}}}], "metrics": 0.968606, "context": "openml-nomao-145854", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-nomao-145854-042", "modules": [{"role": "dataset", "module": "openml-nomao-145854"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 63, "num.trees": 1427, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.666453376598656}}}], "metrics": 0.968461, "context": "openml-nomao-145854", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-click-prediction-small-7295-123", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 2, "num.trees": 905, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.343183791893534}}}], "metrics": 0.835011, "context": "openml-click-prediction-small-7295", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-click-prediction-small-7295-008", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 18, "mtry": 2, "num.trees": 289, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.880066952574998}}}], "metrics": 0.834835, "context": "openml-click-prediction-small-7295", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-click-prediction-small-7295-060", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 95, "mtry": 4, "num.trees": 1410, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.876035581529141}}}], "metrics": 0.83481, "context": "openml-click-prediction-small-7295", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-click-prediction-small-7295-140", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 58, "mtry": 5, "num.trees": 725, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.720389469666406}}}], "metrics": 0.83466, "context": "openml-click-prediction-small-7295", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-click-prediction-small-7295-115", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 29, "mtry": 5, "num.trees": 1327, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.844459293712862}}}], "metrics": 0.83466, "context": "openml-click-prediction-small-7295", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-bioresponse-145677-005", "modules": [{"role": "dataset", "module": "openml-bioresponse-145677"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 8, "mtry": 123, "num.trees": 941, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.530339042469859}}}], "metrics": 0.813383, "context": "openml-bioresponse-145677", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-bioresponse-145677-059", "modules": [{"role": "dataset", "module": "openml-bioresponse-145677"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 27, "mtry": 230, "num.trees": 871, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.936901156138629}}}], "metrics": 0.812317, "context": "openml-bioresponse-145677", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-bioresponse-145677-034", "modules": [{"role": "dataset", "module": "openml-bioresponse-145677"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 7, "mtry": 169, "num.trees": 1352, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.4727206680690871}}}], "metrics": 0.812317, "context": "openml-bioresponse-145677", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-bioresponse-145677-074", "modules": [{"role": "dataset", "module": "openml-bioresponse-145677"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 5, "mtry": 230, "num.trees": 142, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.445174450636841}}}], "metrics": 0.81205, "context": "openml-bioresponse-145677", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-bioresponse-145677-039", "modules": [{"role": "dataset", "module": "openml-bioresponse-145677"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 4, "mtry": 353, "num.trees": 662, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.530660353717394}}}], "metrics": 0.81125, "context": "openml-bioresponse-145677", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-monks-problems-1-146064-143", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-146064"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 4, "num.trees": 662, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.554860244877636}}}], "metrics": 1.0, "context": "openml-monks-problems-1-146064", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-monks-problems-1-146064-135", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-146064"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 8, "mtry": 4, "num.trees": 1041, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.679822951788083}}}], "metrics": 1.0, "context": "openml-monks-problems-1-146064", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-monks-problems-1-146064-125", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-146064"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 19, "mtry": 5, "num.trees": 878, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.942767773172818}}}], "metrics": 1.0, "context": "openml-monks-problems-1-146064", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-monks-problems-1-146064-061", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-146064"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 10, "mtry": 4, "num.trees": 1980, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.633965038810857}}}], "metrics": 1.0, "context": "openml-monks-problems-1-146064", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-monks-problems-1-146064-059", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-146064"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 21, "mtry": 4, "num.trees": 568, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.996795258950442}}}], "metrics": 1.0, "context": "openml-monks-problems-1-146064", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-qsar-biodeg-145862-132", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 29, "num.trees": 82, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.5954028638545419}}}], "metrics": 0.875829, "context": "openml-qsar-biodeg-145862", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-qsar-biodeg-145862-105", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 4, "mtry": 38, "num.trees": 747, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.939286098023877}}}], "metrics": 0.872986, "context": "openml-qsar-biodeg-145862", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-qsar-biodeg-145862-141", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 13, "mtry": 34, "num.trees": 87, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.66940214689821}}}], "metrics": 0.872038, "context": "openml-qsar-biodeg-145862", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-qsar-biodeg-145862-194", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 13, "num.trees": 261, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.94211204200983}}}], "metrics": 0.872038, "context": "openml-qsar-biodeg-145862", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-qsar-biodeg-145862-198", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 1, "mtry": 9, "num.trees": 1129, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.951237788586877}}}], "metrics": 0.87109, "context": "openml-qsar-biodeg-145862", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-spambase-145979-191", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 1, "mtry": 10, "num.trees": 1466, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.792023594630882}}}], "metrics": 0.953706, "context": "openml-spambase-145979", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-spambase-145979-164", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 1, "mtry": 18, "num.trees": 695, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.835272585134953}}}], "metrics": 0.952836, "context": "openml-spambase-145979", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-spambase-145979-045", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 1, "mtry": 9, "num.trees": 1694, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.873154430347495}}}], "metrics": 0.952836, "context": "openml-spambase-145979", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-spambase-145979-108", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 21, "num.trees": 121, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.818991835205816}}}], "metrics": 0.952619, "context": "openml-spambase-145979", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-spambase-145979-095", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 16, "num.trees": 1057, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.682625863561407}}}], "metrics": 0.95175, "context": "openml-spambase-145979", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-diabetes-37-010", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 2, "num.trees": 1682, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.743187963403761}}}], "metrics": 0.777344, "context": "openml-diabetes-37", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-diabetes-37-120", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 6, "num.trees": 119, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.62218752859626}}}], "metrics": 0.776042, "context": "openml-diabetes-37", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-diabetes-37-163", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 6, "mtry": 8, "num.trees": 860, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.674020117893815}}}], "metrics": 0.77474, "context": "openml-diabetes-37", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-diabetes-37-023", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 2, "num.trees": 1937, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.460002518468536}}}], "metrics": 0.77474, "context": "openml-diabetes-37", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-diabetes-37-055", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 22, "mtry": 2, "num.trees": 1236, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.845244694594294}}}], "metrics": 0.77474, "context": "openml-diabetes-37", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-ilpd-145848-193", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 1, "num.trees": 285, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.665483157057315}}}], "metrics": 0.725557, "context": "openml-ilpd-145848", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-ilpd-145848-030", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 1, "num.trees": 718, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.3877586219925431}}}], "metrics": 0.723842, "context": "openml-ilpd-145848", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-ilpd-145848-184", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 5, "mtry": 1, "num.trees": 1961, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.966494771605358}}}], "metrics": 0.722127, "context": "openml-ilpd-145848", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-ilpd-145848-029", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 1, "num.trees": 1237, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.766522833774798}}}], "metrics": 0.722127, "context": "openml-ilpd-145848", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-ilpd-145848-188", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 9, "mtry": 1, "num.trees": 1173, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.4166940252529461}}}], "metrics": 0.722127, "context": "openml-ilpd-145848", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-australian-125923-178", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 35, "mtry": 14, "num.trees": 39, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.566407881607302}}}], "metrics": 0.875362, "context": "openml-australian-125923", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-australian-125923-125", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 1, "mtry": 2, "num.trees": 783, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.350774617330171}}}], "metrics": 0.872464, "context": "openml-australian-125923", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-australian-125923-119", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 1, "num.trees": 1944, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.645235133543611}}}], "metrics": 0.872464, "context": "openml-australian-125923", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-australian-125923-099", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 1, "mtry": 12, "num.trees": 532, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.655025290953927}}}], "metrics": 0.872464, "context": "openml-australian-125923", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-australian-125923-106", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 10, "mtry": 9, "num.trees": 1351, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.265872075851075}}}], "metrics": 0.871014, "context": "openml-australian-125923", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-kr-vs-kp-3-180", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 29, "num.trees": 1844, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.848761990736239}}}], "metrics": 0.996871, "context": "openml-kr-vs-kp-3", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-kr-vs-kp-3-001", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 28, "num.trees": 74, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.797984473081306}}}], "metrics": 0.996558, "context": "openml-kr-vs-kp-3", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-kr-vs-kp-3-046", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 5, "mtry": 18, "num.trees": 499, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.882877915166318}}}], "metrics": 0.995932, "context": "openml-kr-vs-kp-3", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-kr-vs-kp-3-199", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 22, "num.trees": 1124, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.879011891200207}}}], "metrics": 0.995932, "context": "openml-kr-vs-kp-3", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-kr-vs-kp-3-133", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 21, "num.trees": 493, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.625761140650138}}}], "metrics": 0.995932, "context": "openml-kr-vs-kp-3", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-bioresponse-14966-125", "modules": [{"role": "dataset", "module": "openml-bioresponse-14966"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 6, "mtry": 314, "num.trees": 1475, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.701508172252215}}}], "metrics": 0.814183, "context": "openml-bioresponse-14966", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-bioresponse-14966-100", "modules": [{"role": "dataset", "module": "openml-bioresponse-14966"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 4, "mtry": 244, "num.trees": 918, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.63800949358847}}}], "metrics": 0.81365, "context": "openml-bioresponse-14966", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-bioresponse-14966-023", "modules": [{"role": "dataset", "module": "openml-bioresponse-14966"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 453, "num.trees": 338, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.706441986351274}}}], "metrics": 0.812317, "context": "openml-bioresponse-14966", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-bioresponse-14966-168", "modules": [{"role": "dataset", "module": "openml-bioresponse-14966"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 26, "mtry": 176, "num.trees": 755, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.820768081396818}}}], "metrics": 0.812317, "context": "openml-bioresponse-14966", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-bioresponse-14966-210", "modules": [{"role": "dataset", "module": "openml-bioresponse-14966"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 7, "mtry": 75, "num.trees": 1362, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.760170243005268}}}], "metrics": 0.811784, "context": "openml-bioresponse-14966", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-bioresponse-9910-019", "modules": [{"role": "dataset", "module": "openml-bioresponse-9910"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 5, "mtry": 383, "num.trees": 1840, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.844805078650825}}}], "metrics": 0.81205, "context": "openml-bioresponse-9910", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-bioresponse-9910-012", "modules": [{"role": "dataset", "module": "openml-bioresponse-9910"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 4, "mtry": 396, "num.trees": 254, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.812702212436125}}}], "metrics": 0.811517, "context": "openml-bioresponse-9910", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-bioresponse-9910-166", "modules": [{"role": "dataset", "module": "openml-bioresponse-9910"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 1, "mtry": 886, "num.trees": 1305, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.863233709079213}}}], "metrics": 0.81125, "context": "openml-bioresponse-9910", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-bioresponse-9910-235", "modules": [{"role": "dataset", "module": "openml-bioresponse-9910"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 116, "num.trees": 666, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.696108606806956}}}], "metrics": 0.810717, "context": "openml-bioresponse-9910", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-bioresponse-9910-181", "modules": [{"role": "dataset", "module": "openml-bioresponse-9910"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 283, "num.trees": 751, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.854457326931879}}}], "metrics": 0.810451, "context": "openml-bioresponse-9910", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-click-prediction-small-14971-074", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 5, "mtry": 3, "num.trees": 1527, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.201023358199745}}}], "metrics": 0.835211, "context": "openml-click-prediction-small-14971", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-click-prediction-small-14971-057", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 5, "mtry": 2, "num.trees": 1077, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.237410821765661}}}], "metrics": 0.835011, "context": "openml-click-prediction-small-14971", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-click-prediction-small-14971-076", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 30, "mtry": 3, "num.trees": 1000, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.47713825311511804}}}], "metrics": 0.83491, "context": "openml-click-prediction-small-14971", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-click-prediction-small-14971-194", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 60, "mtry": 4, "num.trees": 955, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.740515681076795}}}], "metrics": 0.834885, "context": "openml-click-prediction-small-14971", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-click-prediction-small-14971-068", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 3, "num.trees": 417, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.185120756155811}}}], "metrics": 0.834885, "context": "openml-click-prediction-small-14971", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-ozone-level-8hr-145855-151", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 4, "mtry": 10, "num.trees": 1884, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.51096021477133}}}], "metrics": 0.945146, "context": "openml-ozone-level-8hr-145855", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-ozone-level-8hr-145855-029", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 6, "num.trees": 1226, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.582503861282021}}}], "metrics": 0.944751, "context": "openml-ozone-level-8hr-145855", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-ozone-level-8hr-145855-046", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 70, "num.trees": 1773, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.673065726947971}}}], "metrics": 0.944751, "context": "openml-ozone-level-8hr-145855", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-ozone-level-8hr-145855-009", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 4, "mtry": 6, "num.trees": 1812, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.790766618237831}}}], "metrics": 0.944751, "context": "openml-ozone-level-8hr-145855", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-ozone-level-8hr-145855-025", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 6, "mtry": 69, "num.trees": 1791, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.996145924855955}}}], "metrics": 0.944357, "context": "openml-ozone-level-8hr-145855", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-monks-problems-2-3493-265", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 3, "num.trees": 1912, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.806923327106051}}}], "metrics": 1.0, "context": "openml-monks-problems-2-3493", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-monks-problems-2-3493-215", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 1, "mtry": 6, "num.trees": 1401, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.761606345069595}}}], "metrics": 1.0, "context": "openml-monks-problems-2-3493", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-monks-problems-2-3493-081", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 3, "num.trees": 796, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.906565770949237}}}], "metrics": 1.0, "context": "openml-monks-problems-2-3493", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-monks-problems-2-3493-288", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 1, "mtry": 5, "num.trees": 1198, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.936212580907159}}}], "metrics": 1.0, "context": "openml-monks-problems-2-3493", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-monks-problems-2-3493-057", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 1, "mtry": 5, "num.trees": 1856, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.893367332220077}}}], "metrics": 1.0, "context": "openml-monks-problems-2-3493", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-tic-tac-toe-49-124", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 1, "mtry": 3, "num.trees": 668, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.903756491444074}}}], "metrics": 0.993737, "context": "openml-tic-tac-toe-49", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-tic-tac-toe-49-262", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 4, "num.trees": 1266, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.933396459044889}}}], "metrics": 0.993737, "context": "openml-tic-tac-toe-49", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-tic-tac-toe-49-136", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 9, "num.trees": 1715, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.718928738846444}}}], "metrics": 0.992693, "context": "openml-tic-tac-toe-49", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-tic-tac-toe-49-196", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 7, "mtry": 5, "num.trees": 1886, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.774319498846307}}}], "metrics": 0.992693, "context": "openml-tic-tac-toe-49", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-tic-tac-toe-49-232", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 7, "num.trees": 1045, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.66227087166626}}}], "metrics": 0.992693, "context": "openml-tic-tac-toe-49", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-gina-agnostic-3891-200", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 5, "mtry": 29, "num.trees": 1716, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.926828412502073}}}], "metrics": 0.945502, "context": "openml-gina-agnostic-3891", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-gina-agnostic-3891-087", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 97, "num.trees": 476, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.945908479206264}}}], "metrics": 0.944925, "context": "openml-gina-agnostic-3891", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-gina-agnostic-3891-010", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 1, "mtry": 109, "num.trees": 1666, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.882978629390709}}}], "metrics": 0.943772, "context": "openml-gina-agnostic-3891", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-gina-agnostic-3891-198", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 18, "mtry": 29, "num.trees": 1666, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.972929601208307}}}], "metrics": 0.942042, "context": "openml-gina-agnostic-3891", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-gina-agnostic-3891-197", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 4, "mtry": 15, "num.trees": 907, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.897440502978861}}}], "metrics": 0.942042, "context": "openml-gina-agnostic-3891", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-wilt-9914-056", "modules": [{"role": "dataset", "module": "openml-wilt-9914"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 18, "mtry": 4, "num.trees": 830, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.811287341942079}}}], "metrics": 0.985948, "context": "openml-wilt-9914", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-wilt-9914-063", "modules": [{"role": "dataset", "module": "openml-wilt-9914"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 19, "mtry": 4, "num.trees": 219, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.932866033143364}}}], "metrics": 0.985741, "context": "openml-wilt-9914", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-wilt-9914-290", "modules": [{"role": "dataset", "module": "openml-wilt-9914"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 4, "num.trees": 855, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.689854550128803}}}], "metrics": 0.985534, "context": "openml-wilt-9914", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-wilt-9914-294", "modules": [{"role": "dataset", "module": "openml-wilt-9914"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 6, "mtry": 4, "num.trees": 839, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.712260079290718}}}], "metrics": 0.985534, "context": "openml-wilt-9914", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-wilt-9914-060", "modules": [{"role": "dataset", "module": "openml-wilt-9914"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 4, "num.trees": 1315, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.731294165807776}}}], "metrics": 0.985121, "context": "openml-wilt-9914", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-amazon-employee-access-34539-098", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-34539"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 3, "num.trees": 1038, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.858786555402912}}}], "metrics": 0.952425, "context": "openml-amazon-employee-access-34539", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-amazon-employee-access-34539-266", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-34539"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 5, "num.trees": 1924, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.792366479430348}}}], "metrics": 0.951845, "context": "openml-amazon-employee-access-34539", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-amazon-employee-access-34539-296", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-34539"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 7, "num.trees": 896, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.99398351914715}}}], "metrics": 0.951662, "context": "openml-amazon-employee-access-34539", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-amazon-employee-access-34539-216", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-34539"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 4, "mtry": 5, "num.trees": 555, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.655125912767835}}}], "metrics": 0.951601, "context": "openml-amazon-employee-access-34539", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-amazon-employee-access-34539-248", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-34539"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 1, "mtry": 9, "num.trees": 741, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.533093812153675}}}], "metrics": 0.951326, "context": "openml-amazon-employee-access-34539", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-mozilla4-3899-313", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 2, "num.trees": 745, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.983821202930994}}}], "metrics": 0.955613, "context": "openml-mozilla4-3899", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-mozilla4-3899-186", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 5, "num.trees": 1396, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.96138188065961}}}], "metrics": 0.955484, "context": "openml-mozilla4-3899", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-mozilla4-3899-090", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 4, "num.trees": 1918, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.633618092350662}}}], "metrics": 0.955355, "context": "openml-mozilla4-3899", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-mozilla4-3899-283", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 1, "mtry": 2, "num.trees": 835, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.935061054094695}}}], "metrics": 0.955227, "context": "openml-mozilla4-3899", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-mozilla4-3899-102", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 5, "num.trees": 341, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.998089142958634}}}], "metrics": 0.955162, "context": "openml-mozilla4-3899", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-kc1-3917-346", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 4, "mtry": 15, "num.trees": 1672, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.417269509541802}}}], "metrics": 0.869132, "context": "openml-kc1-3917", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-kc1-3917-347", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 7, "mtry": 15, "num.trees": 90, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.980354770692065}}}], "metrics": 0.868184, "context": "openml-kc1-3917", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-kc1-3917-238", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 4, "mtry": 10, "num.trees": 1464, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.36221272123511905}}}], "metrics": 0.867236, "context": "openml-kc1-3917", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-kc1-3917-008", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 4, "mtry": 2, "num.trees": 1557, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.988462080620229}}}], "metrics": 0.866761, "context": "openml-kc1-3917", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-kc1-3917-363", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 9, "mtry": 18, "num.trees": 354, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.7883490097709}}}], "metrics": 0.866761, "context": "openml-kc1-3917", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-spambase-43-195", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 10, "num.trees": 391, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.940039959480055}}}], "metrics": 0.955879, "context": "openml-spambase-43", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-spambase-43-317", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 11, "num.trees": 955, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.929938174015842}}}], "metrics": 0.954358, "context": "openml-spambase-43", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-spambase-43-107", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 1, "mtry": 3, "num.trees": 647, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.802655639196746}}}], "metrics": 0.953706, "context": "openml-spambase-43", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-spambase-43-336", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 15, "num.trees": 1487, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.915664977906272}}}], "metrics": 0.953054, "context": "openml-spambase-43", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-spambase-43-355", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 16, "num.trees": 1871, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.764004632621072}}}], "metrics": 0.951967, "context": "openml-spambase-43", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-blood-transfusion-service-center-145836-351", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 8, "mtry": 4, "num.trees": 138, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.183650298556313}}}], "metrics": 0.794118, "context": "openml-blood-transfusion-service-center-145836", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-blood-transfusion-service-center-145836-239", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 26, "mtry": 4, "num.trees": 974, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.24010096215643}}}], "metrics": 0.792781, "context": "openml-blood-transfusion-service-center-145836", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-blood-transfusion-service-center-145836-069", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 22, "mtry": 4, "num.trees": 627, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.172960934974253}}}], "metrics": 0.792781, "context": "openml-blood-transfusion-service-center-145836", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-blood-transfusion-service-center-145836-180", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 20, "mtry": 2, "num.trees": 354, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.227551748766564}}}], "metrics": 0.792781, "context": "openml-blood-transfusion-service-center-145836", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-blood-transfusion-service-center-145836-108", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-145836"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 16, "mtry": 3, "num.trees": 275, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.122643647924997}}}], "metrics": 0.792781, "context": "openml-blood-transfusion-service-center-145836", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-nomao-9977-283", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 4, "mtry": 46, "num.trees": 1485, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.892103841830976}}}], "metrics": 0.970666, "context": "openml-nomao-9977", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-nomao-9977-023", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 1, "mtry": 29, "num.trees": 425, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.977797472779639}}}], "metrics": 0.970463, "context": "openml-nomao-9977", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-nomao-9977-245", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 15, "num.trees": 1540, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.934801235841587}}}], "metrics": 0.970231, "context": "openml-nomao-9977", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-nomao-9977-079", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 53, "num.trees": 1777, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.976343308971263}}}], "metrics": 0.970231, "context": "openml-nomao-9977", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-nomao-9977-219", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 58, "num.trees": 945, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.796867710002698}}}], "metrics": 0.969853, "context": "openml-nomao-9977", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-phoneme-145857-261", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 2, "num.trees": 1317, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.834407846187241}}}], "metrics": 0.915063, "context": "openml-phoneme-145857", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-phoneme-145857-003", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 1, "num.trees": 388, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.92880702172406}}}], "metrics": 0.914323, "context": "openml-phoneme-145857", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-phoneme-145857-230", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 1, "num.trees": 1243, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.770284208841622}}}], "metrics": 0.913953, "context": "openml-phoneme-145857", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-phoneme-145857-162", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 4, "num.trees": 776, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.817123677465133}}}], "metrics": 0.913768, "context": "openml-phoneme-145857", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-phoneme-145857-332", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 2, "num.trees": 1484, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.922813930572011}}}], "metrics": 0.912842, "context": "openml-phoneme-145857", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-madelon-9976-123", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 4, "mtry": 169, "num.trees": 1083, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.922582228574902}}}], "metrics": 0.870769, "context": "openml-madelon-9976", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-madelon-9976-349", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 7, "mtry": 192, "num.trees": 635, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.997893955884501}}}], "metrics": 0.864615, "context": "openml-madelon-9976", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-madelon-9976-199", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 200, "num.trees": 1852, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.807634855969809}}}], "metrics": 0.863077, "context": "openml-madelon-9976", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-madelon-9976-091", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 5, "mtry": 217, "num.trees": 772, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.710198917333037}}}], "metrics": 0.861538, "context": "openml-madelon-9976", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-madelon-9976-280", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 250, "num.trees": 1009, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.760259168292396}}}], "metrics": 0.861538, "context": "openml-madelon-9976", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-credit-g-146803-294", "modules": [{"role": "dataset", "module": "openml-credit-g-146803"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 9, "mtry": 11, "num.trees": 1800, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.683790572802536}}}], "metrics": 0.778, "context": "openml-credit-g-146803", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-credit-g-146803-015", "modules": [{"role": "dataset", "module": "openml-credit-g-146803"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 7, "mtry": 15, "num.trees": 153, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.82432183357887}}}], "metrics": 0.777, "context": "openml-credit-g-146803", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-credit-g-146803-169", "modules": [{"role": "dataset", "module": "openml-credit-g-146803"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 10, "mtry": 14, "num.trees": 761, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.706832690117881}}}], "metrics": 0.776, "context": "openml-credit-g-146803", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-credit-g-146803-392", "modules": [{"role": "dataset", "module": "openml-credit-g-146803"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 5, "mtry": 18, "num.trees": 151, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.173590936209075}}}], "metrics": 0.775, "context": "openml-credit-g-146803", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-credit-g-146803-302", "modules": [{"role": "dataset", "module": "openml-credit-g-146803"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 21, "mtry": 16, "num.trees": 835, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.682921313284896}}}], "metrics": 0.774, "context": "openml-credit-g-146803", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-monks-problems-3-3494-397", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 14, "mtry": 6, "num.trees": 1501, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.640996541734785}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-monks-problems-3-3494-186", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 5, "num.trees": 923, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.622309136390686}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-monks-problems-3-3494-201", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 20, "mtry": 6, "num.trees": 1613, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.520281555363908}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-monks-problems-3-3494-200", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 18, "mtry": 6, "num.trees": 994, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.972703111497685}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-monks-problems-3-3494-396", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 3, "num.trees": 1558, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.806403271504678}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-ozone-level-8hr-9978-154", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 7, "mtry": 11, "num.trees": 71, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.608370804856531}}}], "metrics": 0.945146, "context": "openml-ozone-level-8hr-9978", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-ozone-level-8hr-9978-050", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 4, "mtry": 40, "num.trees": 1927, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.962075452134013}}}], "metrics": 0.945146, "context": "openml-ozone-level-8hr-9978", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-ozone-level-8hr-9978-174", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 29, "num.trees": 1464, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.39304246352985506}}}], "metrics": 0.944751, "context": "openml-ozone-level-8hr-9978", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-ozone-level-8hr-9978-249", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 7, "mtry": 15, "num.trees": 1649, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.689766218699515}}}], "metrics": 0.944751, "context": "openml-ozone-level-8hr-9978", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-ozone-level-8hr-9978-297", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 17, "num.trees": 1878, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.40660646492615304}}}], "metrics": 0.944357, "context": "openml-ozone-level-8hr-9978", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-banknote-authentication-10093-242", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 5, "mtry": 3, "num.trees": 1999, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.959515849198215}}}], "metrics": 0.994898, "context": "openml-banknote-authentication-10093", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-banknote-authentication-10093-208", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 2, "num.trees": 91, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.973089224495925}}}], "metrics": 0.994169, "context": "openml-banknote-authentication-10093", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-banknote-authentication-10093-370", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 10, "mtry": 3, "num.trees": 1526, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.970903935143724}}}], "metrics": 0.994169, "context": "openml-banknote-authentication-10093", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-banknote-authentication-10093-176", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 2, "num.trees": 548, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.861096899397671}}}], "metrics": 0.994169, "context": "openml-banknote-authentication-10093", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-banknote-authentication-10093-355", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 2, "num.trees": 1006, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.621645807242021}}}], "metrics": 0.994169, "context": "openml-banknote-authentication-10093", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-monks-problems-1-3492-405", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 5, "mtry": 6, "num.trees": 1672, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.509501810348593}}}], "metrics": 1.0, "context": "openml-monks-problems-1-3492", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-monks-problems-1-3492-033", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 7, "mtry": 6, "num.trees": 682, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.90166635743808}}}], "metrics": 1.0, "context": "openml-monks-problems-1-3492", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-monks-problems-1-3492-335", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 4, "num.trees": 1431, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.557573201227933}}}], "metrics": 1.0, "context": "openml-monks-problems-1-3492", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-monks-problems-1-3492-045", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 4, "num.trees": 1745, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.88375401054509}}}], "metrics": 1.0, "context": "openml-monks-problems-1-3492", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-monks-problems-1-3492-043", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 5, "num.trees": 1726, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.722130583319813}}}], "metrics": 1.0, "context": "openml-monks-problems-1-3492", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-phoneme-9952-127", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 1, "mtry": 2, "num.trees": 758, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.817173327249475}}}], "metrics": 0.915618, "context": "openml-phoneme-9952", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-phoneme-9952-017", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 1, "num.trees": 1868, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.861027448414825}}}], "metrics": 0.915063, "context": "openml-phoneme-9952", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-phoneme-9952-058", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 4, "mtry": 2, "num.trees": 1810, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.888993637333624}}}], "metrics": 0.914323, "context": "openml-phoneme-9952", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-phoneme-9952-271", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 1, "mtry": 2, "num.trees": 1902, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.920087165036239}}}], "metrics": 0.913212, "context": "openml-phoneme-9952", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-phoneme-9952-367", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 4, "mtry": 1, "num.trees": 1453, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.950621315115131}}}], "metrics": 0.913027, "context": "openml-phoneme-9952", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-hill-valley-9970-007", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 47, "num.trees": 660, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.666985400510021}}}], "metrics": 0.599835, "context": "openml-hill-valley-9970", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-hill-valley-9970-445", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 61, "num.trees": 738, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.669904829747975}}}], "metrics": 0.598185, "context": "openml-hill-valley-9970", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-hill-valley-9970-054", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 82, "num.trees": 1842, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.712556975730695}}}], "metrics": 0.59571, "context": "openml-hill-valley-9970", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-hill-valley-9970-025", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 23, "num.trees": 1870, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.987828678847291}}}], "metrics": 0.59571, "context": "openml-hill-valley-9970", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-hill-valley-9970-269", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 4, "mtry": 57, "num.trees": 103, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.710400910302997}}}], "metrics": 0.594884, "context": "openml-hill-valley-9970", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-eeg-eye-state-14951-205", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 1, "mtry": 3, "num.trees": 868, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.855567298782989}}}], "metrics": 0.944192, "context": "openml-eeg-eye-state-14951", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-eeg-eye-state-14951-251", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 6, "num.trees": 1707, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.996458486025222}}}], "metrics": 0.944059, "context": "openml-eeg-eye-state-14951", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-eeg-eye-state-14951-303", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 4, "num.trees": 381, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.858250038372353}}}], "metrics": 0.943057, "context": "openml-eeg-eye-state-14951", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-eeg-eye-state-14951-426", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 7, "num.trees": 1034, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.978386246575974}}}], "metrics": 0.942123, "context": "openml-eeg-eye-state-14951", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-eeg-eye-state-14951-380", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 2, "num.trees": 1635, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.777686836454086}}}], "metrics": 0.937784, "context": "openml-eeg-eye-state-14951", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-amazon-employee-access-9911-048", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-9911"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 5, "num.trees": 337, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.78665617944207}}}], "metrics": 0.952333, "context": "openml-amazon-employee-access-9911", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-amazon-employee-access-9911-056", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-9911"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 6, "mtry": 4, "num.trees": 441, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.652239618869498}}}], "metrics": 0.952211, "context": "openml-amazon-employee-access-9911", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-amazon-employee-access-9911-065", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-9911"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 4, "mtry": 5, "num.trees": 608, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.626590202027}}}], "metrics": 0.952119, "context": "openml-amazon-employee-access-9911", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-amazon-employee-access-9911-209", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-9911"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 7, "mtry": 5, "num.trees": 1580, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.88250879815314}}}], "metrics": 0.952089, "context": "openml-amazon-employee-access-9911", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-amazon-employee-access-9911-176", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-9911"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 5, "mtry": 3, "num.trees": 375, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.936396710574627}}}], "metrics": 0.952089, "context": "openml-amazon-employee-access-9911", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-bank-marketing-145833-097", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 30, "mtry": 7, "num.trees": 289, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.505649674148299}}}], "metrics": 0.908319, "context": "openml-bank-marketing-145833", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-bank-marketing-145833-239", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 9, "mtry": 8, "num.trees": 729, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.324986338126473}}}], "metrics": 0.90823, "context": "openml-bank-marketing-145833", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-bank-marketing-145833-048", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 5, "mtry": 8, "num.trees": 1670, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.172225332865492}}}], "metrics": 0.908009, "context": "openml-bank-marketing-145833", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-bank-marketing-145833-307", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 12, "mtry": 6, "num.trees": 1041, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.45579182729125}}}], "metrics": 0.907943, "context": "openml-bank-marketing-145833", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-bank-marketing-145833-210", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 1, "mtry": 11, "num.trees": 603, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.161119988840073}}}], "metrics": 0.907921, "context": "openml-bank-marketing-145833", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-sylva-agnostic-3889-123", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 79, "num.trees": 653, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.961320871929638}}}], "metrics": 0.994443, "context": "openml-sylva-agnostic-3889", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-sylva-agnostic-3889-072", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 1, "mtry": 108, "num.trees": 1021, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.830511822761036}}}], "metrics": 0.994373, "context": "openml-sylva-agnostic-3889", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-sylva-agnostic-3889-034", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 1, "mtry": 35, "num.trees": 1828, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.927341575035825}}}], "metrics": 0.994373, "context": "openml-sylva-agnostic-3889", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-sylva-agnostic-3889-395", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 141, "num.trees": 69, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.62963003939949}}}], "metrics": 0.994304, "context": "openml-sylva-agnostic-3889", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-sylva-agnostic-3889-264", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 83, "num.trees": 334, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.544433019659482}}}], "metrics": 0.994304, "context": "openml-sylva-agnostic-3889", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-eeg-eye-state-9983-462", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 1, "mtry": 3, "num.trees": 1454, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.936030229879543}}}], "metrics": 0.94466, "context": "openml-eeg-eye-state-9983", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-eeg-eye-state-9983-022", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 4, "num.trees": 512, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.881982862646691}}}], "metrics": 0.943258, "context": "openml-eeg-eye-state-9983", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-eeg-eye-state-9983-152", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 4, "mtry": 4, "num.trees": 1250, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.884767763805576}}}], "metrics": 0.941389, "context": "openml-eeg-eye-state-9983", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-eeg-eye-state-9983-081", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 5, "mtry": 4, "num.trees": 1617, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.89958377154544}}}], "metrics": 0.940854, "context": "openml-eeg-eye-state-9983", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-eeg-eye-state-9983-432", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 6, "num.trees": 822, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.831709529669024}}}], "metrics": 0.940788, "context": "openml-eeg-eye-state-9983", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-qsar-biodeg-9957-326", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 9, "mtry": 6, "num.trees": 17, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.846112493565306}}}], "metrics": 0.880569, "context": "openml-qsar-biodeg-9957", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-qsar-biodeg-9957-417", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 1, "mtry": 32, "num.trees": 670, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.981554615194909}}}], "metrics": 0.874882, "context": "openml-qsar-biodeg-9957", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-qsar-biodeg-9957-433", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 8, "num.trees": 1652, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.80657346919179}}}], "metrics": 0.872038, "context": "openml-qsar-biodeg-9957", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-qsar-biodeg-9957-035", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 2, "num.trees": 1706, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.994744165334851}}}], "metrics": 0.872038, "context": "openml-qsar-biodeg-9957", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-qsar-biodeg-9957-222", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 20, "mtry": 35, "num.trees": 1590, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.37955091865733304}}}], "metrics": 0.87109, "context": "openml-qsar-biodeg-9957", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-credit-g-145972-344", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 7, "num.trees": 845, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.446531426487491}}}], "metrics": 0.778, "context": "openml-credit-g-145972", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-credit-g-145972-320", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 14, "num.trees": 1321, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.506247436068952}}}], "metrics": 0.777, "context": "openml-credit-g-145972", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-credit-g-145972-438", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 10, "mtry": 10, "num.trees": 470, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.952953285258263}}}], "metrics": 0.776, "context": "openml-credit-g-145972", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-credit-g-145972-387", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 10, "mtry": 12, "num.trees": 1560, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.629117360292003}}}], "metrics": 0.775, "context": "openml-credit-g-145972", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-credit-g-145972-329", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 4, "mtry": 11, "num.trees": 1407, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.5603775209514419}}}], "metrics": 0.775, "context": "openml-credit-g-145972", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-steel-plates-fault-145872-333", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 64, "mtry": 26, "num.trees": 14, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.783364669140428}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-steel-plates-fault-145872-305", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 36, "mtry": 27, "num.trees": 1340, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.259663377213292}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-steel-plates-fault-145872-098", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 76, "mtry": 20, "num.trees": 1924, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.486490589985624}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-steel-plates-fault-145872-322", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 5, "mtry": 18, "num.trees": 1880, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.626012290129438}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-steel-plates-fault-145872-321", "modules": [{"role": "dataset", "module": "openml-steel-plates-fault-145872"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 51, "mtry": 27, "num.trees": 934, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.178714761976153}}}], "metrics": 1.0, "context": "openml-steel-plates-fault-145872", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-phishingwebsites-34537-491", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-34537"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 17, "num.trees": 1247, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.951162793603726}}}], "metrics": 0.973225, "context": "openml-phishingwebsites-34537", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-phishingwebsites-34537-242", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-34537"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 1, "mtry": 13, "num.trees": 723, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.904116284218617}}}], "metrics": 0.973134, "context": "openml-phishingwebsites-34537", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-phishingwebsites-34537-456", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-34537"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 1, "mtry": 9, "num.trees": 1161, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.918891964526847}}}], "metrics": 0.973044, "context": "openml-phishingwebsites-34537", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-phishingwebsites-34537-232", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-34537"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 19, "num.trees": 1008, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.802167107095011}}}], "metrics": 0.973044, "context": "openml-phishingwebsites-34537", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-phishingwebsites-34537-254", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-34537"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 1, "mtry": 14, "num.trees": 1090, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.901613231259398}}}], "metrics": 0.972773, "context": "openml-phishingwebsites-34537", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-blood-transfusion-service-center-10101-393", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 38, "mtry": 4, "num.trees": 939, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.340973778441548}}}], "metrics": 0.794118, "context": "openml-blood-transfusion-service-center-10101", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-blood-transfusion-service-center-10101-396", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 10, "mtry": 4, "num.trees": 1501, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.160814598179422}}}], "metrics": 0.794118, "context": "openml-blood-transfusion-service-center-10101", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-blood-transfusion-service-center-10101-281", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 6, "mtry": 3, "num.trees": 61, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.16964040400926}}}], "metrics": 0.792781, "context": "openml-blood-transfusion-service-center-10101", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-blood-transfusion-service-center-10101-500", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 66, "mtry": 3, "num.trees": 1516, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.573731144121848}}}], "metrics": 0.792781, "context": "openml-blood-transfusion-service-center-10101", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-blood-transfusion-service-center-10101-468", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 18, "mtry": 3, "num.trees": 795, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.20832500923425}}}], "metrics": 0.792781, "context": "openml-blood-transfusion-service-center-10101", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-electricity-146012-462", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 6, "num.trees": 1595, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.93965847203508}}}], "metrics": 0.933528, "context": "openml-electricity-146012", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-electricity-146012-313", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 6, "num.trees": 1638, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.865652545704506}}}], "metrics": 0.932512, "context": "openml-electricity-146012", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-electricity-146012-215", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 1, "mtry": 7, "num.trees": 621, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.974365011136979}}}], "metrics": 0.929754, "context": "openml-electricity-146012", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-electricity-146012-387", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 1, "mtry": 7, "num.trees": 83, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.726428750972264}}}], "metrics": 0.929754, "context": "openml-electricity-146012", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-electricity-146012-370", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 8, "num.trees": 285, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.756855980237015}}}], "metrics": 0.928452, "context": "openml-electricity-146012", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-climate-model-simulation-crashes-9980-426", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 10, "num.trees": 649, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.53971392728854}}}], "metrics": 0.918519, "context": "openml-climate-model-simulation-crashes-9980", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-climate-model-simulation-crashes-9980-450", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 4, "mtry": 12, "num.trees": 1608, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.943052011681721}}}], "metrics": 0.918519, "context": "openml-climate-model-simulation-crashes-9980", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-climate-model-simulation-crashes-9980-427", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 20, "mtry": 10, "num.trees": 1959, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.664381216326728}}}], "metrics": 0.918519, "context": "openml-climate-model-simulation-crashes-9980", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-climate-model-simulation-crashes-9980-210", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 40, "mtry": 11, "num.trees": 983, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.832721703778952}}}], "metrics": 0.918519, "context": "openml-climate-model-simulation-crashes-9980", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-climate-model-simulation-crashes-9980-116", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 8, "mtry": 12, "num.trees": 1533, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.596274588909}}}], "metrics": 0.918519, "context": "openml-climate-model-simulation-crashes-9980", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-monks-problems-3-146066-001", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 3, "mtry": 6, "num.trees": 46, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.669566536974162}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-monks-problems-3-146066-452", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 5, "mtry": 4, "num.trees": 1071, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.881910779117607}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-monks-problems-3-146066-460", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 6, "mtry": 5, "num.trees": 918, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.632225250545889}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-monks-problems-3-146066-459", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 5, "mtry": 4, "num.trees": 150, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.493847669498064}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-monks-problems-3-146066-458", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 5, "mtry": 4, "num.trees": 661, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.582063615857624}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-phishingwebsites-14952-371", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-14952"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 4, "mtry": 15, "num.trees": 907, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.897440502978861}}}], "metrics": 0.973225, "context": "openml-phishingwebsites-14952", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-phishingwebsites-14952-093", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-14952"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 2, "mtry": 12, "num.trees": 1720, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.898500980110839}}}], "metrics": 0.972953, "context": "openml-phishingwebsites-14952", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-phishingwebsites-14952-361", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-14952"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 1, "mtry": 13, "num.trees": 1135, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.854480522382073}}}], "metrics": 0.972863, "context": "openml-phishingwebsites-14952", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-phishingwebsites-14952-320", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-14952"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 1, "mtry": 16, "num.trees": 355, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.70246597295627}}}], "metrics": 0.972773, "context": "openml-phishingwebsites-14952", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7607-openml-phishingwebsites-14952-352", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-14952"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7607", "config": {"min.node.size": 1, "mtry": 13, "num.trees": 1677, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.837290443666279}}}], "metrics": 0.972773, "context": "openml-phishingwebsites-14952", "schema": "ranger-7607", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-click-prediction-small-14971-014", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 5, "mtry": 2, "num.trees": 1066, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.79791567819193}}}], "metrics": 0.83491, "context": "openml-click-prediction-small-14971", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-click-prediction-small-14971-050", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 54, "mtry": 3, "num.trees": 1755, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.866179002565332}}}], "metrics": 0.83486, "context": "openml-click-prediction-small-14971", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-click-prediction-small-14971-072", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 16, "mtry": 3, "num.trees": 1001, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.482789642992429}}}], "metrics": 0.83476, "context": "openml-click-prediction-small-14971", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-click-prediction-small-14971-100", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 51, "mtry": 8, "num.trees": 907, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.548874636879191}}}], "metrics": 0.83466, "context": "openml-click-prediction-small-14971", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-click-prediction-small-14971-082", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 83, "mtry": 8, "num.trees": 1413, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.825978329405189}}}], "metrics": 0.83456, "context": "openml-click-prediction-small-14971", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-monks-problems-3-146066-150", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 4, "num.trees": 1740, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.22492260097060401}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-monks-problems-3-146066-135", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 2, "num.trees": 111, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.997163280867971}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-monks-problems-3-146066-238", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 12, "mtry": 3, "num.trees": 1666, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.735664543765597}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-monks-problems-3-146066-041", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 6, "mtry": 3, "num.trees": 523, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.625133624440059}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-monks-problems-3-146066-040", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-146066"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 18, "mtry": 4, "num.trees": 1813, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.629495817259885}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-146066", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-bank-marketing-145833-034", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 5, "num.trees": 404, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.230844649416395}}}], "metrics": 0.908275, "context": "openml-bank-marketing-145833", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-bank-marketing-145833-225", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 24, "mtry": 7, "num.trees": 1725, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.560205930401571}}}], "metrics": 0.90812, "context": "openml-bank-marketing-145833", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-bank-marketing-145833-275", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 9, "mtry": 7, "num.trees": 1799, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.29359187327791}}}], "metrics": 0.908075, "context": "openml-bank-marketing-145833", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-bank-marketing-145833-370", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 5, "mtry": 5, "num.trees": 929, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.220326433610171}}}], "metrics": 0.908075, "context": "openml-bank-marketing-145833", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-bank-marketing-145833-348", "modules": [{"role": "dataset", "module": "openml-bank-marketing-145833"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 11, "num.trees": 1268, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.265894661098719}}}], "metrics": 0.907987, "context": "openml-bank-marketing-145833", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-qsar-biodeg-9957-234", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 19, "mtry": 37, "num.trees": 456, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.568360352283344}}}], "metrics": 0.874882, "context": "openml-qsar-biodeg-9957", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-qsar-biodeg-9957-189", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 39, "num.trees": 1629, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.429226618376561}}}], "metrics": 0.872986, "context": "openml-qsar-biodeg-9957", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-qsar-biodeg-9957-018", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 4, "num.trees": 166, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.912934045726433}}}], "metrics": 0.872038, "context": "openml-qsar-biodeg-9957", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-qsar-biodeg-9957-230", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 30, "num.trees": 842, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.682523618172854}}}], "metrics": 0.872038, "context": "openml-qsar-biodeg-9957", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-qsar-biodeg-9957-223", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 5, "num.trees": 948, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.991504626604728}}}], "metrics": 0.87109, "context": "openml-qsar-biodeg-9957", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-mozilla4-3899-335", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 5, "num.trees": 711, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.965206503053196}}}], "metrics": 0.955741, "context": "openml-mozilla4-3899", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-mozilla4-3899-282", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 566, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.785088136792183}}}], "metrics": 0.955484, "context": "openml-mozilla4-3899", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-mozilla4-3899-298", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 2, "num.trees": 967, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.837761086272076}}}], "metrics": 0.955355, "context": "openml-mozilla4-3899", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-mozilla4-3899-295", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 4, "mtry": 5, "num.trees": 1079, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.960385136166587}}}], "metrics": 0.955355, "context": "openml-mozilla4-3899", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-mozilla4-3899-247", "modules": [{"role": "dataset", "module": "openml-mozilla4-3899"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 768, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.818545765406452}}}], "metrics": 0.955227, "context": "openml-mozilla4-3899", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-eeg-eye-state-9983-333", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 4, "num.trees": 1207, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.945290831639431}}}], "metrics": 0.943324, "context": "openml-eeg-eye-state-9983", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-eeg-eye-state-9983-211", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 3, "num.trees": 333, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.904351679282263}}}], "metrics": 0.942857, "context": "openml-eeg-eye-state-9983", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-eeg-eye-state-9983-286", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 4, "num.trees": 1811, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.843782764743082}}}], "metrics": 0.942323, "context": "openml-eeg-eye-state-9983", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-eeg-eye-state-9983-309", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 63, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.981178258312866}}}], "metrics": 0.941121, "context": "openml-eeg-eye-state-9983", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-eeg-eye-state-9983-341", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 6, "num.trees": 1704, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.808403112925589}}}], "metrics": 0.940854, "context": "openml-eeg-eye-state-9983", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-click-prediction-small-7295-351", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 42, "mtry": 5, "num.trees": 190, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.581418007938191}}}], "metrics": 0.835211, "context": "openml-click-prediction-small-7295", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-click-prediction-small-7295-091", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 6, "mtry": 3, "num.trees": 1874, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.24226180233527}}}], "metrics": 0.835111, "context": "openml-click-prediction-small-7295", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-click-prediction-small-7295-299", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 28, "mtry": 3, "num.trees": 648, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.470215026568621}}}], "metrics": 0.835061, "context": "openml-click-prediction-small-7295", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-click-prediction-small-7295-324", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 75, "mtry": 6, "num.trees": 541, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.805220454628579}}}], "metrics": 0.835036, "context": "openml-click-prediction-small-7295", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-click-prediction-small-7295-049", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 15, "mtry": 3, "num.trees": 1391, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.344597107334994}}}], "metrics": 0.834985, "context": "openml-click-prediction-small-7295", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-bank-marketing-14965-181", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 30, "mtry": 11, "num.trees": 39, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.740840144339018}}}], "metrics": 0.908208, "context": "openml-bank-marketing-14965", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-bank-marketing-14965-108", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 35, "mtry": 10, "num.trees": 155, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.910629198793322}}}], "metrics": 0.908142, "context": "openml-bank-marketing-14965", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-bank-marketing-14965-288", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 13, "mtry": 6, "num.trees": 1466, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.159637517877854}}}], "metrics": 0.908142, "context": "openml-bank-marketing-14965", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-bank-marketing-14965-197", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 5, "mtry": 9, "num.trees": 639, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.127789273136295}}}], "metrics": 0.908098, "context": "openml-bank-marketing-14965", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-bank-marketing-14965-035", "modules": [{"role": "dataset", "module": "openml-bank-marketing-14965"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 8, "num.trees": 809, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.252777999988757}}}], "metrics": 0.908031, "context": "openml-bank-marketing-14965", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-phoneme-9952-338", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 1, "num.trees": 1410, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.756594515149482}}}], "metrics": 0.915248, "context": "openml-phoneme-9952", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-phoneme-9952-115", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 1, "num.trees": 755, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.912888730224222}}}], "metrics": 0.914878, "context": "openml-phoneme-9952", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-phoneme-9952-218", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 2, "num.trees": 601, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.773671285831369}}}], "metrics": 0.914693, "context": "openml-phoneme-9952", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-phoneme-9952-156", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 1, "num.trees": 1139, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.792428792174906}}}], "metrics": 0.914508, "context": "openml-phoneme-9952", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-phoneme-9952-264", "modules": [{"role": "dataset", "module": "openml-phoneme-9952"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 4, "num.trees": 1997, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.839762465353124}}}], "metrics": 0.914508, "context": "openml-phoneme-9952", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-spambase-43-079", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 4, "mtry": 11, "num.trees": 1937, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.912845843168907}}}], "metrics": 0.953271, "context": "openml-spambase-43", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-spambase-43-305", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 19, "num.trees": 629, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.995483377319761}}}], "metrics": 0.953271, "context": "openml-spambase-43", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-spambase-43-017", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 6, "mtry": 7, "num.trees": 1385, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.971407580864616}}}], "metrics": 0.952836, "context": "openml-spambase-43", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-spambase-43-210", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 4, "mtry": 7, "num.trees": 161, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.82066720162984}}}], "metrics": 0.952619, "context": "openml-spambase-43", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-spambase-43-349", "modules": [{"role": "dataset", "module": "openml-spambase-43"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 11, "num.trees": 1414, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.641673927335069}}}], "metrics": 0.952619, "context": "openml-spambase-43", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-bioresponse-9910-354", "modules": [{"role": "dataset", "module": "openml-bioresponse-9910"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 5, "mtry": 211, "num.trees": 1606, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.700757725373842}}}], "metrics": 0.81365, "context": "openml-bioresponse-9910", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-bioresponse-9910-089", "modules": [{"role": "dataset", "module": "openml-bioresponse-9910"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 369, "num.trees": 285, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.920713713136502}}}], "metrics": 0.813117, "context": "openml-bioresponse-9910", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-bioresponse-9910-165", "modules": [{"role": "dataset", "module": "openml-bioresponse-9910"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 101, "num.trees": 1390, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.927833766886033}}}], "metrics": 0.81205, "context": "openml-bioresponse-9910", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-bioresponse-9910-292", "modules": [{"role": "dataset", "module": "openml-bioresponse-9910"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 10, "mtry": 398, "num.trees": 765, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.88359440381173}}}], "metrics": 0.81205, "context": "openml-bioresponse-9910", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-bioresponse-9910-142", "modules": [{"role": "dataset", "module": "openml-bioresponse-9910"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 500, "num.trees": 1013, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.99022346381098}}}], "metrics": 0.81205, "context": "openml-bioresponse-9910", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-electricity-146012-386", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 6, "num.trees": 1478, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.941023809881881}}}], "metrics": 0.933461, "context": "openml-electricity-146012", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-electricity-146012-526", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 5, "num.trees": 1282, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.935344664589502}}}], "metrics": 0.932159, "context": "openml-electricity-146012", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-electricity-146012-178", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 7, "num.trees": 1370, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.648153702588752}}}], "metrics": 0.930394, "context": "openml-electricity-146012", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-electricity-146012-518", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 5, "mtry": 6, "num.trees": 276, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.804772956343368}}}], "metrics": 0.929974, "context": "openml-electricity-146012", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-electricity-146012-161", "modules": [{"role": "dataset", "module": "openml-electricity-146012"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 4, "num.trees": 1794, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.922211051499471}}}], "metrics": 0.929776, "context": "openml-electricity-146012", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-ada-agnostic-3896-526", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 31, "mtry": 10, "num.trees": 1514, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.620078295376152}}}], "metrics": 0.855546, "context": "openml-ada-agnostic-3896", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-ada-agnostic-3896-485", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 45, "mtry": 6, "num.trees": 660, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.909295576182194}}}], "metrics": 0.855327, "context": "openml-ada-agnostic-3896", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-ada-agnostic-3896-227", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 7, "mtry": 20, "num.trees": 974, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.161741153872572}}}], "metrics": 0.855107, "context": "openml-ada-agnostic-3896", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-ada-agnostic-3896-351", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 12, "mtry": 4, "num.trees": 1013, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.545870586461388}}}], "metrics": 0.855107, "context": "openml-ada-agnostic-3896", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-ada-agnostic-3896-229", "modules": [{"role": "dataset", "module": "openml-ada-agnostic-3896"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 12, "mtry": 9, "num.trees": 619, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.38135132798925}}}], "metrics": 0.854888, "context": "openml-ada-agnostic-3896", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-banknote-authentication-145834-373", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 11, "mtry": 3, "num.trees": 1569, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.978625929821283}}}], "metrics": 0.995627, "context": "openml-banknote-authentication-145834", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-banknote-authentication-145834-080", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 3, "num.trees": 1730, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.970147476345301}}}], "metrics": 0.994898, "context": "openml-banknote-authentication-145834", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-banknote-authentication-145834-467", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 3, "num.trees": 1443, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.997871207608841}}}], "metrics": 0.994169, "context": "openml-banknote-authentication-145834", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-banknote-authentication-145834-118", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 1, "num.trees": 1108, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.950048385420814}}}], "metrics": 0.994169, "context": "openml-banknote-authentication-145834", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-banknote-authentication-145834-156", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-145834"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 2, "num.trees": 1689, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.702799358335324}}}], "metrics": 0.994169, "context": "openml-banknote-authentication-145834", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-diabetes-37-507", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 2, "num.trees": 749, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.776056892191991}}}], "metrics": 0.782552, "context": "openml-diabetes-37", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-diabetes-37-161", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 6, "mtry": 2, "num.trees": 736, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.681664337520488}}}], "metrics": 0.782552, "context": "openml-diabetes-37", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-diabetes-37-312", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 2, "num.trees": 613, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.607707745814696}}}], "metrics": 0.78125, "context": "openml-diabetes-37", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-diabetes-37-350", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 6, "mtry": 2, "num.trees": 1934, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.24932298453058999}}}], "metrics": 0.78125, "context": "openml-diabetes-37", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-diabetes-37-081", "modules": [{"role": "dataset", "module": "openml-diabetes-37"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 6, "num.trees": 422, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.388507561804727}}}], "metrics": 0.778646, "context": "openml-diabetes-37", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-wilt-9889-234", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 5, "mtry": 5, "num.trees": 1069, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.498960825940594}}}], "metrics": 0.985328, "context": "openml-wilt-9889", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-wilt-9889-411", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 7, "mtry": 4, "num.trees": 590, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.741201859293506}}}], "metrics": 0.985328, "context": "openml-wilt-9889", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-wilt-9889-379", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 5, "num.trees": 440, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.402440885570832}}}], "metrics": 0.985121, "context": "openml-wilt-9889", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-wilt-9889-381", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 10, "mtry": 5, "num.trees": 1858, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.658196504809894}}}], "metrics": 0.985121, "context": "openml-wilt-9889", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-wilt-9889-473", "modules": [{"role": "dataset", "module": "openml-wilt-9889"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 903, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.700613792380318}}}], "metrics": 0.985121, "context": "openml-wilt-9889", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-phishingwebsites-14952-290", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-14952"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 13, "num.trees": 968, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.884767837566324}}}], "metrics": 0.973587, "context": "openml-phishingwebsites-14952", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-phishingwebsites-14952-332", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-14952"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 7, "num.trees": 1982, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.936677305260673}}}], "metrics": 0.973315, "context": "openml-phishingwebsites-14952", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-phishingwebsites-14952-498", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-14952"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 18, "num.trees": 1206, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.849299587355927}}}], "metrics": 0.973044, "context": "openml-phishingwebsites-14952", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-phishingwebsites-14952-058", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-14952"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 9, "num.trees": 1883, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.793416856788099}}}], "metrics": 0.973044, "context": "openml-phishingwebsites-14952", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-phishingwebsites-14952-074", "modules": [{"role": "dataset", "module": "openml-phishingwebsites-14952"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 11, "num.trees": 998, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.957567096734419}}}], "metrics": 0.972953, "context": "openml-phishingwebsites-14952", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-monks-problems-1-146064-001", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-146064"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 13, "mtry": 6, "num.trees": 886, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.787032808526419}}}], "metrics": 1.0, "context": "openml-monks-problems-1-146064", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-monks-problems-1-146064-381", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-146064"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 4, "mtry": 5, "num.trees": 497, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.766292875632644}}}], "metrics": 1.0, "context": "openml-monks-problems-1-146064", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-monks-problems-1-146064-406", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-146064"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 3, "num.trees": 525, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.527881787391379}}}], "metrics": 1.0, "context": "openml-monks-problems-1-146064", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-monks-problems-1-146064-075", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-146064"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 13, "mtry": 4, "num.trees": 817, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.726555200363509}}}], "metrics": 1.0, "context": "openml-monks-problems-1-146064", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-monks-problems-1-146064-403", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-146064"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 4, "num.trees": 214, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.447672465653159}}}], "metrics": 1.0, "context": "openml-monks-problems-1-146064", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-pc1-3918-418", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 18, "mtry": 12, "num.trees": 1045, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.570754671632312}}}], "metrics": 0.941389, "context": "openml-pc1-3918", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-pc1-3918-349", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 9, "mtry": 9, "num.trees": 256, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.600263801496476}}}], "metrics": 0.941389, "context": "openml-pc1-3918", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-pc1-3918-451", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 23, "mtry": 13, "num.trees": 1626, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.531655337591656}}}], "metrics": 0.941389, "context": "openml-pc1-3918", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-pc1-3918-406", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 30, "mtry": 5, "num.trees": 1676, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.74381090560928}}}], "metrics": 0.940487, "context": "openml-pc1-3918", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-pc1-3918-065", "modules": [{"role": "dataset", "module": "openml-pc1-3918"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 16, "mtry": 15, "num.trees": 372, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.590212182980031}}}], "metrics": 0.940487, "context": "openml-pc1-3918", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-monks-problems-2-146065-176", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-146065"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 6, "num.trees": 1405, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.935869343858212}}}], "metrics": 1.0, "context": "openml-monks-problems-2-146065", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-monks-problems-2-146065-169", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-146065"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 4, "num.trees": 1270, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.873473642137833}}}], "metrics": 1.0, "context": "openml-monks-problems-2-146065", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-monks-problems-2-146065-512", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-146065"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 5, "num.trees": 1812, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.723043383681215}}}], "metrics": 1.0, "context": "openml-monks-problems-2-146065", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-monks-problems-2-146065-092", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-146065"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 4, "num.trees": 758, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.782561136316508}}}], "metrics": 1.0, "context": "openml-monks-problems-2-146065", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-monks-problems-2-146065-509", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-146065"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 6, "num.trees": 727, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.910131325060502}}}], "metrics": 1.0, "context": "openml-monks-problems-2-146065", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-qsar-biodeg-145862-312", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 34, "num.trees": 263, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.34738219792489}}}], "metrics": 0.873934, "context": "openml-qsar-biodeg-145862", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-qsar-biodeg-145862-469", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 26, "num.trees": 794, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.488320171274245}}}], "metrics": 0.872986, "context": "openml-qsar-biodeg-145862", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-qsar-biodeg-145862-133", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 29, "num.trees": 898, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.859735338017344}}}], "metrics": 0.872986, "context": "openml-qsar-biodeg-145862", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-qsar-biodeg-145862-167", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 41, "num.trees": 101, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.2540912872646}}}], "metrics": 0.872038, "context": "openml-qsar-biodeg-145862", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-qsar-biodeg-145862-141", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-145862"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 47, "mtry": 41, "num.trees": 510, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.687692180462182}}}], "metrics": 0.872038, "context": "openml-qsar-biodeg-145862", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-hill-valley-9970-008", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 24, "num.trees": 1178, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.919234101031907}}}], "metrics": 0.59901, "context": "openml-hill-valley-9970", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-hill-valley-9970-530", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 45, "num.trees": 166, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.664526956249028}}}], "metrics": 0.598185, "context": "openml-hill-valley-9970", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-hill-valley-9970-420", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 56, "num.trees": 40, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.733949775900692}}}], "metrics": 0.596535, "context": "openml-hill-valley-9970", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-hill-valley-9970-580", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 65, "num.trees": 988, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.691743954946287}}}], "metrics": 0.596535, "context": "openml-hill-valley-9970", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-hill-valley-9970-457", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 8, "num.trees": 853, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.813312427559868}}}], "metrics": 0.594059, "context": "openml-hill-valley-9970", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-pc4-3902-449", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 36, "num.trees": 348, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.781327160913497}}}], "metrics": 0.915638, "context": "openml-pc4-3902", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-pc4-3902-114", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 14, "num.trees": 683, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.970501329912804}}}], "metrics": 0.914952, "context": "openml-pc4-3902", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-pc4-3902-061", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 15, "num.trees": 341, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.707912478526123}}}], "metrics": 0.912894, "context": "openml-pc4-3902", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-pc4-3902-217", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 5, "mtry": 28, "num.trees": 389, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.648160319472663}}}], "metrics": 0.912209, "context": "openml-pc4-3902", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-pc4-3902-195", "modules": [{"role": "dataset", "module": "openml-pc4-3902"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 18, "num.trees": 1755, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.853503582649864}}}], "metrics": 0.912209, "context": "openml-pc4-3902", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-monks-problems-2-3493-427", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 6, "num.trees": 478, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.696524857566692}}}], "metrics": 1.0, "context": "openml-monks-problems-2-3493", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-monks-problems-2-3493-028", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 4, "mtry": 5, "num.trees": 727, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.898365459404886}}}], "metrics": 1.0, "context": "openml-monks-problems-2-3493", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-monks-problems-2-3493-206", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 6, "num.trees": 869, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.661492204177193}}}], "metrics": 1.0, "context": "openml-monks-problems-2-3493", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-monks-problems-2-3493-432", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 4, "num.trees": 1829, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.860189231694676}}}], "metrics": 1.0, "context": "openml-monks-problems-2-3493", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-monks-problems-2-3493-024", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 4, "mtry": 3, "num.trees": 1208, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.897819709288888}}}], "metrics": 1.0, "context": "openml-monks-problems-2-3493", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-amazon-employee-access-9911-286", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-9911"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 5, "num.trees": 173, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.657893129996955}}}], "metrics": 0.952516, "context": "openml-amazon-employee-access-9911", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-amazon-employee-access-9911-014", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-9911"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 4, "mtry": 4, "num.trees": 1803, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.5934603278292341}}}], "metrics": 0.952333, "context": "openml-amazon-employee-access-9911", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-amazon-employee-access-9911-455", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-9911"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 11, "mtry": 5, "num.trees": 826, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.880304237757809}}}], "metrics": 0.952211, "context": "openml-amazon-employee-access-9911", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-amazon-employee-access-9911-467", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-9911"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 367, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.909505134029314}}}], "metrics": 0.95218, "context": "openml-amazon-employee-access-9911", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-amazon-employee-access-9911-027", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-9911"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 8, "num.trees": 1182, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.471064292732626}}}], "metrics": 0.952119, "context": "openml-amazon-employee-access-9911", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-electricity-219-505", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 6, "num.trees": 1479, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.90899003946688}}}], "metrics": 0.933505, "context": "openml-electricity-219", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-electricity-219-536", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 7, "num.trees": 231, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.89665510985069}}}], "metrics": 0.931475, "context": "openml-electricity-219", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-electricity-219-614", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 6, "mtry": 6, "num.trees": 1412, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.989774916321039}}}], "metrics": 0.931321, "context": "openml-electricity-219", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-electricity-219-014", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 5, "mtry": 6, "num.trees": 1413, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.827695389930159}}}], "metrics": 0.930636, "context": "openml-electricity-219", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-electricity-219-045", "modules": [{"role": "dataset", "module": "openml-electricity-219"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 1140, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.930477916193195}}}], "metrics": 0.930195, "context": "openml-electricity-219", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-magictelescope-3954-627", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 2, "num.trees": 848, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.980234607937746}}}], "metrics": 0.883859, "context": "openml-magictelescope-3954", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-magictelescope-3954-011", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 2, "num.trees": 1668, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.752523158653639}}}], "metrics": 0.883701, "context": "openml-magictelescope-3954", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-magictelescope-3954-578", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 2, "num.trees": 460, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.821237128716893}}}], "metrics": 0.883333, "context": "openml-magictelescope-3954", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-magictelescope-3954-580", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 2, "num.trees": 304, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.937932900316082}}}], "metrics": 0.883281, "context": "openml-magictelescope-3954", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-magictelescope-3954-232", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 2, "num.trees": 621, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.58576339755673}}}], "metrics": 0.883123, "context": "openml-magictelescope-3954", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-eeg-eye-state-14951-245", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 5, "mtry": 4, "num.trees": 1259, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.99716949458234}}}], "metrics": 0.94219, "context": "openml-eeg-eye-state-14951", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-eeg-eye-state-14951-236", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 4, "mtry": 6, "num.trees": 1651, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.951651146542281}}}], "metrics": 0.941522, "context": "openml-eeg-eye-state-14951", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-eeg-eye-state-14951-230", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 5, "num.trees": 1851, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.812433952558786}}}], "metrics": 0.940721, "context": "openml-eeg-eye-state-14951", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-eeg-eye-state-14951-442", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 5, "mtry": 5, "num.trees": 1585, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.932163004158065}}}], "metrics": 0.940587, "context": "openml-eeg-eye-state-14951", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-eeg-eye-state-14951-475", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-14951"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 6, "num.trees": 1508, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.762888477020897}}}], "metrics": 0.939853, "context": "openml-eeg-eye-state-14951", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-bioresponse-145677-170", "modules": [{"role": "dataset", "module": "openml-bioresponse-145677"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 12, "mtry": 143, "num.trees": 242, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.906991483829916}}}], "metrics": 0.814183, "context": "openml-bioresponse-145677", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-bioresponse-145677-290", "modules": [{"role": "dataset", "module": "openml-bioresponse-145677"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 240, "num.trees": 1639, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.708657065825537}}}], "metrics": 0.813916, "context": "openml-bioresponse-145677", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-bioresponse-145677-117", "modules": [{"role": "dataset", "module": "openml-bioresponse-145677"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 14, "mtry": 268, "num.trees": 1832, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.959127533854917}}}], "metrics": 0.81365, "context": "openml-bioresponse-145677", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-bioresponse-145677-115", "modules": [{"role": "dataset", "module": "openml-bioresponse-145677"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 10, "mtry": 275, "num.trees": 1635, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.991924377647229}}}], "metrics": 0.813383, "context": "openml-bioresponse-145677", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-bioresponse-145677-395", "modules": [{"role": "dataset", "module": "openml-bioresponse-145677"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 4, "mtry": 375, "num.trees": 300, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.524190013762563}}}], "metrics": 0.813383, "context": "openml-bioresponse-145677", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-amazon-employee-access-34539-490", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-34539"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 1356, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.821058769151568}}}], "metrics": 0.952486, "context": "openml-amazon-employee-access-34539", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-amazon-employee-access-34539-050", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-34539"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 6, "num.trees": 1807, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.850258877733722}}}], "metrics": 0.952394, "context": "openml-amazon-employee-access-34539", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-amazon-employee-access-34539-589", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-34539"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 4, "mtry": 3, "num.trees": 946, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.727316118753515}}}], "metrics": 0.952394, "context": "openml-amazon-employee-access-34539", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-amazon-employee-access-34539-320", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-34539"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 5, "num.trees": 761, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.988671321421862}}}], "metrics": 0.952394, "context": "openml-amazon-employee-access-34539", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-amazon-employee-access-34539-617", "modules": [{"role": "dataset", "module": "openml-amazon-employee-access-34539"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 6, "num.trees": 1056, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.937494431016967}}}], "metrics": 0.952364, "context": "openml-amazon-employee-access-34539", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-banknote-authentication-10093-156", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 2, "num.trees": 123, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.816971332603134}}}], "metrics": 0.994898, "context": "openml-banknote-authentication-10093", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-banknote-authentication-10093-491", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 9, "mtry": 3, "num.trees": 168, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.969457927765325}}}], "metrics": 0.994898, "context": "openml-banknote-authentication-10093", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-banknote-authentication-10093-588", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 10, "mtry": 1, "num.trees": 75, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.960001602908596}}}], "metrics": 0.994898, "context": "openml-banknote-authentication-10093", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-banknote-authentication-10093-485", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 2, "num.trees": 731, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.734431239543483}}}], "metrics": 0.994169, "context": "openml-banknote-authentication-10093", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-banknote-authentication-10093-261", "modules": [{"role": "dataset", "module": "openml-banknote-authentication-10093"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 6, "mtry": 3, "num.trees": 235, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.922455621394329}}}], "metrics": 0.994169, "context": "openml-banknote-authentication-10093", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-phoneme-145857-178", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 2, "num.trees": 969, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.759391054580919}}}], "metrics": 0.915618, "context": "openml-phoneme-145857", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-phoneme-145857-224", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 1, "num.trees": 887, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.992067455477081}}}], "metrics": 0.914878, "context": "openml-phoneme-145857", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-phoneme-145857-584", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 3, "num.trees": 414, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.692493598628789}}}], "metrics": 0.913397, "context": "openml-phoneme-145857", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-phoneme-145857-676", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 6, "mtry": 2, "num.trees": 1057, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.928494033496827}}}], "metrics": 0.913212, "context": "openml-phoneme-145857", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-phoneme-145857-055", "modules": [{"role": "dataset", "module": "openml-phoneme-145857"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 4, "num.trees": 337, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.929782657860778}}}], "metrics": 0.913212, "context": "openml-phoneme-145857", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-tic-tac-toe-49-385", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 4, "mtry": 5, "num.trees": 1391, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.946960608381778}}}], "metrics": 0.993737, "context": "openml-tic-tac-toe-49", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-tic-tac-toe-49-180", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 6, "num.trees": 873, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.728127024299465}}}], "metrics": 0.993737, "context": "openml-tic-tac-toe-49", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-tic-tac-toe-49-344", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 958, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.883633856382221}}}], "metrics": 0.993737, "context": "openml-tic-tac-toe-49", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-tic-tac-toe-49-266", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 347, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.874553890293464}}}], "metrics": 0.993737, "context": "openml-tic-tac-toe-49", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-tic-tac-toe-49-188", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-49"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 3, "num.trees": 529, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.878919378458522}}}], "metrics": 0.993737, "context": "openml-tic-tac-toe-49", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-nomao-9977-395", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 32, "num.trees": 337, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.908697090274654}}}], "metrics": 0.970173, "context": "openml-nomao-9977", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-nomao-9977-013", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 47, "num.trees": 969, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.759391054580919}}}], "metrics": 0.970144, "context": "openml-nomao-9977", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-nomao-9977-603", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 17, "num.trees": 821, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.761850238125771}}}], "metrics": 0.970028, "context": "openml-nomao-9977", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-nomao-9977-385", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 5, "mtry": 13, "num.trees": 1760, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.912413726514205}}}], "metrics": 0.969882, "context": "openml-nomao-9977", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-nomao-9977-569", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 7, "mtry": 48, "num.trees": 1284, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.870599457575008}}}], "metrics": 0.969795, "context": "openml-nomao-9977", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-gina-agnostic-3891-646", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 4, "mtry": 90, "num.trees": 1684, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.988718724856153}}}], "metrics": 0.948097, "context": "openml-gina-agnostic-3891", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-gina-agnostic-3891-662", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 12, "mtry": 76, "num.trees": 1728, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.998636619118042}}}], "metrics": 0.945213, "context": "openml-gina-agnostic-3891", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-gina-agnostic-3891-348", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 12, "mtry": 46, "num.trees": 909, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.912218140042387}}}], "metrics": 0.944637, "context": "openml-gina-agnostic-3891", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-gina-agnostic-3891-001", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 6, "mtry": 117, "num.trees": 1099, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.94747951189056}}}], "metrics": 0.944348, "context": "openml-gina-agnostic-3891", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-gina-agnostic-3891-774", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 18, "mtry": 56, "num.trees": 1789, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.97846188864205}}}], "metrics": 0.943772, "context": "openml-gina-agnostic-3891", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-scene-3485-082", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 268, "num.trees": 186, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.632447413518094}}}], "metrics": 0.96801, "context": "openml-scene-3485", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-scene-3485-184", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 9, "mtry": 298, "num.trees": 1183, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.978779312362894}}}], "metrics": 0.967595, "context": "openml-scene-3485", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-scene-3485-463", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 14, "mtry": 274, "num.trees": 449, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.968433001218364}}}], "metrics": 0.967595, "context": "openml-scene-3485", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-scene-3485-772", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 10, "mtry": 293, "num.trees": 727, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.5876260370714591}}}], "metrics": 0.967595, "context": "openml-scene-3485", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-scene-3485-781", "modules": [{"role": "dataset", "module": "openml-scene-3485"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 270, "num.trees": 625, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.53587630414404}}}], "metrics": 0.967595, "context": "openml-scene-3485", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-kc2-3913-228", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 15, "num.trees": 398, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.167711258493364}}}], "metrics": 0.85249, "context": "openml-kc2-3913", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-kc2-3913-604", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 9, "mtry": 13, "num.trees": 1941, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.313976615690626}}}], "metrics": 0.85249, "context": "openml-kc2-3913", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-kc2-3913-221", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 8, "mtry": 18, "num.trees": 1949, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.284148663375527}}}], "metrics": 0.85249, "context": "openml-kc2-3913", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-kc2-3913-722", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 13, "mtry": 1, "num.trees": 375, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.416323139239103}}}], "metrics": 0.850575, "context": "openml-kc2-3913", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-kc2-3913-519", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 4, "mtry": 2, "num.trees": 1378, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.301870246324688}}}], "metrics": 0.850575, "context": "openml-kc2-3913", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-credit-g-31-650", "modules": [{"role": "dataset", "module": "openml-credit-g-31"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 14, "num.trees": 668, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.25543968717102}}}], "metrics": 0.777, "context": "openml-credit-g-31", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-credit-g-31-210", "modules": [{"role": "dataset", "module": "openml-credit-g-31"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 5, "mtry": 15, "num.trees": 646, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.463333934592083}}}], "metrics": 0.777, "context": "openml-credit-g-31", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-credit-g-31-418", "modules": [{"role": "dataset", "module": "openml-credit-g-31"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 12, "mtry": 8, "num.trees": 1624, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.774834422837012}}}], "metrics": 0.776, "context": "openml-credit-g-31", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-credit-g-31-667", "modules": [{"role": "dataset", "module": "openml-credit-g-31"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 17, "mtry": 9, "num.trees": 1476, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.931164394691587}}}], "metrics": 0.776, "context": "openml-credit-g-31", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-credit-g-31-327", "modules": [{"role": "dataset", "module": "openml-credit-g-31"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 7, "mtry": 13, "num.trees": 437, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.467654967447743}}}], "metrics": 0.776, "context": "openml-credit-g-31", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-monks-problems-1-3492-389", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 3, "num.trees": 83, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.840185955981724}}}], "metrics": 1.0, "context": "openml-monks-problems-1-3492", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-monks-problems-1-3492-668", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 5, "num.trees": 1953, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.563909433456138}}}], "metrics": 1.0, "context": "openml-monks-problems-1-3492", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-monks-problems-1-3492-506", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 5, "num.trees": 1579, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.576416251598857}}}], "metrics": 1.0, "context": "openml-monks-problems-1-3492", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-monks-problems-1-3492-117", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 4, "mtry": 6, "num.trees": 230, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.639165062992834}}}], "metrics": 1.0, "context": "openml-monks-problems-1-3492", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-monks-problems-1-3492-507", "modules": [{"role": "dataset", "module": "openml-monks-problems-1-3492"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 4, "num.trees": 271, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.94684237933252}}}], "metrics": 1.0, "context": "openml-monks-problems-1-3492", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-credit-g-146803-404", "modules": [{"role": "dataset", "module": "openml-credit-g-146803"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 13, "mtry": 7, "num.trees": 259, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.743510471587069}}}], "metrics": 0.779, "context": "openml-credit-g-146803", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-credit-g-146803-139", "modules": [{"role": "dataset", "module": "openml-credit-g-146803"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 6, "num.trees": 85, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.832115479698405}}}], "metrics": 0.778, "context": "openml-credit-g-146803", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-credit-g-146803-493", "modules": [{"role": "dataset", "module": "openml-credit-g-146803"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 11, "mtry": 10, "num.trees": 951, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.503306823247112}}}], "metrics": 0.777, "context": "openml-credit-g-146803", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-credit-g-146803-085", "modules": [{"role": "dataset", "module": "openml-credit-g-146803"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 9, "mtry": 12, "num.trees": 1039, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.659584432723932}}}], "metrics": 0.777, "context": "openml-credit-g-146803", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-credit-g-146803-797", "modules": [{"role": "dataset", "module": "openml-credit-g-146803"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 13, "mtry": 13, "num.trees": 1736, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.659000616613776}}}], "metrics": 0.776, "context": "openml-credit-g-146803", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-monks-problems-3-3494-001", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 21, "mtry": 5, "num.trees": 549, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.653201653482392}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-monks-problems-3-3494-092", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 5, "mtry": 4, "num.trees": 52, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.633253577421419}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-monks-problems-3-3494-329", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 12, "mtry": 3, "num.trees": 1328, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.467690111929551}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-monks-problems-3-3494-737", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 5, "num.trees": 313, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.137910624477081}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-monks-problems-3-3494-736", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 9, "mtry": 5, "num.trees": 7, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.514374113641679}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-blood-transfusion-service-center-10101-206", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 16, "mtry": 2, "num.trees": 704, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.155169538734481}}}], "metrics": 0.795455, "context": "openml-blood-transfusion-service-center-10101", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-blood-transfusion-service-center-10101-552", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 14, "mtry": 4, "num.trees": 635, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.223197030508891}}}], "metrics": 0.794118, "context": "openml-blood-transfusion-service-center-10101", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-blood-transfusion-service-center-10101-805", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 44, "mtry": 4, "num.trees": 1110, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.350957642053254}}}], "metrics": 0.794118, "context": "openml-blood-transfusion-service-center-10101", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-blood-transfusion-service-center-10101-836", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 5, "mtry": 3, "num.trees": 1184, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.134128950326703}}}], "metrics": 0.794118, "context": "openml-blood-transfusion-service-center-10101", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-blood-transfusion-service-center-10101-740", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 14, "mtry": 3, "num.trees": 963, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.22876168445218398}}}], "metrics": 0.794118, "context": "openml-blood-transfusion-service-center-10101", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-ozone-level-8hr-9978-383", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 23, "mtry": 68, "num.trees": 433, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.732360297581181}}}], "metrics": 0.945146, "context": "openml-ozone-level-8hr-9978", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-ozone-level-8hr-9978-718", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 49, "num.trees": 181, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.769672940322198}}}], "metrics": 0.945146, "context": "openml-ozone-level-8hr-9978", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-ozone-level-8hr-9978-231", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 6, "mtry": 72, "num.trees": 46, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.981476874300279}}}], "metrics": 0.945146, "context": "openml-ozone-level-8hr-9978", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-ozone-level-8hr-9978-190", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 55, "num.trees": 135, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.559856507927179}}}], "metrics": 0.945146, "context": "openml-ozone-level-8hr-9978", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-ozone-level-8hr-9978-625", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 9, "num.trees": 1471, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.88990347343497}}}], "metrics": 0.945146, "context": "openml-ozone-level-8hr-9978", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-ozone-level-8hr-145855-752", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 7, "mtry": 34, "num.trees": 1656, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.675286581134424}}}], "metrics": 0.944751, "context": "openml-ozone-level-8hr-145855", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-ozone-level-8hr-145855-480", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 14, "mtry": 20, "num.trees": 1953, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.671046712133102}}}], "metrics": 0.944751, "context": "openml-ozone-level-8hr-145855", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-ozone-level-8hr-145855-322", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 6, "num.trees": 1262, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.457766249962151}}}], "metrics": 0.944751, "context": "openml-ozone-level-8hr-145855", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-ozone-level-8hr-145855-366", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 59, "num.trees": 1876, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.686851796181873}}}], "metrics": 0.944751, "context": "openml-ozone-level-8hr-145855", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-ozone-level-8hr-145855-286", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-145855"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 12, "mtry": 20, "num.trees": 1898, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.525587477558292}}}], "metrics": 0.944751, "context": "openml-ozone-level-8hr-145855", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-wdbc-9946-068", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 5, "num.trees": 1939, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.975024063419551}}}], "metrics": 0.970123, "context": "openml-wdbc-9946", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-wdbc-9946-840", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 6, "num.trees": 1351, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.882329746871255}}}], "metrics": 0.968366, "context": "openml-wdbc-9946", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-wdbc-9946-112", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 5, "num.trees": 94, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.723283789865673}}}], "metrics": 0.968366, "context": "openml-wdbc-9946", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-wdbc-9946-653", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 7, "num.trees": 716, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.971884871996008}}}], "metrics": 0.968366, "context": "openml-wdbc-9946", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-wdbc-9946-652", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 12, "num.trees": 1259, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.734940750920214}}}], "metrics": 0.968366, "context": "openml-wdbc-9946", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-spambase-145979-619", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 5, "num.trees": 283, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.930377499316819}}}], "metrics": 0.953923, "context": "openml-spambase-145979", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-spambase-145979-648", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 7, "num.trees": 671, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.936104561225511}}}], "metrics": 0.953706, "context": "openml-spambase-145979", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-spambase-145979-042", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 13, "num.trees": 233, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.719124423596077}}}], "metrics": 0.952836, "context": "openml-spambase-145979", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-spambase-145979-479", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 19, "num.trees": 1548, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.826275736512616}}}], "metrics": 0.952836, "context": "openml-spambase-145979", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-spambase-145979-882", "modules": [{"role": "dataset", "module": "openml-spambase-145979"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 6, "num.trees": 28, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.707602308504283}}}], "metrics": 0.952619, "context": "openml-spambase-145979", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-bioresponse-14966-057", "modules": [{"role": "dataset", "module": "openml-bioresponse-14966"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 227, "num.trees": 1866, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.873719548946246}}}], "metrics": 0.813383, "context": "openml-bioresponse-14966", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-bioresponse-14966-437", "modules": [{"role": "dataset", "module": "openml-bioresponse-14966"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 5, "mtry": 337, "num.trees": 1007, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.548671534564346}}}], "metrics": 0.813117, "context": "openml-bioresponse-14966", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-bioresponse-14966-795", "modules": [{"role": "dataset", "module": "openml-bioresponse-14966"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 4, "mtry": 134, "num.trees": 1143, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.726819257345051}}}], "metrics": 0.813117, "context": "openml-bioresponse-14966", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-bioresponse-14966-189", "modules": [{"role": "dataset", "module": "openml-bioresponse-14966"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 4, "mtry": 182, "num.trees": 1646, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.983935431716964}}}], "metrics": 0.813117, "context": "openml-bioresponse-14966", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-bioresponse-14966-475", "modules": [{"role": "dataset", "module": "openml-bioresponse-14966"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 18, "mtry": 237, "num.trees": 1724, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.819778320076875}}}], "metrics": 0.81285, "context": "openml-bioresponse-14966", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-diabetes-145976-848", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 5, "num.trees": 237, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.250406189193018}}}], "metrics": 0.78125, "context": "openml-diabetes-145976", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-diabetes-145976-949", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 8, "mtry": 4, "num.trees": 217, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.727805759990588}}}], "metrics": 0.78125, "context": "openml-diabetes-145976", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-diabetes-145976-486", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 2, "num.trees": 900, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.545220489404164}}}], "metrics": 0.779948, "context": "openml-diabetes-145976", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-diabetes-145976-334", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 4, "mtry": 4, "num.trees": 287, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.539231396629475}}}], "metrics": 0.778646, "context": "openml-diabetes-145976", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-diabetes-145976-150", "modules": [{"role": "dataset", "module": "openml-diabetes-145976"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 5, "mtry": 2, "num.trees": 763, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.275085888151079}}}], "metrics": 0.777344, "context": "openml-diabetes-145976", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-kc1-3917-965", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 21, "num.trees": 1048, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.416082988074049}}}], "metrics": 0.869132, "context": "openml-kc1-3917", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-kc1-3917-188", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 4, "mtry": 10, "num.trees": 454, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.392350208433345}}}], "metrics": 0.869132, "context": "openml-kc1-3917", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-kc1-3917-855", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 1, "num.trees": 1633, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.73964478939306}}}], "metrics": 0.868184, "context": "openml-kc1-3917", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-kc1-3917-297", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 13, "num.trees": 1659, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.360110843763687}}}], "metrics": 0.868184, "context": "openml-kc1-3917", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-kc1-3917-969", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 19, "num.trees": 1905, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.542955696233548}}}], "metrics": 0.86771, "context": "openml-kc1-3917", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-hill-valley-145847-295", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 28, "num.trees": 401, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.951114067924209}}}], "metrics": 0.60396, "context": "openml-hill-valley-145847", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-hill-valley-145847-666", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 14, "num.trees": 1134, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.783513994212262}}}], "metrics": 0.60396, "context": "openml-hill-valley-145847", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-hill-valley-145847-114", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 35, "num.trees": 686, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.840658442815766}}}], "metrics": 0.59901, "context": "openml-hill-valley-145847", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-hill-valley-145847-1000", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 73, "num.trees": 1044, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.703176636598073}}}], "metrics": 0.598185, "context": "openml-hill-valley-145847", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-hill-valley-145847-200", "modules": [{"role": "dataset", "module": "openml-hill-valley-145847"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 30, "num.trees": 1205, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.850192879675888}}}], "metrics": 0.59736, "context": "openml-hill-valley-145847", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-madelon-9976-761", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 179, "num.trees": 668, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.935508782044053}}}], "metrics": 0.868077, "context": "openml-madelon-9976", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-madelon-9976-235", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 35, "mtry": 139, "num.trees": 1069, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.930120643018745}}}], "metrics": 0.866923, "context": "openml-madelon-9976", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-madelon-9976-639", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 190, "num.trees": 377, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.832311713462696}}}], "metrics": 0.866154, "context": "openml-madelon-9976", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-madelon-9976-990", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 156, "num.trees": 1388, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.814734656945802}}}], "metrics": 0.865385, "context": "openml-madelon-9976", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-madelon-9976-721", "modules": [{"role": "dataset", "module": "openml-madelon-9976"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 192, "num.trees": 1480, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.80438510326203}}}], "metrics": 0.865, "context": "openml-madelon-9976", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-tic-tac-toe-145804-159", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-145804"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 3, "num.trees": 1558, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.827082970156334}}}], "metrics": 0.993737, "context": "openml-tic-tac-toe-145804", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-tic-tac-toe-145804-186", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-145804"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 4, "num.trees": 1903, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.761292303027585}}}], "metrics": 0.993737, "context": "openml-tic-tac-toe-145804", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-tic-tac-toe-145804-573", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-145804"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 4, "num.trees": 1425, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.945903867902234}}}], "metrics": 0.993737, "context": "openml-tic-tac-toe-145804", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-tic-tac-toe-145804-434", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-145804"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 4, "mtry": 4, "num.trees": 556, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.811150639387779}}}], "metrics": 0.993737, "context": "openml-tic-tac-toe-145804", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-tic-tac-toe-145804-1032", "modules": [{"role": "dataset", "module": "openml-tic-tac-toe-145804"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 4, "num.trees": 1135, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.842684325971641}}}], "metrics": 0.993737, "context": "openml-tic-tac-toe-145804", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-kr-vs-kp-145953-501", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 28, "num.trees": 895, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.986969374725595}}}], "metrics": 0.997184, "context": "openml-kr-vs-kp-145953", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-kr-vs-kp-145953-664", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 34, "num.trees": 604, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.850261852052063}}}], "metrics": 0.997184, "context": "openml-kr-vs-kp-145953", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-kr-vs-kp-145953-814", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 33, "num.trees": 686, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.993259252933785}}}], "metrics": 0.997184, "context": "openml-kr-vs-kp-145953", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-kr-vs-kp-145953-486", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 30, "num.trees": 1581, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.872668841131963}}}], "metrics": 0.997184, "context": "openml-kr-vs-kp-145953", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-kr-vs-kp-145953-064", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-145953"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 24, "num.trees": 493, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.863134412025101}}}], "metrics": 0.996871, "context": "openml-kr-vs-kp-145953", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-ilpd-145848-518", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 1, "num.trees": 855, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.710016266652383}}}], "metrics": 0.730703, "context": "openml-ilpd-145848", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-ilpd-145848-480", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 9, "mtry": 1, "num.trees": 747, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.935040023061447}}}], "metrics": 0.727273, "context": "openml-ilpd-145848", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-ilpd-145848-162", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 6, "mtry": 1, "num.trees": 1730, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.839452287368476}}}], "metrics": 0.725557, "context": "openml-ilpd-145848", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-ilpd-145848-347", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 1, "num.trees": 846, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.922412882279605}}}], "metrics": 0.725557, "context": "openml-ilpd-145848", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-ilpd-145848-316", "modules": [{"role": "dataset", "module": "openml-ilpd-145848"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 3, "mtry": 1, "num.trees": 1620, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.557995852828026}}}], "metrics": 0.725557, "context": "openml-ilpd-145848", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-kr-vs-kp-3-1096", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 33, "num.trees": 1570, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.955039792205207}}}], "metrics": 0.997184, "context": "openml-kr-vs-kp-3", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-kr-vs-kp-3-397", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 22, "num.trees": 1792, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.985213753883727}}}], "metrics": 0.997184, "context": "openml-kr-vs-kp-3", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-kr-vs-kp-3-248", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 27, "num.trees": 1272, "replace": false, "respect.unordered.factors": true, "sample.fraction": 0.8799624388339}}}], "metrics": 0.997184, "context": "openml-kr-vs-kp-3", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-kr-vs-kp-3-1052", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 28, "num.trees": 1545, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.835335516254418}}}], "metrics": 0.997184, "context": "openml-kr-vs-kp-3", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-kr-vs-kp-3-564", "modules": [{"role": "dataset", "module": "openml-kr-vs-kp-3"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 1, "mtry": 35, "num.trees": 1560, "replace": false, "respect.unordered.factors": false, "sample.fraction": 0.975359175889753}}}], "metrics": 0.996871, "context": "openml-kr-vs-kp-3", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-credit-g-145972-098", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 15, "mtry": 15, "num.trees": 1668, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.991525299730711}}}], "metrics": 0.778, "context": "openml-credit-g-145972", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-credit-g-145972-666", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 13, "mtry": 17, "num.trees": 180, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.603968364861794}}}], "metrics": 0.778, "context": "openml-credit-g-145972", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-credit-g-145972-641", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 2, "mtry": 16, "num.trees": 308, "replace": true, "respect.unordered.factors": false, "sample.fraction": 0.483924275450409}}}], "metrics": 0.778, "context": "openml-credit-g-145972", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-credit-g-145972-1074", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 14, "mtry": 7, "num.trees": 1291, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.73595849731937}}}], "metrics": 0.778, "context": "openml-credit-g-145972", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-7609-openml-credit-g-145972-208", "modules": [{"role": "dataset", "module": "openml-credit-g-145972"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-7609", "config": {"min.node.size": 16, "mtry": 17, "num.trees": 997, "replace": true, "respect.unordered.factors": true, "sample.fraction": 0.479848857712932}}}], "metrics": 0.777, "context": "openml-credit-g-145972", "schema": "ranger-7609", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-click-prediction-small-14971-009", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 6, "num.trees": 84, "replace": true, "sample.fraction": 0.332975279237144}}}], "metrics": 0.834084, "context": "openml-click-prediction-small-14971", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-click-prediction-small-14971-012", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 3, "num.trees": 174, "replace": true, "sample.fraction": 0.632652994571254}}}], "metrics": 0.833909, "context": "openml-click-prediction-small-14971", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-click-prediction-small-14971-013", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 7, "num.trees": 149, "replace": true, "sample.fraction": 0.50898595910985}}}], "metrics": 0.833809, "context": "openml-click-prediction-small-14971", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-click-prediction-small-14971-005", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 7, "num.trees": 79, "replace": false, "sample.fraction": 0.170189496409148}}}], "metrics": 0.833709, "context": "openml-click-prediction-small-14971", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-click-prediction-small-14971-003", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-14971"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 2, "num.trees": 31, "replace": false, "sample.fraction": 0.827893365034834}}}], "metrics": 0.832808, "context": "openml-click-prediction-small-14971", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-eeg-eye-state-9983-005", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 9, "num.trees": 250, "replace": true, "sample.fraction": 0.582588484557346}}}], "metrics": 0.918558, "context": "openml-eeg-eye-state-9983", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-eeg-eye-state-9983-004", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 8, "num.trees": 254, "replace": false, "sample.fraction": 0.425671584182419}}}], "metrics": 0.915087, "context": "openml-eeg-eye-state-9983", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-eeg-eye-state-9983-016", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 12, "num.trees": 257, "replace": true, "sample.fraction": 0.545755154453218}}}], "metrics": 0.914953, "context": "openml-eeg-eye-state-9983", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-eeg-eye-state-9983-002", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 9, "num.trees": 17, "replace": true, "sample.fraction": 0.870788089581765}}}], "metrics": 0.911081, "context": "openml-eeg-eye-state-9983", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-eeg-eye-state-9983-008", "modules": [{"role": "dataset", "module": "openml-eeg-eye-state-9983"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 2, "num.trees": 83, "replace": true, "sample.fraction": 0.648862784146331}}}], "metrics": 0.910347, "context": "openml-eeg-eye-state-9983", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-magictelescope-3954-005", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 7, "num.trees": 100, "replace": true, "sample.fraction": 0.715629280405119}}}], "metrics": 0.879443, "context": "openml-magictelescope-3954", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-magictelescope-3954-017", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 10, "num.trees": 403, "replace": true, "sample.fraction": 0.659921359247528}}}], "metrics": 0.879338, "context": "openml-magictelescope-3954", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-magictelescope-3954-025", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 9, "num.trees": 998, "replace": true, "sample.fraction": 0.451844692067243}}}], "metrics": 0.878391, "context": "openml-magictelescope-3954", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-magictelescope-3954-011", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 8, "num.trees": 216, "replace": false, "sample.fraction": 0.671374686574563}}}], "metrics": 0.878128, "context": "openml-magictelescope-3954", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-magictelescope-3954-009", "modules": [{"role": "dataset", "module": "openml-magictelescope-3954"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 10, "num.trees": 282, "replace": true, "sample.fraction": 0.42053396725095804}}}], "metrics": 0.877813, "context": "openml-magictelescope-3954", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-nomao-9977-022", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 22, "num.trees": 52, "replace": false, "sample.fraction": 0.9337609377224}}}], "metrics": 0.968519, "context": "openml-nomao-9977", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-nomao-9977-017", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 75, "num.trees": 93, "replace": true, "sample.fraction": 0.946340253250673}}}], "metrics": 0.96759, "context": "openml-nomao-9977", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-nomao-9977-012", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 24, "num.trees": 187, "replace": true, "sample.fraction": 0.782396663259715}}}], "metrics": 0.967039, "context": "openml-nomao-9977", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-nomao-9977-015", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 29, "num.trees": 218, "replace": false, "sample.fraction": 0.544591762218624}}}], "metrics": 0.966749, "context": "openml-nomao-9977", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-nomao-9977-009", "modules": [{"role": "dataset", "module": "openml-nomao-9977"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 22, "num.trees": 216, "replace": false, "sample.fraction": 0.5537991960998628}}}], "metrics": 0.966691, "context": "openml-nomao-9977", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-click-prediction-small-7295-001", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 2, "num.trees": 164, "replace": true, "sample.fraction": 0.420604197541252}}}], "metrics": 0.835161, "context": "openml-click-prediction-small-7295", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-click-prediction-small-7295-021", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 4, "num.trees": 325, "replace": true, "sample.fraction": 0.296003535203636}}}], "metrics": 0.83491, "context": "openml-click-prediction-small-7295", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-click-prediction-small-7295-050", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 4, "num.trees": 181, "replace": false, "sample.fraction": 0.325488227629103}}}], "metrics": 0.83481, "context": "openml-click-prediction-small-7295", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-click-prediction-small-7295-007", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 2, "num.trees": 296, "replace": false, "sample.fraction": 0.254827392078005}}}], "metrics": 0.834735, "context": "openml-click-prediction-small-7295", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-click-prediction-small-7295-013", "modules": [{"role": "dataset", "module": "openml-click-prediction-small-7295"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 2, "num.trees": 234, "replace": true, "sample.fraction": 0.640737132099457}}}], "metrics": 0.834685, "context": "openml-click-prediction-small-7295", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-sylva-agnostic-3889-009", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 85, "num.trees": 653, "replace": false, "sample.fraction": 0.813205408258364}}}], "metrics": 0.994443, "context": "openml-sylva-agnostic-3889", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-sylva-agnostic-3889-033", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 67, "num.trees": 308, "replace": false, "sample.fraction": 0.872641097032465}}}], "metrics": 0.994443, "context": "openml-sylva-agnostic-3889", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-sylva-agnostic-3889-036", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 52, "num.trees": 283, "replace": false, "sample.fraction": 0.850199347781017}}}], "metrics": 0.994095, "context": "openml-sylva-agnostic-3889", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-sylva-agnostic-3889-048", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 71, "num.trees": 433, "replace": true, "sample.fraction": 0.92221200808417}}}], "metrics": 0.994095, "context": "openml-sylva-agnostic-3889", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-sylva-agnostic-3889-041", "modules": [{"role": "dataset", "module": "openml-sylva-agnostic-3889"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 64, "num.trees": 803, "replace": false, "sample.fraction": 0.697149731381796}}}], "metrics": 0.994026, "context": "openml-sylva-agnostic-3889", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-hill-valley-9970-048", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 93, "num.trees": 88, "replace": false, "sample.fraction": 0.38440314414911003}}}], "metrics": 0.596535, "context": "openml-hill-valley-9970", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-hill-valley-9970-024", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 51, "num.trees": 579, "replace": false, "sample.fraction": 0.727512734942138}}}], "metrics": 0.587459, "context": "openml-hill-valley-9970", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-hill-valley-9970-023", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 14, "num.trees": 1520, "replace": false, "sample.fraction": 0.909934549196623}}}], "metrics": 0.586634, "context": "openml-hill-valley-9970", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-hill-valley-9970-045", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 16, "num.trees": 1097, "replace": false, "sample.fraction": 0.93851462493185}}}], "metrics": 0.584983, "context": "openml-hill-valley-9970", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-hill-valley-9970-057", "modules": [{"role": "dataset", "module": "openml-hill-valley-9970"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 62, "num.trees": 1048, "replace": false, "sample.fraction": 0.650101018184796}}}], "metrics": 0.584983, "context": "openml-hill-valley-9970", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-gina-agnostic-3891-018", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 81, "num.trees": 258, "replace": false, "sample.fraction": 0.904766877694055}}}], "metrics": 0.943483, "context": "openml-gina-agnostic-3891", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-gina-agnostic-3891-005", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 46, "num.trees": 376, "replace": false, "sample.fraction": 0.747376868128777}}}], "metrics": 0.942618, "context": "openml-gina-agnostic-3891", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-gina-agnostic-3891-068", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 60, "num.trees": 372, "replace": false, "sample.fraction": 0.767570711649023}}}], "metrics": 0.939735, "context": "openml-gina-agnostic-3891", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-gina-agnostic-3891-047", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 92, "num.trees": 166, "replace": false, "sample.fraction": 0.732483358797617}}}], "metrics": 0.939446, "context": "openml-gina-agnostic-3891", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-gina-agnostic-3891-063", "modules": [{"role": "dataset", "module": "openml-gina-agnostic-3891"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 148, "num.trees": 188, "replace": false, "sample.fraction": 0.591064467467368}}}], "metrics": 0.937428, "context": "openml-gina-agnostic-3891", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-ozone-level-8hr-9978-047", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 47, "num.trees": 652, "replace": false, "sample.fraction": 0.566559484461322}}}], "metrics": 0.944751, "context": "openml-ozone-level-8hr-9978", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-ozone-level-8hr-9978-084", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 30, "num.trees": 1287, "replace": false, "sample.fraction": 0.984818308264948}}}], "metrics": 0.944751, "context": "openml-ozone-level-8hr-9978", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-ozone-level-8hr-9978-068", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 36, "num.trees": 1395, "replace": true, "sample.fraction": 0.49133830140344803}}}], "metrics": 0.944751, "context": "openml-ozone-level-8hr-9978", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-ozone-level-8hr-9978-054", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 32, "num.trees": 985, "replace": true, "sample.fraction": 0.739203938376158}}}], "metrics": 0.944357, "context": "openml-ozone-level-8hr-9978", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-ozone-level-8hr-9978-060", "modules": [{"role": "dataset", "module": "openml-ozone-level-8hr-9978"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 33, "num.trees": 1245, "replace": true, "sample.fraction": 0.746103597735055}}}], "metrics": 0.944357, "context": "openml-ozone-level-8hr-9978", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-kc1-3917-033", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 5, "num.trees": 229, "replace": true, "sample.fraction": 0.712562922481447}}}], "metrics": 0.865813, "context": "openml-kc1-3917", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-kc1-3917-018", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 7, "num.trees": 196, "replace": true, "sample.fraction": 0.693434450286441}}}], "metrics": 0.865339, "context": "openml-kc1-3917", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-kc1-3917-048", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 1, "num.trees": 709, "replace": false, "sample.fraction": 0.940143319033086}}}], "metrics": 0.864865, "context": "openml-kc1-3917", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-kc1-3917-092", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 5, "num.trees": 1918, "replace": true, "sample.fraction": 0.694162590405904}}}], "metrics": 0.864865, "context": "openml-kc1-3917", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-kc1-3917-031", "modules": [{"role": "dataset", "module": "openml-kc1-3917"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 21, "num.trees": 864, "replace": true, "sample.fraction": 0.756650384515524}}}], "metrics": 0.864865, "context": "openml-kc1-3917", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-qsar-biodeg-9957-052", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 28, "num.trees": 340, "replace": true, "sample.fraction": 0.627149670175277}}}], "metrics": 0.869194, "context": "openml-qsar-biodeg-9957", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-qsar-biodeg-9957-050", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 30, "num.trees": 415, "replace": true, "sample.fraction": 0.511992275156081}}}], "metrics": 0.867299, "context": "openml-qsar-biodeg-9957", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-qsar-biodeg-9957-069", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 25, "num.trees": 962, "replace": true, "sample.fraction": 0.5725506760645659}}}], "metrics": 0.867299, "context": "openml-qsar-biodeg-9957", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-qsar-biodeg-9957-097", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 41, "num.trees": 1419, "replace": true, "sample.fraction": 0.892958624754101}}}], "metrics": 0.865403, "context": "openml-qsar-biodeg-9957", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-qsar-biodeg-9957-026", "modules": [{"role": "dataset", "module": "openml-qsar-biodeg-9957"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 21, "num.trees": 615, "replace": false, "sample.fraction": 0.459377069654875}}}], "metrics": 0.865403, "context": "openml-qsar-biodeg-9957", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-climate-model-simulation-crashes-9980-040", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 10, "num.trees": 1725, "replace": false, "sample.fraction": 0.668996914359741}}}], "metrics": 0.92037, "context": "openml-climate-model-simulation-crashes-9980", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-climate-model-simulation-crashes-9980-046", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 11, "num.trees": 246, "replace": false, "sample.fraction": 0.5674105454003439}}}], "metrics": 0.918519, "context": "openml-climate-model-simulation-crashes-9980", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-climate-model-simulation-crashes-9980-022", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 13, "num.trees": 347, "replace": true, "sample.fraction": 0.912823647889309}}}], "metrics": 0.918519, "context": "openml-climate-model-simulation-crashes-9980", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-climate-model-simulation-crashes-9980-080", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 10, "num.trees": 352, "replace": false, "sample.fraction": 0.747212049528025}}}], "metrics": 0.918519, "context": "openml-climate-model-simulation-crashes-9980", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-climate-model-simulation-crashes-9980-098", "modules": [{"role": "dataset", "module": "openml-climate-model-simulation-crashes-9980"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 10, "num.trees": 1787, "replace": true, "sample.fraction": 0.836251008464023}}}], "metrics": 0.916667, "context": "openml-climate-model-simulation-crashes-9980", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-monks-problems-3-3494-099", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 2, "num.trees": 1108, "replace": false, "sample.fraction": 0.915738393948413}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-monks-problems-3-3494-046", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 4, "num.trees": 188, "replace": false, "sample.fraction": 0.857660512928851}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-monks-problems-3-3494-032", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 4, "num.trees": 1040, "replace": false, "sample.fraction": 0.822202212666161}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-monks-problems-3-3494-038", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 2, "num.trees": 321, "replace": true, "sample.fraction": 0.89641350756865}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-monks-problems-3-3494-039", "modules": [{"role": "dataset", "module": "openml-monks-problems-3-3494"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 3, "num.trees": 1159, "replace": false, "sample.fraction": 0.583124879002571}}}], "metrics": 0.98917, "context": "openml-monks-problems-3-3494", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-blood-transfusion-service-center-10101-005", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 4, "num.trees": 1318, "replace": false, "sample.fraction": 0.17328957032878}}}], "metrics": 0.792781, "context": "openml-blood-transfusion-service-center-10101", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-blood-transfusion-service-center-10101-043", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 4, "num.trees": 1790, "replace": true, "sample.fraction": 0.1339444558369}}}], "metrics": 0.791444, "context": "openml-blood-transfusion-service-center-10101", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-blood-transfusion-service-center-10101-091", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 4, "num.trees": 807, "replace": false, "sample.fraction": 0.194404307147488}}}], "metrics": 0.791444, "context": "openml-blood-transfusion-service-center-10101", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-blood-transfusion-service-center-10101-017", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 2, "num.trees": 248, "replace": false, "sample.fraction": 0.150464494223706}}}], "metrics": 0.790107, "context": "openml-blood-transfusion-service-center-10101", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-blood-transfusion-service-center-10101-065", "modules": [{"role": "dataset", "module": "openml-blood-transfusion-service-center-10101"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 3, "num.trees": 1041, "replace": true, "sample.fraction": 0.227011230424978}}}], "metrics": 0.790107, "context": "openml-blood-transfusion-service-center-10101", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-credit-g-31-057", "modules": [{"role": "dataset", "module": "openml-credit-g-31"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 14, "num.trees": 502, "replace": true, "sample.fraction": 0.911387046054006}}}], "metrics": 0.775, "context": "openml-credit-g-31", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-credit-g-31-006", "modules": [{"role": "dataset", "module": "openml-credit-g-31"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 20, "num.trees": 532, "replace": false, "sample.fraction": 0.403128281678073}}}], "metrics": 0.775, "context": "openml-credit-g-31", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-credit-g-31-065", "modules": [{"role": "dataset", "module": "openml-credit-g-31"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 13, "num.trees": 1991, "replace": true, "sample.fraction": 0.669622708926909}}}], "metrics": 0.774, "context": "openml-credit-g-31", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-credit-g-31-074", "modules": [{"role": "dataset", "module": "openml-credit-g-31"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 14, "num.trees": 1581, "replace": false, "sample.fraction": 0.4073085195152091}}}], "metrics": 0.774, "context": "openml-credit-g-31", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-credit-g-31-047", "modules": [{"role": "dataset", "module": "openml-credit-g-31"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 12, "num.trees": 401, "replace": true, "sample.fraction": 0.4628303923876961}}}], "metrics": 0.773, "context": "openml-credit-g-31", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-monks-problems-2-3493-042", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 4, "num.trees": 1532, "replace": false, "sample.fraction": 0.995611334615387}}}], "metrics": 0.983361, "context": "openml-monks-problems-2-3493", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-monks-problems-2-3493-082", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 5, "num.trees": 1226, "replace": false, "sample.fraction": 0.93070672119502}}}], "metrics": 0.978369, "context": "openml-monks-problems-2-3493", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-monks-problems-2-3493-003", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 3, "num.trees": 1226, "replace": false, "sample.fraction": 0.991301994305104}}}], "metrics": 0.973378, "context": "openml-monks-problems-2-3493", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-monks-problems-2-3493-011", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 5, "num.trees": 897, "replace": true, "sample.fraction": 0.957887157402001}}}], "metrics": 0.973378, "context": "openml-monks-problems-2-3493", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-monks-problems-2-3493-051", "modules": [{"role": "dataset", "module": "openml-monks-problems-2-3493"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 5, "num.trees": 1005, "replace": true, "sample.fraction": 0.936887229816057}}}], "metrics": 0.973378, "context": "openml-monks-problems-2-3493", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-kc2-3913-079", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 9, "num.trees": 1159, "replace": false, "sample.fraction": 0.35876707339193703}}}], "metrics": 0.850575, "context": "openml-kc2-3913", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-kc2-3913-081", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 20, "num.trees": 1640, "replace": true, "sample.fraction": 0.552712431643158}}}], "metrics": 0.848659, "context": "openml-kc2-3913", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-kc2-3913-064", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 13, "num.trees": 813, "replace": false, "sample.fraction": 0.227334113279358}}}], "metrics": 0.848659, "context": "openml-kc2-3913", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-kc2-3913-061", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 1, "num.trees": 1837, "replace": false, "sample.fraction": 0.5908302982570599}}}], "metrics": 0.848659, "context": "openml-kc2-3913", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-kc2-3913-056", "modules": [{"role": "dataset", "module": "openml-kc2-3913"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 15, "num.trees": 1824, "replace": false, "sample.fraction": 0.2911248910008}}}], "metrics": 0.848659, "context": "openml-kc2-3913", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-wdbc-9946-075", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 7, "num.trees": 295, "replace": false, "sample.fraction": 0.991231436282396}}}], "metrics": 0.966608, "context": "openml-wdbc-9946", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-wdbc-9946-051", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 8, "num.trees": 1138, "replace": true, "sample.fraction": 0.896134247072041}}}], "metrics": 0.963093, "context": "openml-wdbc-9946", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-wdbc-9946-063", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 5, "num.trees": 742, "replace": false, "sample.fraction": 0.889513864764012}}}], "metrics": 0.963093, "context": "openml-wdbc-9946", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-wdbc-9946-074", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 6, "num.trees": 921, "replace": false, "sample.fraction": 0.767515957495198}}}], "metrics": 0.963093, "context": "openml-wdbc-9946", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-wdbc-9946-003", "modules": [{"role": "dataset", "module": "openml-wdbc-9946"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 2, "num.trees": 1813, "replace": false, "sample.fraction": 0.717792411148548}}}], "metrics": 0.961336, "context": "openml-wdbc-9946", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-australian-125923-001", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 8, "num.trees": 30, "replace": true, "sample.fraction": 0.168520513433032}}}], "metrics": 0.876812, "context": "openml-australian-125923", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-australian-125923-012", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 2, "num.trees": 695, "replace": false, "sample.fraction": 0.649879243085161}}}], "metrics": 0.872464, "context": "openml-australian-125923", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-australian-125923-080", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 13, "num.trees": 472, "replace": true, "sample.fraction": 0.543591627455317}}}], "metrics": 0.872464, "context": "openml-australian-125923", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-australian-125923-005", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 13, "num.trees": 392, "replace": true, "sample.fraction": 0.36320336055941904}}}], "metrics": 0.871014, "context": "openml-australian-125923", "schema": "ranger-5889", "source": "hpob"}, {"id": "hpob-ranger-5889-openml-australian-125923-002", "modules": [{"role": "dataset", "module": "openml-australian-125923"}, {"role": "verifiedAlgorithm", "module": {"schema": "ranger-5889", "config": {"mtry": 5, "num.trees": 494, "replace": true, "sample.fraction": 0.5687009379267689}}}], "metrics": 0.871014, "context": "openml-australian-125923", "schema": "ranger-5889", "source": "hpob"}, {"id": "huggingface-sutd-ai-albert-base-v2-finetuned-squad", "modules": [{"role": "model", "module": {"name": "albert-base-v2-finetuned-squad", "description": "A fine-tuned version of albert-base-v2 on the squad_v2 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "albert-base-v2-finetuned-squad is a fine-tuned version of albert-base-v2 on the squad_v2 dataset. It is suitable for question answering tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for 3 epochs and achieved a loss of 0.9650 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 0.965, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-chaitanya97-wav2vec2-large-xls-r-300m-hindi-colab", "modules": [{"role": "model", "module": {"name": "wav2vec2-large-xls-r-300m-hindi-colab", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0003, "train_batch_size": 8, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 5, "num_epochs": 5, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset. The model is intended for automatic speech recognition tasks in Hindi. The model was trained using Adam optimizer with a learning rate of 0.0003 and a linear learning rate scheduler. The model was trained for 5 epochs with a batch size of 16. The model achieved a WER of 1.0 on the validation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 6.1583, "split": "val", "protocol": "loss"}, {"dataset": "common-voice", "metric": 7.281, "split": "test", "protocol": "loss"}, {"dataset": "common-voice", "metric": 1.0, "protocol": "WER"}], "source": "huggingface"}, {"id": "huggingface-jimregan-wav2vec2-large-xls-r-300m-irish-colab", "modules": [{"role": "model", "module": {"name": "wav2vec2-large-xls-r-300m-irish-colab", "description": "A fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0003, "train_batch_size": 32, "eval_batch_size": 16, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 210, "mixed_precision_training": true}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "A fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset. The model is suitable for automatic speech recognition tasks. The model was trained with Adam optimizer with a learning rate of 0.0003, and a linear learning rate scheduler with 500 warmup steps. The model was trained for 210 epochs with mixed precision training. The model achieved a loss of 1.4286 and a WER of 0.5097 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 1.4286, "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.5097, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-ayamerushia-wav2vec2-large-xls-r-300m-ia", "modules": [{"role": "model", "module": {"name": "wav2vec2-large-xls-r-300m-ia", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-300m on the Common Voice 8 dataset for Interlingua."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 3e-05, "train_batch_size": 16, "eval_batch_size": 4, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 400, "num_epochs": 30, "mixed_precision_training": true}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "The wav2vec2-large-xls-r-300m-ia model is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the Common Voice 8 dataset for Interlingua. The model was trained using masked language modeling and next sentence prediction objectives. The model is suitable for automatic speech recognition tasks. The model was trained using PyTorch 1.10.0+cu111 and Transformers 4.17.0.dev0."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 8.6074, "protocol": "wer"}, {"dataset": "common-voice", "metric": 2.4147, "protocol": "cer"}], "source": "huggingface"}, {"id": "huggingface-asahi417-tner-xlm-roberta-base-uncased-ontonotes5", "modules": [{"role": "model", "module": {"name": "XLM-RoBERTa for NER", "description": "XLM-RoBERTa model fine-tuned on Named Entity Recognition (NER) task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_name": "xlm-roberta-base", "tokenizer_name": "xlm-roberta-base", "batch_size": 32, "learning_rate": 5e-05, "epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "XLM-RoBERTa is a transformer model pre-trained on a large multilingual corpus. This model has been fine-tuned on the Named Entity Recognition (NER) task using the OntoNotes 5.0 dataset. The model can be used for token classification tasks, such as NER, in multiple languages. The model achieved an F1-score of 91.2 on the OntoNotes 5.0 dataset. The hyperparameters used for fine-tuning include a batch size of 32, a learning rate of 5e-5, and 3 epochs."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-axhyra-test-irony-trained-test", "modules": [{"role": "model", "module": {"name": "test_irony_trained_test", "description": "Fine-tuned version of distilbert-base-uncased on the tweet_eval dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 9.207906329883037e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 4}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "test_irony_trained_test is a fine-tuned version of distilbert-base-uncased on the tweet_eval dataset. It is a text classification model that predicts whether a tweet is ironic or not. The model achieved an F1 score of 0.6680 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 9.207906329883037e-05 and a batch size of 8 for 4 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "tweeteval"}], "metrics": [{"dataset": "tweeteval", "metric": 0.6680395323922843, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-fse-fi", "modules": [{"role": "model", "module": {"name": "opus-mt-fse-fi", "description": "A transformer-align model for translating from FSE to Finnish."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-fse-fi model is a transformer-align model that translates from FSE to Finnish. It achieved a BLEU score of 90.2 and a chr-F score of 0.943 on the JW300.fse.fi test set."}}], "metrics": [{"dataset": "jw300", "metric": 90.2, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.943, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-sn-es", "modules": [{"role": "model", "module": {"name": "opus-mt-sn-es", "description": "A machine translation model that translates from the Shona language to Spanish."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-sn-es is a machine translation model that translates from the Shona language to Spanish. The model uses the transformer-align architecture and was preprocessed using normalization and SentencePiece. The model achieved a BLEU score of 32.5 and a chr-F score of 0.509 on the JW300.sn.es test set."}}], "metrics": [{"dataset": "jw300", "metric": 32.5, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.509, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-vanichandna-xlm-roberta-finetuned-squad", "modules": [{"role": "model", "module": {"name": "vanichandna/xlmroberta-squad", "description": "Fine-tuned version of xlm-roberta-base on an SQuAD v1.1 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"optimizer": {"name": "AdamWeightDecay", "learning_rate": {"name": "PolynomialDecay", "initial_learning_rate": 2e-05, "decay_steps": 16476, "end_learning_rate": 0.0, "power": 1.0, "cycle": false}, "decay": 0.0, "beta_1": 0.9, "beta_2": 0.999, "epsilon": 1e-08, "amsgrad": false, "weight_decay_rate": 0.01}, "training_precision": "mixed_float16"}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of xlm-roberta-base on an SQuAD v1.1 dataset. The model is best suited for question-answering tasks. The model was trained using mixed precision and the AdamWeightDecay optimizer with a learning rate of 2e-05 and a weight decay rate of 0.01. The model was trained for 2 epochs and achieved a train loss of 0.6636."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 0.6636, "protocol": "train_loss"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 2.0, "protocol": "epoch"}], "source": "huggingface"}, {"id": "huggingface-cataluna84-xlm-roberta-base-finetuned-panx-it", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-it", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8124 on the evaluation set. The model is suitable for token classification tasks in Italian language. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8124, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-sv-yap", "modules": [{"role": "model", "module": {"name": "opus-mt-sv-yap", "description": "A machine translation model that translates from Swedish (sv) to Yapese (yap)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-sv-yap is a machine translation model that translates from Swedish to Yapese. The model uses the transformer-align architecture and pre-processing techniques such as normalization and SentencePiece. The model achieved a BLEU score of 27.3 and a chr-F score of 0.461 on the JW300.sv.yap test set."}}], "metrics": [{"dataset": "jw300", "metric": 27.3, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.461, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-es-bi", "modules": [{"role": "model", "module": {"name": "opus-mt-es-bi", "description": "A machine translation model that translates from Spanish (es) to Bislama (bi)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-es-bi is a machine translation model that translates from Spanish to Bislama. The model is based on the transformer-align architecture and uses normalization and SentencePiece for pre-processing. The model achieves a BLEU score of 28.0 and a chr-F score of 0.473 on the JW300.es.bi test set."}}], "metrics": [{"dataset": "jw300", "metric": 28.0, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.473, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-mbeukman-xlm-roberta-base-finetuned-naija-finetuned-ner-naija", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-naija-finetuned-ner-naija", "description": "A token classification model fine-tuned on the MasakhaNER dataset for named entity recognition in Nigerian Pidgin."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"max_seq_length": 200, "batch_size": 32, "learning_rate": 5e-05, "epochs": 50}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a transformer-based token classification model fine-tuned on the MasakhaNER dataset for named entity recognition in Nigerian Pidgin. The model was fine-tuned for 50 epochs with a maximum sequence length of 200, 32 batch size, and 5e-5 learning rate. The model is intended for NLP research into interpretability or transfer learning and not for production use. The model's limitations include being trained on a relatively small dataset covering one task in one domain and may perform poorly on other tasks. The model is licensed under the Apache License, Version 2.0."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "masakhaner"}], "metrics": [{"dataset": "masakhaner", "metric": 88.06, "protocol": "f1"}, {"dataset": "masakhaner", "metric": 87.04, "protocol": "precision"}, {"dataset": "masakhaner", "metric": 89.12, "protocol": "recall"}], "source": "huggingface"}, {"id": "huggingface-hardwarize-q-frozenlake-v1-4x4-noslippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained model of a Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-4x4-no_slippery"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model was trained using the Q-Learning algorithm and evaluated on the FrozenLake-v1-4x4-no_slippery environment. The model achieved a mean reward of 1.00 +/- 0.00, but the verification status is unknown."}}, {"role": "dataset", "purpose": "The environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-transfo-xl-wt103", "modules": [{"role": "model", "module": {"name": "Transfo-xl-wt103", "description": "The Transformer-XL model is a causal (uni-directional) transformer with relative positioning (sinuso\u00efdal) embeddings which can reuse previously computed hidden-states to attend to longer context (memory). This model also uses adaptive softmax inputs and outputs (tied)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "lowercasing and removing any character other than the 26 letters a through z, and space", "training_corpus": ["WikiText-103"], "batch_size": null, "optimizer": null}}}, {"role": "taskType", "module": "text-generation"}, {"role": "solutionSummary", "module": {"summary": "Transfo-xl-wt103 is a transformer model pre-trained on the Wikitext-103 dataset. It is a causal transformer with relative positioning embeddings that can reuse previously computed hidden-states to attend to longer context. The model is best suited for text generation tasks. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-edresson-wav2vec2-large-100k-voxpopuli-ft-common-voice-plus-tts-dataset-portuguese", "modules": [{"role": "model", "module": {"name": "Wav2vec2 Large 100k Voxpopuli fine-tuned with Common Voice and TTS-Portuguese Corpus in Portuguese", "description": "Wav2vec2 Large 100k Voxpopuli fine-tuned in Portuguese using the Common Voice 7.0 and TTS-Portuguese Corpus."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_name": "Edresson/wav2vec2-large-100k-voxpopuli-ft-Common-Voice_plus_TTS-Dataset-portuguese", "tokenizer_name": "Edresson/wav2vec2-large-100k-voxpopuli-ft-Common-Voice_plus_TTS-Dataset-portuguese", "resample": {"orig_freq": 48000, "new_freq": 16000}}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Wav2vec2 Large 100k Voxpopuli fine-tuned with Common Voice and TTS-Portuguese Corpus in Portuguese is a speech recognition model that was fine-tuned on Common Voice 7.0 and TTS-Portuguese Corpus. The model is intended to be used for automatic speech recognition tasks in Portuguese. The model uses Wav2vec2 architecture and achieves a WER of 20.39 on the Common Voice 7.0 test dataset."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-patrickvonplaten-hello-2b", "modules": [{"role": "model", "module": {"name": "hello_2b", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-2b on the COMMON_VOICE - TR dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-05, "train_batch_size": 2, "eval_batch_size": 8, "seed": 42, "distributed_type": "multi-GPU", "num_devices": 2, "gradient_accumulation_steps": 8, "total_train_batch_size": 32, "total_eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 30.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "hello_2b is a fine-tuned version of facebook/wav2vec2-xls-r-2b on the COMMON_VOICE - TR dataset. The model is intended for automatic speech recognition tasks. The model was trained using Adam optimizer with a learning rate of 1e-5, and a linear learning rate scheduler with warmup steps of 500. The model was trained for 30 epochs with a batch size of 2 and a gradient accumulation step of 8. The model achieved a loss of 1.2725 and a WER of 0.9531 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 1.2725, "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.9531, "protocol": "WER"}], "source": "huggingface"}, {"id": "huggingface-speech-seq2seq-wav2vec2-2-bart-large-no-adapter-frozen-enc", "modules": [{"role": "model", "module": {"name": "Unnamed ASR model", "description": "A speech recognition model trained on the librispeech_asr dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0001, "train_batch_size": 8, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 3.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is an unnamed speech recognition model trained on the librispeech_asr dataset. The model was trained from scratch and achieved a validation WER of 1.0. The model was trained using the Adam optimizer with a learning rate of 0.0001 and a linear learning rate scheduler with warmup steps of 500. The model was trained for 3 epochs with a batch size of 16 and mixed precision training enabled. The model was trained using the Transformers library version 4.17.0.dev0 with PyTorch version 1.10.2+cu113."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "librispeech"}], "metrics": [{"dataset": "librispeech", "metric": 4.679, "split": "val", "protocol": "loss"}, {"dataset": "librispeech", "metric": 18.7898, "split": "test", "protocol": "loss"}, {"dataset": "librispeech", "metric": 1.0, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-artifact-ai-en-spacy-ontonotes-roberta-base-ner", "modules": [{"role": "model", "module": {"name": "en_spacy_ontonotes_roberta_base_ner", "description": "A spaCy model for named entity recognition (NER) using the OntoNotes 5.0 corpus and the RoBERTa base transformer architecture."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"spaCy_version": ">=3.4.1,<3.5.0", "pipeline": ["transformer", "ner"], "transformer_architecture": "RoBERTa base"}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "en_spacy_ontonotes_roberta_base_ner is a spaCy model for named entity recognition (NER) using the OntoNotes 5.0 corpus and the RoBERTa base transformer architecture. It has 18 labels for 1 component. The model achieved an F1 score of 86.49% on the test set. It can be used for NER tasks in English language text processing."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-awalmeida-dqn-spaceinvadersnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "DQN", "description": "A trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "buffer_size": 100000, "exploration_final_eps": 0.01, "exploration_fraction": 0.1, "frame_stack": 4, "gradient_steps": 1, "learning_rate": 0.0001, "learning_starts": 100000, "n_timesteps": 10000000.0, "optimize_memory_usage": true, "policy": "CnnPolicy", "target_update_interval": 1000, "train_freq": 4, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "The DQN model is a reinforcement learning agent trained on the SpaceInvadersNoFrameskip-v4 environment using the stable-baselines3 library and the RL Zoo. The model achieved a mean reward of 657.00 +/- 102.03. The hyperparameters used for training include batch size, buffer size, exploration fraction, learning rate, and target update interval, among others. The model is suitable for playing SpaceInvadersNoFrameskip-v4, but may not generalize well to other environments."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 657.0, "split": "val", "protocol": "mean_reward"}, {"dataset": "atari-grand-challenge", "metric": 102.03, "split": "test", "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-jkson-swin-tiny-patch4-window7-224-finetuned-eurosat", "modules": [{"role": "model", "module": {"name": "swin-tiny-patch4-window7-224-finetuned-eurosat", "description": "A fine-tuned version of microsoft/swin-tiny-patch4-window7-224 on the imagefolder dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 32, "eval_batch_size": 32, "seed": 42, "gradient_accumulation_steps": 4, "total_train_batch_size": 128, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "num_epochs": 3}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "A fine-tuned version of microsoft/swin-tiny-patch4-window7-224 on the imagefolder dataset. Achieves an accuracy of 0.9807 on the evaluation set. The model is suitable for image classification tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "objectfolder"}], "metrics": [{"dataset": "objectfolder", "metric": 0.9807407407407407, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-yayab-q-frozenlake-v1-4x4-noslippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained model of a Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-4x4-no_slippery", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model's hyperparameters include the algorithm used, the environment, the maximum number of steps per episode, the number of episodes to evaluate the agent, the Q-Table learned by the agent, and the random seed used for evaluation. The model achieved a mean reward of 1.0 with no standard deviation."}}, {"role": "dataset", "purpose": "Environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-iis2009002-xlm-roberta-base-finetuned-panx-en", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-en", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieved an F1 score of 0.6922 on the evaluation set. The model is suitable for token classification tasks in multilingual settings."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.692179700499168, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-joefarrington-q-frozenlake-v1-4x4-noslippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained model of a Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-4x4-no_slippery", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model's hyperparameters include the algorithm used, the environment, the maximum number of steps per episode, the number of episodes to evaluate the agent, the Q-table learned by the agent, and the random seed used for evaluation. The model achieved a mean reward of 1.00 +/- 0.00."}}, {"role": "dataset", "purpose": "Environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "extra": "1.00 +/- 0.00", "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-deepset-bert-medium-squad2-distilled", "modules": [{"role": "model", "module": {"name": "deepset/bert-medium-squad2-distilled", "description": "A distilled BERT model pre-trained on SQuAD 2.0 training set for question answering task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 6, "n_epochs": 2, "max_seq_len": 384, "learning_rate": 3e-05, "lr_schedule": "LinearWarmup", "embeds_dropout_prob": 0.1, "temperature": 5, "distillation_loss_weight": 1}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "This is a distilled BERT model pre-trained on SQuAD 2.0 training set for question answering task. The model was trained using haystack's distillation feature with deepset/bert-large-uncased-whole-word-masking-squad2 as the teacher model. The model achieved an exact match score of 68.64 and an F1 score of 72.76 on the SQuAD 2.0 dev set. The model is suitable for question answering tasks in English language."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 68.6431398972458, "protocol": "exact_match"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 72.7637083790805, "protocol": "F1"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-en-uk", "modules": [{"role": "model", "module": {"name": "opus-mt-en-uk", "description": "A transformer-align model for English to Ukrainian translation."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-en-uk model is a transformer-align model for English to Ukrainian translation. It was trained on the OPUS dataset using normalization and SentencePiece pre-processing. The model achieved a BLEU score of 50.2 and a chr-F score of 0.674 on the Tatoeba.en.uk test set."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-snics-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. The model is best suited for text classification tasks. The model achieved an accuracy of 0.9245 and an F1 score of 0.9244 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.9245, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.9244334678544425, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-chutiantao-distilbert-base-uncased-finetuned-squad-2", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-squad-2", "description": "A fine-tuned version of distilbert-base-uncased on the SQuAD dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-squad-2 is a fine-tuned version of distilbert-base-uncased on the SQuAD dataset. It is suitable for question answering tasks. The model was trained with Adam optimizer with a learning rate of 5e-05 and a batch size of 16. The model was trained for 3 epochs and achieved a loss of 1.6620 on the validation set."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 1.662, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-lus-fi", "modules": [{"role": "model", "module": {"name": "opus-mt-lus-fi", "description": "A transformer-align model for translating from Lus to Finnish."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-lus-fi model is a transformer-align model that translates from Lus to Finnish. It achieved a BLEU score of 22.6 and a chr-F score of 0.441 on the JW300.lus.fi test set."}}], "metrics": [{"dataset": "jw300", "metric": 22.6, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.441, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-baxterai-sentimentclassifier", "modules": [{"role": "model", "module": {"name": "SentimentClassifier", "description": "A fine-tuned version of distilbert-base-uncased on the amazon_polarity dataset for text classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 3e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "SentimentClassifier is a fine-tuned version of distilbert-base-uncased on the amazon_polarity dataset for text classification. The model achieves an accuracy and F1 score of 0.91 on the evaluation set. The model is suitable for text classification tasks, but more information is needed to determine its intended uses and limitations. The model was trained using PyTorch 1.11.0+cu113 and Transformers 4.19.2 with a linear learning rate scheduler and Adam optimizer."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "amazon-review"}], "metrics": [{"dataset": "amazon-review", "metric": 0.91, "protocol": "accuracy"}, {"dataset": "amazon-review", "metric": 0.91, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-surrey-nlp-roberta-large-finetuned-abbr", "modules": [{"role": "model", "module": {"name": "roberta-large-finetuned-ner", "description": "A fine-tuned version of roberta-large on the PLOD-unfiltered dataset for the task of Abbreviation Detection."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 4, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 6}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of the roberta-large model on the PLOD-unfiltered dataset for the task of Abbreviation Detection. The model was trained using the Adam optimizer with a learning rate of 2e-05 and a batch size of 8. The model achieved a precision of 0.9663, recall of 0.9627, F1 score of 0.9645, and accuracy of 0.9608 on the evaluation set. The model is suitable for sequence labeling tasks such as abbreviation detection."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "acronym-identification"}], "metrics": [{"dataset": "acronym-identification", "metric": 0.9662545190541101, "protocol": "Precision"}, {"dataset": "acronym-identification", "metric": 0.9627013733169376, "protocol": "Recall"}, {"dataset": "acronym-identification", "metric": 0.9644746737300262, "protocol": "F1"}, {"dataset": "acronym-identification", "metric": 0.9607518572002093, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-sb3-dqn-beamridernoframeskip-v4", "modules": [{"role": "model", "module": {"name": "DQN", "description": "A trained model of a DQN agent playing BeamRiderNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "buffer_size": 10000, "exploration_final_eps": 0.01, "exploration_fraction": 0.1, "frame_stack": 4, "gradient_steps": 1, "learning_rate": 0.0001, "learning_starts": 100000, "n_timesteps": 10000000.0, "optimize_memory_usage": true, "policy": "CnnPolicy", "target_update_interval": 1000, "train_freq": 4, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "The DQN model is a reinforcement learning agent trained on the BeamRiderNoFrameskip-v4 environment using the stable-baselines3 library and the RL Zoo. The model achieved a mean reward of 4777.20 with a standard deviation of 2013.79. The hyperparameters used for training include batch size, buffer size, exploration fraction, learning rate, and target update interval, among others. The model is suitable for tasks that require reinforcement learning, such as game playing and robotics."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 4777.2, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-nickmuchi-vit-finetuned-chest-xray-pneumonia", "modules": [{"role": "model", "module": {"name": "vit-finetuned-chest-xray-pneumonia", "description": "A fine-tuned version of google/vit-base-patch16-224-in21k on the chest-xray-pneumonia dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 10}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of google/vit-base-patch16-224-in21k on the chest-xray-pneumonia dataset. It achieves an accuracy of 0.9551 on the evaluation set. The model is intended for image classification tasks and is limited to the chest-xray-pneumonia dataset. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler. The model was trained for 10 epochs with a batch size of 16."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "chest-x-ray-images-chest-x-ray-images-for-pneumonia-detection"}], "metrics": [{"dataset": "chest-x-ray-images-chest-x-ray-images-for-pneumonia-detection", "metric": 0.9551, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-ilo-es", "modules": [{"role": "model", "module": {"name": "opus-mt-ilo-es", "description": "A machine translation model that translates from the Ilo language to Spanish."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-ilo-es is a machine translation model that translates from the Ilo language to Spanish. The model uses the transformer-align architecture and was preprocessed using normalization and SentencePiece. The model achieved a BLEU score of 30.7 and a chr-F score of 0.496 on the JW300 test set."}}], "metrics": [{"dataset": "jw300", "metric": 30.7, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.496, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-jcai1-distilbert-base-uncased-finetuned-imdb", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-imdb", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-imdb is a fine-tuned version of distilbert-base-uncased on the imdb dataset. It can be used for text classification tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 64. The model was trained for 3 epochs and achieved a loss of 2.4721 on the evaluation set. The model was trained using PyTorch 1.11.0+cu113 and Transformers 4.18.0."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 2.4721, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-burakyldrm-wav2vec2-burak-v2-1", "modules": [{"role": "model", "module": {"name": "wav2vec2-burak-v2.1", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0003, "train_batch_size": 16, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 30, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "wav2vec2-burak-v2.1 is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset. It is a speech recognition model that can transcribe speech to text. The model was trained using PyTorch and Transformers libraries. The model achieved a WER of 0.4605 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.0741, "split": "val", "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.5006, "split": "test", "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.4605, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-anirudh21-distilbert-base-uncased-finetuned-mrpc", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-mrpc", "description": "A fine-tuned version of distilbert-base-uncased on the MRPC dataset from the GLUE benchmark."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-mrpc is a fine-tuned version of distilbert-base-uncased on the MRPC dataset from the GLUE benchmark. It is suitable for text classification tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for 5 epochs. The model achieved an accuracy of 0.8456 and an F1 score of 0.8959 on the evaluation set."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-ko-hu", "modules": [{"role": "model", "module": {"name": "kor-hun", "description": "A transformer model for translating from Korean to Hungarian."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece (spm32k,spm32k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "kor-hun is a transformer model trained on a large corpus of Korean text and is intended for translating Korean to Hungarian. The model uses normalization and SentencePiece (spm32k,spm32k) for preprocessing. The model has been evaluated on the Tatoeba-test.kor.hun dataset and achieved a BLEU score of 28.6 and a chrF2 score of 0.52."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "tatoeba-translation-challenge"}], "metrics": [{"dataset": "tatoeba-translation-challenge", "metric": 28.6, "protocol": "BLEU"}, {"dataset": "tatoeba-translation-challenge", "metric": 0.52, "protocol": "chrF2"}], "source": "huggingface"}, {"id": "huggingface-nickprock-distilbert-base-uncased-banking77-classification", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-banking77-classification", "description": "Fine-tuned version of distilbert-base-uncased on the banking77 dataset for text classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 20}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of distilbert-base-uncased on the banking77 dataset for text classification. The model can be used for addressing tickets in the banking domain. The model achieved an accuracy of 0.9240 and an F1 score of 0.9243 on the evaluation set. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 20 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "banking77"}], "metrics": [{"dataset": "banking77", "metric": 0.924025974025974, "split": "val", "protocol": "Accuracy"}, {"dataset": "banking77", "metric": 0.924025974025974, "split": "test", "protocol": "Accuracy"}, {"dataset": "banking77", "metric": 0.924025974025974, "split": "val", "protocol": "F1 Score"}, {"dataset": "banking77", "metric": 0.9243068139192416, "split": "test", "protocol": "F1 Score"}, {"dataset": "banking77", "metric": 0.31516405940055847, "protocol": "Loss"}], "source": "huggingface"}, {"id": "huggingface-ericklerouge123-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8649 on the evaluation set. The model is suitable for token classification tasks in German language. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8648740833380706, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-sumedh-distilbart-cnn-12-6-amazonreviews", "modules": [{"role": "model", "module": {"name": "DistilBART", "description": "A pre-trained summarization model based on BART architecture."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 4, "eval_batch_size": 4, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "DistilBART is a pre-trained summarization model based on BART architecture. It was trained on the Amazon Reviews Multi dataset using Adam optimizer with a learning rate of 2e-05. The model was trained for 1 epoch with a batch size of 4 and mixed precision training. The model achieved a validation loss of 1.6294 and a Rouge1 score of 11.009. The model is intended for summarization tasks."}}, {"role": "dataset", "purpose": "For model training.", "module": "amazon-product-data"}], "metrics": [{"dataset": "amazon-product-data", "metric": 1.2875, "protocol": "Training Loss"}, {"dataset": "amazon-product-data", "metric": 1.6294, "protocol": "Validation Loss"}, {"dataset": "amazon-product-data", "metric": 11.009, "protocol": "Rouge1"}, {"dataset": "amazon-product-data", "metric": 7.4618, "protocol": "Rouge2"}, {"dataset": "amazon-product-data", "metric": 10.5573, "protocol": "Rougel"}, {"dataset": "amazon-product-data", "metric": 10.8087, "protocol": "Rougelsum"}, {"dataset": "amazon-product-data", "metric": 58.3382, "protocol": "Gen Len"}], "source": "huggingface"}, {"id": "huggingface-anuragshas-wav2vec2-xls-r-300m-bn-cv9-with-lm", "modules": [{"role": "model", "module": {"name": "XLS-R-300M - Bengali", "description": "Fine-tuned model on the Common Voice 9 - BN dataset for automatic speech recognition."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 7.5e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "training_steps": 8692, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of the XLS-R-300M model on the Common Voice 9 - BN dataset for automatic speech recognition. The model achieved a WER of 20.150 and a CER of 4.813 on the evaluation set. The model is intended for speech recognition tasks in Bengali language. The model was trained using the Transformers library with PyTorch backend and optimized using Adam optimizer with a linear learning rate scheduler. The model was trained for 8692 steps with a batch size of 128 using mixed precision training."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 20.15, "protocol": "wer"}, {"dataset": "common-voice", "metric": 4.813, "protocol": "cer"}], "source": "huggingface"}, {"id": "huggingface-ineg-glue-sst-classifier", "modules": [{"role": "model", "module": {"name": "glue_sst_classifier", "description": "A fine-tuned version of bert-base-cased on the glue dataset for text classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-05, "train_batch_size": 128, "eval_batch_size": 128, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "num_epochs": 1.0}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "glue_sst_classifier is a fine-tuned version of bert-base-cased on the glue dataset for text classification. The model achieved an F1 score of 0.9034 and an accuracy of 0.9014 on the evaluation set. The model is suitable for text classification tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.9033707865168539, "protocol": "f1"}, {"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.9013761467889908, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-kg-fr", "modules": [{"role": "model", "module": {"name": "opus-mt-kg-fr", "description": "A transformer-align model trained on the OPUS dataset for translation from kg to fr."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-kg-fr model is a transformer-align model trained on the OPUS dataset for translation from kg to fr. The model achieved a BLEU score of 26.0 and a chr-F score of 0.433 on the JW300.kg.fr test set."}}, {"role": "dataset", "purpose": "For evaluation.", "module": "jw300"}], "metrics": [{"dataset": "jw300", "metric": 26.0, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.433, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-ftorres-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 environment."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "is_slippery": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 environment. The agent was trained using a custom implementation of the Q-Learning algorithm. The model achieved a mean reward of 7.56 with a standard deviation of 2.71 over multiple evaluation episodes."}}, {"role": "dataset", "purpose": "The environment used to train the agent.", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.56, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-pkumc-distilbert-base-uncased-finetuned-cola", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-cola", "description": "A fine-tuned version of distilbert-base-uncased on the glue dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-cola is a fine-tuned version of distilbert-base-uncased on the glue dataset. It can be used for text classification tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for 5 epochs. The evaluation results show that the model achieved an eval_loss of 0.5175 and an eval_matthews_correlation of 0.4847."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.5175, "protocol": "eval_loss"}, {"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.4847, "protocol": "eval_matthews_correlation"}, {"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 31.1926, "protocol": "eval_runtime"}, {"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 33.437, "protocol": "eval_samples_per_second"}, {"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 2.116, "protocol": "eval_steps_per_second"}, {"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 2.01, "protocol": "epoch"}, {"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 1073.0, "protocol": "step"}], "source": "huggingface"}, {"id": "huggingface-optimum-distilbert-base-uncased-finetuned-banking77", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-banking77", "description": "A fine-tuned version of distilbert-base-uncased on the banking77 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 9.686210354742596e-05, "train_batch_size": 64, "eval_batch_size": 32, "seed": 40, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-banking77 is a fine-tuned version of distilbert-base-uncased on the banking77 dataset. It can be used for text classification tasks in the banking domain. The model achieved an accuracy of 0.925 and an F1 score of 0.9250 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 9.686210354742596e-05 and a batch size of 64 for 5 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "banking77"}], "metrics": [{"dataset": "banking77", "metric": 0.2935, "protocol": "loss"}, {"dataset": "banking77", "metric": 0.925, "protocol": "accuracy"}, {"dataset": "banking77", "metric": 0.925, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-gchhablani-fnet-base-finetuned-stsb", "modules": [{"role": "model", "module": {"name": "fnet-base-finetuned-stsb", "description": "A fine-tuned version of google/fnet-base on the GLUE STSB dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "num_epochs": 3.0}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "fnet-base-finetuned-stsb is a fine-tuned version of google/fnet-base on the GLUE STSB dataset. It is intended for text classification tasks. The model was trained using the run_glue script with Adam optimizer and a learning rate of 2e-05. The model achieved a Spearmanr score of 0.8219 on the GLUE STSB dataset."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "semantic-textual-similarity-2012-2016-sts"}], "metrics": [{"dataset": "semantic-textual-similarity-2012-2016-sts", "metric": 0.8219, "protocol": "Spearmanr"}], "source": "huggingface"}, {"id": "huggingface-krisorn-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 game."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 game. The model includes the Q-Table learned by the agent and can be used to evaluate the agent's performance. The mean reward achieved by the agent is 7.56 with a standard deviation of 2.71."}}, {"role": "dataset", "purpose": "The game environment used for training and evaluation.", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.56, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-giolisandro-t5-small-finetuned-en-to-ro", "modules": [{"role": "model", "module": {"name": "t5-small-finetuned-en-to-ro", "description": "A fine-tuned version of t5-small on the wmt16 dataset for English to Romanian translation."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1, "mixed_precision_training": true}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "t5-small-finetuned-en-to-ro is a transformer model fine-tuned on the wmt16 dataset for English to Romanian translation. The model was trained for one epoch with a batch size of 16 and a learning rate of 2e-05. The model achieved a BLEU score of 7.3474 and a generated length of 18.2586. The model is suitable for English to Romanian translation tasks, but its performance may vary depending on the specific use case and data distribution."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wmt-2016"}], "metrics": [{"dataset": "wmt-2016", "metric": 7.3474, "protocol": "Bleu"}, {"dataset": "wmt-2016", "metric": 18.2586, "protocol": "Gen Len"}], "source": "huggingface"}, {"id": "huggingface-elhamagk-distilbert-base-uncased-finetuned-imdb", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-imdb", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-imdb is a fine-tuned version of distilbert-base-uncased on the imdb dataset. It can be used for text classification tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 64. The model was trained for 3 epochs and achieved a loss of 2.4721 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 2.4721, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-neulab-distilgpt2-finetuned-wikitext103", "modules": [{"role": "model", "module": {"name": "distilgpt2", "description": "A GPT-2 model that has been distilled to a smaller size for faster inference."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"context": "sliding window"}}}, {"role": "taskType", "module": "text-generation"}, {"role": "solutionSummary", "module": {"summary": "This is a distilgpt2 model that has been fine-tuned on the Wikitext-103 dataset. It achieves a perplexity of 18.25 using a sliding window context. The model was released as part of the paper 'Neuro-Symbolic Language Modeling with Automaton-augmented Retrieval' (ICML'2022). The model is suitable for text generation tasks and has been distilled to a smaller size for faster inference."}}, {"role": "dataset", "purpose": "For fine-tuning.", "module": "wikitext-103"}], "metrics": [{"dataset": "wikitext-103", "metric": 18.25, "protocol": "perplexity"}], "source": "huggingface"}, {"id": "huggingface-against61-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 game."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 game. The agent's Q-Table is provided, along with hyperparameters such as the maximum number of steps per episode and the number of episodes used for evaluation. The model's performance is evaluated based on the mean reward achieved over the evaluation episodes."}}, {"role": "dataset", "purpose": "The game environment used for training and evaluation.", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.56, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-andi611-bert-base-cased-ner-conll2003", "modules": [{"role": "model", "module": {"name": "bert-base-cased-ner", "description": "A fine-tuned version of bert-base-cased on the conll2003 dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 32, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 5}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-base-cased-ner is a fine-tuned version of bert-base-cased on the conll2003 dataset for token classification. The model achieved high precision, recall, f1-score, and accuracy on the evaluation set. It can be used for named entity recognition tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 0.9406, "protocol": "precision"}, {"dataset": "conll-2003", "metric": 0.9463, "protocol": "recall"}, {"dataset": "conll-2003", "metric": 0.9434, "protocol": "f1"}, {"dataset": "conll-2003", "metric": 0.9861, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-sivakumar-distilbert-base-uncased-finetuned-squad", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-squad", "description": "A fine-tuned version of distilbert-base-uncased on the squad_v2 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-squad is a fine-tuned version of distilbert-base-uncased on the squad_v2 dataset. It is suitable for question answering tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for 3 epochs and achieved a loss of 1.4101 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 1.4101, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-nates-test-org-coat-tiny", "modules": [{"role": "model", "module": {"name": "coat_tiny", "description": "A small image classification model trained on the COCO dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"image_size": 224, "batch_size": 64, "optimizer": {"name": "Adam", "learning_rate": 0.001}, "num_epochs": 50}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "coat_tiny is a small image classification model trained on the COCO dataset. It achieves an accuracy of 0.85 on the COCO dataset. The model is suitable for image classification tasks that require a small model size and can be trained on a limited amount of data."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "coco-microsoft-common-objects-in-context"}], "metrics": [{"dataset": "coco-microsoft-common-objects-in-context", "metric": 0.85, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-mrm8488-bertin-gpt-j-6b-es-v1-8bit", "modules": [{"role": "model", "module": {"name": "BERTIN-GPT-J-6B with 8-bit weights (Quantized)", "description": "An adaptation of hivemind/gpt-j-6B-8bit, a version of the latest checkpoint (1M steps) bertin-project/bertin-gpt-j-6B that is modified so you can generate and fine-tune the model in Colab or equivalent desktop GPU."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"quantization": "8-bit", "batch_size": "variable", "optimizer": {"name": "Adam", "learning_rate": "variable", "beta1": 0.9, "beta2": 0.999, "weight_decay": 0.01}}}}, {"role": "taskType", "module": "text-generation"}, {"role": "solutionSummary", "module": {"summary": "BERTIN-GPT-J-6B with 8-bit weights (Quantized) is an adaptation of hivemind/gpt-j-6B-8bit, a version of the latest checkpoint (1M steps) bertin-project/bertin-gpt-j-6B that is modified so you can generate and fine-tune the model in Colab or equivalent desktop GPU. The model is suitable for text generation tasks in Spanish. The model uses 8-bit quantization for storage, and all computations are performed in float16 or float32. The model is scalable for fine-tuning with LoRA and 8-bit Adam. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For evaluation.", "module": "wikitext-2"}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-ariesutiono-scibert-lm-const-finetuned-20", "modules": [{"role": "model", "module": {"name": "scibert-lm-const-finetuned-20", "description": "A fine-tuned version of allenai/scibert_scivocab_cased on the conll2003 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 4, "eval_batch_size": 4, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 20, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "scibert-lm-const-finetuned-20 is a fine-tuned version of allenai/scibert_scivocab_cased on the conll2003 dataset. It is suitable for token classification tasks. The model was trained for 20 epochs with a learning rate of 2e-05 and a batch size of 4. The model uses Adam optimizer with betas=(0.9,0.999) and epsilon=1e-08. The model was trained using mixed precision training with Native AMP. The model achieved a loss of 2.0099 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 2.0099, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-redpandaainlp-opus-mt-en-ro-finetuned-en-to-ro", "modules": [{"role": "model", "module": {"name": "opus-mt-en-ro-finetuned-en-to-ro", "description": "A fine-tuned version of Helsinki-NLP/opus-mt-en-ro on the wmt16 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1, "mixed_precision_training": true}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of Helsinki-NLP/opus-mt-en-ro on the wmt16 dataset. It is intended for sequence-to-sequence language modeling tasks, specifically for English to Romanian translation. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model achieved a Bleu score of 28.1505 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wmt-2016"}], "metrics": [{"dataset": "wmt-2016", "metric": 28.1505, "protocol": "bleu"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-el-fi", "modules": [{"role": "model", "module": {"name": "opus-mt-el-fi", "description": "A transformer-align model for translating from Greek (el) to Finnish (fi)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-el-fi is a transformer-align model for translating from Greek to Finnish. The model was trained on the OPUS dataset using normalization and SentencePiece preprocessing. The model achieved a BLEU score of 25.3 and a chr-F score of 0.517 on the JW300.el.fi test set."}}], "metrics": [{"dataset": "jw300", "metric": 25.3, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.517, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-teacookies-autonlp-roberta-base-squad2-24465522", "modules": [{"role": "model", "module": {"name": "AutoNLP-RoBERTa-base-SQuAD2", "description": "A model trained using AutoNLP for extractive question answering on the SQuAD2 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_id": 24465522, "pretrained_model": "roberta-base", "problem_type": "Extractive Question Answering"}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "AutoNLP-RoBERTa-base-SQuAD2 is a model trained using AutoNLP for extractive question answering on the SQuAD2 dataset. The model is based on the RoBERTa-base architecture and can be accessed through cURL or Python API. The model has a CO2 emissions of 44.450538076574766 grams. The model is best suited for extractive question answering tasks."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-0xkrm-q-frozenlake-v1-4x4-noslippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained model of a Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-4x4-no_slippery"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model was trained using the Q-Learning algorithm and evaluated on the FrozenLake-v1-4x4-no_slippery environment. The model achieved a mean reward of 1.00 +/- 0.00, but the verification status is unknown."}}, {"role": "dataset", "purpose": "The environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "extra": "1.00 +/- 0.00", "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-sania67-xlsr-fine-tuned-urdu-v2", "modules": [{"role": "model", "module": {"name": "XLSR_Fine_Tuned_Urdu_V2", "description": "A fine-tuned version of facebook/wav2vec2-large-xlsr-53 on the common_voice_8_0 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0001, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 1000, "num_epochs": 30, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "XLSR_Fine_Tuned_Urdu_V2 is a fine-tuned version of facebook/wav2vec2-large-xlsr-53 on the common_voice_8_0 dataset. The model is intended for automatic speech recognition tasks in Urdu. The model was trained using Adam optimizer with a learning rate of 0.0001 and a batch size of 8. The model achieved a WER of 0.4382 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.2581, "split": "val", "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.8023, "split": "test", "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.4382, "protocol": "WER"}], "source": "huggingface"}, {"id": "huggingface-facebook-blenderbot-small-90m", "modules": [{"role": "model", "module": {"name": "Open-domain chatbot", "description": "A large-scale neural model trained on blended_skill_talk dataset to generate engaging and human-like multi-turn conversations."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_size": ["90M", "2.7B", "9.4B"], "generation_strategy": "Choice of generation strategy"}}}, {"role": "taskType", "module": "conversational"}, {"role": "solutionSummary", "module": {"summary": "This model is an open-domain chatbot that uses large-scale neural models to generate engaging and human-like multi-turn conversations. The model was trained on the blended_skill_talk dataset and evaluated using perplexity. The model outperforms existing approaches in terms of engagingness and humanness measurements. However, the model has limitations, and failure cases were analyzed to understand its limitations."}}, {"role": "dataset", "purpose": "For model training.", "module": "blended-skill-talk"}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-malanga-finetuning-sentiment-model-3000-samples", "modules": [{"role": "model", "module": {"name": "finetuning-sentiment-model-3000-samples", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "finetuning-sentiment-model-3000-samples is a fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis. The model achieved an accuracy of 0.87 and an F1 score of 0.8713 on the evaluation set. The model is suitable for text classification tasks, but its performance may vary depending on the specific use case and data distribution."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.87, "protocol": "accuracy"}, {"dataset": "imdb-movie-reviews", "metric": 0.8712871287128714, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-jyb-vit-base-beans", "modules": [{"role": "model", "module": {"name": "vit-base-beans", "description": "A fine-tuned version of google/vit-base-patch16-224-in21k on the beans dataset for image classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "seed": 1337, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5.0}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "vit-base-beans is a fine-tuned version of google/vit-base-patch16-224-in21k on the beans dataset for image classification. The model achieved an accuracy of 0.9849 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler. The model was trained for 5 epochs with a batch size of 8. The model was trained using Transformers 4.25.0.dev0, Pytorch 1.7.1+cu110, Datasets 2.4.0, and Tokenizers 0.13.2."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "plantvillage"}], "metrics": [{"dataset": "plantvillage", "metric": 0.9849624060150376, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-tlttl-tluo-xml-roberta-base-amazon-review-sentiment-v4", "modules": [{"role": "model", "module": {"name": "tluo_xml_roberta_base_amazon_review_sentiment_v4", "description": "Fine-tuned version of XLM-RoBERTa-base on an unknown dataset for sentiment analysis of Amazon reviews."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1.5745609276104923e-05, "train_batch_size": 4, "eval_batch_size": 4, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "tluo_xml_roberta_base_amazon_review_sentiment_v4 is a fine-tuned version of XLM-RoBERTa-base on an unknown dataset for sentiment analysis of Amazon reviews. The model achieved an accuracy of 0.6137 and a loss of 0.9589 on the evaluation set. The model is suitable for text classification tasks, but the details of the dataset and the model's limitations are unknown."}}, {"role": "dataset", "purpose": "For sentiment analysis.", "module": "amazon-product-data"}], "metrics": [{"dataset": "amazon-product-data", "metric": 0.9589, "protocol": "loss"}, {"dataset": "amazon-product-data", "metric": 0.6137, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-es-is", "modules": [{"role": "model", "module": {"name": "spa-isl", "description": "A transformer-align model for translating from Spanish to Icelandic."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece (spm32k,spm32k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The spa-isl model is a transformer-align model that translates from Spanish to Icelandic. It was trained on the Tatoeba dataset and achieved a BLEU score of 27.1 and a chrF2 score of 0.528 on the Tatoeba-test.spa.isl test set. The model uses normalization and SentencePiece (spm32k,spm32k) for preprocessing."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "tatoeba"}], "metrics": [{"dataset": "tatoeba", "metric": 27.1, "protocol": "BLEU"}, {"dataset": "tatoeba", "metric": 0.528, "protocol": "chrF2_score"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-ko-en", "modules": [{"role": "model", "module": {"name": "transformer-align", "description": "A transformer model trained on Korean-English parallel corpus for translation."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece (spm32k,spm32k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The transformer-align model is a transformer model trained on a Korean-English parallel corpus for translation. It uses normalization and SentencePiece (spm32k,spm32k) for preprocessing. The model achieved a BLEU score of 41.3 and a chrF2 score of 0.588 on the Tatoeba-test.kor.eng test set."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "tatoeba-translation-challenge"}], "metrics": [{"dataset": "tatoeba-translation-challenge", "metric": 41.3, "protocol": "BLEU"}, {"dataset": "tatoeba-translation-challenge", "metric": 0.588, "protocol": "chrF2_score"}], "source": "huggingface"}, {"id": "huggingface-eslamxm-mbart-finetune-en-cnn", "modules": [{"role": "model", "module": {"name": "mbert-finetune-en-cnn", "description": "A fine-tuned version of facebook/mbart-large-50 on the cnn_dailymail dataset for abstractive summarization."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0005, "train_batch_size": 4, "eval_batch_size": 4, "seed": 42, "gradient_accumulation_steps": 8, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 250, "num_epochs": 5, "label_smoothing_factor": 0.1}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "mbert-finetune-en-cnn is a fine-tuned version of facebook/mbart-large-50 on the cnn_dailymail dataset for abstractive summarization. The model achieved a Rouge-1 score of 37.69, Rouge-2 score of 16.47, Rouge-l score of 35.53, Gen Len of 79.93, Bertscore of 74.92, and a loss of 3.5577 on the evaluation set. The model is suitable for abstractive summarization tasks, but its performance may vary depending on the input data and the task requirements."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "cnn-daily-mail"}], "metrics": [{"dataset": "cnn-daily-mail", "metric": 3.5577, "protocol": "Loss"}, {"dataset": "cnn-daily-mail", "metric": 37.69, "protocol": "Rouge-1"}, {"dataset": "cnn-daily-mail", "metric": 16.47, "protocol": "Rouge-2"}, {"dataset": "cnn-daily-mail", "metric": 35.53, "protocol": "Rouge-l"}, {"dataset": "cnn-daily-mail", "metric": 79.93, "protocol": "Gen Len"}, {"dataset": "cnn-daily-mail", "metric": 74.92, "protocol": "Bertscore"}], "source": "huggingface"}, {"id": "huggingface-coolzhao-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8600 on the evaluation set. The model is suitable for token classification tasks in German language. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8600306626540231, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-amagzari-t5-v1-1-small-finetuned-samsum", "modules": [{"role": "model", "module": {"name": "t5-v1_1-small-finetuned-samsum", "description": "A fine-tuned version of google/t5-v1_1-small on the samsum dataset for sequence-to-sequence language modeling."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5.6e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 4}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "t5-v1_1-small-finetuned-samsum is a fine-tuned version of google/t5-v1_1-small on the samsum dataset for sequence-to-sequence language modeling. The model achieved a Rouge1 score of 0.4061, Rouge2 score of 0.1804, Rougel score of 0.3478, and Rougelsum score of 0.3774 on the evaluation set. The model is intended for text summarization tasks, but more information is needed to determine its limitations and intended uses."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "samsum-corpus"}], "metrics": [{"dataset": "samsum-corpus", "metric": 0.4061, "protocol": "Rouge1"}, {"dataset": "samsum-corpus", "metric": 0.1804, "protocol": "Rouge2"}, {"dataset": "samsum-corpus", "metric": 0.3478, "protocol": "Rougel"}, {"dataset": "samsum-corpus", "metric": 0.3774, "protocol": "Rougelsum"}], "source": "huggingface"}, {"id": "huggingface-saeedmaroof-hubert-large-xlsr-common1000asli-demo-colab-dd", "modules": [{"role": "model", "module": {"name": "hubert-large-xlsr-common1000asli-demo-colab-dd", "description": "Fine-tuned version of facebook/hubert-large-ll60k on the common_voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0003, "train_batch_size": 128, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 256, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 1000, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/hubert-large-ll60k on the common_voice dataset. The model is suitable for automatic speech recognition tasks. The model was trained with Adam optimizer and a learning rate of 0.0003. The model was trained for 1000 epochs with a batch size of 256. The model achieved a loss of 1.0754 and a word error rate (WER) of 0.5189 on the evaluation set. The model was trained using PyTorch 1.10.0+cu102 and Transformers 4.11.3."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 1.0754, "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.5189, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-jcastanyo-q-frozenlake-v1-8x8-slippery-v3", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained model of a Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-8x8", "slippery": true}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model was trained using the Q-Learning algorithm on the FrozenLake-v1-8x8 environment. The model achieved a mean reward of 0.29 with a standard deviation of 0.45. The model can be loaded and evaluated using the provided code snippet."}}, {"role": "dataset", "purpose": "The environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 0.29, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-sb3-qrdqn-pongnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "QRDQN Agent playing PongNoFrameskip-v4", "description": "A trained QRDQN agent playing PongNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"env_wrapper": "stable_baselines3.common.atari_wrappers.AtariWrapper", "exploration_fraction": 0.025, "frame_stack": 4, "n_timesteps": 10000000.0, "optimize_memory_usage": true, "policy": "CnnPolicy", "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained QRDQN agent playing PongNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The model was trained for 10 million timesteps with hyperparameters including an exploration fraction of 0.025, frame stack of 4, and a CnnPolicy. The model achieved a mean reward of 20.70 with a standard deviation of 0.46."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-100k"}], "metrics": [{"dataset": "atari-100k", "metric": 20.7, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-setfit-distilbert-base-uncased-sst2-train-32-5", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased__sst2__train-32-5", "description": "A fine-tuned version of distilbert-base-uncased on the SST-2 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 4, "eval_batch_size": 4, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 50, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of distilbert-base-uncased on the SST-2 dataset. The model was trained with Adam optimizer and linear learning rate scheduler for 50 epochs. The model achieved an accuracy of 0.6826 and a loss of 0.6248 on the evaluation set. The model is suitable for text classification tasks."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "sst-stanford-sentiment-treebank"}], "metrics": [{"dataset": "sst-stanford-sentiment-treebank", "metric": 0.6826, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-deepset-bert-base-uncased-squad2", "modules": [{"role": "model", "module": {"name": "bert-base-uncased for QA", "description": "Pretrained BERT model on English language using extractive question answering (QA) task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "n_epochs": 3, "base_LM_model": "bert-base-uncased", "max_seq_len": 384, "learning_rate": 3e-05, "lr_schedule": "LinearWarmup", "warmup_proportion": 0.2, "doc_stride": 128, "max_query_length": 64}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "bert-base-uncased for QA is a BERT model pre-trained on a large corpus of English data in a self-supervised fashion. It is fine-tuned on the SQuAD 2.0 dataset for extractive question answering task. The model is intended to extract the answer from the given context for the given question. The model achieved an exact match score of 73.68% and an F1 score of 77.88% on the SQuAD 2.0 validation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 73.67977764676156, "protocol": "Exact Match"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 77.87647139308865, "protocol": "F1"}], "source": "huggingface"}, {"id": "huggingface-arnolfokam-mbert-base-uncased-ner-pcm", "modules": [{"role": "model", "module": {"name": "mbert-base-uncased-ner-pcm", "description": "A fine-tuned Multilingual BERT base uncased model for Named Entity Recognition using 10 high-resourced languages, fine-tuned on the Nigerian Pidgin corpus of the MasakhaNER dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "batch_size": 32, "max_seq_length": 164, "epochs": 30}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "mbert-base-uncased-ner-pcm is a fine-tuned Multilingual BERT base uncased model for Named Entity Recognition using 10 high-resourced languages, fine-tuned on the Nigerian Pidgin corpus of the MasakhaNER dataset. It recognizes four types of entities: dates & time, location, organizations, and person. The model is intended for research purposes concerning Named Entity Recognition for African Languages and is not intended for practical purposes. The model was trained on a single NVIDIA P5000 from Paperspace."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-ru-eu", "modules": [{"role": "model", "module": {"name": "rus-eus", "description": "A transformer model for translating Russian to Basque."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece (spm4k,spm4k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "A transformer model for translating Russian to Basque. The model was trained on the Tatoeba dataset and achieved a BLEU score of 29.7 and a chrF2 score of 0.539 on the test set. The model uses normalization and SentencePiece (spm4k,spm4k) for preprocessing."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "tatoeba-translation-challenge"}], "metrics": [{"dataset": "tatoeba-translation-challenge", "metric": 29.7, "protocol": "BLEU"}, {"dataset": "tatoeba-translation-challenge", "metric": 0.539, "protocol": "chrF2"}], "source": "huggingface"}, {"id": "huggingface-skvayzer-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 game."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 game. The agent's Q-Table is provided, along with hyperparameters such as the maximum number of steps per episode and the number of episodes used to evaluate the agent. The mean reward achieved by the agent is also provided."}}, {"role": "dataset", "purpose": "The game environment used for training and evaluation.", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.56, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-setfit-distilbert-base-uncased-sst2-train-32-0", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased__sst2__train-32-0", "description": "A fine-tuned version of distilbert-base-uncased on the SST-2 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 4, "eval_batch_size": 4, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 50, "mixed_precision_training": true}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of distilbert-base-uncased on the SST-2 dataset. It can be used for text classification tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 4. The model was trained for 50 epochs and achieved an accuracy of 0.7183 and a loss of 0.8558 on the evaluation set. The model was trained using mixed precision training."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "sst-stanford-sentiment-treebank"}], "metrics": [{"dataset": "sst-stanford-sentiment-treebank", "metric": 0.8558, "protocol": "loss"}, {"dataset": "sst-stanford-sentiment-treebank", "metric": 0.7183, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-jhgan-ko-sbert-nli", "modules": [{"role": "model", "module": {"name": "ko-sbert-nli", "description": "A sentence-transformers model trained on KorNLI dataset for Korean sentence embeddings."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"max_seq_length": 128, "pooling_mode": "mean_tokens", "batch_size": 64, "loss": {"name": "MultipleNegativesRankingLoss", "scale": 20.0, "similarity_fct": "cos_sim"}, "optimizer": {"name": "AdamW", "lr": 2e-05}, "scheduler": "WarmupLinear", "warmup_steps": 889, "weight_decay": 0.01}}}, {"role": "taskType", "module": "sentence-similarity"}, {"role": "solutionSummary", "module": {"summary": "ko-sbert-nli is a sentence-transformers model trained on KorNLI dataset for Korean sentence embeddings. It can be used for clustering or semantic search. The model was trained with a MultipleNegativesRankingLoss loss function and AdamW optimizer. The model achieved good results on KorSTS evaluation dataset. The model is suitable for tasks that require Korean sentence embeddings."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-forkits-dqn-spaceinvadersnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "DQN", "description": "A trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "buffer_size": 100000, "exploration_final_eps": 0.01, "exploration_fraction": 0.1, "frame_stack": 4, "gradient_steps": 1, "learning_rate": 0.0001, "learning_starts": 100000, "n_timesteps": 3500000.0, "optimize_memory_usage": true, "policy": "CnnPolicy", "target_update_interval": 1000, "train_freq": 4, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The model was trained with a batch size of 32, a buffer size of 100000, and a learning rate of 0.0001. The model achieved a mean reward of 844.50 with a standard deviation of 275.98. The model is suitable for reinforcement learning tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 844.5, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-alextoyment-q-frozenlake-v1-4x4-noslippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained model of a Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-4x4-no_slippery"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model was trained using the Q-Learning algorithm and evaluated on the FrozenLake-v1-4x4-no_slippery environment. The model achieved a mean reward of 1.00 +/- 0.00, but the verification status is unknown."}}, {"role": "dataset", "purpose": "The environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "extra": "1.00 +/- 0.00", "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-sq-sv", "modules": [{"role": "model", "module": {"name": "opus-mt-sq-sv", "description": "A machine translation model that translates from Albanian (sq) to Swedish (sv) using the transformer-align architecture."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-sq-sv is a machine translation model that translates from Albanian to Swedish using the transformer-align architecture. The model was trained on the OPUS dataset and achieved a BLEU score of 36.2 on the JW300.sq.sv test set."}}], "metrics": [{"dataset": "jw300", "metric": 36.2, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.559, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-en-ar", "modules": [{"role": "model", "module": {"name": "eng-ara", "description": "A transformer model pre-trained on English and Arabic languages for translation."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece (spm32k,spm32k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "eng-ara is a transformer model pre-trained on English and Arabic languages for translation. It was trained on the Tatoeba-test.eng.ara dataset and achieved a BLEU score of 14.0 and a chrF2 score of 0.437. The model uses normalization and SentencePiece (spm32k,spm32k) for pre-processing. The model is suitable for translating between English and Arabic languages."}}, {"role": "dataset", "purpose": "For evaluation.", "module": "tatoeba-translation-challenge"}], "metrics": [{"dataset": "tatoeba-translation-challenge", "metric": 14.0, "protocol": "BLEU"}, {"dataset": "tatoeba-translation-challenge", "metric": 0.437, "protocol": "chrF2_score"}], "source": "huggingface"}, {"id": "huggingface-speechbrain-mtl-mimic-voicebank", "modules": [{"role": "model", "module": {"name": "ResNet-like model", "description": "A ResNet-like model for speech enhancement and robust ASR training using mimic loss."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"pretrained_model": "speechbrain/mtl-mimic-voicebank", "test_PESQ": 3.05, "test_COVL": 3.74, "valid_WER": 2.89, "test_WER": 2.8}}}, {"role": "taskType", "module": "audio-to-audio"}, {"role": "solutionSummary", "module": {"summary": "The ResNet-like model is a speech enhancement and robust ASR training model that uses mimic loss. The model is pre-trained on clean speech features and fine-tuned on the Voicebank and DEMAND datasets. The model can be used for enhancement and ASR tasks. The model is trained with recordings sampled at 16kHz (single channel)."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-torayeff-bert-finetuned-ner", "modules": [{"role": "model", "module": {"name": "bert-finetuned-ner", "description": "A fine-tuned version of bert-base-cased on the conll2003 dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-finetuned-ner is a fine-tuned version of bert-base-cased on the conll2003 dataset for token classification. The model achieved high precision, recall, F1 score, and accuracy on the evaluation set. The model is suitable for named entity recognition tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 0.9359059291156012, "protocol": "precision"}, {"dataset": "conll-2003", "metric": 0.9510265903736116, "protocol": "recall"}, {"dataset": "conll-2003", "metric": 0.9434056761268781, "protocol": "f1"}, {"dataset": "conll-2003", "metric": 0.9861511744275033, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-cj-mills-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8576 on the evaluation set. The model is suitable for token classification tasks in German language. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8575809199318569, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-microsoft-xclip-base-patch16-16-frames", "modules": [{"role": "model", "module": {"name": "X-CLIP (base-sized model)", "description": "X-CLIP is a minimal extension of CLIP for general video-language understanding. The model is trained in a contrastive way on (video, text) pairs. This allows the model to be used for tasks like zero-shot, few-shot or fully supervised video classification and video-text retrieval."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"patch_resolution": 16, "frames_per_video": 16, "resolution": "224x224"}}}, {"role": "taskType", "module": "video-classification"}, {"role": "solutionSummary", "module": {"summary": "X-CLIP is a base-sized model trained on Kinetics-400 for general video-language understanding. The model is trained in a contrastive way on (video, text) pairs, which allows it to be used for tasks like zero-shot, few-shot or fully supervised video classification and video-text retrieval. The model achieves a top-1 accuracy of 84.7% and a top-5 accuracy of 96.8%."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "kinetics-400"}], "metrics": [{"dataset": "kinetics-400", "metric": 84.7, "protocol": "top-1 accuracy"}, {"dataset": "kinetics-400", "metric": 96.8, "protocol": "top-5 accuracy"}], "source": "huggingface"}, {"id": "huggingface-autoevaluate-roberta-base-squad2", "modules": [{"role": "model", "module": {"name": "roberta-base for QA", "description": "A fine-tuned RoBERTa model on the SQuAD2.0 dataset for the task of Question Answering."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 96, "n_epochs": 2, "base_LM_model": "roberta-base", "max_seq_len": 386, "learning_rate": 3e-05, "lr_schedule": "LinearWarmup", "warmup_proportion": 0.2, "doc_stride": 128, "max_query_length": 64}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned RoBERTa model on the SQuAD2.0 dataset for the task of Question Answering. The model was trained on question-answer pairs, including unanswerable questions. It can be used for extractive QA tasks. The model can be used in Haystack or Transformers. The distilled version of this model is called deepset/tinyroberta-squad2. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 79.87029394424324, "protocol": "exact"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 82.91251169582613, "protocol": "f1"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 77.93522267206478, "protocol": "HasAns_exact"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 84.02838248389763, "protocol": "HasAns_f1"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 5928.0, "protocol": "HasAns_total"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 81.79983179142137, "protocol": "NoAns_exact"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 81.79983179142137, "protocol": "NoAns_f1"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 5945.0, "protocol": "NoAns_total"}], "source": "huggingface"}, {"id": "huggingface-rohank447-swin-tiny-patch4-window7-224-finetuned-vosap", "modules": [{"role": "model", "module": {"name": "swin-tiny-patch4-window7-224-finetuned-vosap", "description": "A fine-tuned version of microsoft/swin-tiny-patch4-window7-224 on the imagefolder dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 32, "eval_batch_size": 32, "seed": 42, "gradient_accumulation_steps": 4, "total_train_batch_size": 128, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "num_epochs": 20}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of microsoft/swin-tiny-patch4-window7-224 on the imagefolder dataset. The model achieved an accuracy of 0.75 on the evaluation set. The model is intended for image classification tasks. The hyperparameters used for training include a learning rate of 5e-05, a batch size of 32, and a total train batch size of 128. The model was trained for 20 epochs using the Adam optimizer with betas=(0.9, 0.999) and epsilon=1e-08."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "objectfolder"}], "metrics": [{"dataset": "objectfolder", "metric": 0.75, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-palak-albert-large-v2-squad", "modules": [{"role": "model", "module": {"name": "albert-large-v2_squad", "description": "Fine-tuned version of albert-large-v2 on the squadV1 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 3e-05, "train_batch_size": 16, "eval_batch_size": 32, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "albert-large-v2_squad is a fine-tuned version of albert-large-v2 on the squadV1 dataset. It is a question-answering model that can be used to answer questions based on a given context. The model was trained using Adam optimizer with a learning rate of 3e-05 and a batch size of 16. The model achieved an exact match score of 84.8% and an F1 score of 91.8% on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 84.80605487228004, "protocol": "exact_match"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 91.80638438705844, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-chaunguyen23-phobert-base-finetuned-imdb", "modules": [{"role": "model", "module": {"name": "phobert-base-finetuned-imdb", "description": "A fine-tuned version of vinai/phobert-base on the imdb dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "phobert-base-finetuned-imdb is a fine-tuned version of vinai/phobert-base on the imdb dataset. The model is suitable for text classification tasks. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64. The model was trained for 3 epochs and achieved a loss of 2.6149 on the evaluation set. The model was trained using PyTorch 1.11.0+cu113 and Transformers 4.20.1."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 2.6149, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-kingabzpro-wav2vec2-large-xls-r-300m-urdu", "modules": [{"role": "model", "module": {"name": "wav2vec2-large-xls-r-300m-Urdu", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset for Urdu speech recognition."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0001, "train_batch_size": 32, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 1000, "num_epochs": 200}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "The wav2vec2-large-xls-r-300m-Urdu model is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset for Urdu speech recognition. The model achieved a WER of 39.89% and a CER of 16.7% on the Common Voice 8 test set. The model was trained with Adam optimizer with a learning rate of 0.0001, and a linear learning rate scheduler with warmup steps of 1000. The model was trained for 200 epochs with a batch size of 32 and a gradient accumulation step of 2."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-clevrly-xlnet-base-rte-finetuned", "modules": [{"role": "model", "module": {"name": "xlnet-base-rte-finetuned", "description": "A fine-tuned version of xlnet-base-cased on the glue dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 1, "eval_batch_size": 1, "seed": 42, "gradient_accumulation_steps": 8, "total_train_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "xlnet-base-rte-finetuned is a fine-tuned version of xlnet-base-cased on the glue dataset. It is a transformer model that can be used for text classification tasks. The model achieved an accuracy of 0.7039 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler. The model was trained for 5 epochs with a batch size of 8."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.703971119133574, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-fxmarty-distilbert-base-uncased-finetuned-sst-2-english-int8-static", "modules": [{"role": "model", "module": {"name": "DistilBERT base model (uncased) finetuned on SST-2", "description": "A quantized version of the DistilBERT base model (uncased) finetuned on the SST-2 dataset using static Post-Training Quantization (PTQ) with ONNX Runtime and \ud83e\udd17 Optimum library."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"quantization_method": "static PTQ", "accuracy": 0.894}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a quantized version of the DistilBERT base model (uncased) finetuned on the SST-2 dataset using static Post-Training Quantization (PTQ) with ONNX Runtime and \ud83e\udd17 Optimum library. The model can be used for text classification tasks. The model achieves an accuracy of 0.894 on the validation set. The model is a fork of https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-hamzab-roberta-fake-news-classification", "modules": [{"role": "model", "module": {"name": "roberta-fake-news-classification", "description": "A RoBERTa-base model fine-tuned on the fake-and-real-news-dataset to classify news articles as either true or fake."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_architecture": "RoBERTa-base", "max_length": 512, "padding": "max_length", "truncation": true}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a RoBERTa-base model fine-tuned on the fake-and-real-news-dataset to classify news articles as either true or fake. The model takes a news article as input and predicts whether it is true or fake with 100% accuracy on the fine-tuning dataset. The model can be used in Python code or with Gradio for real-time testing."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "news-articles-dataset-with-summary"}], "metrics": [{"dataset": "news-articles-dataset-with-summary", "metric": 1.0, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-fi-wls", "modules": [{"role": "model", "module": {"name": "opus-mt-fi-wls", "description": "A machine translation model that translates from Finnish (fi) to Welsh (wls) using the transformer-align architecture."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-fi-wls is a machine translation model that translates from Finnish to Welsh. It uses the transformer-align architecture and was preprocessed using normalization and SentencePiece. The model achieved a BLEU score of 24.7 and a chr-F score of 0.466 on the JW300.fi.wls test set."}}], "metrics": [{"dataset": "jw300", "metric": 24.7, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.466, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-mos-en", "modules": [{"role": "model", "module": {"name": "opus-mt-mos-en", "description": "A machine translation model that translates from the Mos language to English."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-mos-en is a machine translation model that translates from the Mos language to English. The model uses the transformer-align architecture and pre-processing techniques such as normalization and SentencePiece. The model has been benchmarked on the JW300.mos.en test set and achieved a BLEU score of 26.1 and a chr-F score of 0.408."}}, {"role": "dataset", "purpose": "Test set for benchmarking.", "module": "jw300"}], "metrics": [{"dataset": "jw300", "metric": 26.1, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.408, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-savasy-bert-base-turkish-sentiment-cased", "modules": [{"role": "model", "module": {"name": "Bert-base Turkish Sentiment Model", "description": "Pretrained model on Turkish language using a masked language modeling (MLM) objective."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_type": "bert", "max_seq_length": 128, "per_gpu_train_batch_size": 32, "learning_rate": 2e-05, "num_train_epochs": 3.0}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "Bert-base Turkish Sentiment Model is a transformer model pre-trained on a large Turkish corpus. It can be used for sentiment analysis tasks in Turkish language. The model is fine-tuned on a merged dataset of movie and product reviews and tweet dataset. The model achieves an accuracy of 95.4% on the SST-2 dataset. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training.", "module": "imdb-movie-reviews"}, {"role": "dataset", "purpose": "For model training.", "module": "twitter-sentiment-analysis-entity-level-twitter-sentiment-analysis-dataset"}, {"role": "dataset", "purpose": "For evaluation.", "module": "sst-stanford-sentiment-treebank"}], "metrics": [{"dataset": "sst-stanford-sentiment-treebank", "metric": 0.9539942492811602, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-ayazhankad-bert-finetuned-semantic-chinese", "modules": [{"role": "model", "module": {"name": "bert-finetuned-sentiment-chinese", "description": "A fine-tuned version of bert-base-chinese on the Douban Movies Short Comments dataset for multilabel text classification based on semantics."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-finetuned-sentiment-chinese is a fine-tuned version of bert-base-chinese on the Douban Movies Short Comments dataset for multilabel text classification based on semantics. The model assigns one of five labels to the input text, ranging from very negative to very positive. The model is suitable for multilabel text classification tasks in Chinese, but may exhibit biases present in the training data and the base model."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "douban-douban-conversation-corpus"}], "metrics": [{"dataset": "douban-douban-conversation-corpus", "metric": 0.4446, "protocol": "loss"}, {"dataset": "douban-douban-conversation-corpus", "metric": 0.5309, "protocol": "f1"}, {"dataset": "douban-douban-conversation-corpus", "metric": 0.704, "protocol": "roc_auc"}, {"dataset": "douban-douban-conversation-corpus", "metric": 0.512, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-zne-sv", "modules": [{"role": "model", "module": {"name": "opus-mt-zne-sv", "description": "A transformer-align model for translating from zne to sv."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-zne-sv model is a transformer-align model that translates from the ZNE language to Swedish. The model was preprocessed using normalization and SentencePiece. The model achieved a BLEU score of 25.2 and a chr-F score of 0.425 on the JW300.zne.sv test set."}}], "metrics": [{"dataset": "jw300", "metric": 25.2, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.425, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-wende-bert-finetuned-ner", "modules": [{"role": "model", "module": {"name": "bert-finetuned-ner", "description": "A fine-tuned version of bert-base-cased on the conll2003 dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-finetuned-ner is a fine-tuned version of bert-base-cased on the conll2003 dataset for token classification. The model achieved high precision, recall, F1 score, and accuracy on the evaluation set. The model is suitable for named entity recognition tasks, but caution should be taken when deploying it in human-interacting systems as it may reflect the biases of the systems it was trained on."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 0.9321670242614293, "protocol": "Precision"}, {"dataset": "conll-2003", "metric": 0.9505217098619994, "protocol": "Recall"}, {"dataset": "conll-2003", "metric": 0.9412548954253812, "protocol": "F1"}, {"dataset": "conll-2003", "metric": 0.9860334373344322, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-jethuestad-dat259-nor-wav2vec2", "modules": [{"role": "model", "module": {"name": "dat259-nor-wav2vec2", "description": "A fine-tuned version of NbAiLab/nb-wav2vec2-300m-nynorsk on the common_voice_8_0 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0001, "train_batch_size": 16, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 5, "num_epochs": 10, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "dat259-nor-wav2vec2 is a fine-tuned version of NbAiLab/nb-wav2vec2-300m-nynorsk on the common_voice_8_0 dataset. It is a speech recognition model that can transcribe Norwegian speech to text. The model was trained using the Wav2Vec2 architecture and achieved a WER of 1.1259 on the evaluation set. The model was trained using PyTorch and Transformers libraries."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 11.0168, "split": "val", "protocol": "loss"}, {"dataset": "common-voice", "metric": 10.9446, "split": "test", "protocol": "loss"}, {"dataset": "common-voice", "metric": 1.1259, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-mmeet611-finetuning-sentiment-model-3000-samples", "modules": [{"role": "model", "module": {"name": "finetuning-sentiment-model-3000-samples", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis. It achieves an accuracy of 0.8633 and an F1 score of 0.8629 on the evaluation set. The model is suitable for text classification tasks, but its performance may vary depending on the specific use case and data distribution. The model was trained using PyTorch 1.11.0+cu113 and Transformers 4.20.1."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.8633, "protocol": "accuracy"}, {"dataset": "imdb-movie-reviews", "metric": 0.8629, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-kulinwot-swin-tiny-patch4-window7-224-finetuned-eurosat", "modules": [{"role": "model", "module": {"name": "swin-tiny-patch4-window7-224-finetuned-eurosat", "description": "A fine-tuned version of microsoft/swin-tiny-patch4-window7-224 on the imagefolder dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "gradient_accumulation_steps": 4, "total_train_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "num_epochs": 3}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "A fine-tuned version of microsoft/swin-tiny-patch4-window7-224 on the imagefolder dataset. The model achieved an accuracy of 0.7656 on the evaluation set. More information is needed to describe the model and its intended uses and limitations."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "objectfolder"}], "metrics": [{"dataset": "objectfolder", "metric": 0.7656078860898138, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-sv-ig", "modules": [{"role": "model", "module": {"name": "opus-mt-sv-ig", "description": "A machine translation model that translates from Swedish (sv) to Igbo (ig) using a transformer-align architecture."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-sv-ig model is a machine translation model that translates from Swedish to Igbo using a transformer-align architecture. The model achieved a BLEU score of 31.1 and a chr-F score of 0.479 on the JW300.sv.ig test set."}}], "metrics": [{"dataset": "jw300", "metric": 31.1, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.479, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-es-eu", "modules": [{"role": "model", "module": {"name": "spa-eus", "description": "A transformer model for translating from Spanish to Basque."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece (spm32k,spm32k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "spa-eus is a transformer model trained on Spanish to Basque translation task. The model uses normalization and SentencePiece (spm32k,spm32k) for preprocessing. The model achieved a BLEU score of 37.0 and a chrF2 score of 0.638 on the Tatoeba-test.spa.eus dataset."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "tatoeba"}], "metrics": [{"dataset": "tatoeba", "metric": 37.0, "protocol": "BLEU"}, {"dataset": "tatoeba", "metric": 0.638, "protocol": "chrF2_score"}], "source": "huggingface"}, {"id": "huggingface-jo-kwsm-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8646 on the evaluation set. The model is suitable for token classification tasks in German language. The training was done using Adam optimizer with a learning rate of 5e-05 and a batch size of 24. The model was trained for 3 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8645595618439068, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-mosesju-distilbert-base-uncased-finetuned-news", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-news", "description": "A fine-tuned version of distilbert-base-uncased on the ag_news dataset for categorizing news headlines into one of four categories: World, Sports, Science & Technology, or Business."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0002, "train_batch_size": 32, "eval_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-news is a fine-tuned version of distilbert-base-uncased on the ag_news dataset for categorizing news headlines into one of four categories: World, Sports, Science & Technology, or Business. The model achieved an accuracy of 0.9388 and an F1 score of 0.9388 on the evaluation set. The model is limited by the training data it used and may produce confused results if used with news stories outside of the four intended categories."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "ag-news-ags-news-corpus"}], "metrics": [{"dataset": "ag-news-ags-news-corpus", "metric": 0.9388157894736842, "protocol": "accuracy"}, {"dataset": "ag-news-ags-news-corpus", "metric": 0.9388275184627893, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-sahajtomar-french-semantic", "modules": [{"role": "model", "module": {"name": "French STS", "description": "A sentence-transformer model trained on the STS dataset for French language."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_type": "sentence-transformers", "model_name": "SentenceTransformer", "embedding_size": "default", "batch_size": "default"}}}, {"role": "taskType", "module": "sentence-similarity"}, {"role": "solutionSummary", "module": {"summary": "French STS is a sentence-transformer model trained on the STS dataset for French language. It can be used to encode sentences into embeddings and calculate their similarity. The model achieved an accuracy of 87.4% on the STS dev dataset and 85.8% on the STS test dataset. The model is suitable for tasks such as information retrieval and clustering/grouping."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "sts-benchmark"}], "metrics": [{"dataset": "sts-benchmark", "metric": 87.4, "protocol": "STS dev (french)"}, {"dataset": "sts-benchmark", "metric": 85.8, "protocol": "STS test (french)"}], "source": "huggingface"}, {"id": "huggingface-hiro90-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. The model is best suited for text classification tasks. The model achieved an accuracy of 0.924 and an F1 score of 0.9241 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.924, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.9240516019628855, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-mbeukman-xlm-roberta-base-finetuned-hausa-finetuned-ner-hausa", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-hausa-finetuned-ner-hausa", "description": "A token classification model fine-tuned on the MasakhaNER dataset for Hausa NER."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"max_seq_length": 200, "batch_size": 32, "learning_rate": 5e-05, "epochs": 50}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a token classification model fine-tuned on the MasakhaNER dataset for Hausa NER. The model is transformer-based and was fine-tuned for 50 epochs with a maximum sequence length of 200, 32 batch size, and 5e-5 learning rate. The model is intended for NLP research into interpretability or transfer learning and is not designed for production use. The model's limitations include being trained on a relatively small dataset covering one task in one domain and may perform poorly on other tasks. The model is licensed under the Apache License, Version 2.0."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "masakhaner"}], "metrics": [{"dataset": "masakhaner", "metric": 92.27, "protocol": "f1"}, {"dataset": "masakhaner", "metric": 90.46, "protocol": "precision"}, {"dataset": "masakhaner", "metric": 94.16, "protocol": "recall"}], "source": "huggingface"}, {"id": "huggingface-google-electra-large-generator", "modules": [{"role": "model", "module": {"name": "ELECTRA", "description": "A method for self-supervised language representation learning that pre-trains transformer networks using relatively little compute."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"pre-training_method": "discriminator-based", "model_size": "large"}}}, {"role": "taskType", "module": "fill-mask"}, {"role": "solutionSummary", "module": {"summary": "ELECTRA is a method for self-supervised language representation learning that pre-trains transformer networks using a discriminator-based approach. It can be used to pre-train transformer networks using relatively little compute. ELECTRA models are trained to distinguish 'real' input tokens vs 'fake' input tokens generated by another neural network. The model achieves state-of-the-art results on the SQuAD 2.0 dataset. The model can be fine-tuned on downstream tasks including classification tasks, QA tasks, and sequence tagging tasks."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-drewski-distilbert-base-uncased-finetuned-cola", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-cola", "description": "A fine-tuned version of distilbert-base-uncased on the glue dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-cola is a fine-tuned version of distilbert-base-uncased on the glue dataset. It is suitable for text classification tasks. The model achieved a Matthews Correlation score of 0.5258 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler. The model was trained for 5 epochs with a batch size of 16."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.5258252097729852, "protocol": "matthews_correlation"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-fr-kg", "modules": [{"role": "model", "module": {"name": "opus-mt-fr-kg", "description": "A machine translation model that translates from French (fr) to Kongo (kg) language."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-fr-kg is a machine translation model that translates from French to Kongo language. The model uses transformer-align architecture and normalization + SentencePiece pre-processing. The model has been evaluated on JW300.fr.kg test set and achieved a BLEU score of 30.4 and a chr-F score of 0.523."}}], "metrics": [{"dataset": "jw300", "metric": 30.4, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.523, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-fabriceyhc-bert-base-uncased-amazon-polarity", "modules": [{"role": "model", "module": {"name": "bert-base-uncased-amazon_polarity", "description": "Fine-tuned version of bert-base-uncased on the amazon_polarity dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 1, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 1782000, "training_steps": 17820000}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of bert-base-uncased on the amazon_polarity dataset. It can be used for text classification tasks. The model achieved an accuracy of 0.94647 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 5e-05 and a linear learning rate scheduler with warmup steps of 1782000. The model was trained for 17820000 steps with a batch size of 1 for training and 8 for evaluation."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "amazon-review"}], "metrics": [{"dataset": "amazon-review", "metric": 0.94647, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-husnu-wav2vec2-large-xls-r-300m-turkish-colab", "modules": [{"role": "model", "module": {"name": "wav2vec2-large-xls-r-300m-turkish-colab", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice_6.1 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0003, "train_batch_size": 16, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 30, "mixed_precision_training": true}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice_6.1 dataset. The model is intended for automatic speech recognition tasks. The model was trained using Adam optimizer with a learning rate of 0.0003, and a linear learning rate scheduler with 500 warmup steps. The model achieved a WER of 0.3508 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.056, "split": "val", "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.438, "split": "test", "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.3508, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-amir36-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. The model is best suited for text classification tasks. The model achieved an accuracy of 0.921 and an F1 score of 0.920970510317642 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.921, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.920970510317642, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-mishig-test-regex-searchreplace", "modules": [{"role": "model", "module": {"name": "Wav2Vec2-Base for Speaker Identification", "description": "A ported version of S3PRL's Wav2Vec2 for the SUPERB Speaker Identification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_name": "wav2vec2-base", "preprocessing": {"sampling_rate": "16kHz"}}}}, {"role": "taskType", "module": "audio-classification"}, {"role": "solutionSummary", "module": {"summary": "Wav2Vec2-Base for Speaker Identification is a ported version of S3PRL's Wav2Vec2 for the SUPERB Speaker Identification task. The model is trained on the VoxCeleb1 dataset and can classify each utterance for its speaker identity as a multi-class classification. The model is best used via the Audio Classification pipeline or directly. The evaluation metric is accuracy."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-azizbarank-mbert-finetuned-azerbaijani-ner", "modules": [{"role": "model", "module": {"name": "mbert-finetuned-azerbaijani-ner", "description": "A fine-tuned version of bert-base-multilingual-cased on the wikiann dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "mbert-finetuned-azerbaijani-ner is a fine-tuned version of bert-base-multilingual-cased on the wikiann dataset for token classification. The model achieved high precision, recall, F1 score, and accuracy on the evaluation set. The model is suitable for named entity recognition tasks in Azerbaijani language."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wikiann"}], "metrics": [{"dataset": "wikiann", "metric": 0.8898541731306236, "protocol": "precision"}, {"dataset": "wikiann", "metric": 0.915416533673795, "protocol": "recall"}, {"dataset": "wikiann", "metric": 0.9024543738200126, "protocol": "f1"}, {"dataset": "wikiann", "metric": 0.966948310139165, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-thomassimonini-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 environment."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "q-Taxi-v3 is a Q-Learning agent trained to play the Taxi-v3 environment. The model achieved a mean reward of 7.56 +/- 2.71. The model can be loaded using the provided pickle file and evaluated using the evaluate_agent function."}}, {"role": "dataset", "purpose": "OpenAI Gym environment", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.56, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-idea-ccnl-yuyuanqa-gpt2-3-5b", "modules": [{"role": "model", "module": {"name": "YuyuanQA-GPT2-3.5B", "description": "A GPT2 model fine-tuned on 10K medical Q&A pairs."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_size": "3.5B", "tokenizer": "GPT2Tokenizer", "max_length": 150, "top_p": 0.6, "num_return_sequences": 5, "do_sample": true}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "YuyuanQA-GPT2-3.5B is a GPT2 model fine-tuned on 10K medical Q&A pairs. It is intended for use in medical question answering tasks. The model is best suited for tasks that require the whole sentence to make decisions, such as sequence classification, token classification, or question answering. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For fine-tuning.", "module": "medical-question-pairs-medical-question-pairs-mqp-dataset"}], "metrics": [{"dataset": "medical-question-pairs-medical-question-pairs-mqp-dataset", "metric": 0.22304, "split": "val", "protocol": "bleu score"}, {"dataset": "medical-question-pairs-medical-question-pairs-mqp-dataset", "metric": 0.19099, "split": "test", "protocol": "bleu score"}], "source": "huggingface"}, {"id": "huggingface-mrm8488-roberta-large-finetuned-wsc", "modules": [{"role": "model", "module": {"name": "RoBERTa (large) fine-tuned on Winograd Schema Challenge (WSC) data", "description": "RoBERTa is a transformer model pretrained on a large corpus of English data in a self-supervised fashion. This model is fine-tuned on the WSC dataset using a single cross-entropy loss term over the log-probabilities for the query and all mined candidates. The candidates are mined using spaCy from each input sentence in isolation, so the approach remains strictly pointwise."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 16, "optimizer": {"name": "Adam", "learning_rate": 2e-05, "beta1": 0.9, "beta2": 0.98, "weight_decay": 0.01, "eps": 1e-06}, "dropout": 0.1, "attention_dropout": 0.1, "max_positions": 512, "warmup_updates": 250, "total_num_updates": 2000, "max_sentences": 16, "max_update": 2000, "seed": 1}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "RoBERTa is a transformer model pretrained on a large corpus of English data in a self-supervised fashion. This model is fine-tuned on the WSC dataset using a single cross-entropy loss term over the log-probabilities for the query and all mined candidates. The model is suitable for question-answering tasks, such as the WSC dataset. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training.", "module": "wsc-winograd-schema-challenge"}], "metrics": [{"dataset": "wsc-winograd-schema-challenge", "metric": 0.9230769230769231, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-infinitejoy-wav2vec2-large-xls-r-300m-odia-cv8", "modules": [{"role": "model", "module": {"name": "wav2vec2-large-xls-r-300m-odia-cv8", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-300m on the MOZILLA-FOUNDATION/COMMON_VOICE_8_0 - OR dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0003, "train_batch_size": 32, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 100.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "The wav2vec2-large-xls-r-300m-odia-cv8 model is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the MOZILLA-FOUNDATION/COMMON_VOICE_8_0 - OR dataset. The model is intended for automatic speech recognition tasks. The model achieved a WER of 0.5818 on the evaluation set. The model was trained using PyTorch 1.10.2+cu102 and Transformers 4.17.0.dev0."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.5385, "split": "val", "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.8015, "split": "test", "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.5818, "protocol": "WER"}], "source": "huggingface"}, {"id": "huggingface-palak-distilroberta-base-squad", "modules": [{"role": "model", "module": {"name": "distilroberta-base_squad", "description": "A fine-tuned version of distilroberta-base on the squadV1 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 3e-05, "train_batch_size": 32, "eval_batch_size": 32, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "distilroberta-base_squad is a fine-tuned version of distilroberta-base on the squadV1 dataset. It can be used for question answering tasks. The model was trained with Adam optimizer with a learning rate of 3e-05 and a batch size of 32. The model was trained for 3 epochs. The evaluation results show that the model has an F1 score of 88.015% and an exact match score of 80.974% on the squadV1 dataset."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 80.97445600756859, "protocol": "exact_match"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 88.0153886332912, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-jungwoo4021-wav2vec2-base-ks-padpt1600", "modules": [{"role": "model", "module": {"name": "wav2vec2-base-ks-padpt1600", "description": "A fine-tuned version of facebook/wav2vec2-base on the superb dataset for audio classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.003, "train_batch_size": 256, "eval_batch_size": 256, "seed": 0, "gradient_accumulation_steps": 4, "total_train_batch_size": 1024, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "num_epochs": 10.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "audio-classification"}, {"role": "solutionSummary", "module": {"summary": "wav2vec2-base-ks-padpt1600 is a fine-tuned version of facebook/wav2vec2-base on the superb dataset for audio classification. The model was trained using Adam optimizer with a learning rate of 0.003 and a linear learning rate scheduler with a warmup ratio of 0.1. The model achieved an accuracy of 0.6111 and a loss of 1.6019 on the evaluation set. The model is suitable for audio classification tasks, but its performance may vary depending on the specific use case and data distribution."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "mediaspeech"}], "metrics": [{"dataset": "mediaspeech", "metric": 0.6111, "protocol": "accuracy"}, {"dataset": "mediaspeech", "metric": 1.6019, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-racheltong-wav2vec2-large-xlsr-chinese", "modules": [{"role": "model", "module": {"name": "wav2vec2-large-xlsr-chinese", "description": "A fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.001, "train_batch_size": 16, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 1000, "num_epochs": 15, "mixed_precision_training": true}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "A fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset. The model is suitable for automatic speech recognition tasks in Chinese. The model was trained with Adam optimizer and linear learning rate scheduler. The model was trained for 15 epochs with mixed precision training. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 16.1908, "split": "val", "protocol": "loss"}, {"dataset": "common-voice", "metric": 3.3216, "split": "test", "protocol": "loss"}, {"dataset": "common-voice", "metric": 1.0, "protocol": "CER"}], "source": "huggingface"}, {"id": "huggingface-malteos-gpt2-xl-wechsel-german", "modules": [{"role": "model", "module": {"name": "German GPT2-XL (1.5B)", "description": "Pretrained model on German language using a causal language modeling (CLM) objective."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": null, "optimizer": null}}}, {"role": "taskType", "module": "text-generation"}, {"role": "solutionSummary", "module": {"summary": "German GPT2-XL (1.5B) is a transformer model pretrained on a large corpus of German data in a self-supervised fashion. It can be used for text generation or fine-tuned for downstream tasks. The model is best at generating texts from a prompt. The model reflects the biases inherent to the systems they were trained on, so caution should be taken when deploying it into systems that interact with humans."}}, {"role": "dataset", "purpose": "For model training.", "module": "oscar"}], "metrics": [{"dataset": "oscar", "metric": 14.5, "protocol": "PPL"}], "source": "huggingface"}, {"id": "huggingface-robertomca97-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. The model is best suited for text classification tasks. The model achieved an accuracy of 0.9255 and an F1 score of 0.9258 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.9255, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.9257511693451751, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-sujathass-bert-base-uncased-finetuned-cola", "modules": [{"role": "model", "module": {"name": "bert-base-uncased-finetuned-cola", "description": "A fine-tuned version of bert-base-uncased on the glue dataset for text classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 32, "eval_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 4}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-base-uncased-finetuned-cola is a fine-tuned version of bert-base-uncased on the glue dataset for text classification. The model achieved a Matthews Correlation score of 0.5911 on the evaluation set. The model is suitable for text classification tasks, but its performance may vary depending on the specific task and dataset. Caution should be taken when deploying it in human-interacting systems as the model reflects the biases of the systems it was trained on."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.5911, "protocol": "matthews_correlation"}], "source": "huggingface"}, {"id": "huggingface-shafin-distilbert-base-uncased-finetuned-cust-similarity-2", "modules": [{"role": "model", "module": {"name": "shafin/distilbert-base-uncased-finetuned-cust-similarity-2", "description": "A sentence-transformers model that maps sentences and paragraphs to a 128-dimensional dense vector space for clustering or semantic search."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"max_seq_length": 128, "do_lower_case": false, "batch_size": 16, "loss": "OnlineContrastiveLoss", "epochs": 15, "optimizer": {"name": "AdamW", "learning_rate": 2e-05}, "scheduler": "WarmupLinear", "warmup_steps": 3000, "weight_decay": 0.01}}}, {"role": "taskType", "module": "sentence-similarity"}, {"role": "solutionSummary", "module": {"summary": "shafin/distilbert-base-uncased-finetuned-cust-similarity-2 is a sentence-transformers model that maps sentences and paragraphs to a 128-dimensional dense vector space for clustering or semantic search. The model was trained using a custom dataset and the OnlineContrastiveLoss loss function. The model architecture consists of a DistilBertModel, a pooling layer, and two dense layers with Tanh activation functions. The model was trained for 15 epochs with an AdamW optimizer and a learning rate of 2e-05. No evaluation scores were provided."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-6001k1d-dqn-spaceinvadersnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "DQN", "description": "A trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "buffer_size": 100000, "exploration_final_eps": 0.01, "exploration_fraction": 0.1, "frame_stack": 4, "gradient_steps": 1, "learning_rate": 0.0001, "learning_starts": 100000, "n_timesteps": 1000000.0, "optimize_memory_usage": false, "policy": "CnnPolicy", "target_update_interval": 1000, "train_freq": 4, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "The DQN model is a reinforcement learning agent trained on the SpaceInvadersNoFrameskip-v4 environment using the stable-baselines3 library and the RL Zoo. The model achieved a mean reward of 599.00 +/- 222.51. The hyperparameters used for training include batch size, buffer size, exploration fraction, learning rate, and target update interval, among others. The RL Zoo provides a training framework for stable-baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 599.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-atlijas-byt5-is-ocr-post-processing-modern-texts", "modules": [{"role": "model", "module": {"name": "byt5-is-ocr-post-processing-modern-texts", "description": "A model that generates a revised version of a given Icelandic OCRed text. The model was trained with simpleT5 on 900.000 lines of which only 50.000 were from real OCRed texts. It can be assumed that increasing the amount of OCRed data can significantly improve the model."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "atlijas/byt5-is-ocr-post-processing-old-texts", "tokenizer": "atlijas/byt5-is-ocr-post-processing-old-texts", "num_return_sequences": 1, "max_length": 150, "batch_size": 32}}}, {"role": "taskType", "module": "text-generation"}, {"role": "solutionSummary", "module": {"summary": "byt5-is-ocr-post-processing-modern-texts is a model that generates a revised version of a given Icelandic OCRed text. The model was trained with simpleT5 on 900.000 lines of which only 50.000 were from real OCRed texts. It can be assumed that increasing the amount of OCRed data can significantly improve the model. The model achieved a chrF error rate reduction of 30.1% and a proportional BLEU improvement of 19.8% on a test set of various Icelandic texts from the 80's and 90's."}}, {"role": "dataset", "purpose": "For pre-training.", "module": "mc4"}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-joriscos-dcunet-libri1mix-enhsingle-16k", "modules": [{"role": "model", "module": {"name": "JorisCos/DCUNet_Libri1Mix_enhsignle_16k", "description": "Asteroid model trained on the `enh_single` task of the Libri1Mix dataset using DCUNet architecture."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"data": {"n_src": 1, "sample_rate": 16000, "segment": 3, "task": "enh_single", "train_dir": "data/wav16k/min/train-360", "valid_dir": "data/wav16k/min/dev"}, "filterbank": {"stft_n_filters": 1024, "stft_kernel_size": 1024, "stft_stride": 256}, "masknet": {"architecture": "Large-DCUNet-20", "fix_length_mode": "pad", "n_src": 1}, "optim": {"lr": 0.001, "optimizer": "adam", "weight_decay": 1e-05}, "training": {"batch_size": 2, "early_stop": true, "epochs": 200, "gradient_clipping": 5, "half_lr": true, "num_workers": 4}}}}, {"role": "taskType", "module": "audio-to-audio"}, {"role": "solutionSummary", "module": {"summary": "JorisCos/DCUNet_Libri1Mix_enhsignle_16k is an Asteroid model trained on the `enh_single` task of the Libri1Mix dataset using DCUNet architecture. The model was trained to enhance single-channel audio. The model achieved good results on the Libri1Mix min test set. The model is licensed under Attribution-ShareAlike 3.0 Unported by Joris Cosentino."}}, {"role": "dataset", "purpose": "For model training.", "module": "librimix"}], "metrics": [{"dataset": "librimix", "metric": 13.154035391645971, "protocol": "si_sdr"}, {"dataset": "librimix", "metric": 9.704254085786271, "protocol": "si_sdr_imp"}, {"dataset": "librimix", "metric": 13.568058873121435, "protocol": "sdr"}, {"dataset": "librimix", "metric": 10.065396073908367, "protocol": "sdr_imp"}, {"dataset": "librimix", "metric": 13.568058873121435, "protocol": "sar"}, {"dataset": "librimix", "metric": 10.065396073908367, "protocol": "sar_imp"}, {"dataset": "librimix", "metric": 0.9199373340235417, "protocol": "stoi"}, {"dataset": "librimix", "metric": 0.12401751048300132, "protocol": "stoi_imp"}], "source": "huggingface"}, {"id": "huggingface-jenniferjane-ner-trainer", "modules": [{"role": "model", "module": {"name": "ner_trainer", "description": "Fine-tuned version of distilbert-base-uncased on the conll2003 dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "ner_trainer is a fine-tuned version of distilbert-base-uncased on the conll2003 dataset for token classification. The model achieved high scores on the evaluation set, with a precision of 0.9231, recall of 0.9325, F1 of 0.9278, and accuracy of 0.9830. The model is suitable for named entity recognition tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 0.9231450719822812, "protocol": "precision"}, {"dataset": "conll-2003", "metric": 0.9325427900212552, "protocol": "recall"}, {"dataset": "conll-2003", "metric": 0.9278201346763871, "protocol": "f1"}, {"dataset": "conll-2003", "metric": 0.9830333455128918, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-reaverlee-xlm-roberta-base-finetuned-panx-en", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-en", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "xlm-roberta-base-finetuned-panx-en is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. The model achieved an F1 score of 0.6859 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 5e-05 and a linear learning rate scheduler for 3 epochs. The model was trained using Transformers 4.22.2, Pytorch 1.10.0, Datasets 2.7.1, and Tokenizers 0.12.1."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.6858725761772854, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-manishkalra-finetuning-sentiment-model-3000-samples", "modules": [{"role": "model", "module": {"name": "finetuning-sentiment-model-3000-samples", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "finetuning-sentiment-model-3000-samples is a fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis. The model achieves an accuracy of 0.87 and an F1 score of 0.8770 on the evaluation set. The model is suitable for text classification tasks, but its performance may vary depending on the specific use case and data distribution."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.87, "protocol": "accuracy"}, {"dataset": "imdb-movie-reviews", "metric": 0.877, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-tner-deberta-large-wnut2017", "modules": [{"role": "model", "module": {"name": "tner/deberta-large-wnut2017", "description": "Fine-tuned version of microsoft/deberta-large on the tner/wnut2017 dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"dataset": ["tner/wnut2017"], "model": "microsoft/deberta-large", "crf": true, "max_length": 128, "epoch": 15, "batch_size": 16, "lr": 1e-05, "gradient_accumulation_steps": 4, "weight_decay": 1e-07, "lr_warmup_step_ratio": 0.1, "max_grad_norm": 10.0}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "tner/deberta-large-wnut2017 is a fine-tuned version of microsoft/deberta-large on the tner/wnut2017 dataset for token classification. The model achieved an F1 score of 0.5105, precision of 0.6932, and recall of 0.4041 on the test set. The model is suitable for named entity recognition tasks, but caution should be taken when deploying it in human-interacting systems as it reflects the biases of the systems it was trained on."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wnut-2017-wnut-2017-emerging-and-rare-entity-recognition"}], "metrics": [{"dataset": "wnut-2017-wnut-2017-emerging-and-rare-entity-recognition", "metric": 0.5105386416861827, "protocol": "f1"}, {"dataset": "wnut-2017-wnut-2017-emerging-and-rare-entity-recognition", "metric": 0.6931637519872814, "protocol": "precision"}, {"dataset": "wnut-2017-wnut-2017-emerging-and-rare-entity-recognition", "metric": 0.4040778498609824, "protocol": "recall"}, {"dataset": "wnut-2017-wnut-2017-emerging-and-rare-entity-recognition", "metric": 0.4263428845085451, "protocol": "f1_macro"}, {"dataset": "wnut-2017-wnut-2017-emerging-and-rare-entity-recognition", "metric": 0.6003185137596864, "protocol": "precision_macro"}, {"dataset": "wnut-2017-wnut-2017-emerging-and-rare-entity-recognition", "metric": 0.35195768262641947, "protocol": "recall_macro"}, {"dataset": "wnut-2017-wnut-2017-emerging-and-rare-entity-recognition", "metric": 0.5936768149882904, "protocol": "f1_entity_span"}, {"dataset": "wnut-2017-wnut-2017-emerging-and-rare-entity-recognition", "metric": 0.8060413354531002, "protocol": "precision_entity_span"}, {"dataset": "wnut-2017-wnut-2017-emerging-and-rare-entity-recognition", "metric": 0.46987951807228917, "protocol": "recall_entity_span"}], "source": "huggingface"}, {"id": "huggingface-krassy-xlm-roberta-base-finetuned-marc-en", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-marc-en", "description": "A fine-tuned version of xlm-roberta-base on the amazon_reviews_multi dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "xlm-roberta-base-finetuned-marc-en is a fine-tuned version of xlm-roberta-base on the amazon_reviews_multi dataset. The model is suitable for text classification tasks. The model was trained for 2 epochs with a learning rate of 2e-05 and an Adam optimizer with betas=(0.9,0.999) and epsilon=1e-08. The model achieved a loss of 0.9005 and an MAE of 0.5 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "amazon-product-data"}], "metrics": [{"dataset": "amazon-product-data", "metric": 0.9005, "protocol": "loss"}, {"dataset": "amazon-product-data", "metric": 0.5, "protocol": "mae"}], "source": "huggingface"}, {"id": "huggingface-anuragshas-wav2vec2-large-xlsr-53-dv", "modules": [{"role": "model", "module": {"name": "Anurag Singh XLSR Wav2Vec2 Large 53 Dhivehi", "description": "Fine-tuned Wav2Vec2-Large-XLSR-53 on Dhivehi using the Common Voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "Wav2Vec2-Large-XLSR-53", "batch_size": 8, "optimizer": {"name": "Adam", "learning_rate": 0.0001, "beta1": 0.9, "beta2": 0.98, "weight_decay": 0.01}}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Anurag Singh XLSR Wav2Vec2 Large 53 Dhivehi is a fine-tuned model based on Wav2Vec2-Large-XLSR-53, trained on the Common Voice dataset for Dhivehi speech recognition. The model can be used directly for speech recognition without a language model. The model was trained on the Common Voice train and validation datasets and evaluated on the Common Voice test dataset, achieving a WER of 55.68%."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 55.68, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-gurkan08-bert-turkish-text-classification", "modules": [{"role": "model", "module": {"name": "Turkish News Text Classification", "description": "A Turkish text classification model obtained by fine-tuning the Turkish bert model (dbmdz/bert-base-turkish-cased)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_name": "gurkan08/bert-turkish-text-classification", "tokenizer_name": "gurkan08/bert-turkish-text-classification", "pipeline": "sentiment-analysis"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a Turkish text classification model fine-tuned on a dataset consisting of 11 classes obtained from https://www.trthaber.com/. The model is based on the Turkish bert model (dbmdz/bert-base-turkish-cased) and can be used for sentiment analysis. The model achieved a train f1-weighted score of 97% and a test f1-weighted score of 94%."}}, {"role": "dataset", "purpose": "Dataset consisting of 11 classes obtained from https://www.trthaber.com/.", "module": "tr-news"}], "metrics": [{"dataset": "tr-news", "metric": 97.0, "split": "val", "protocol": "f1-weighted score"}, {"dataset": "tr-news", "metric": 94.0, "split": "test", "protocol": "f1-weighted score"}], "source": "huggingface"}, {"id": "huggingface-microsoft-xclip-base-patch16-ucf-8-shot", "modules": [{"role": "model", "module": {"name": "X-CLIP (base-sized model)", "description": "X-CLIP is a minimal extension of CLIP for general video-language understanding. The model is trained in a contrastive way on (video, text) pairs. This allows the model to be used for tasks like zero-shot, few-shot or fully supervised video classification and video-text retrieval."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"patch_resolution": 16, "frames_per_video": 32, "resolution": "224x224"}}}, {"role": "taskType", "module": "video-classification"}, {"role": "solutionSummary", "module": {"summary": "X-CLIP is a base-sized model trained in a few-shot fashion on UCF101 for general video-language understanding. The model is suitable for tasks like zero-shot, few-shot or fully supervised video classification and video-text retrieval. The model achieves a top-1 accuracy of 88.3%."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "ucf101-ucf101-human-actions-dataset"}], "metrics": [{"dataset": "ucf101-ucf101-human-actions-dataset", "metric": 88.3, "protocol": "top-1 accuracy"}], "source": "huggingface"}, {"id": "huggingface-mdroth-bert-finetuned-ner", "modules": [{"role": "model", "module": {"name": "bert-finetuned-ner", "description": "A fine-tuned version of bert-base-cased on the conll2003 dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-finetuned-ner is a fine-tuned version of bert-base-cased on the conll2003 dataset for token classification. The model achieved high precision, recall, F1 score, and accuracy on the evaluation set. The model is suitable for named entity recognition tasks, but caution should be taken when deploying it in human-interacting systems as it may reflect the biases of the systems it was trained on."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 0.9352387245993722, "protocol": "precision"}, {"dataset": "conll-2003", "metric": 0.9527095254123191, "protocol": "recall"}, {"dataset": "conll-2003", "metric": 0.9438932888703627, "protocol": "f1"}, {"dataset": "conll-2003", "metric": 0.9868134455760287, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-embo-bio-lm", "modules": [{"role": "model", "module": {"name": "bio-lm", "description": "RoBERTa base pre-trained model further trained using a masked language modeling task on a compendium of English scientific textual examples from the life sciences using the BioLang dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"tokenizer": "roberta-base", "batch_size": {"train": 16, "eval": 16}, "learning_rate": 5e-05, "weight_decay": 0.0, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "max_grad_norm": 1.0, "epochs": 3.0}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "bio-lm is a RoBERTa base pre-trained model further trained using a masked language modeling task on a compendium of English scientific textual examples from the life sciences using the BioLang dataset. The model is intended to be fine-tuned for downstream tasks, token classification in particular. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training.", "module": "biolama"}], "metrics": [{"dataset": "biolama", "metric": 0.814471959728645, "protocol": "recall"}], "source": "huggingface"}, {"id": "huggingface-ramybaly-ner-nerd-fine", "modules": [{"role": "model", "module": {"name": "ner_nerd_fine", "description": "Fine-tuned version of bert-base-uncased on the nerd dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 3e-05, "train_batch_size": 16, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "num_epochs": 10}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "ner_nerd_fine is a fine-tuned version of bert-base-uncased on the nerd dataset for token classification. The model achieved an accuracy of 0.9050 on the evaluation set. The model is suitable for named entity recognition tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "few-nerd"}], "metrics": [{"dataset": "few-nerd", "metric": 0.9050232835369201, "protocol": "accuracy"}, {"dataset": "few-nerd", "metric": 0.6326, "protocol": "precision"}, {"dataset": "few-nerd", "metric": 0.6734, "protocol": "recall"}, {"dataset": "few-nerd", "metric": 0.6524, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-flair-ner-english-ontonotes", "modules": [{"role": "model", "module": {"name": "Flair NER-English-Ontonotes", "description": "A sequence tagger model for English named entity recognition (NER) with 18 classes."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"embeddings": ["en-crawl", "news-forward", "news-backward"], "hidden_size": 256, "tag_type": "ner", "tag_dictionary": "Ontonotes"}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "Flair NER-English-Ontonotes is a sequence tagger model for English named entity recognition (NER) with 18 classes. It is based on Flair embeddings and LSTM-CRF. The model is intended to be fine-tuned on downstream tasks, such as sequence classification, token classification, or question answering. The model is suitable for tasks that require NER, such as information extraction, text classification, and question answering."}}, {"role": "dataset", "purpose": "For model training.", "module": "ontonotes-5-0"}], "metrics": [{"dataset": "ontonotes-5-0", "metric": 89.27, "protocol": "F1-Score"}], "source": "huggingface"}, {"id": "huggingface-robingeibel-bigbird-base-finetuned-big-patent", "modules": [{"role": "model", "module": {"name": "bigbird-base-finetuned-big_patent", "description": "A fine-tuned version of bigbird-base-finetuned-big_patent on the big_patent dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 1, "eval_batch_size": 1, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "text-generation"}, {"role": "solutionSummary", "module": {"summary": "bigbird-base-finetuned-big_patent is a transformer model fine-tuned on the big_patent dataset. It can be used for text generation tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 1. The model was trained for 1 epoch and achieved a validation loss of 1.0686. The model was trained using PyTorch 1.11.0+cu113 and Transformers 4.20.1."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "bigpatent"}], "metrics": [{"dataset": "bigpatent", "metric": 1.0686, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-en-pis", "modules": [{"role": "model", "module": {"name": "opus-mt-en-pis", "description": "A transformer-align model for translating from English to pis."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-en-pis is a transformer-align model that translates from English to pis. The model was trained on the OPUS dataset using normalization and SentencePiece preprocessing. The model achieved a BLEU score of 38.3 and a chr-F score of 0.571 on the JW300.en.pis test set."}}], "metrics": [{"dataset": "jw300", "metric": 38.3, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.571, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-no-da", "modules": [{"role": "model", "module": {"name": "nor-dan", "description": "A transformer model for translating Norwegian to Danish."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece (spm12k,spm12k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "A transformer model for translating Norwegian to Danish. The model was trained on the Tatoeba dataset and achieved a BLEU score of 65.0 and a chrF2 score of 0.792 on the test set. The model uses normalization and SentencePiece (spm12k,spm12k) for preprocessing."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "tatoeba"}], "metrics": [{"dataset": "tatoeba", "metric": 65.0, "protocol": "BLEU"}, {"dataset": "tatoeba", "metric": 0.792, "protocol": "chrF2"}], "source": "huggingface"}, {"id": "huggingface-aiface-test285", "modules": [{"role": "model", "module": {"name": "test285", "description": "A fine-tuned version of aiface/cv8 on the vivos_dataset dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0003, "train_batch_size": 16, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 30, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "test285 is a fine-tuned version of aiface/cv8 on the vivos_dataset dataset. The model is intended for automatic speech recognition tasks. The model was trained using PyTorch and Transformers with a linear learning rate scheduler and mixed precision training. The model achieved an evaluation loss of 0.3865 and a word error rate of 0.3012 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "vivos-vivos-corpus"}], "metrics": [{"dataset": "vivos-vivos-corpus", "metric": 0.3865, "protocol": "eval_loss"}, {"dataset": "vivos-vivos-corpus", "metric": 0.3012, "protocol": "eval_wer"}, {"dataset": "vivos-vivos-corpus", "metric": 39.5722, "protocol": "eval_runtime"}, {"dataset": "vivos-vivos-corpus", "metric": 19.205, "protocol": "eval_samples_per_second"}, {"dataset": "vivos-vivos-corpus", "metric": 2.401, "protocol": "eval_steps_per_second"}, {"dataset": "vivos-vivos-corpus", "metric": 1.1, "protocol": "epoch"}, {"dataset": "vivos-vivos-corpus", "metric": 400.0, "protocol": "step"}], "source": "huggingface"}, {"id": "huggingface-shivkumarganesh-whisper-small-hi", "modules": [{"role": "model", "module": {"name": "Whisper Small Hi - Shiv Kumar Ganesh", "description": "A fine-tuned version of openai/whisper-small on the Common Voice 11.0 dataset for Automatic Speech Recognition."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-05, "train_batch_size": 64, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "training_steps": 5000, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Whisper Small Hi - Shiv Kumar Ganesh is a fine-tuned version of openai/whisper-small on the Common Voice 11.0 dataset for Automatic Speech Recognition. The model achieved a WER of 21.3% on the test set. The model was trained using PyTorch and Transformers with a linear learning rate scheduler and mixed precision training."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 21.30001146394589, "protocol": "WER"}], "source": "huggingface"}, {"id": "huggingface-anton-l-wav2vec2-large-xlsr-53-kyrgyz", "modules": [{"role": "model", "module": {"name": "Wav2Vec2-Large-XLSR-53-Kyrgyz", "description": "Fine-tuned Wav2Vec2-Large-XLSR-53 on Kyrgyz using the Common Voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "facebook/wav2vec2-large-xlsr-53", "batch_size": 16, "optimizer": {"name": "Adam", "learning_rate": 0.0003, "beta1": 0.9, "beta2": 0.98, "weight_decay": 0.005}, "num_epochs": 30}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Wav2Vec2-Large-XLSR-53-Kyrgyz is a speech recognition model fine-tuned on the Common Voice dataset for Kyrgyz. The model is based on the Wav2Vec2-Large-XLSR-53 architecture and was fine-tuned using masked language modeling (MLM) objective. The model can be used directly for speech recognition without a language model. The model was trained on the Common Voice train and validation datasets using Adam optimizer with a learning rate of 3e-4 and a weight decay of 0.005. The model achieved a WER of 31.88% on the Common Voice Kyrgyz test dataset."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 31.88, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-merlintk-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 game."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 game. The agent's Q-Table is provided, along with hyperparameters such as the maximum number of steps per episode and the number of episodes used for evaluation. The model achieved a mean reward of 7.56 with a standard deviation of 2.71."}}, {"role": "dataset", "purpose": "The game environment used for training and evaluation.", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.56, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-ykirpichev-q-frozenlake-v1-4x4-noslippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained model of a Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-4x4-no_slippery", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model's hyperparameters include the algorithm used, the environment, the maximum number of steps per episode, the number of episodes to evaluate the agent, the Q-table learned by the agent, and the random seed used for evaluation. The model achieved a mean reward of 1.00 with no standard deviation."}}, {"role": "dataset", "purpose": "Environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-indonesian-nlp-wav2vec2-large-xlsr-indonesian", "modules": [{"role": "model", "module": {"name": "XLSR Wav2Vec2 Indonesian by Indonesian NLP", "description": "Fine-tuned model on the Indonesian Common Voice dataset using Wav2Vec2-Large-XLSR-53 architecture."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"architecture": "Wav2Vec2-Large-XLSR-53", "batch_size": 8, "optimizer": {"name": "Adam", "learning_rate": 5e-05, "beta1": 0.9, "beta2": 0.98, "epsilon": 1e-06}}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned model on the Indonesian Common Voice dataset using the Wav2Vec2-Large-XLSR-53 architecture. The model can be used for automatic speech recognition tasks in Indonesian. The model was trained on the Common Voice train, validation, and synthetic voice datasets. The model achieved a WER of 14.29% on the Indonesian Common Voice test dataset."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 14.29, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-lt-eo", "modules": [{"role": "model", "module": {"name": "lit-epo", "description": "A transformer-align model for translating from Lithuanian to Esperanto."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece (spm4k,spm4k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The lit-epo model is a transformer-align model that translates from Lithuanian to Esperanto. It was trained on the Tatoeba dataset and achieved a BLEU score of 13.0 and a chrF2 score of 0.313 on the Tatoeba-test.lit.epo test set. The model uses normalization and SentencePiece (spm4k,spm4k) for preprocessing."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "tatoeba"}], "metrics": [{"dataset": "tatoeba", "metric": 13.0, "protocol": "BLEU"}, {"dataset": "tatoeba", "metric": 0.313, "protocol": "chrF2"}], "source": "huggingface"}, {"id": "huggingface-pig4431-rtm-roberta-5e", "modules": [{"role": "model", "module": {"name": "rtm_roBERTa_5E", "description": "Fine-tuned version of roberta-base on the rotten_tomatoes dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-05, "train_batch_size": 16, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "rtm_roBERTa_5E is a fine-tuned version of roberta-base on the rotten_tomatoes dataset. It is a transformer model pre-trained on a large English corpus and fine-tuned for text classification. The model is suitable for tasks that require text classification, such as sentiment analysis. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.8667, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-reachrkr-q-taxi-v3-v1", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3-v1", "description": "A Q-Learning agent trained to play the Taxi-v3 environment."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "is_slippery": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 environment. The agent was trained to maximize the reward by learning the optimal Q-values for each state-action pair. The model achieved a mean reward of 7.54 with a standard deviation of 2.69 over multiple evaluation episodes."}}, {"role": "dataset", "purpose": "The environment used to train the agent.", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.54, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-explosion-vi-udv25-vietnamesevtb-trf", "modules": [{"role": "model", "module": {"name": "vi_udv25_vietnamesevtb_trf", "description": "A pipeline for Vietnamese language processing using spaCy with a transformer-based model."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"spaCy_version": ">=3.2.1,<3.3.0", "pipeline": ["experimental_char_ner_tokenizer", "transformer", "tagger", "morphologizer", "parser", "experimental_edit_tree_lemmatizer"]}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "vi_udv25_vietnamesevtb_trf is a pipeline for Vietnamese language processing using spaCy with a transformer-based model. The pipeline includes components for tokenization, sentence segmentation, part-of-speech tagging, morphological analysis, dependency parsing, and lemmatization. The model was trained on the Universal Dependencies v2.5 dataset and achieves high accuracy on various language processing tasks, including token classification, sentence segmentation, part-of-speech tagging, morphological analysis, dependency parsing, and lemmatization."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "universal-dependencies"}], "metrics": [{"dataset": "universal-dependencies", "metric": 87.9, "protocol": "TOKEN_F"}, {"dataset": "universal-dependencies", "metric": 86.84, "protocol": "TOKEN_P"}, {"dataset": "universal-dependencies", "metric": 89.0, "protocol": "TOKEN_R"}, {"dataset": "universal-dependencies", "metric": 98.42, "protocol": "TOKEN_ACC"}, {"dataset": "universal-dependencies", "metric": 94.33, "protocol": "SENTS_F"}, {"dataset": "universal-dependencies", "metric": 96.23, "protocol": "SENTS_P"}, {"dataset": "universal-dependencies", "metric": 92.5, "protocol": "SENTS_R"}, {"dataset": "universal-dependencies", "metric": 88.05, "protocol": "TAG_ACC"}, {"dataset": "universal-dependencies", "metric": 90.19, "protocol": "POS_ACC"}, {"dataset": "universal-dependencies", "metric": 96.95, "protocol": "MORPH_ACC"}, {"dataset": "universal-dependencies", "metric": 68.08, "protocol": "DEP_UAS"}, {"dataset": "universal-dependencies", "metric": 60.64, "protocol": "DEP_LAS"}, {"dataset": "universal-dependencies", "metric": 89.35, "protocol": "LEMMA_ACC"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-war-fr", "modules": [{"role": "model", "module": {"name": "opus-mt-war-fr", "description": "A machine translation model that translates from the War language to French."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-war-fr is a machine translation model that translates from the War language to French. The model was trained on the OPUS dataset using the transformer-align model with normalization and SentencePiece preprocessing. The model achieved a BLEU score of 30.2 and a chr-F score of 0.482 on the JW300.war.fr test set."}}], "metrics": [{"dataset": "jw300", "metric": 30.2, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.482, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-ronykroy-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. The model is best suited for text classification tasks. The model achieved an accuracy of 0.922 and an F1 score of 0.9222 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.922, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.9222310284051585, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-es-kg", "modules": [{"role": "model", "module": {"name": "opus-mt-es-kg", "description": "A machine translation model that translates from Spanish (es) to Kyrgyz (kg) using the transformer-align architecture."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-es-kg is a machine translation model that translates from Spanish to Kyrgyz. It uses the transformer-align architecture and was trained on the OPUS dataset. The model achieved a BLEU score of 25.6 and a chr-F score of 0.488 on the JW300.es.kg test set."}}], "metrics": [{"dataset": "jw300", "metric": 25.6, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.488, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-amagzari-bart-base-finetuned-samsum-v2", "modules": [{"role": "model", "module": {"name": "bart-base-finetuned-samsum-v2", "description": "A fine-tuned version of facebook/bart-base on the samsum dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 4, "eval_batch_size": 4, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1, "mixed_precision_training": true}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/bart-base on the samsum dataset. The model is best suited for sequence-to-sequence language modeling tasks. The model achieved a Rouge1 score of 47.3928 on the evaluation set. The training was done using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler. The model was trained for 1 epoch with mixed precision training."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "samsum-corpus"}], "metrics": [{"dataset": "samsum-corpus", "metric": 47.3928, "protocol": "rouge1"}, {"dataset": "samsum-corpus", "metric": 24.0713, "protocol": "rouge2"}, {"dataset": "samsum-corpus", "metric": 40.029, "protocol": "rougeL"}, {"dataset": "samsum-corpus", "metric": 43.6252, "protocol": "rougeLsum"}], "source": "huggingface"}, {"id": "huggingface-ahmedshabana-distilbert-base-uncased-finetuned-mnli", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-mnli", "description": "A fine-tuned version of distilbert-base-uncased on the GLUE dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-mnli is a fine-tuned version of distilbert-base-uncased on the GLUE dataset. It is suitable for text classification tasks. The model achieved an accuracy of 0.42 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 16 for 5 epochs."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-fr-xh", "modules": [{"role": "model", "module": {"name": "opus-mt-fr-xh", "description": "A transformer-align model for translating from French to Xhosa."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-fr-xh model is a transformer-align model that translates from French to Xhosa. It achieved a BLEU score of 25.1 and a chr-F score of 0.523 on the JW300.fr.xh test set."}}, {"role": "dataset", "purpose": "Test set for benchmarking.", "module": "jw300"}], "metrics": [{"dataset": "jw300", "metric": 25.1, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.523, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-k-masaki-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8649 on the evaluation set. The model is suitable for token classification tasks in German language. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8648740833380706, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-huangjia-xlm-roberta-base-finetuned-panx-fr", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-fr", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 48, "eval_batch_size": 48, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "xlm-roberta-base-finetuned-panx-fr is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. The model achieved an F1 score of 0.8204 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 5e-05 and a batch size of 48 for 3 epochs. The model was trained using the Transformers 4.11.3, Pytorch 1.10.2, Datasets 1.18.4, and Tokenizers 0.10.3."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8204272363150867, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-hieuit7-wav2vec2-common-voice-vi-demo", "modules": [{"role": "model", "module": {"name": "wav2vec2-common_voice-vi-demo", "description": "Fine-tuned version of facebook/wav2vec2-large-xlsr-53 on the COMMON_VOICE - VI dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0003, "train_batch_size": 16, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 15.0, "mixed_precision_training": true}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/wav2vec2-large-xlsr-53 on the COMMON_VOICE - VI dataset. The model is intended for automatic speech recognition tasks. The model was trained with Adam optimizer with a learning rate of 0.0003 and a linear learning rate scheduler with 500 warmup steps. The model was trained for 15 epochs with mixed precision training. The model achieved a validation loss of 5.9657 and a WER of 1.0."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 5.9657, "protocol": "loss"}, {"dataset": "common-voice", "metric": 1.0, "protocol": "WER"}], "source": "huggingface"}, {"id": "huggingface-sebis-code-trans-t5-large-source-code-summarization-sql-transfer-learning-finetune", "modules": [{"role": "model", "module": {"name": "CodeTrans model for source code summarization sql", "description": "Pretrained model on programming language sql using the t5 large model architecture."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_size": "t5-large", "batch_size": 256, "optimizer": {"name": "AdaFactor", "learning_rate_schedule": "inverse square root"}}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "CodeTrans is a transformer model pre-trained on a large corpus of sql code snippets. It can be used for source code summarization tasks or fine-tuned on other sql code tasks. The model is suitable for unparsed and untokenized sql code, but the performance should be better if the sql code is tokenized. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-affahrizain-distilbert-base-uncased-mlm-finetuned-imdb", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-mlm-finetuned-imdb", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 128, "eval_batch_size": 128, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-mlm-finetuned-imdb is a fine-tuned version of distilbert-base-uncased on the imdb dataset. It can be used for text classification tasks. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 128. The model was trained for 3 epochs and achieved a loss of 0.6271 on the evaluation set. The model was trained using Transformers 4.20.1, Pytorch 1.12.0+cu113, Datasets 2.4.0, and Tokenizers 0.12.1."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.6271, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-jamesmarcel-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "xlm-roberta-base-finetuned-panx-de is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. The model achieved an F1 score of 0.8621 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 5e-05 and a batch size of 24. The model was trained for 3 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8621, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-ja-tr", "modules": [{"role": "model", "module": {"name": "jpn-tur", "description": "A transformer model for Japanese to Turkish translation."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece (spm32k,spm32k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "A transformer model for Japanese to Turkish translation. The model was trained on the Tatoeba dataset and achieved a BLEU score of 16.7 and a chrF2 score of 0.434 on the test set. The model uses normalization and SentencePiece (spm32k,spm32k) for preprocessing."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "tatoeba-translation-challenge"}], "metrics": [{"dataset": "tatoeba-translation-challenge", "metric": 16.7, "protocol": "BLEU"}, {"dataset": "tatoeba-translation-challenge", "metric": 0.434, "protocol": "chrF2"}], "source": "huggingface"}, {"id": "huggingface-kapilkd13-xls-r-hi-test", "modules": [{"role": "model", "module": {"name": "facebook/wav2vec2-xls-r-300m fine-tuned on Common Voice 7.0 - HI", "description": "Fine-tuned model on the Common Voice 7.0 - HI dataset for Automatic Speech Recognition."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0003, "train_batch_size": 16, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "training_steps": 8000, "mixed_precision_training": true}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the Common Voice 7.0 - HI dataset for Automatic Speech Recognition. The model achieved a Test WER of 38.18. The model was fine-tuned using Adam optimizer with a learning rate of 0.0003, a batch size of 16, and a linear learning rate scheduler with warmup steps of 500. The model was trained for 8000 steps with mixed precision training. The model was trained using Transformers 4.16.0.dev0, Pytorch 1.10.1+cu102, Datasets 1.18.3, and Tokenizers 0.11.0."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 38.18, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-patrickvonplaten-wav2vec2-xls-r-phoneme-300m-tr", "modules": [{"role": "model", "module": {"name": "Wav2vec2-xls-r-phoneme-300m-tr", "description": "Fine-tuned version of wav2vec2-xls-r-300m on the COMMON_VOICE - TR dataset for automatic speech recognition."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0005, "train_batch_size": 16, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 20.0, "mixed_precision_training": true}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Wav2vec2-xls-r-phoneme-300m-tr is a fine-tuned version of wav2vec2-xls-r-300m on the COMMON_VOICE - TR dataset for automatic speech recognition. The model achieved a loss of 0.6380 and a PER of 0.1664 on the evaluation set. The model is intended for automatic speech recognition tasks and is limited to the Turkish language. The model was trained using PyTorch 1.8.1 and Transformers 4.13.0.dev0."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.638, "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.1664, "protocol": "PER"}], "source": "huggingface"}, {"id": "huggingface-muhtasham-bert-uncased-l-2-h-128-a-2-finetuned-emotion-finetuned-tweet", "modules": [{"role": "model", "module": {"name": "bert_uncased_L-2_H-128_A-2-finetuned-emotion-finetuned-tweet", "description": "A fine-tuned version of muhtasham/bert_uncased_L-2_H-128_A-2-finetuned-emotion on the imdb dataset for text classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 3e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "num_epochs": 200}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of muhtasham/bert_uncased_L-2_H-128_A-2-finetuned-emotion on the imdb dataset for text classification. The model achieved an accuracy of 0.87168 and an F1 score of 0.87167 on the evaluation set. The model is intended for text classification tasks, but its limitations and intended uses are not specified in the model card."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.87168, "protocol": "accuracy"}, {"dataset": "imdb-movie-reviews", "metric": 0.8716747437975058, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-softcatala-wav2vec2-large-xlsr-catala", "modules": [{"role": "model", "module": {"name": "Wav2Vec2-Large-XLSR-Catal\u00e0", "description": "Fine-tuned facebook/wav2vec2-large-xlsr-53 on Catalan language using the Common Voice and ParlamentParla datasets."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "facebook/wav2vec2-large-xlsr-53", "preprocessing": {"resample": {"original_sampling_rate": 48000, "target_sampling_rate": 16000}}}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Wav2Vec2-Large-XLSR-Catal\u00e0 is a speech recognition model fine-tuned on the Catalan language using the Common Voice and ParlamentParla datasets. The model can be used directly without a language model. The model achieved a WER of 6.92% on the test split of the combined dataset and 12.99% on the Google Crowdsourced Corpus. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 6.92, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-kurianbenoy-distilbert-base-uncased-finetuned-imdb", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-imdb", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-imdb is a fine-tuned version of distilbert-base-uncased on the imdb dataset. It is a transformer model that can be used for text classification tasks. The model achieved an accuracy of 0.923 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler for 3 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.923, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-projecte-aina-roberta-base-ca-cased-pos", "modules": [{"role": "model", "module": {"name": "roberta-base-ca-cased-pos", "description": "Part-of-speech-tagging (POS) model for the Catalan language fine-tuned from the roberta-base-ca model."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 16, "learning_rate": 5e-05, "epochs": 5}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "The roberta-base-ca-cased-pos model is a Part-of-speech-tagging (POS) model for the Catalan language. It is fine-tuned from the roberta-base-ca model, a RoBERTa base model pre-trained on a medium-size corpus collected from publicly available corpora and crawlers. The model can be used to Part-of-speech-tagging (POS) a text. The model is limited by its training dataset and may not generalize well for all use cases."}}, {"role": "dataset", "purpose": "For training and evaluation.", "module": "universal-dependencies"}], "metrics": [{"dataset": "universal-dependencies", "metric": 0.9893832385244624, "protocol": "F1"}], "source": "huggingface"}, {"id": "huggingface-yaxin-electra-small-discriminator-yelp-mlm", "modules": [{"role": "model", "module": {"name": "test-electra-small-yelp", "description": "Fine-tuned version of google/electra-small-discriminator on the yelp_review_full dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 8, "eval_batch_size": 8, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0}}}, {"role": "taskType", "module": "fill-mask"}, {"role": "solutionSummary", "module": {"summary": "test-electra-small-yelp is a fine-tuned version of google/electra-small-discriminator on the yelp_review_full dataset. The model is intended for masked language modeling tasks. The model achieved an accuracy of 0.5677 on the evaluation set. The training hyperparameters include a learning rate of 5e-05, a train batch size of 8, an eval batch size of 8, and 3 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "yelp2018"}], "metrics": [{"dataset": "yelp2018", "metric": 0.5677007577622891, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-z3c1f4-distilbert-base-uncased-finetuned-cola", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-cola", "description": "A fine-tuned version of distilbert-base-uncased on the glue dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-cola is a fine-tuned version of distilbert-base-uncased on the glue dataset. It is suitable for text classification tasks. The model achieved a Matthews Correlation score of 0.5321 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 16 for 5 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.5321, "protocol": "matthews_correlation"}], "source": "huggingface"}, {"id": "huggingface-thodum-q-frozenlake-v1-4x4-noslippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained model of a Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-4x4-no_slippery"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model was trained using the Q-Learning algorithm and evaluated on the FrozenLake-v1-4x4-no_slippery environment. The model achieved a mean reward of 1.00 +/- 0.00, but the verification status is unknown."}}, {"role": "dataset", "purpose": "The environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-xkang-distilbert-base-uncased-finetuned-imdb-whole-word-masking", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-imdb-whole-word-masking", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-imdb-whole-word-masking is a fine-tuned version of distilbert-base-uncased on the imdb dataset. It can be used for text classification tasks. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64. The model was trained for 3 epochs and achieved a loss of 3.3043 on the evaluation set. The model was trained using PyTorch 1.10.0 and Transformers 4.16.0.dev0."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 3.3043, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-gcmsrc-xlm-roberta-base-finetuned-panx-fr", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-fr", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "xlm-roberta-base-finetuned-panx-fr is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. The model achieved an F1 score of 0.9069 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 5e-05 and a linear learning rate scheduler for 3 epochs. The model was trained using Transformers 4.11.3, Pytorch 1.12.1+cu102, Datasets 1.16.1, and Tokenizers 0.10.3."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.9068825910931175, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-patrickvonplaten-wav2vec2-common-voice-tamil", "modules": [{"role": "model", "module": {"name": "wav2vec2-common_voice-tamil", "description": "Fine-tuned version of facebook/wav2vec2-large-xlsr-53 on the COMMON_VOICE - TA dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0003, "train_batch_size": 16, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 3.0, "mixed_precision_training": true}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/wav2vec2-large-xlsr-53 on the COMMON_VOICE - TA dataset. The model is intended for automatic speech recognition tasks in Tamil. The model achieved a WER of 1.0070 on the evaluation set. The training was done using PyTorch and Transformers framework with mixed precision training."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 2.54, "split": "val", "protocol": "loss"}, {"dataset": "common-voice", "metric": 2.598, "split": "test", "protocol": "loss"}, {"dataset": "common-voice", "metric": 1.007, "protocol": "WER"}], "source": "huggingface"}, {"id": "huggingface-dbusai-q-taxi-v3-v5", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3-v5", "description": "A Q-Learning agent trained to play the Taxi-v3 game."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 game. The agent's Q-Table is provided, along with hyperparameters such as the maximum number of steps per episode and the number of episodes used for evaluation. The model achieved a mean reward of 11.75 with a standard deviation of 1.44."}}, {"role": "dataset", "purpose": "The game environment used for training and evaluation.", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 11.75, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-cfinley-punct-restore-fr", "modules": [{"role": "model", "module": {"name": "punct_restore_fr", "description": "A fine-tuned version of camembert-base on a raw, French opensubtitles dataset for punctuation restoration on French YouTube auto-generated subtitles."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 16, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "punct_restore_fr is a fine-tuned version of camembert-base on a raw, French opensubtitles dataset for punctuation restoration on French YouTube auto-generated subtitles. The model classifies tokens based on the beginning of French sentences (B-SENT) and everything else (O). The model is suitable for measuring more in a corpus such as words per sentence, grammar structures per sentence, etc. The model was trained on 1 million Open Subtitles (French) sentences and achieved an accuracy of 0.9915 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "opensubtitles"}], "metrics": [{"dataset": "opensubtitles", "metric": 0.991500810518732, "protocol": "Accuracy"}, {"dataset": "opensubtitles", "metric": 0.9601, "protocol": "Precision"}, {"dataset": "opensubtitles", "metric": 0.9527, "protocol": "Recall"}, {"dataset": "opensubtitles", "metric": 0.9564, "protocol": "F1"}], "source": "huggingface"}, {"id": "huggingface-madlag-bert-base-uncased-squadv1-x1-84-f88-7-d36-hybrid-filled-v1", "modules": [{"role": "model", "module": {"name": "BERT-base uncased model fine-tuned on SQuAD v1", "description": "A BERT-base model fine-tuned on SQuAD v1 dataset for question answering task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"optimizer": "Adam", "learning_rate": 0.0001, "batch_size": 256, "num_heads": 96, "num_layers": 12, "hidden_size": 768}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "This is a BERT-base model fine-tuned on the SQuAD v1 dataset for question answering task. The model was pruned using nn_pruning library to reduce the number of weights by 50% while maintaining the accuracy. The model is case-insensitive and can be used for question answering tasks. The model was trained on BookCorpus and English Wikipedia dataset. The model achieved an EM score of 81.69 and an F1 score of 88.72 on the SQuAD v1 dataset."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 81.69, "protocol": "EM"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 88.72, "protocol": "F1"}], "source": "huggingface"}, {"id": "huggingface-adilism-wav2vec2-large-xlsr-kyrgyz", "modules": [{"role": "model", "module": {"name": "Wav2Vec2-Large-XLSR-53-Kyrgyz", "description": "Fine-tuned Wav2Vec2-Large-XLSR-53 on Kyrgyz using the Common Voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "facebook/wav2vec2-large-xlsr-53", "batch_size": 8, "optimizer": {"name": "Adam", "learning_rate": 5e-05}}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Wav2Vec2-Large-XLSR-53-Kyrgyz is a speech recognition model fine-tuned on the Common Voice dataset for Kyrgyz. The model can be used directly for speech recognition without a language model. The model was trained on the Common Voice train and validation datasets. The model achieved a WER of 34.08% on the Common Voice Kyrgyz test dataset."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 34.08, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-google-tapas-small-masklm", "modules": [{"role": "model", "module": {"name": "tapas_masklm_small_reset", "description": "A small version of the TAPAS model pre-trained on a large corpus of English data in a self-supervised fashion using a masked language modeling (MLM) objective."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"tokenizer": "TapasTokenizer", "padding": "max_length"}}}, {"role": "taskType", "module": "table-question-answering"}, {"role": "solutionSummary", "module": {"summary": "The tapas_masklm_small_reset model is a small version of the TAPAS model pre-trained on a large corpus of English data in a self-supervised fashion using a masked language modeling (MLM) objective. It is intended to be fine-tuned on a downstream task such as table question answering. The model is suitable for answering questions about tabular data, and it can predict masked values in the table. The model is based on the transformer architecture and can be used with the TapasTokenizer. The model has not been evaluated on a specific task."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-rekcul-q-frozenlake-v1-4x4-noslippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-4x4-no_slippery", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent playing FrozenLake-v1-4x4-no_slippery. The model includes the Q-Table learned by the agent and can be used to evaluate the agent's performance. The agent achieves a mean reward of 1.00 with no standard deviation."}}, {"role": "dataset", "purpose": "Environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-alireza1044-albert-base-v2-mrpc", "modules": [{"role": "model", "module": {"name": "mrpc", "description": "Fine-tuned version of albert-base-v2 on the GLUE MRPC dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 32, "eval_batch_size": 8, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 4.0}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "mrpc is a fine-tuned version of albert-base-v2 on the GLUE MRPC dataset. It can be used for text classification tasks. The model achieved an accuracy of 0.8627 and an F1 score of 0.9011 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 32 for 4 epochs. The model was trained using Transformers 4.9.0, Pytorch 1.9.0+cu102, Datasets 1.10.2, and Tokenizers 0.10.3."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "mrpc-microsoft-research-paraphrase-corpus"}], "metrics": [{"dataset": "mrpc-microsoft-research-paraphrase-corpus", "metric": 0.8627, "protocol": "accuracy"}, {"dataset": "mrpc-microsoft-research-paraphrase-corpus", "metric": 0.9011, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-abhishek-deberta-v3-base-autotrain", "modules": [{"role": "model", "module": {"name": "DeBERTaV3", "description": "DeBERTaV3 is a transformer model that improves the efficiency of DeBERTa using ELECTRA-Style pre-training with Gradient Disentangled Embedding Sharing. It has 12 layers and a hidden size of 768, with 86M backbone parameters and a vocabulary containing 128K tokens."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"max_seq_length": 256, "per_device_train_batch_size": 8, "learning_rate": 2e-05, "num_train_epochs": 3}}}, {"role": "taskType", "module": "fill-mask"}, {"role": "solutionSummary", "module": {"summary": "DeBERTaV3 is a transformer model that improves the efficiency of DeBERTa using ELECTRA-Style pre-training with Gradient Disentangled Embedding Sharing. It outperforms RoBERTa, XLNet, ELECTRA, and DeBERTa on a majority of NLU tasks. The model is best suited for fine-tuning on downstream tasks such as text classification and question answering. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-cemilcelik-q-frozenlake-v1-4x4-noslippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained model of a Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-4x4-no_slippery", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model's hyperparameters include the algorithm used, the environment, the maximum number of steps per episode, the number of episodes to evaluate the agent, the Q-Table learned by the agent, and the random seed used for evaluation. The model achieved a mean reward of 1.0 with no standard deviation."}}, {"role": "dataset", "purpose": "Environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-milyiyo-stog-t5-small", "modules": [{"role": "model", "module": {"name": "stog-t5-small", "description": "A fine-tuned version of t5-small on the web_nlg dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.001, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1}}}, {"role": "taskType", "module": "text-generation"}, {"role": "solutionSummary", "module": {"summary": "stog-t5-small is a fine-tuned version of t5-small on the web_nlg dataset. It can be used for text generation tasks. The model was trained with Adam optimizer with a learning rate of 0.001 and a batch size of 16. The model was trained for 1 epoch. The model achieved a loss of 0.1414 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "webnlg"}], "metrics": [{"dataset": "webnlg", "metric": 0.1414, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-shila-distilbert-base-uncased-finetuned-squad", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-squad", "description": "A fine-tuned version of distilbert-base-uncased on the squad_v2_loading_script dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-squad is a fine-tuned version of distilbert-base-uncased on the squad_v2_loading_script dataset. It is suitable for question answering tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for 3 epochs and achieved a loss of 4.9348 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 4.9348, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-gchhablani-bert-base-cased-finetuned-qnli", "modules": [{"role": "model", "module": {"name": "bert-base-cased-finetuned-qnli", "description": "A fine-tuned version of bert-base-cased on the GLUE QNLI dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "num_epochs": 3.0}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-base-cased-finetuned-qnli is a fine-tuned version of bert-base-cased on the GLUE QNLI dataset. It is intended for text classification tasks. The model achieved an accuracy of 0.9099 on the evaluation set. The model was trained using the Adam optimizer with a learning rate of 2e-05 and a batch size of 16 for 3 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "qnli-question-answering-nli"}], "metrics": [{"dataset": "qnli-question-answering-nli", "metric": 0.9099395936298736, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-drishtisharma-autonlp-text-classification-catalonia-independence-autonlp-633018323", "modules": [{"role": "model", "module": {"name": "AutoNLP Text Classification Model", "description": "A multi-class classification model trained using AutoNLP on the Catalonia Independence dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"problem_type": "Multi-class Classification", "model_id": 633018323}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a multi-class classification model trained using AutoNLP on the Catalonia Independence dataset. The model can be used to classify text into one of the classes in the dataset. The model achieved an accuracy of 0.709 and was trained using a multi-class classification problem type."}}, {"role": "dataset", "purpose": "For model training and validation.", "module": "cic-catalonia-independence-corpus"}], "metrics": [{"dataset": "cic-catalonia-independence-corpus", "metric": 0.681106686592102, "protocol": "loss"}, {"dataset": "cic-catalonia-independence-corpus", "metric": 0.709136109384711, "protocol": "accuracy"}, {"dataset": "cic-catalonia-independence-corpus", "metric": 0.6987186860138147, "protocol": "macro_f1"}, {"dataset": "cic-catalonia-independence-corpus", "metric": 0.709136109384711, "protocol": "micro_f1"}, {"dataset": "cic-catalonia-independence-corpus", "metric": 0.7059639788836748, "protocol": "weighted_f1"}, {"dataset": "cic-catalonia-independence-corpus", "metric": 0.7174345617951404, "protocol": "macro_precision"}, {"dataset": "cic-catalonia-independence-corpus", "metric": 0.709136109384711, "protocol": "micro_precision"}, {"dataset": "cic-catalonia-independence-corpus", "metric": 0.712710833401347, "protocol": "weighted_precision"}, {"dataset": "cic-catalonia-independence-corpus", "metric": 0.6912117894374218, "protocol": "macro_recall"}, {"dataset": "cic-catalonia-independence-corpus", "metric": 0.709136109384711, "protocol": "micro_recall"}, {"dataset": "cic-catalonia-independence-corpus", "metric": 0.709136109384711, "protocol": "weighted_recall"}], "source": "huggingface"}, {"id": "huggingface-osanseviero-flair-ner-english", "modules": [{"role": "model", "module": {"name": "Flair English NER", "description": "A sequence tagger model for named entity recognition (NER) in English language using Flair library."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_type": "sequence tagger", "architecture": "LSTM-CRF", "embeddings": {"word_embedding": "glove", "embedding_size": 100}, "training": {"batch_size": 32, "learning_rate": 0.1, "max_epochs": 150}}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "Flair English NER is a sequence tagger model for named entity recognition in English language. It uses LSTM-CRF architecture with GloVe word embeddings of size 100. The model is trained on the CoNLL-2003 dataset and achieves an F1-score of 90.51. It can be used for token classification tasks in English language."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 90.51, "protocol": "F1-score"}], "source": "huggingface"}, {"id": "huggingface-nikitabaramiia-ppo-carracing-v0", "modules": [{"role": "model", "module": {"name": "PPO Agent playing CarRacing-v0", "description": "A trained model of a PPO agent playing CarRacing-v0 using the stable-baselines3 library."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "PPO"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a PPO agent playing CarRacing-v0 using the stable-baselines3 library. The model achieved a mean reward of 231.54 +/- 229.22 on the CarRacing-v0 dataset. The model can be used for reinforcement learning tasks."}}, {"role": "dataset", "purpose": "Used for model training.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 231.54, "split": "val", "protocol": "mean_reward"}, {"dataset": "openai-gym", "metric": 229.22, "split": "test", "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-vasudevgupta-speech-jax-wav2vec2-large-lv60-100h", "modules": [{"role": "model", "module": {"name": "Wav2Vec2", "description": "A speech recognition model that uses self-supervised learning to learn speech representations."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0005, "batch_size": 16, "num_train_steps": 40000, "num_warmup_steps": 500, "feature_extractor": "ConvFeatureExtractor", "feature_extractor_kwargs": {"conv_dim": 512, "num_conv_layers": 12, "dropout": 0.1}, "encoder": "TransformerEncoder", "encoder_kwargs": {"num_layers": 12, "hidden_dim": 768, "num_heads": 12, "dropout": 0.1}}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Wav2Vec2 is a speech recognition model that uses self-supervised learning to learn speech representations. The model uses a feature extractor and an encoder to extract features from audio data and predict transcriptions. The model is best suited for speech recognition tasks and has achieved a WER of 5.5% on the Librispeech-test-clean dataset."}}, {"role": "dataset", "purpose": "For evaluation.", "module": "librispeech"}], "metrics": [{"dataset": "librispeech", "metric": 5.5, "protocol": "WER"}], "source": "huggingface"}, {"id": "huggingface-birgermoell-q-frozenlake-v1-4x4-noslippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained model of a Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-4x4-no_slippery", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model's hyperparameters include the algorithm used, the environment, the maximum number of steps per episode, the number of episodes to evaluate the agent, the Q-table learned by the agent, and the random seed used for evaluation. The model achieved a mean reward of 1.0 with no standard deviation."}}, {"role": "dataset", "purpose": "Environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-coyote78-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8649 on the evaluation set. The model is suitable for token classification tasks in German language. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8648740833380706, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-drishtisharma-wav2vec2-large-xls-r-300m-gn-k1", "modules": [{"role": "model", "module": {"name": "wav2vec2-large-xls-r-300m-gn-k1", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-300m on the MOZILLA-FOUNDATION/COMMON_VOICE_8_0 - GN dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.00018, "train_batch_size": 16, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 600, "num_epochs": 200, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the MOZILLA-FOUNDATION/COMMON_VOICE_8_0 - GN dataset. The model is best suited for automatic speech recognition tasks. The model achieved a WER of 0.6631 on the Common Voice 8 dataset. The model was trained using Adam optimizer with a learning rate of 0.00018, and a linear learning rate scheduler with warmup steps of 600. The model was trained for 200 epochs with mixed precision training. The model was evaluated using PyTorch 1.10.0+cu111, Transformers 4.16.2, Datasets 1.18.3, and Tokenizers 0.11.0."}}, {"role": "dataset", "purpose": "For model training.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.6631, "protocol": "wer"}, {"dataset": "common-voice", "metric": 0.13311897106109324, "protocol": "cer"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-to-en", "modules": [{"role": "model", "module": {"name": "opus-mt-to-en", "description": "A machine translation model that translates from the 'to' language to English."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-to-en model is a machine translation model that translates from the 'to' language to English. It uses the transformer-align model and pre-processing techniques such as normalization and SentencePiece. The model achieves a BLEU score of 49.3 and a chr-F score of 0.627 on the JW300.to.en test set."}}], "metrics": [{"dataset": "jw300", "metric": 49.3, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.627, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-mrm8488-bert-small2bert-small-finetuned-cnn-daily-mail-summarization", "modules": [{"role": "model", "module": {"name": "Bert-small2Bert-small Summarization with \ud83e\udd17EncoderDecoder Framework", "description": "A fine-tuned BERT2BERT model on the CNN/Dailymail summarization dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"tokenizer": "BertTokenizerFast", "max_length": 512}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned BERT2BERT model on the CNN/Dailymail summarization dataset. The model achieves a ROUGE-2 score of 17.37 on the test dataset. The model can be used to generate summaries of input text up to a maximum length of 512 tokens."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "cnn-daily-mail"}], "metrics": [{"dataset": "cnn-daily-mail", "metric": 17.37, "protocol": "ROUGE-2"}], "source": "huggingface"}, {"id": "huggingface-ramos-ramos-emb-gam-dino", "modules": [{"role": "model", "module": {"name": "Emb-GAM (DINO patch embeddings)", "description": "LogisticRegressionCV model trained on averages of patch embeddings from the Imagenette dataset. This forms the GAM of an Emb-GAM extended to images. Patch embeddings are meant to be extracted with the facebook/dino-vitb16 DINO checkpoint."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"Cs": 10, "class_weight": null, "cv": "StratifiedKFold(n_splits=5, random_state=1, shuffle=True)", "dual": false, "fit_intercept": true, "intercept_scaling": 1.0, "l1_ratios": null, "max_iter": 100, "multi_class": "auto", "n_jobs": null, "penalty": "l2", "random_state": 1, "refit": false, "scoring": null, "solver": "lbfgs", "tol": 0.0001, "verbose": 0}}}, {"role": "taskType", "module": "tabular-classification"}, {"role": "solutionSummary", "module": {"summary": "Emb-GAM (DINO patch embeddings) is a logistic regression model trained on averages of patch embeddings from the Imagenette dataset. The patch embeddings are extracted with the facebook/dino-vitb16 DINO checkpoint. The model is not intended to be used in production. The model is suitable for image classification tasks and visualizes patch contributions per label."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-graphcore-rahult-t5-small-finetuned-xsum", "modules": [{"role": "model", "module": {"name": "t5-small-finetuned-xsum", "description": "A fine-tuned version of t5-small on the xsum dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 1, "eval_batch_size": 1, "seed": 42, "distributed_type": "IPU", "gradient_accumulation_steps": 16, "total_train_batch_size": 16, "total_eval_batch_size": 5, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1, "training_precision": "Mixed Precision"}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "t5-small-finetuned-xsum is a fine-tuned version of t5-small on the xsum dataset. It is a transformer model that can be used for summarization tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler. The model was trained for 1 epoch with mixed precision training. The model achieved a loss of 2.4688 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xsum"}], "metrics": [{"dataset": "xsum", "metric": 2.4688, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-abhishekverma-bert-finetuned-ner", "modules": [{"role": "model", "module": {"name": "bert-finetuned-ner", "description": "A fine-tuned version of bert-base-cased on the conll2003 dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-finetuned-ner is a fine-tuned version of bert-base-cased on the conll2003 dataset for token classification. The model achieved high precision, recall, F1 score, and accuracy on the evaluation set. The model is suitable for named entity recognition tasks, but caution should be taken when deploying it in human-interacting systems as it may reflect the biases of the systems it was trained on."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 0.9325508348487354, "protocol": "precision"}, {"dataset": "conll-2003", "metric": 0.9493436553349041, "protocol": "recall"}, {"dataset": "conll-2003", "metric": 0.9408723209073472, "protocol": "f1"}, {"dataset": "conll-2003", "metric": 0.9862247601106728, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-butchland-dqn-spaceinvadersnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "DQN Agent playing SpaceInvadersNoFrameskip-v4", "description": "A trained DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "buffer_size": 100000, "exploration_final_eps": 0.01, "exploration_fraction": 0.1, "frame_stack": 4, "gradient_steps": 1, "learning_rate": 0.0001, "learning_starts": 100000, "n_timesteps": 1000000.0, "optimize_memory_usage": false, "policy": "CnnPolicy", "target_update_interval": 1000, "train_freq": 4, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The model was trained with a batch size of 32, a buffer size of 100000, and a learning rate of 0.0001. The model achieved a mean reward of 582.00 +/- 129.21 on the SpaceInvadersNoFrameskip-v4 dataset. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 582.0, "split": "val", "protocol": "mean_reward"}, {"dataset": "atari-grand-challenge", "metric": 129.21, "split": "test", "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-fveredas-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8649 on the evaluation set. The model is suitable for token classification tasks in German language. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8648740833380706, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-beki-en-spacy-pii-distilbert", "modules": [{"role": "model", "module": {"name": "en_spacy_pii_distilbert", "description": "A spaCy model for named entity recognition (NER) trained on a new dataset for structured PII generated by Privy."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"spaCy_version": ">=3.4.1,<3.5.0", "pipeline": ["transformer", "ner"], "components": ["transformer", "ner"], "vectors": {"keys": 0, "unique_vectors": 0, "dimensions": 0}, "optimizer": {"type": "Adam", "learning_rate": null}, "loss": {"TRANSFORMER_LOSS": 61154.85, "NER_LOSS": 56001.88}}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "en_spacy_pii_distilbert is a spaCy model for named entity recognition (NER) trained on a new dataset for structured PII generated by Privy. The model achieved an F1 score of 95.42% on the test set. The model is suitable for identifying named entities of type DATE_TIME, LOC, NRP, ORG, and PER."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-cardiffnlp-twitter-roberta-base-2021-124m-emoji", "modules": [{"role": "model", "module": {"name": "cardiffnlp/twitter-roberta-base-2021-124m-emoji", "description": "Fine-tuned version of cardiffnlp/twitter-roberta-base-2021-124m on the tweet_eval (emoji) dataset via tweetnlp."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"max_length": 128}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of cardiffnlp/twitter-roberta-base-2021-124m on the tweet_eval (emoji) dataset via tweetnlp. The model can be used for text classification tasks on social media data. The model achieved a micro F1 score of 0.46162 and a macro F1 score of 0.34612351090521765 on the test split of the tweet_eval dataset."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "tweeteval"}], "metrics": [{"dataset": "tweeteval", "metric": 0.46162, "protocol": "micro_f1_tweet_eval/emoji"}, {"dataset": "tweeteval", "metric": 0.34612351090521765, "protocol": "macro_f1_tweet_eval/emoji"}, {"dataset": "tweeteval", "metric": 0.46162, "protocol": "accuracy_tweet_eval/emoji"}], "source": "huggingface"}, {"id": "huggingface-hpl-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. The model is best suited for text classification tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 64. The model achieved an accuracy of 0.9405 and an F1 score of 0.9409 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.9405, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.9408676491029256, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-sania67-fine-tunning-on-cv-dataset", "modules": [{"role": "model", "module": {"name": "Fine_Tunning_on_CV_dataset", "description": "Fine-tuned version of facebook/wav2vec2-large-xlsr-53 on the common_voice_8_0 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0001, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 1000, "num_epochs": 30, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Fine-tuned version of facebook/wav2vec2-large-xlsr-53 on the common_voice_8_0 dataset. Achieves a WER of 0.4734 on the evaluation set. The model is suitable for automatic speech recognition tasks. The model was trained using PyTorch 1.11.0+cu113 and Transformers 4.21.0."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.3038, "split": "val", "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.7892, "split": "test", "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.4734, "protocol": "WER"}], "source": "huggingface"}, {"id": "huggingface-clisi2000-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. It can be used for text classification tasks. The model achieved an accuracy of 0.9245 and an F1 score of 0.9246 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emocontext"}], "metrics": [{"dataset": "emocontext", "metric": 0.9245, "protocol": "accuracy"}, {"dataset": "emocontext", "metric": 0.9246284188099615, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-beltran-finetuning-sentiment-model-3000-samples", "modules": [{"role": "model", "module": {"name": "finetuning-sentiment-model-3000-samples", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "finetuning-sentiment-model-3000-samples is a fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis. The model achieved an accuracy of 0.8567 and an F1 score of 0.8571 on the evaluation set. The model is suitable for text classification tasks, but its performance may vary depending on the specific use case and data distribution."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.8566666666666667, "protocol": "accuracy"}, {"dataset": "imdb-movie-reviews", "metric": 0.8571428571428571, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-mbeukman-xlm-roberta-base-finetuned-swahili-finetuned-ner-yoruba", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-swahili-finetuned-ner-yoruba", "description": "A token classification model fine-tuned on the MasakhaNER dataset for named entity recognition in Yoruba."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"max_seq_length": 200, "batch_size": 32, "learning_rate": 5e-05, "epochs": 50}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a token classification model fine-tuned on the MasakhaNER dataset for named entity recognition in Yoruba. The model is transformer-based and was fine-tuned for 50 epochs with a maximum sequence length of 200, 32 batch size, and 5e-5 learning rate. The model is intended for NLP research into interpretability or transfer learning and is not designed for production use. The model's limitations include being trained on a relatively small dataset covering one task in one domain and may perform badly or in an unfair/biased way if used on other tasks. The model is licensed under the Apache License, Version 2.0."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "masakhaner"}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-jgriffi-xlm-roberta-base-finetuned-panx-en", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-en", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 12, "eval_batch_size": 12, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification. It achieves an F1 score of 0.7055 on the evaluation set. The model is suitable for token classification tasks in multilingual settings."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.7054833239118146, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-kg-es", "modules": [{"role": "model", "module": {"name": "opus-mt-kg-es", "description": "A machine translation model that translates from the Kongo language (kg) to Spanish (es)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-kg-es model is a machine translation model that translates from the Kongo language to Spanish. The model uses the transformer-align architecture and was preprocessed using normalization and SentencePiece. The model achieved a BLEU score of 22.4 and a chr-F score of 0.402 on the JW300.kg.es test set."}}], "metrics": [{"dataset": "jw300", "metric": 22.4, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.402, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-danielvasic-en-acnl-roberta-pipeline", "modules": [{"role": "model", "module": {"name": "en_acnl_roberta_pipeline", "description": "A spaCy pipeline for token classification tasks such as POS tagging, sentence boundary detection, and dependency parsing."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"spaCy_version": ">=3.1.3,<3.2.0", "pipeline": ["transformer", "tagger", "parser"], "transformer_loss": 3784861.59, "tagger_loss": 698704.8, "parser_loss": 5540167.0}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "en_acnl_roberta_pipeline is a spaCy pipeline for token classification tasks such as POS tagging, sentence boundary detection, and dependency parsing. The model was trained on OntoNotes dataset and achieved high accuracy scores on various metrics such as TAG_ACC, DEP_UAS, DEP_LAS, SENTS_P, SENTS_R, and SENTS_F. The model uses a transformer, tagger, and parser components in the pipeline."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-lewtun-xlm-roberta-base-finetuned-marc", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-marc", "description": "A fine-tuned version of xlm-roberta-base on the amazon_reviews_multi dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "xlm-roberta-base-finetuned-marc is a fine-tuned version of xlm-roberta-base on the amazon_reviews_multi dataset. The model is best suited for text classification tasks. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for 2 epochs and achieved a loss of 0.9932 and a mean absolute error of 0.4838 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "amazon-product-data"}], "metrics": [{"dataset": "amazon-product-data", "metric": 0.9932, "protocol": "loss"}, {"dataset": "amazon-product-data", "metric": 0.4838, "protocol": "mae"}], "source": "huggingface"}, {"id": "huggingface-gary109-ai-light-dance-singing-ft-pretrain-wav2vec2-large-lv60", "modules": [{"role": "model", "module": {"name": "ai-light-dance_singing_ft_pretrain_wav2vec2-large-lv60", "description": "Fine-tuned version of gary109/ai-light-dance_pretrain_wav2vec2-large-lv60 on the GARY109/AI_LIGHT_DANCE - ONSET-SINGING dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 2, "eval_batch_size": 2, "seed": 42, "gradient_accumulation_steps": 16, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "cosine", "num_epochs": 10.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "ai-light-dance_singing_ft_pretrain_wav2vec2-large-lv60 is a fine-tuned version of gary109/ai-light-dance_pretrain_wav2vec2-large-lv60 on the GARY109/AI_LIGHT_DANCE - ONSET-SINGING dataset. The model is intended for automatic speech recognition tasks. The model was trained using Adam optimizer with a learning rate of 5e-05 and cosine learning rate scheduler. The model was trained for 10 epochs with a batch size of 32. The model achieved a WER of 0.9230 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "children-s-song-dataset"}], "metrics": [{"dataset": "children-s-song-dataset", "metric": 1.2885, "split": "val", "protocol": "loss"}, {"dataset": "children-s-song-dataset", "metric": 1.5296, "split": "test", "protocol": "loss"}, {"dataset": "children-s-song-dataset", "metric": 0.923, "protocol": "WER"}], "source": "huggingface"}, {"id": "huggingface-patrickvonplaten-unispeech-sat-base-plus-timit-ft", "modules": [{"role": "model", "module": {"name": "unispeech-sat-base-plus-timit-ft", "description": "Fine-tuned version of microsoft/unispeech-sat-base-plus on the TIMIT_ASR - NA dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0001, "train_batch_size": 32, "eval_batch_size": 1, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 1000, "num_epochs": 20.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "unispeech-sat-base-plus-timit-ft is a fine-tuned version of microsoft/unispeech-sat-base-plus on the TIMIT_ASR - NA dataset. It is intended for automatic speech recognition tasks. The model was trained with masked language modeling and next sentence prediction objectives. The model was trained on BookCorpus and English Wikipedia datasets. The model was trained with Adam optimizer with a learning rate of 0.0001, betas of 0.9 and 0.999, and epsilon of 1e-08. The model was trained for 20 epochs with a batch size of 32 and mixed precision training. The model achieved a loss of 0.6549 and a WER of 0.4051 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "timit-timit-acoustic-phonetic-continuous-speech-corpus"}], "metrics": [{"dataset": "timit-timit-acoustic-phonetic-continuous-speech-corpus", "metric": 0.6549, "protocol": "loss"}, {"dataset": "timit-timit-acoustic-phonetic-continuous-speech-corpus", "metric": 0.4051, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-karthiksv-vit-base-patch16-224-cifar10", "modules": [{"role": "model", "module": {"name": "vit-base-patch16-224-cifar10", "description": "A fine-tuned version of google/vit-base-patch16-224-in21k on the cifar10 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "seed": 1337, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "vit-base-patch16-224-cifar10 is a fine-tuned version of google/vit-base-patch16-224-in21k on the cifar10 dataset. The model is intended for image classification tasks. The hyperparameters used during training include a learning rate of 2e-05, train batch size of 8, and 3 epochs. The model was trained using Adam optimizer with betas=(0.9,0.999) and epsilon=1e-08. The model achieved an accuracy of 0.1004 on the test set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "cifar-10"}], "metrics": [{"dataset": "cifar-10", "metric": 0.1004, "protocol": "Accuracy"}, {"dataset": "cifar-10", "metric": 0.07725693204097324, "protocol": "Precision Macro"}, {"dataset": "cifar-10", "metric": 0.1004, "protocol": "Precision Micro"}, {"dataset": "cifar-10", "metric": 0.07725693204097323, "protocol": "Precision Weighted"}, {"dataset": "cifar-10", "metric": 0.1004, "protocol": "Recall Macro"}, {"dataset": "cifar-10", "metric": 0.1004, "protocol": "Recall Micro"}, {"dataset": "cifar-10", "metric": 0.1004, "protocol": "Recall Weighted"}, {"dataset": "cifar-10", "metric": 0.07942008420616108, "protocol": "F1 Macro"}, {"dataset": "cifar-10", "metric": 0.1004, "protocol": "F1 Micro"}, {"dataset": "cifar-10", "metric": 0.07942008420616108, "protocol": "F1 Weighted"}, {"dataset": "cifar-10", "metric": 2.3154706954956055, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-tamarab-bert-emotion", "modules": [{"role": "model", "module": {"name": "bert-emotion", "description": "Fine-tuned version of distilbert-base-cased on the tweet_eval dataset for emotion classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 4, "eval_batch_size": 4, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-emotion is a fine-tuned version of distilbert-base-cased on the tweet_eval dataset for emotion classification. The model achieved a precision of 0.7463 and a recall of 0.7096 on the evaluation set. The model is suitable for text classification tasks, but its performance may vary depending on the specific use case and data distribution."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "tweeteval"}], "metrics": [{"dataset": "tweeteval", "metric": 0.7462955517135084, "protocol": "Precision"}, {"dataset": "tweeteval", "metric": 0.7095634380533169, "protocol": "Recall"}, {"dataset": "tweeteval", "metric": 0.7209, "protocol": "Fscore"}], "source": "huggingface"}, {"id": "huggingface-tner-roberta-large-tweebank-ner", "modules": [{"role": "model", "module": {"name": "tner/roberta-large-tweebank-ner", "description": "A fine-tuned version of roberta-large on the tner/tweebank_ner dataset for named entity recognition."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "roberta-large", "crf": true, "max_length": 128, "epoch": 15, "batch_size": 64, "lr": 1e-05, "gradient_accumulation_steps": 1, "lr_warmup_step_ratio": 0.1, "max_grad_norm": 10.0}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of the roberta-large model on the tner/tweebank_ner dataset for named entity recognition. The model achieved an F1 score of 0.7439 on the test set. The model is best suited for tasks that require named entity recognition. The model was trained with a batch size of 64, a learning rate of 1e-05, and a maximum sequence length of 128. The model reflects the biases inherent to the systems they were trained on, so caution should be taken when deploying it into systems that interact with humans."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "tweebank"}], "metrics": [{"dataset": "tweebank", "metric": 0.7439490445859872, "protocol": "F1"}, {"dataset": "tweebank", "metric": 0.7121951219512195, "protocol": "Precision"}, {"dataset": "tweebank", "metric": 0.7786666666666666, "protocol": "Recall"}, {"dataset": "tweebank", "metric": 0.7354319457314183, "protocol": "F1 (macro)"}, {"dataset": "tweebank", "metric": 0.712928566565599, "protocol": "Precision (macro)"}, {"dataset": "tweebank", "metric": 0.7620465365030582, "protocol": "Recall (macro)"}, {"dataset": "tweebank", "metric": 0.8178343949044585, "protocol": "F1 (entity span)"}, {"dataset": "tweebank", "metric": 0.7829268292682927, "protocol": "Precision (entity span)"}, {"dataset": "tweebank", "metric": 0.856, "protocol": "Recall (entity span)"}], "source": "huggingface"}, {"id": "huggingface-lewtun-roberta-large-finetuned-clinc-12", "modules": [{"role": "model", "module": {"name": "roberta-large-finetuned-clinc-12", "description": "A fine-tuned version of roberta-large on the clinc_oos dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 3, "mixed_precision_training": true}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of the roberta-large model on the clinc_oos dataset. The model achieved an accuracy of 0.9765 on the evaluation set. The model is suitable for text classification tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "clinc-single-domain-oos"}], "metrics": [{"dataset": "clinc-single-domain-oos", "metric": 0.9764516129032258, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-devarshi-brain-tumor-class-swin", "modules": [{"role": "model", "module": {"name": "Brain_Tumor_Class_swin", "description": "A fine-tuned version of microsoft/swin-base-patch4-window7-224-in22k on the imagefolder dataset for image classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 32, "eval_batch_size": 32, "seed": 42, "gradient_accumulation_steps": 4, "total_train_batch_size": 128, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "num_epochs": 3}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "Brain_Tumor_Class_swin is a fine-tuned version of microsoft/swin-base-patch4-window7-224-in22k on the imagefolder dataset for image classification. The model achieved an accuracy of 0.9936 on the evaluation set. The model is suitable for image classification tasks, but its intended uses and limitations are not specified. The training and evaluation data, as well as the model description, are not provided."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "objectfolder"}], "metrics": [{"dataset": "objectfolder", "metric": 0.9936204146730463, "protocol": "accuracy"}, {"dataset": "objectfolder", "metric": 0.9936204146730463, "protocol": "f1"}, {"dataset": "objectfolder", "metric": 0.9936204146730463, "protocol": "recall"}, {"dataset": "objectfolder", "metric": 0.9936204146730463, "protocol": "precision"}], "source": "huggingface"}, {"id": "huggingface-hezzze-dqn-spaceinvadersnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "DQN Agent playing SpaceInvadersNoFrameskip-v4", "description": "A trained DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "buffer_size": 100000, "exploration_final_eps": 0.01, "exploration_fraction": 0.1, "frame_stack": 4, "gradient_steps": 1, "learning_rate": 0.0001, "learning_starts": 100000, "n_timesteps": 1000000.0, "optimize_memory_usage": false, "policy": "CnnPolicy", "target_update_interval": 1000, "train_freq": 4, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The model was trained with a batch size of 32, a buffer size of 100000, and a learning rate of 0.0001. The model achieved a mean reward of 573.50 with a standard deviation of 171.74 on the SpaceInvadersNoFrameskip-v4 dataset. The model is suitable for reinforcement learning tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-100k"}], "metrics": [{"dataset": "atari-100k", "metric": 573.5, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-sophiestein-experiment-2", "modules": [{"role": "model", "module": {"name": "experiment_2", "description": "Fine-tuned version of distilbert-base-uncased on the conll2003 dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "experiment_2 is a fine-tuned version of distilbert-base-uncased on the conll2003 dataset for token classification. The model achieved high precision, recall, F1 score, and accuracy on the evaluation set. The model is suitable for token classification tasks, such as named entity recognition. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 0.8840954508052192, "protocol": "precision"}, {"dataset": "conll-2003", "metric": 0.8925943508188939, "protocol": "recall"}, {"dataset": "conll-2003", "metric": 0.8883245733183724, "protocol": "f1"}, {"dataset": "conll-2003", "metric": 0.9746737103791174, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-en-ca", "modules": [{"role": "model", "module": {"name": "opus-mt-en-ca", "description": "A transformer-align model for translating from English to Catalan."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-en-ca model is a transformer-align model that translates English to Catalan. It was trained on the OPUS dataset using normalization and SentencePiece preprocessing. The model achieved a BLEU score of 47.2 and a chr-F score of 0.665 on the Tatoeba.en.ca test set."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-marioarteaga-distilbert-base-uncased-finetuned-squad", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-squad", "description": "A fine-tuned version of distilbert-base-uncased on the squad dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-squad is a fine-tuned version of distilbert-base-uncased on the squad dataset. It is suitable for question answering tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for 1 epoch and achieved a validation loss of 1.2052."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 1.2493, "split": "val", "protocol": "loss"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 1.2052, "split": "test", "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-danielcfho-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 environment."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "is_slippery": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 environment. The model was evaluated on the mean reward metric and achieved a score of 7.50 +/- 2.78. The model can be loaded from the Hugging Face model hub and used to evaluate the agent on new episodes of the environment."}}, {"role": "dataset", "purpose": "OpenAI Gym environment", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.5, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-patrickvonplaten-roberta2roberta-cnn-dailymail-fp16", "modules": [{"role": "model", "module": {"name": "Roberta2Roberta Summarization with \ud83e\udd17 EncoderDecoder Framework", "description": "Roberta2Roberta model fine-tuned on summarization using the \ud83e\udd17 EncoderDecoder Framework."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"encoder": "roberta-base", "decoder": "roberta-base", "batch_size": 16, "max_length": 142, "min_length": 56, "no_repeat_ngram_size": 3, "early_stopping": true, "length_penalty": 2.0, "num_beams": 4, "optimizer": {"name": "Adam", "learning_rate": 0.0001, "beta1": 0.9, "beta2": 0.999, "weight_decay": 0.01}}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "Roberta2Roberta is a EncoderDecoderModel fine-tuned on summarization using the \ud83e\udd17 EncoderDecoder Framework. The model is based on two Roberta models, one for the encoder and one for the decoder. The model is intended for summarization tasks and can be used to generate summaries from articles. The model was fine-tuned on the CNN/Daily Mail dataset and achieved reasonable results. The model reflects the biases inherent to the systems they were trained on, so caution should be taken when deploying it into systems that interact with humans."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-es-et", "modules": [{"role": "model", "module": {"name": "opus-mt-es-et", "description": "A transformer-align model for translating from Spanish to Estonian."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-es-et is a transformer-align model for translating from Spanish to Estonian. It was trained on the OPUS dataset using normalization and SentencePiece pre-processing. The model achieved a BLEU score of 20.7 and a chr-F score of 0.466 on the JW300.es.et test set."}}], "metrics": [{"dataset": "jw300", "metric": 20.7, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.466, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-ocm-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8649 on the evaluation set. The model is suitable for token classification tasks in German language. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8648740833380706, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-anirudh21-albert-xlarge-v2-finetuned-mrpc", "modules": [{"role": "model", "module": {"name": "albert-xlarge-v2-finetuned-mrpc", "description": "A fine-tuned version of albert-xlarge-v2 on the GLUE dataset for text classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of albert-xlarge-v2 on the GLUE dataset for text classification. The model achieved an accuracy of 0.7132 and an F1 score of 0.8146 on the evaluation set. The model is suitable for text classification tasks, but its intended uses and limitations are not specified in the model card."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-cardiffnlp-twitter-roberta-base-dec2020-tweet-topic-multi-2020", "modules": [{"role": "model", "module": {"name": "cardiffnlp/twitter-roberta-base-dec2020-tweet-topic-multi-2020", "description": "A fine-tuned version of cardiffnlp/twitter-roberta-base-dec2020 on the tweet_topic_multi dataset for text classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "cardiffnlp/twitter-roberta-base-dec2020", "problem_type": "multi_label_classification", "tokenizer": "AutoTokenizer", "batch_size": null}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "A fine-tuned version of cardiffnlp/twitter-roberta-base-dec2020 on the tweet_topic_multi dataset for text classification. The model is fine-tuned on train_2020 split and validated on test_2021 split of tweet_topic. The model is suitable for multi-label classification tasks on Twitter data. The model achieves an F1 score of 0.73 (micro) and 0.53 (macro) and an accuracy of 0.50 on the test set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "tweeteval"}], "metrics": [{"dataset": "tweeteval", "metric": 0.7294463087248323, "split": "val", "protocol": "f1"}, {"dataset": "tweeteval", "metric": 0.5347990396677114, "split": "test", "protocol": "f1"}, {"dataset": "tweeteval", "metric": 0.5026801667659321, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-martinomensio-racism-models-m-vote-nonstrict-epoch-1", "modules": [{"role": "model", "module": {"name": "BETO fine-tuned on Datathon Against Racism dataset", "description": "A fine-tuned version of BETO (Spanish BERT) trained on the Datathon Against Racism dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_name": "dccuchile/bert-base-spanish-wwm-uncased", "method": "m-vote-nonstrict", "epoch": 1}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of BETO (Spanish BERT) trained on the Datathon Against Racism dataset. It is intended for text classification tasks in Spanish, specifically for detecting racism. The model was fine-tuned using six different methods for ground-truth estimations, and this specific model was trained using the m-vote-nonstrict method for one epoch. The model can be used with the `text-classification` pipeline from the Transformers library."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "biascorp"}], "metrics": [{"dataset": "biascorp", "metric": 0.9265261888504028, "protocol": "racist"}, {"dataset": "biascorp", "metric": 0.802951991558075, "protocol": "non-racist"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-chk-es", "modules": [{"role": "model", "module": {"name": "opus-mt-chk-es", "description": "A machine translation model that translates from the Chechen language (chk) to Spanish (es)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-chk-es is a machine translation model that translates from the Chechen language to Spanish. The model uses the transformer-align architecture and was preprocessed using normalization and SentencePiece. The model achieved a BLEU score of 20.8 and a chr-F score of 0.374 on the JW300.chk.es test set."}}, {"role": "dataset", "purpose": "Test set for benchmarking.", "module": "jw300"}], "metrics": [{"dataset": "jw300", "metric": 20.8, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.374, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-wuxiaofei-finetuning-sentiment-model-3000-samples", "modules": [{"role": "model", "module": {"name": "finetuning-sentiment-model-3000-samples", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 2, "eval_batch_size": 2, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "finetuning-sentiment-model-3000-samples is a fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis. The model achieved an accuracy of 0.86 and an F1 score of 0.8636 on the evaluation set. The model is suitable for text classification tasks, but its performance may vary depending on the specific use case and data distribution."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.86, "protocol": "accuracy"}, {"dataset": "imdb-movie-reviews", "metric": 0.8636, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-jcplus-stable-diffusion-v1-5", "modules": [{"role": "model", "module": {"name": "Stable Diffusion v1-5", "description": "A latent text-to-image diffusion model capable of generating photo-realistic images given any text input."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"resolution": "512x512", "text_encoder": "CLIP ViT-L/14", "training_data": "LAION-2B (en) and subsets thereof", "optimizer": "AdamW", "gradient_accumulations": 2, "batch_size": 2048, "learning_rate": 0.0001}}}, {"role": "taskType", "module": "text-to-image"}, {"role": "solutionSummary", "module": {"summary": "Stable Diffusion v1-5 is a latent text-to-image diffusion model that generates photo-realistic images given any text input. The model is intended for research purposes only and is not suitable for generating harmful content. The model was trained on LAION-2B (en) and subsets thereof. The model is not perfect and has limitations, such as not being able to render legible text and not performing well on more difficult tasks that involve compositionality. The model was trained mainly with English captions and will not work as well in other languages. The model reflects the biases inherent to the systems they were trained on, so caution should be taken when deploying it into systems that interact with humans."}}, {"role": "dataset", "purpose": "For evaluation.", "module": "coco-microsoft-common-objects-in-context"}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-vnktrmnb-distilbert-base-uncased-finetuned-squad", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-squad", "description": "A fine-tuned version of distilbert-base-uncased on the squad_v2 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-squad is a fine-tuned version of distilbert-base-uncased on the squad_v2 dataset. It is suitable for question answering tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for 1 epoch and achieved a validation loss of 1.2589."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 1.2748, "split": "val", "protocol": "loss"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 1.2589, "split": "test", "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-mascariddu8-bert-finetuned-ner", "modules": [{"role": "model", "module": {"name": "bert-finetuned-ner", "description": "A fine-tuned version of bert-base-cased on the conll2003 dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-finetuned-ner is a fine-tuned version of bert-base-cased on the conll2003 dataset for token classification. The model achieved high precision, recall, F1 score, and accuracy on the evaluation set. The model is suitable for named entity recognition tasks, but caution should be taken when deploying it in human-interacting systems as it may reflect the biases of the systems it was trained on."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 0.9357296670531721, "protocol": "precision"}, {"dataset": "conll-2003", "metric": 0.9506900033658701, "protocol": "recall"}, {"dataset": "conll-2003", "metric": 0.9431505133984472, "protocol": "f1"}, {"dataset": "conll-2003", "metric": 0.9857390946017542, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-damianr13-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 game."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 game. The agent's Q-Table is provided, along with hyperparameters such as the maximum number of steps per episode and the number of episodes used to evaluate the agent. The model achieved a mean reward of 7.56 with a standard deviation of 2.71."}}, {"role": "dataset", "purpose": "The game environment used for training and evaluation.", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.56, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-chieunq-xlm-r-base-finetuned-uit-vquad-1", "modules": [{"role": "model", "module": {"name": "XLM-Roberta-base", "description": "A multilingual transformer model pretrained on a large corpus of data in a self-supervised fashion."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_checkpoint": "chieunq/XLM-R-base-finetuned-uit-vquad-1", "pipeline": "question-answering"}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "The XLM-Roberta-base model was fine-tuned on the UIT-vquad dataset for question answering. The model achieved an EM score of 60.63 and an F1 score of 79.63. The model is a multilingual transformer model pretrained on a large corpus of data in a self-supervised fashion. The model can be used for various NLP tasks, including question answering, and can be fine-tuned on other datasets for better performance."}}, {"role": "dataset", "purpose": "For fine-tuning and evaluation.", "module": "uit-viquad"}], "metrics": [{"dataset": "uit-viquad", "metric": 60.63, "protocol": "EM (exact match)"}, {"dataset": "uit-viquad", "metric": 79.63, "protocol": "F1"}], "source": "huggingface"}, {"id": "huggingface-alred-bart-base-finetuned-summarization-cnn-ver2", "modules": [{"role": "model", "module": {"name": "bart-base-finetuned-summarization-cnn-ver2", "description": "A fine-tuned version of facebook/bart-base on the cnn_dailymail dataset for summarization."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 1, "eval_batch_size": 1, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/bart-base on the cnn_dailymail dataset for summarization. The model achieved a validation loss of 2.1715. The model is suitable for summarizing news articles, but its performance may vary depending on the input data and the quality of the summaries required."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "cnn-daily-mail"}], "metrics": [{"dataset": "cnn-daily-mail", "metric": 2.3329, "split": "val", "protocol": "loss"}, {"dataset": "cnn-daily-mail", "metric": 2.1715, "split": "test", "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-kiran146-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. The model is best suited for text classification tasks. The model achieved an accuracy of 0.9225 and an F1 score of 0.9228 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.9225, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.9227765339978083, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-en-lus", "modules": [{"role": "model", "module": {"name": "opus-mt-en-lus", "description": "A transformer-align model for translating from English to Lushootseed (lus)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-en-lus is a transformer-align model for translating from English to Lushootseed (lus). The model was trained on the OPUS dataset using normalization and SentencePiece pre-processing. The model achieved a BLEU score of 36.8 and a chr-F score of 0.581 on the JW300.en.lus test set."}}, {"role": "dataset", "purpose": "For benchmarking.", "module": "jw300"}], "metrics": [{"dataset": "jw300", "metric": 36.8, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.581, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-efi-fr", "modules": [{"role": "model", "module": {"name": "opus-mt-efi-fr", "description": "A transformer-align model trained on the efi to fr language pair for translation."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-efi-fr model is a transformer-align model trained on the efi to fr language pair for translation. It achieved a BLEU score of 25.1 and a chr-F score of 0.419 on the JW300.efi.fr test set. The model uses normalization and SentencePiece for pre-processing."}}, {"role": "dataset", "purpose": "Test set for benchmarking.", "module": "jw300"}], "metrics": [{"dataset": "jw300", "metric": 25.1, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.419, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-infinitejoy-wav2vec2-large-xls-r-300m-basaa", "modules": [{"role": "model", "module": {"name": "wav2vec2-large-xls-r-300m-basaa", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-300m on the MOZILLA-FOUNDATION/COMMON_VOICE_7_0 - BAS dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 7e-05, "train_batch_size": 32, "eval_batch_size": 32, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 200.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the MOZILLA-FOUNDATION/COMMON_VOICE_7_0 - BAS dataset. The model is intended for automatic speech recognition tasks. The model achieved a WER of 0.4981 on the evaluation set. The training was done using Adam optimizer with a learning rate of 7e-05 and a batch size of 32. The model was trained for 200 epochs with mixed precision training. The model was trained using Transformers 4.16.0.dev0, Pytorch 1.10.1+cu102, Datasets 1.17.1.dev0, and Tokenizers 0.11.0."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 104.08, "protocol": "Test WER"}, {"dataset": "common-voice", "metric": 228.48, "protocol": "Test CER"}], "source": "huggingface"}, {"id": "huggingface-maxaontrix-distilbert-base-uncased-finetuned-ner-finetuned-ner", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-ner-finetuned-ner", "description": "A fine-tuned DistilBERT model on the skript dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned DistilBERT model on the skript dataset for token classification task. The model was trained for 3 epochs with a learning rate of 2e-05 and an Adam optimizer with betas=(0.9,0.999) and epsilon=1e-08. The model achieved a precision of 0.0581, recall of 0.0450, F1 score of 0.0507, and accuracy of 0.7974 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 0.0581, "protocol": "precision"}, {"dataset": "conll-2003", "metric": 0.045, "protocol": "recall"}, {"dataset": "conll-2003", "metric": 0.0507, "protocol": "f1"}, {"dataset": "conll-2003", "metric": 0.7974, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-fan-s-reddit-tc-bert", "modules": [{"role": "model", "module": {"name": "bert-uncased-base", "description": "Fine-tuned version of bert-base-uncased on a Reddit-dialogue dataset for text classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 320, "eval_batch_size": 80, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5.0}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-uncased-base is a fine-tuned version of bert-base-uncased on a Reddit-dialogue dataset for text classification. It can be used to predict whether two sentences are related. The model achieved an accuracy of 0.9267 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler. The model reflects the biases inherent to the systems they were trained on, so caution should be taken when deploying it into systems that interact with humans."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "reddit-corpus"}], "metrics": [{"dataset": "reddit-corpus", "metric": 0.9267, "protocol": "accuracy"}, {"dataset": "reddit-corpus", "metric": 0.2297, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-axwl-q-taxi-v3-tst", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing Taxi-v3", "description": "A trained model of a Q-Learning agent playing Taxi-v3."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing Taxi-v3. The model's Q-Table is provided along with the maximum number of steps per episode, the number of episodes to evaluate the agent, and the random seed used for evaluation. The model's performance is evaluated based on the mean reward achieved over the evaluation episodes."}}, {"role": "dataset", "purpose": "OpenAI Gym environment", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.56, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-davidenam-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. The model is best suited for text classification tasks. The model achieved an accuracy of 0.9205 and an F1 score of 0.9203 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.9205, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.9203318889648883, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-adache-xlm-roberta-base-finetuned-panx-it", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-it", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "xlm-roberta-base-finetuned-panx-it is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. The model achieved an F1 score of 0.8248 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 5e-05 and a linear learning rate scheduler for 3 epochs. The model was trained using Transformers 4.19.2, Pytorch 1.11.0+cu113, Datasets 2.2.2, and Tokenizers 0.12.1."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8247845711940912, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-abrinkmann-sbert-xtremedistil-l6-h256-uncased-mean-cosine-h32", "modules": [{"role": "model", "module": {"name": "ABrinkmann/sbert_xtremedistil-l6-h256-uncased-mean-cosine-h32", "description": "A sentence-transformers model that maps sentences and paragraphs to a 32-dimensional dense vector space for clustering or semantic search."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "loss": "CosineSimilarityLoss", "optimizer": {"name": "AdamW", "learning_rate": 2e-05}, "epochs": 1, "warmup_steps": 26, "weight_decay": 0.01}}}, {"role": "taskType", "module": "sentence-similarity"}, {"role": "solutionSummary", "module": {"summary": "ABrinkmann/sbert_xtremedistil-l6-h256-uncased-mean-cosine-h32 is a sentence-transformers model that maps sentences and paragraphs to a 32-dimensional dense vector space for clustering or semantic search. The model was trained with a batch size of 32, CosineSimilarityLoss, AdamW optimizer with a learning rate of 2e-05, 1 epoch, 26 warmup steps, and a weight decay of 0.01. No evaluation scores were provided."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-humancompatibleai-ppo-seals-cartpole-v0", "modules": [{"role": "model", "module": {"name": "PPO", "description": "A trained PPO agent playing seals/CartPole-v0 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 256, "clip_range": 0.4, "ent_coef": 0.008508727919228772, "gae_lambda": 0.9, "gamma": 0.9999, "learning_rate": 0.0012403278189645594, "max_grad_norm": 0.8, "n_envs": 8, "n_epochs": 10, "n_steps": 512, "n_timesteps": 100000.0, "policy": "MlpPolicy", "policy_kwargs": {"activation_fn": "ReLU", "net_arch": [{"pi": [64, 64], "vf": [64, 64]}]}, "vf_coef": 0.489343896591493, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained PPO agent playing seals/CartPole-v0 using the stable-baselines3 library and the RL Zoo. The model was trained with the hyperparameters listed above and achieved a mean reward of 500.00 on the seals/CartPole-v0 dataset. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "safe-control-gym"}], "metrics": [{"dataset": "safe-control-gym", "metric": 500.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-de-ht", "modules": [{"role": "model", "module": {"name": "opus-mt-de-ht", "description": "A transformer-align model for translating from German (de) to Haitian Creole (ht)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-de-ht is a transformer-align model for translating from German to Haitian Creole. The model was trained on the OPUS dataset using normalization and SentencePiece preprocessing. The model achieved a BLEU score of 21.8 and a chr-F score of 0.39 on the JW300.de.ht test set."}}], "metrics": [{"dataset": "jw300", "metric": 21.8, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.39, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-ryo-hsgw-xlm-roberta-base-finetuned-panx-fr", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-fr", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8326 on the evaluation set. The model is suitable for token classification tasks in French language. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8325761399966348, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-crabz-distil-slovakbert-upos", "modules": [{"role": "model", "module": {"name": "distil-slovakbert-upos", "description": "A fine-tuned version of crabz/distil-slovakbert on the universal_dependencies sk_snk dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 32, "eval_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 10.0}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "distil-slovakbert-upos is a fine-tuned version of crabz/distil-slovakbert on the universal_dependencies sk_snk dataset. It is a transformer model that can be used for token classification tasks. The model was trained with Adam optimizer with a learning rate of 5e-05 and a batch size of 32. The model achieved high precision, recall, F1 score, and accuracy on the evaluation set. The model was trained using the Transformers, PyTorch, Datasets, and Tokenizers frameworks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "universal-dependencies"}], "metrics": [{"dataset": "universal-dependencies", "metric": 0.9771104035797263, "protocol": "Precision"}, {"dataset": "universal-dependencies", "metric": 0.9785418821096173, "protocol": "Recall"}, {"dataset": "universal-dependencies", "metric": 0.9778256189451022, "protocol": "F1"}, {"dataset": "universal-dependencies", "metric": 0.9800851200513933, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-jonatasgrosman-wav2vec2-large-xlsr-53-italian", "modules": [{"role": "model", "module": {"name": "XLSR Wav2Vec2 Italian by Jonatas Grosman", "description": "Fine-tuned XLSR-53 large model for speech recognition in Italian."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_id": "jonatasgrosman/wav2vec2-large-xlsr-53-italian", "batch_size": 1, "sampling_rate": 16000}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned XLSR-53 large model for speech recognition in Italian. The model was fine-tuned on the train and validation splits of Common Voice 6.1. The model can be used directly for speech recognition without a language model. The model is suitable for tasks such as sequence classification, token classification, or question answering. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 9.41, "protocol": "wer"}, {"dataset": "common-voice", "metric": 6.91, "protocol": "wer"}, {"dataset": "common-voice", "metric": 2.29, "protocol": "cer"}, {"dataset": "common-voice", "metric": 1.83, "protocol": "cer"}], "source": "huggingface"}, {"id": "huggingface-vesteinn-xlmr-enis-finetuned-cola", "modules": [{"role": "model", "module": {"name": "XLMR-ENIS-finetuned-cola", "description": "A fine-tuned version of vesteinn/XLMR-ENIS on the glue dataset for text classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "XLMR-ENIS-finetuned-cola is a transformer model fine-tuned on the GLUE dataset for text classification. The model achieved a Matthews Correlation score of 0.6306 on the evaluation set. The model is suitable for text classification tasks, but its intended uses and limitations are not specified in the model card. The model was trained using PyTorch 1.9.0+cu102, Transformers 4.10.3, Datasets 1.12.1, and Tokenizers 0.10.3."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.6306425398187112, "protocol": "matthews_correlation"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-sv-yo", "modules": [{"role": "model", "module": {"name": "opus-mt-sv-yo", "description": "A transformer-align model for translating from Swedish (sv) to Yoruba (yo)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-sv-yo model is a transformer-align model that translates from Swedish to Yoruba. It achieved a BLEU score of 26.4 and a chr-F score of 0.432 on the JW300.sv.yo test set. The model uses normalization and SentencePiece for pre-processing."}}], "metrics": [{"dataset": "jw300", "metric": 26.4, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.432, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-vidyavenkappa-pegasus-samsum", "modules": [{"role": "model", "module": {"name": "pegasus-samsum", "description": "A fine-tuned version of google/pegasus-large on the samsum dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 1, "eval_batch_size": 1, "seed": 42, "gradient_accumulation_steps": 16, "total_train_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 5}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "pegasus-samsum is a fine-tuned version of google/pegasus-large on the samsum dataset. It is a model for text summarization tasks. The model was trained with Adam optimizer with a learning rate of 5e-05 and a linear learning rate scheduler with 500 warmup steps. The model was trained for 5 epochs with a total train batch size of 16. The model achieved a loss of 1.3086 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "samsum-corpus"}], "metrics": [{"dataset": "samsum-corpus", "metric": 1.3086, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-bhadresh-savani-electra-base-emotion", "modules": [{"role": "model", "module": {"name": "Electra-base-emotion", "description": "A transformer model fine-tuned on the Twitter-Sentiment-Analysis dataset for emotion classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "Electra-base", "batch_size": 32, "optimizer": {"name": "AdamW", "learning_rate": 2e-05, "epsilon": 1e-08}, "epochs": 8}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "Electra-base-emotion is a transformer model fine-tuned on the Twitter-Sentiment-Analysis dataset for emotion classification. The model is best suited for classifying emotions in text data. The model uses the Electra-base architecture and was trained with AdamW optimizer with a learning rate of 2e-5 for 8 epochs. The model achieved an accuracy of 0.9195 and an F1 score of 0.918975455617076 on the test set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "twitter-sentiment-analysis-entity-level-twitter-sentiment-analysis-dataset"}], "metrics": [{"dataset": "twitter-sentiment-analysis-entity-level-twitter-sentiment-analysis-dataset", "metric": 0.9195, "protocol": "Accuracy"}, {"dataset": "twitter-sentiment-analysis-entity-level-twitter-sentiment-analysis-dataset", "metric": 0.918975455617076, "protocol": "F1 Score"}], "source": "huggingface"}, {"id": "huggingface-textattack-albert-base-v2-sst-2", "modules": [{"role": "model", "module": {"name": "albert-base-v2", "description": "A transformer model pre-trained on a large English corpus and fine-tuned for sequence classification using TextAttack and the GLUE dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "learning_rate": 3e-05, "max_seq_length": 64, "loss_function": "cross-entropy"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "The albert-base-v2 model was fine-tuned for sequence classification using TextAttack and the GLUE dataset. The model was trained with a cross-entropy loss function and achieved an accuracy of 0.9254587155963303 on the eval set after 2 epochs. The model is suitable for text classification tasks."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.9254587155963303, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-sg-fr", "modules": [{"role": "model", "module": {"name": "opus-mt-sg-fr", "description": "A transformer-align model for translating from sg to fr."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-sg-fr model is a transformer-align model that translates from sg to fr. It achieved a BLEU score of 24.9 and a chr-F score of 0.42 on the JW300.sg.fr test set. The model was preprocessed using normalization and SentencePiece."}}], "metrics": [{"dataset": "jw300", "metric": 24.9, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.42, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-danhsf-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "xlm-roberta-base-finetuned-panx-de is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. The model achieved an F1 score of 0.8591 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 5e-05 and a batch size of 24. The model was trained for 3 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8591, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-elozano-tweet-emotion-eval", "modules": [{"role": "model", "module": {"name": "Sentiment Analysis Model", "description": "A model trained to classify text into different sentiment categories."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_type": "BERT", "max_seq_length": 128, "batch_size": 32, "learning_rate": 2e-05, "num_epochs": 3}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "The sentiment analysis model is trained on the tweet_eval dataset to classify text into different sentiment categories. The model uses BERT as the underlying architecture and achieves an accuracy of 85% on the evaluation dataset. The model can be used to classify text into different sentiment categories such as anger, joy, optimism, and sadness."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "tweeteval"}], "metrics": [{"dataset": "tweeteval", "metric": 0.85, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-reichenbach-wav2vec2-large-xls-r-300m-hi", "modules": [{"role": "model", "module": {"name": "wav2vec2-large-xls-r-300m-hi", "description": "A fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset for Hindi speech recognition."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 7.5e-05, "train_batch_size": 16, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 50, "mixed_precision_training": true}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "The wav2vec2-large-xls-r-300m-hi model is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset for Hindi speech recognition. The model achieved a WER of 0.9420 and a loss of 2.4749 on the evaluation set. The model is intended for automatic speech recognition tasks in Hindi and may have limitations when used for other languages or tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 1.2289, "split": "val", "protocol": "loss"}, {"dataset": "common-voice", "metric": 2.4749, "split": "test", "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.942, "split": "val", "protocol": "WER"}, {"dataset": "common-voice", "metric": 0.942, "split": "test", "protocol": "WER"}], "source": "huggingface"}, {"id": "huggingface-jaybeeja-q-frozenlake-v1-4x4-noslippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained model of a Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-4x4-no_slippery", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model's hyperparameters include the algorithm used, the environment, the maximum number of steps per episode, the number of episodes to evaluate the agent, the Q-Table learned by the agent, and the random seed used for evaluation. The model achieved a mean reward of 1.0 with no standard deviation."}}, {"role": "dataset", "purpose": "Environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-chandrasutrisnotjhong-distilbert-base-uncased-finetuned-imdb", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-imdb", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-imdb is a fine-tuned version of distilbert-base-uncased on the imdb dataset. It can be used for text classification tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 64. The model was trained for 3 epochs and achieved a loss of 2.4721 on the evaluation set. The model was trained using PyTorch 1.11.0+cu113 and Transformers 4.20.0."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 2.4721, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-ganchengguang-roformer-base-japanese", "modules": [{"role": "model", "module": {"name": "RoBERTa", "description": "Pretrained model on Japanese language using the BERT BPE tokenizer."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"tokenizer": "BERT BPE", "size": "125M"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "RoBERTa is a transformer model pretrained on a large corpus of Japanese texts. It uses the BERT BPE tokenizer and is intended to be fine-tuned on downstream tasks. The model is best suited for text classification tasks, such as binary sentiment classification. The model was trained by Yokohama National University Mori Lab and has achieved high accuracy in JGLUE-marc-ja-v1.0 binary sentiment classification."}}, {"role": "dataset", "purpose": "For model training.", "module": "wikitext-2"}, {"role": "dataset", "purpose": "For evaluation.", "module": "jglue"}], "metrics": [{"dataset": "jglue", "metric": 95.12, "protocol": "binary sentiment classification"}], "source": "huggingface"}, {"id": "huggingface-nikuznetsov-roberta-base-finetuned-cola", "modules": [{"role": "model", "module": {"name": "roberta-base-finetuned-cola", "description": "A fine-tuned version of roberta-base on the glue dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of the roberta-base model on the CoLA task of the GLUE benchmark. The model achieved a Matthews Correlation score of 0.5880 on the evaluation set. The model is suitable for text classification tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.5880199146512337, "protocol": "matthews_correlation"}], "source": "huggingface"}, {"id": "huggingface-andychiang-cdgp-csg-bert-cloth", "modules": [{"role": "model", "module": {"name": "CDGP-CSG-BERT-CLOTH", "description": "Candidate Set Generator in CDGP: Automatic Cloze Distractor Generation based on Pre-trained Language Model"}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"pretrained_language_model": "bert-base-uncased", "optimizer": "adam", "learning_rate": 0.0001, "max_input_length": 64, "batch_size": 64, "epochs": 1}}}, {"role": "taskType", "module": "fill-mask"}, {"role": "solutionSummary", "module": {"summary": "CDGP-CSG-BERT-CLOTH is a Candidate Set Generator in CDGP for automatic cloze distractor generation based on pre-trained language model. It is fine-tuned on CLOTH dataset based on bert-base-uncased model. The model generates candidate set of distractors for a given stem and answer. The model is evaluated based on P@1, F1@3, F1@10, MRR, and NDCG@10 metrics. The model is suitable for generating distractors for middle school and high school English exams."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "cloth-cloze-test-by-teachers"}], "metrics": [{"dataset": "cloth-cloze-test-by-teachers", "metric": 18.5, "protocol": "P@1"}, {"dataset": "cloth-cloze-test-by-teachers", "metric": 13.8, "protocol": "F1@3"}, {"dataset": "cloth-cloze-test-by-teachers", "metric": 15.37, "protocol": "F1@10"}, {"dataset": "cloth-cloze-test-by-teachers", "metric": 29.96, "protocol": "MRR"}, {"dataset": "cloth-cloze-test-by-teachers", "metric": 37.82, "protocol": "NDCG@10"}], "source": "huggingface"}, {"id": "huggingface-infinitejoy-wav2vec2-large-xls-r-300m-hindi", "modules": [{"role": "model", "module": {"name": "wav2vec2-large-xls-r-300m-hindi", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-300m on the MOZILLA-FOUNDATION/COMMON_VOICE_7_0 - HI dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 7.5e-05, "train_batch_size": 32, "eval_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 2000, "num_epochs": 100.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the MOZILLA-FOUNDATION/COMMON_VOICE_7_0 - HI dataset. The model is intended for automatic speech recognition tasks. The model achieved a WER of 1.0194 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 7.5e-05, and a linear learning rate scheduler with warmup steps of 2000. The model was trained for 100 epochs with a batch size of 32 and mixed precision training. The model was trained using Transformers 4.16.0.dev0, Pytorch 1.10.1+cu102, Datasets 1.17.1.dev0, and Tokenizers 0.11.0."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.5414, "protocol": "Loss"}, {"dataset": "common-voice", "metric": 1.0194, "protocol": "Wer"}], "source": "huggingface"}, {"id": "huggingface-axhyra-presentation-emotion-42", "modules": [{"role": "model", "module": {"name": "presentation_emotion_42", "description": "A fine-tuned version of distilbert-base-uncased on the tweet_eval dataset for text classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5.18796906442746e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 4}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "presentation_emotion_42 is a fine-tuned version of distilbert-base-uncased on the tweet_eval dataset for text classification. The model achieved an F1 score of 0.7329 on the evaluation set. The model is suitable for text classification tasks, but its performance may vary depending on the specific use case. The model was trained using Adam optimizer with a learning rate of 5.18796906442746e-05 and a batch size of 8 for 4 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "tweeteval"}], "metrics": [{"dataset": "tweeteval", "metric": 0.732897530282475, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-mbmmurad-wav2vec2-base-cvbn-voted-30pochs", "modules": [{"role": "model", "module": {"name": "wav2vec2-base-cvbn-voted_30pochs", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-300m on the cvbn dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 7.5e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 1000, "num_epochs": 30, "mixed_precision_training": true}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "wav2vec2-base-cvbn-voted_30pochs is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the cvbn dataset. It is suitable for automatic speech recognition tasks. The model was trained using Adam optimizer with a learning rate of 7.5e-05 and a batch size of 16. The model was trained for 30 epochs with mixed precision training. The model achieved an evaluation loss of 0.2136 and an evaluation word error rate of 0.3208."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.2136, "protocol": "eval_loss"}, {"dataset": "common-voice", "metric": 0.3208, "protocol": "eval_wer"}, {"dataset": "common-voice", "metric": 335.1421, "protocol": "eval_runtime"}, {"dataset": "common-voice", "metric": 8.951, "protocol": "eval_samples_per_second"}, {"dataset": "common-voice", "metric": 0.561, "protocol": "eval_steps_per_second"}, {"dataset": "common-voice", "metric": 5.82, "protocol": "epoch"}, {"dataset": "common-voice", "metric": 13600.0, "protocol": "step"}], "source": "huggingface"}, {"id": "huggingface-nielsr-van-base-finetuned-eurosat-imgaug", "modules": [{"role": "model", "module": {"name": "van-base-finetuned-eurosat-imgaug", "description": "A fine-tuned version of Visual-Attention-Network/van-base on the image_folder dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 32, "eval_batch_size": 32, "seed": 42, "gradient_accumulation_steps": 4, "total_train_batch_size": 128, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "num_epochs": 3}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "van-base-finetuned-eurosat-imgaug is a fine-tuned version of Visual-Attention-Network/van-base on the image_folder dataset. The model achieved an accuracy of 0.9885 on the evaluation set. The model is suitable for image classification tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "objectfolder"}], "metrics": [{"dataset": "objectfolder", "metric": 0.9885185185185185, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-sacculifer-dimbat-disaster-distilbert", "modules": [{"role": "model", "module": {"name": "Tweets disaster detection model", "description": "A model trained on part of Disaster Tweet Corpus 2020 dataset to detect disaster-related tweets."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"optimizer": {"batch_size": 16, "num_epochs": 5, "init_lr": 2e-05, "num_warmup_steps": 0, "num_train_steps": "calculated based on the dataset size"}, "training_precision": "float32"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "The Tweets disaster detection model is a transformer-based model trained on a subset of Disaster Tweet Corpus 2020 dataset to detect disaster-related tweets. The model achieved high accuracy and low loss on the training and validation sets. The model can be used to classify tweets as disaster-related or not."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "natural-hazards-twitter-dataset"}], "metrics": [{"dataset": "natural-hazards-twitter-dataset", "metric": 0.14, "protocol": "train_loss"}, {"dataset": "natural-hazards-twitter-dataset", "metric": 0.9516, "protocol": "train_accuracy"}, {"dataset": "natural-hazards-twitter-dataset", "metric": 0.1995, "protocol": "validation_loss"}, {"dataset": "natural-hazards-twitter-dataset", "metric": 0.9324, "protocol": "validation_accuracy"}, {"dataset": "natural-hazards-twitter-dataset", "metric": 2.0, "protocol": "epoch"}], "source": "huggingface"}, {"id": "huggingface-summary71-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 game."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "is_slippery": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 game. The model was trained using a Q-Table and evaluated on the mean reward metric. The model can be loaded and used to play the game or further fine-tuned for other reinforcement learning tasks."}}, {"role": "dataset", "purpose": "The game environment used for training and evaluation.", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.56, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-kws-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 game."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "is_slippery": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 game. The model was trained using a custom implementation and evaluated on the same environment. The mean reward achieved by the agent is 7.56 with a standard deviation of 2.71 over multiple evaluation episodes."}}, {"role": "dataset", "purpose": "The game environment used for training and evaluation.", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.56, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-mattchurgin-distilbert-mrpc", "modules": [{"role": "model", "module": {"name": "distilbert-mrpc", "description": "A fine-tuned version of distilbert-base-uncased on the MRPC task of the GLUE benchmark."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-mrpc is a fine-tuned version of distilbert-base-uncased on the MRPC task of the GLUE benchmark. The model is best suited for text classification tasks. The model was trained with Adam optimizer with a learning rate of 5e-05 and a batch size of 8. The model achieved an accuracy of 0.8480 and an F1 score of 0.8935 on the evaluation set."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-arjuntheprogrammer-distilbert-base-multilingual-cased-sentiment-2", "modules": [{"role": "model", "module": {"name": "distilbert-base-multilingual-cased-sentiment-2", "description": "A fine-tuned version of distilbert-base-multilingual-cased on the amazon_reviews_multi dataset for text classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.00024, "train_batch_size": 16, "eval_batch_size": 16, "seed": 33, "distributed_type": "sagemaker_data_parallel", "num_devices": 8, "total_train_batch_size": 128, "total_eval_batch_size": 128, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 3, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-multilingual-cased-sentiment-2 is a fine-tuned version of distilbert-base-multilingual-cased on the amazon_reviews_multi dataset for text classification. The model achieved an accuracy of 0.7614 and an F1 score of 0.7614 on the evaluation set. The model is suitable for text classification tasks in multiple languages."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "amazon-product-data"}], "metrics": [{"dataset": "amazon-product-data", "metric": 0.7614, "protocol": "accuracy"}, {"dataset": "amazon-product-data", "metric": 0.7614, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-dooglak-tagged-uni-50v6-ner-model-3epochs-augmented", "modules": [{"role": "model", "module": {"name": "Tagged_Uni_50v6_NER_Model_3Epochs_AUGMENTED", "description": "A fine-tuned version of bert-base-cased on the tagged_uni50v6_wikigold_split dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of bert-base-cased on the tagged_uni50v6_wikigold_split dataset for token classification. The model achieved an accuracy of 0.7776 on the evaluation set. More information is needed to describe the model and its intended uses and limitations."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wikisplit"}], "metrics": [{"dataset": "wikisplit", "metric": 0.0, "protocol": "Precision"}, {"dataset": "wikisplit", "metric": 0.0, "protocol": "Recall"}, {"dataset": "wikisplit", "metric": 0.0, "protocol": "F1"}, {"dataset": "wikisplit", "metric": 0.7776, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-tr-ar", "modules": [{"role": "model", "module": {"name": "tur-ara", "description": "A transformer model pre-trained on Turkish and fine-tuned for translation to Arabic."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer", "preprocessing": "normalization + SentencePiece (spm32k,spm32k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "tur-ara is a transformer model pre-trained on Turkish and fine-tuned for translation to Arabic. It achieved a BLEU score of 14.9 and a chrF2 score of 0.455 on the Tatoeba-test.tur.ara dataset. The model uses normalization and SentencePiece (spm32k,spm32k) for pre-processing. The model is suitable for translation tasks from Turkish to Arabic."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "tatoeba"}], "metrics": [{"dataset": "tatoeba", "metric": 14.9, "protocol": "BLEU"}, {"dataset": "tatoeba", "metric": 0.455, "protocol": "chrF2"}], "source": "huggingface"}, {"id": "huggingface-fenixobia-distilbert-base-uncased-finetuned-cola", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-cola", "description": "A fine-tuned version of distilbert-base-uncased on the glue dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-cola is a fine-tuned version of distilbert-base-uncased on the glue dataset. It is suitable for text classification tasks. The model achieved a Matthews Correlation score of 0.5596 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 16 for 5 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.5596, "protocol": "matthews_correlation"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-fi-en", "modules": [{"role": "model", "module": {"name": "transformer-align", "description": "A machine translation model trained on Finnish to English language pairs using normalization and SentencePiece (spm32k,spm32k) pre-processing."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece (spm32k,spm32k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "A transformer model trained on Finnish to English language pairs using normalization and SentencePiece (spm32k,spm32k) pre-processing. The model achieved a BLEU score of 53.4 and a chrF2 score of 0.697 on the test sets. The model is suitable for translating Finnish to English language pairs."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-amrahmed-q-frozenlake-v1-8x8-non-slippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-8x8-no_slippery", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent playing FrozenLake-v1. The model includes the Q-Table learned by the agent and can be used to evaluate the agent's performance on the environment. The agent achieves a mean reward of 1.0 with no standard deviation."}}, {"role": "dataset", "purpose": "Environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-hezzze-q-frozenlake-v1-4x4-noslippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained model of a Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-4x4-no_slippery"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model was trained using the Q-Learning algorithm and evaluated on the FrozenLake-v1-4x4-no_slippery environment. The model achieved a mean reward of 1.00 +/- 0.00, but the verification status is unknown."}}, {"role": "dataset", "purpose": "The environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "extra": "1.00 +/- 0.00", "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-patrickvonplaten-roberta2roberta-share-cnn-dailymail-fp16", "modules": [{"role": "model", "module": {"name": "Shared Roberta2Roberta Summarization with \ud83e\udd17 EncoderDecoder Framework", "description": "A shared Roberta2Roberta model, fine-tuned on summarization using the \ud83e\udd17 EncoderDecoder Framework."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"encoder": "roberta-base", "decoder": "roberta-base", "tie_encoder_decoder": true, "max_length": 142, "min_length": 56, "no_repeat_ngram_size": 3, "early_stopping": true, "length_penalty": 2.0, "num_beams": 4, "batch_size": 16, "optimizer": {"name": "Adam", "learning_rate": 5e-05, "epsilon": 1e-08}, "fp16": true}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "This is a shared Roberta2Roberta model fine-tuned on summarization using the \ud83e\udd17 EncoderDecoder Framework. The model is intended for summarization tasks and is not state-of-the-art, but it produces reasonable results. The model was fine-tuned on the CNN/Daily Mail dataset and achieved a Rouge-2 F1 score of 16.59. The model is an EncoderDecoderModel with both the encoder and decoder being roberta-base RoBERTa models, and the encoder and decoder weights are tied. The model was trained with Adam optimizer with a learning rate of 5e-5 and epsilon of 1e-8. The model is suitable for tasks that require summarization of long texts."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-mrahusain-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 game."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 game. The model includes the Q-Table learned by the agent and can be used to evaluate the agent's performance. The mean reward achieved by the agent is 7.50 +/- 2.72."}}, {"role": "dataset", "purpose": "The game environment used for training and evaluation.", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.5, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-mariolinml-roberta-large-ner-conll2003-0818-v0", "modules": [{"role": "model", "module": {"name": "roberta_large-ner-conll2003_0818_v0", "description": "A fine-tuned version of roberta-large on the conll2003 dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of roberta-large on the conll2003 dataset for token classification. It achieves high precision, recall, F1 score, and accuracy on the evaluation set. The model is suitable for named entity recognition tasks on English text. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 0.9064488392089424, "protocol": "precision"}, {"dataset": "conll-2003", "metric": 0.9332507082152974, "protocol": "recall"}, {"dataset": "conll-2003", "metric": 0.9196545406961529, "protocol": "f1"}, {"dataset": "conll-2003", "metric": 0.9795810129939008, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-aitor-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 environment."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 environment. The model includes the Q-Table learned by the agent, as well as hyperparameters such as the maximum number of steps per episode and the number of episodes used to evaluate the agent. The mean reward achieved by the agent is 7.50 with a standard deviation of 2.76."}}, {"role": "dataset", "purpose": "OpenAI Gym environment", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.5, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-anton-l-wav2vec2-large-xlsr-53-lithuanian", "modules": [{"role": "model", "module": {"name": "Wav2Vec2-Large-XLSR-53-Lithuanian", "description": "Fine-tuned Wav2Vec2-Large-XLSR-53 on Lithuanian using the Common Voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "Wav2Vec2-Large-XLSR-53", "batch_size": 16, "optimizer": {"name": "Adam", "learning_rate": 0.0003, "beta1": 0.9, "beta2": 0.98, "weight_decay": 0.005}}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Wav2Vec2-Large-XLSR-53-Lithuanian is a speech recognition model fine-tuned on the Common Voice dataset for Lithuanian. The model is intended to be used directly (without a language model) and is best suited for speech recognition tasks. The model was trained on the Common Voice train and validation datasets and evaluated on the Common Voice test dataset. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 49.0, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-dooglak-article-50v6-ner-model-3epochs-augmented", "modules": [{"role": "model", "module": {"name": "Article_50v6_NER_Model_3Epochs_AUGMENTED", "description": "A fine-tuned version of bert-base-cased on the article50v6_wikigold_split dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "Article_50v6_NER_Model_3Epochs_AUGMENTED is a fine-tuned version of bert-base-cased on the article50v6_wikigold_split dataset for token classification. The model achieved a precision of 0.0939, recall of 0.0192, F1 score of 0.0318, and accuracy of 0.7867 on the evaluation set. More information is needed to describe the model and its intended uses and limitations."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wikisplit"}], "metrics": [{"dataset": "wikisplit", "metric": 0.0939, "protocol": "Precision"}, {"dataset": "wikisplit", "metric": 0.0192, "protocol": "Recall"}, {"dataset": "wikisplit", "metric": 0.0318, "protocol": "F1"}, {"dataset": "wikisplit", "metric": 0.7867, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-patrickvonplaten-wav2vec2-common-voice-tr-demo-dist", "modules": [{"role": "model", "module": {"name": "wav2vec2-common_voice-tr-demo-dist", "description": "Fine-tuned version of facebook/wav2vec2-large-xlsr-53 on the COMMON_VOICE - TR dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0003, "train_batch_size": 4, "num_gpus": 8, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 1, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 15.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/wav2vec2-large-xlsr-53 on the COMMON_VOICE - TR dataset. The model is intended for automatic speech recognition tasks. The model was trained using Adam optimizer with a learning rate of 0.0003, and a linear learning rate scheduler with warmup steps of 500. The model was trained for 15 epochs with a batch size of 32. The model achieved a loss of 0.3856, WER of 0.3581, and CER of 0.0805 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.3856, "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.3581, "protocol": "WER"}, {"dataset": "common-voice", "metric": 0.0805, "protocol": "CER"}], "source": "huggingface"}, {"id": "huggingface-arampacha-wav2vec2-xls-r-300m-hy-cv", "modules": [{"role": "model", "module": {"name": "Fine-tuned facebook/wav2vec2-xls-r-300m on MOZILLA-FOUNDATION/COMMON_VOICE_8_0 - HY-AM dataset", "description": "This model is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the MOZILLA-FOUNDATION/COMMON_VOICE_8_0 - HY-AM dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0001, "train_batch_size": 64, "eval_batch_size": 64, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 128, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "training_steps": 1200, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the MOZILLA-FOUNDATION/COMMON_VOICE_8_0 - HY-AM dataset. The model is intended for automatic speech recognition tasks. The model was trained using Adam optimizer with a learning rate of 0.0001, and a linear learning rate scheduler with a warmup ratio of 0.1. The model was trained for 1200 steps with a batch size of 128. The model achieved a loss of 0.5891 and a WER of 0.6569 on the evaluation set. The model was trained using Transformers 4.17.0.dev0, Pytorch 1.10.2+cu102, Datasets 1.18.2.dev0, and Tokenizers 0.11.0."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.5891, "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.6569, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-hankzhong-electra-small-discriminator-finetuned-squad", "modules": [{"role": "model", "module": {"name": "electra-small-discriminator-finetuned-squad", "description": "A fine-tuned version of google/electra-small-discriminator on the squad dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 32, "eval_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "electra-small-discriminator-finetuned-squad is a fine-tuned version of google/electra-small-discriminator on the squad dataset. It is suitable for question answering tasks. The model was trained with Adam optimizer with a learning rate of 2e-05, betas=(0.9,0.999), and epsilon=1e-08. The model was trained for 3 epochs with a linear learning rate scheduler. The model achieved a loss of 1.2174 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 1.2174, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-zeeshan-sardar-dqn-spaceinvadersnoframeskip-v", "modules": [{"role": "model", "module": {"name": "DQN", "description": "A reinforcement learning agent trained on SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "buffer_size": 100000, "exploration_final_eps": 0.01, "exploration_fraction": 0.1, "frame_stack": 4, "gradient_steps": 1, "learning_rate": 0.0001, "learning_starts": 50000, "n_timesteps": 1000000.0, "optimize_memory_usage": false, "policy": "CnnPolicy", "target_update_interval": 1000, "train_freq": 4, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a DQN agent trained on SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library. The model was trained using the RL Zoo framework, which includes hyperparameter optimization and pre-trained agents. The model achieved a mean reward of 646.00 +/- 256.01 on the evaluation dataset. The model can be used for reinforcement learning tasks, but caution should be taken when deploying it in real-world systems due to the potential for biases and limitations in the training data and environment."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 646.0, "split": "val", "protocol": "mean_reward"}, {"dataset": "atari-grand-challenge", "metric": 256.01, "split": "test", "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-skr1125-xlm-roberta-base-finetuned-panx-en", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-en", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "xlm-roberta-base-finetuned-panx-en is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification. The model achieved an F1 score of 0.7032 on the evaluation set. The model is suitable for token classification tasks, but its intended uses and limitations are not specified in the model card."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.7032474804031354, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-athar-distilbert-base-uncased-finetuned-cola", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-cola", "description": "A fine-tuned version of distilbert-base-uncased on the glue dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-cola is a fine-tuned version of distilbert-base-uncased on the glue dataset. It is suitable for text classification tasks. The model achieved a Matthews Correlation score of 0.5452 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler. The model was trained for 5 epochs with a batch size of 16."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.5451837431775948, "protocol": "matthews_correlation"}], "source": "huggingface"}, {"id": "huggingface-patrickvonplaten-wav2vec2-base-timit-demo", "modules": [{"role": "model", "module": {"name": "Wav2Vec2 Fine-Tuned on English dataset Timit", "description": "A Wav2Vec2 model fine-tuned on the English dataset Timit for speech recognition."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0003, "batch_size": 32, "num_epochs": 30}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a Wav2Vec2 model fine-tuned on the Timit dataset for speech recognition. The model was fine-tuned for 30 epochs with a batch size of 32 and a learning rate of 3e-4. The model achieved a word error rate of 0.06 on the Timit dataset. The model can be used for speech recognition tasks in English, but caution should be taken when deploying it in systems that interact with humans."}}, {"role": "dataset", "purpose": "For fine-tuning the model.", "module": "timit-timit-acoustic-phonetic-continuous-speech-corpus"}], "metrics": [{"dataset": "timit-timit-acoustic-phonetic-continuous-speech-corpus", "metric": 0.06, "protocol": "word_error_rate"}], "source": "huggingface"}, {"id": "huggingface-tehrannlp-org-bert-large-hatexplain", "modules": [{"role": "model", "module": {"name": "SEED0042", "description": "Fine-tuned version of bert-large-uncased on the HATEXPLAIN dataset for text classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 1, "eval_batch_size": 1, "seed": 42, "distributed_type": "not_parallel", "gradient_accumulation_steps": 32, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 150, "num_epochs": 3}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "SEED0042 is a fine-tuned version of bert-large-uncased on the HATEXPLAIN dataset for text classification. The model achieved an accuracy of 0.4079 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 5e-05 and linear learning rate scheduler. The model was trained for 3 epochs with a batch size of 32. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "hatexplain"}], "metrics": [{"dataset": "hatexplain", "metric": 0.40790842872008326, "protocol": "Accuracy"}, {"dataset": "hatexplain", "metric": 0.8027, "protocol": "Accuracy 0"}, {"dataset": "hatexplain", "metric": 0.1869, "protocol": "Accuracy 1"}, {"dataset": "hatexplain", "metric": 0.2956, "protocol": "Accuracy 2"}], "source": "huggingface"}, {"id": "huggingface-lucio-xls-r-uzbek-cv8", "modules": [{"role": "model", "module": {"name": "XLS-R-300M Uzbek CV8", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-300m on the MOZILLA-FOUNDATION/COMMON_VOICE_8_0 - UZ dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 3e-05, "train_batch_size": 32, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 4, "total_train_batch_size": 128, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 100.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "XLS-R-300M Uzbek CV8 is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the MOZILLA-FOUNDATION/COMMON_VOICE_8_0 - UZ dataset. The model is intended for low-fidelity use cases such as draft video captions and indexing of recorded broadcasts. It is not reliable enough to use as a substitute for live captions for accessibility purposes, and it should not be used in a manner that would infringe the privacy of any of the contributors to the Common Voice dataset nor any other speakers. The model was trained with Adam optimizer, linear learning rate scheduler, and Native AMP mixed precision training for 100 epochs. The model achieved a Test WER (with LM) of 15.065 and a Test CER (with LM) of 3.077."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 15.065, "split": "val", "protocol": "wer"}, {"dataset": "common-voice", "metric": 32.88, "split": "test", "protocol": "wer"}, {"dataset": "common-voice", "metric": 3.077, "split": "val", "protocol": "cer"}, {"dataset": "common-voice", "metric": 6.53, "split": "test", "protocol": "cer"}], "source": "huggingface"}, {"id": "huggingface-superb-wav2vec2-large-superb-er", "modules": [{"role": "model", "module": {"name": "Wav2Vec2-Large for Emotion Recognition", "description": "A ported version of S3PRL's Wav2Vec2 for the SUPERB Emotion Recognition task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "wav2vec2-large-lv60", "preprocessing": {"sampling_rate": "16kHz"}}}}, {"role": "taskType", "module": "audio-classification"}, {"role": "solutionSummary", "module": {"summary": "Wav2Vec2-Large for Emotion Recognition is a ported version of S3PRL's Wav2Vec2 for the SUPERB Emotion Recognition task. The model is trained on IEMOCAP dataset and predicts an emotion class for each utterance. The model is best used via the Audio Classification pipeline or directly. The evaluation metric is accuracy."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "iemocap-the-interactive-emotional-dyadic-motion-capture-iemocap-database"}], "metrics": [{"dataset": "iemocap-the-interactive-emotional-dyadic-motion-capture-iemocap-database", "metric": 0.6564, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-fi-pap", "modules": [{"role": "model", "module": {"name": "opus-mt-fi-pap", "description": "A machine translation model that translates from Finnish (fi) to Papiamento (pap) using the transformer-align architecture."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-fi-pap is a machine translation model that translates from Finnish to Papiamento using the transformer-align architecture. The model achieved a BLEU score of 27.3 and a chr-F score of 0.478 on the JW300.fi.pap test set."}}], "metrics": [{"dataset": "jw300", "metric": 27.3, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.478, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-mvonwyl-distilbert-base-uncased-finetuned-squad2", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-squad2", "description": "A fine-tuned version of distilbert-base-uncased on the squad_v2 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-squad2 is a fine-tuned version of distilbert-base-uncased on the squad_v2 dataset. It is suitable for question answering tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for 3 epochs and achieved a loss of 1.4218 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 1.4218, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-hackathon-pln-es-detect-acoso-twitter-es", "modules": [{"role": "model", "module": {"name": "Detecci\u00f3n de acoso en Twitter Espa\u00f1ol", "description": "A fine-tuned version of mrm8488/distilroberta-finetuned-tweets-hate-speech on an unknown dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of mrm8488/distilroberta-finetuned-tweets-hate-speech on an unknown dataset. It can be used for detecting cyberbullying and hate speech in Spanish tweets. The model achieved an accuracy of 0.9167 on the evaluation set. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "twitter-abusive-behavior"}], "metrics": [{"dataset": "twitter-abusive-behavior", "metric": 0.9167, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-infinitejoy-wav2vec2-large-xls-r-300m-tatar", "modules": [{"role": "model", "module": {"name": "wav2vec2-large-xls-r-300m-tatar", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-300m on the MOZILLA-FOUNDATION/COMMON_VOICE_7_0 - TT dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 7e-05, "train_batch_size": 32, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 4000, "num_epochs": 50.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the MOZILLA-FOUNDATION/COMMON_VOICE_7_0 - TT dataset. The model is intended for automatic speech recognition tasks. The model achieved a WER of 24.392 and a CER of 5.024 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 7e-05, linear learning rate scheduler, and mixed precision training. The model was trained for 50 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 24.392, "protocol": "WER"}, {"dataset": "common-voice", "metric": 5.024, "protocol": "CER"}], "source": "huggingface"}, {"id": "huggingface-martin97bozic-xlm-roberta-base-finetuned-squad", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-squad", "description": "A fine-tuned version of xlm-roberta-base on an unknown dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 24, "eval_batch_size": 24, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "xlm-roberta-base-finetuned-squad is a fine-tuned version of xlm-roberta-base on an unknown dataset. The model is best suited for question-answering tasks. The training hyperparameters include a learning rate of 2e-05, a train batch size of 24, and a total of 3 epochs. The model achieved a loss of 2.1433 on the SQuAD evaluation set."}}, {"role": "dataset", "purpose": "For evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 2.1433, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-prashanth-indicbart-ibart-hi-to-en", "modules": [{"role": "model", "module": {"name": "IndicBART-ibart-hi-to-en", "description": "A fine-tuned version of ai4bharat/IndicBART on the hindi_english_machine_translation dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 32, "eval_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "IndicBART-ibart-hi-to-en is a fine-tuned version of ai4bharat/IndicBART on the hindi_english_machine_translation dataset. The model is intended for Hindi to English machine translation. The model was trained for one epoch with a batch size of 32 and achieved a BLEU score of 1.0626. The model uses the Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler. The model was trained using the Transformers library version 4.19.1 and PyTorch version 1.11.0+cu102."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "hindencorp"}], "metrics": [{"dataset": "hindencorp", "metric": 1.0626, "protocol": "Bleu"}], "source": "huggingface"}, {"id": "huggingface-emre-wav2vec2-xls-r-300m-tr-med-commonvoice8-tr-med-commonvoice8", "modules": [{"role": "model", "module": {"name": "wav2vec2-xls-r-300m-Tr-med-CommonVoice8-Tr-med-CommonVoice8", "description": "A fine-tuned version of emre/wav2vec2-xls-r-300m-Tr-med-CommonVoice8 on the common_voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0001, "train_batch_size": 16, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 300, "num_epochs": 5, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of emre/wav2vec2-xls-r-300m-Tr-med-CommonVoice8 on the common_voice dataset. The model is intended for automatic speech recognition tasks. The model was trained using Adam optimizer with a learning rate of 0.0001 and a linear learning rate scheduler with 300 warmup steps. The model achieved a WER of 0.5010 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.5815, "split": "val", "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.2708, "split": "test", "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.501, "protocol": "WER"}], "source": "huggingface"}, {"id": "huggingface-merve-adulto08f-j-q-age-classification", "modules": [{"role": "model", "module": {"name": "Baseline Model trained on adulto08f_j_q to apply classification on age", "description": "A baseline model trained on adulto08f_j_q dataset using logistic regression."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "LogisticRegression", "C": 0.1, "class_weight": "balanced", "max_iter": 1000}}}, {"role": "taskType", "module": "tabular-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a baseline model trained on adulto08f_j_q dataset using logistic regression. The model achieved low accuracy, recall, precision, and f1 scores. The logs of training, including the models tried in the process, can be found in logs.txt. For better results, it is recommended to use AutoTrain."}}, {"role": "dataset", "purpose": "For model training.", "module": "adult-data-set"}], "metrics": [{"dataset": "adult-data-set", "metric": 0.053776, "protocol": "accuracy"}, {"dataset": "adult-data-set", "metric": 0.058874, "protocol": "recall_macro"}, {"dataset": "adult-data-set", "metric": 0.03801, "protocol": "precision_macro"}, {"dataset": "adult-data-set", "metric": 0.036333, "protocol": "f1_macro"}], "source": "huggingface"}, {"id": "huggingface-ontocord-mt5-fix-asr-vietnamese", "modules": [{"role": "model", "module": {"name": "Ontocord/mt5-fix-asr-vietnamese", "description": "Fine-tuned mt5 to correct output of an ASR model trained on facebook/wav2vec2-large-xlsr-53 which was trained on Vietnamese using the Common Voice, and FOSD."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 8, "learning_rate": 0.0001, "max_length": 100}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Ontocord/mt5-fix-asr-vietnamese is a fine-tuned mt5 model that corrects the output of an ASR model trained on facebook/wav2vec2-large-xlsr-53 which was trained on Vietnamese using the Common Voice and FOSD datasets. The model can be used directly by submitting Vietnamese ASR text, but it is best to use it with the ontocord/wav2vec2-large-xlsr-vietnamese model. The model is suitable for automatic speech recognition tasks, and the test result shows a WER of 25.207182 on the Common Voice Vietnamese test dataset."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 25.207182, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-djagatiya-ner-distilbert-base-uncased-ontonotesv5-englishv4", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased", "description": "A pre-trained transformer model for natural language processing tasks."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"dataset": "conll2012_ontonotesv5-english-v4"}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "The distilbert-base-uncased model is a pre-trained transformer model for natural language processing tasks. This particular model was fine-tuned on the conll2012_ontonotesv5-english-v4 dataset for named entity recognition (NER) tasks. The model achieved an F1-score of 85.53 on the evaluation set, with the highest scores for GPE, PERSON, and ORG entities. The model can be used for NER tasks in English text, but it reflects the biases inherent to the systems it was trained on, so caution should be taken when deploying it into systems that interact with humans."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "conll-2012"}], "metrics": [{"dataset": "conll-2012", "metric": 84.6, "protocol": "Precision"}, {"dataset": "conll-2012", "metric": 86.47, "protocol": "Recall"}, {"dataset": "conll-2012", "metric": 85.53, "protocol": "F1-Score"}], "source": "huggingface"}, {"id": "huggingface-joitandr-dqn-spaceinvadersnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "DQN Agent playing SpaceInvadersNoFrameskip-v4", "description": "A trained DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "buffer_size": 100000, "exploration_final_eps": 0.01, "exploration_fraction": 0.1, "frame_stack": 4, "gradient_steps": 1, "learning_rate": 0.0001, "learning_starts": 100000, "n_timesteps": 1000000.0, "optimize_memory_usage": true, "policy": "CnnPolicy", "target_update_interval": 1000, "train_freq": 4, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The model was trained with a batch size of 32, a buffer size of 100000, and a learning rate of 0.0001. The mean reward achieved by the model on the SpaceInvadersNoFrameskip-v4 dataset is 597.50 with a standard deviation of 100.68. The model is suitable for reinforcement learning tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 597.5, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-anirudh21-xlnet-base-cased-finetuned-rte", "modules": [{"role": "model", "module": {"name": "xlnet-base-cased-finetuned-rte", "description": "A fine-tuned version of xlnet-base-cased on the glue dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "xlnet-base-cased-finetuned-rte is a fine-tuned version of xlnet-base-cased on the glue dataset. It is a transformer model that can be used for text classification tasks. The model achieved an accuracy of 0.6895 on the RTE dataset of the GLUE benchmark. The model was trained with Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler for 5 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.6895306859205776, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-alireza1044-albert-base-v2-qqp", "modules": [{"role": "model", "module": {"name": "qqp", "description": "Fine-tuned version of albert-base-v2 on the GLUE QQP dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 64, "eval_batch_size": 8, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 4.0}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "qqp is a fine-tuned version of albert-base-v2 on the GLUE QQP dataset. It is a text classification model that can be used to determine if two questions are semantically equivalent. The model achieved an accuracy of 0.9050 and an F1 score of 0.8723 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 5e-05 and a batch size of 64 for 4 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "quora-question-pairs"}], "metrics": [{"dataset": "quora-question-pairs", "metric": 0.905, "protocol": "accuracy"}, {"dataset": "quora-question-pairs", "metric": 0.8723, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-dbusai-q-frozenlake-v1-8x8-slippery-v3", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained model of a Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-8x8", "slippery": true}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model achieved a mean reward of 0.93 +/- 0.25. The model can be loaded and evaluated using the provided code snippet."}}, {"role": "dataset", "purpose": "The environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 0.93, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-sem-en", "modules": [{"role": "model", "module": {"name": "sem-eng", "description": "A transformer model pre-trained on a large corpus of Semitic languages and English data for translation."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece (spm32k,spm32k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "A transformer model pre-trained on a large corpus of Semitic languages and English data for translation. The model was pre-processed using normalization and SentencePiece. The model achieved a BLEU score of 41.7 and a chrF2 score of 0.588 on the Tatoeba test set. The model is suitable for translating Semitic languages to English."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-rcanand-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 game."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "is_slippery": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 game. The model was trained using a custom implementation and evaluated on the same environment. The mean reward achieved by the agent is 7.56 with a standard deviation of 2.71 over multiple evaluation episodes."}}, {"role": "dataset", "purpose": "The game environment used for training and evaluation.", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.56, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-husnu-xtremedistil-l6-h256-uncased-tquad-finetuned-lr-2e-05-epochs-6", "modules": [{"role": "model", "module": {"name": "xtremedistil-l6-h256-uncased-TQUAD-finetuned", "description": "Fine-tuned version of microsoft/xtremedistil-l6-h256-uncased on the Turkish squad dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 48, "eval_batch_size": 48, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 6}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "xtremedistil-l6-h256-uncased-TQUAD-finetuned is a fine-tuned version of microsoft/xtremedistil-l6-h256-uncased on the Turkish squad dataset. It is suitable for question-answering tasks in Turkish. The model was trained with Adam optimizer with a learning rate of 2e-05 and linear learning rate decay. The model was trained for 6 epochs with a batch size of 48. The model achieved a loss of 2.8135 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 2.8135, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-saghar-tinybert-general-6l-768d-finetuned-wikitext103", "modules": [{"role": "model", "module": {"name": "TinyBERT_General_6L_768D-finetuned-wikitext103", "description": "A fine-tuned version of huawei-noah/TinyBERT_General_6L_768D on the wikitext dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 32, "eval_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0}}}, {"role": "taskType", "module": "text-generation"}, {"role": "solutionSummary", "module": {"summary": "TinyBERT_General_6L_768D-finetuned-wikitext103 is a fine-tuned version of huawei-noah/TinyBERT_General_6L_768D on the wikitext dataset. The model is suitable for text generation tasks. The training was done for 3 epochs with a learning rate of 2e-05 and a batch size of 32. The model achieved a loss of 3.3768 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "wikitext-2"}], "metrics": [{"dataset": "wikitext-2", "metric": 3.3768, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-omar47-wav2vec2-large-xls-r-300m-urdu-colab-cv8", "modules": [{"role": "model", "module": {"name": "wav2vec2-large-xls-r-300m-urdu-colab-cv8", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset for Urdu language."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0003, "train_batch_size": 16, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 40, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset for Urdu language. The model is suitable for automatic speech recognition tasks. The model was trained with Adam optimizer with a learning rate of 0.0003, and a linear learning rate scheduler with warmup steps of 500. The model was trained for 40 epochs with mixed precision training. The model achieved a loss of 1.4651 and a WER of 0.7 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 1.4651, "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.7, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-rashedsafa-wav2vec2-large-xls-r-300m-bengali-v7", "modules": [{"role": "model", "module": {"name": "wav2vec2-large-xls-r-300m-bengali-v7", "description": "A fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 4e-05, "train_batch_size": 16, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 10, "mixed_precision_training": true}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "A fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset. The model is intended for automatic speech recognition tasks. The model was trained using PyTorch 1.11.0 and Transformers 4.18.0. The model was trained for 10 epochs with a learning rate of 4e-05 and an Adam optimizer with betas=(0.9,0.999) and epsilon=1e-08. The model was trained using mixed precision training."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 3.2999, "protocol": "loss"}, {"dataset": "common-voice", "metric": 1.0, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-mujeensung-roberta-base-mnli-bc", "modules": [{"role": "model", "module": {"name": "roberta-base_mnli_bc", "description": "A fine-tuned version of roberta-base on the GLUE MNLI dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of roberta-base on the GLUE MNLI dataset. The model is best suited for text classification tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model achieved an accuracy of 0.9584 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "multinli-multi-genre-natural-language-inference"}], "metrics": [{"dataset": "multinli-multi-genre-natural-language-inference", "metric": 0.9584, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-nateraw-timm-resnet18-imagenette-160px-5-epochs", "modules": [{"role": "model", "module": {"name": "timm-resnet18-imagenette-160px-5-epochs", "description": "A ResNet18 model trained on the Imagenette dataset with a resolution of 160x160 pixels for 5 epochs using the timm library."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"architecture": "ResNet18", "image_resolution": "160x160", "epochs": 5}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "timm-resnet18-imagenette-160px-5-epochs is a ResNet18 model trained on the Imagenette dataset with a resolution of 160x160 pixels for 5 epochs using the timm library. The model is best suited for image classification tasks. It achieved an accuracy of 0.93 on the Imagenette dataset."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-anirudh21-distilbert-base-uncased-finetuned-rte", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-rte", "description": "A fine-tuned version of distilbert-base-uncased on the glue dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-rte is a fine-tuned version of distilbert-base-uncased on the glue dataset. It is suitable for text classification tasks. The model achieved an accuracy of 0.6173 on the RTE dataset of the GLUE benchmark. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler. The model was trained for 5 epochs with a batch size of 16."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.6173285198555957, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-sb3-a2c-humanoid-v3", "modules": [{"role": "model", "module": {"name": "A2C", "description": "A reinforcement learning agent trained on the Humanoid-v3 environment using the stable-baselines3 library."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"n_timesteps": 2000000, "normalize": true, "policy": "MlpPolicy", "normalize_kwargs": {"norm_obs": true, "norm_reward": false}}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "The A2C model is a reinforcement learning agent trained on the Humanoid-v3 environment using the stable-baselines3 library. The model achieved a mean reward of 380.12 +/- 81.26 on the Humanoid-v3 dataset. The model's hyperparameters include n_timesteps, normalize, policy, and normalize_kwargs. The model can be used for tasks that require reinforcement learning, such as game playing or robotics control."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "mujoco"}], "metrics": [{"dataset": "mujoco", "metric": 380.12, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-felizang-q-frozenlake-v1-4x4-noslippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained model of a Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-4x4-no_slippery"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model achieved a mean reward of 1.00 +/- 0.00. The model can be loaded and evaluated using the provided code snippet."}}, {"role": "dataset", "purpose": "The environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-facebook-detr-resnet-50-dc5", "modules": [{"role": "model", "module": {"name": "DETR (End-to-End Object Detection) model with ResNet-50 backbone (dilated C5 stage)", "description": "DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 object detection (118k annotated images)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"backbone": "ResNet-50", "object_queries": 100, "loss_function": "bipartite matching loss", "optimizer": "AdamW", "learning_rate": 0.0001, "batch_size": 64, "epochs": 300}}}, {"role": "taskType", "module": "object-detection"}, {"role": "solutionSummary", "module": {"summary": "DETR is an encoder-decoder transformer with a convolutional backbone used for object detection. The model uses object queries to detect objects in an image. The model is trained using a bipartite matching loss and achieves an AP of 43.3 on COCO 2017 validation. The model is intended to be fine-tuned for downstream tasks and is suitable for object detection tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "coco-microsoft-common-objects-in-context"}], "metrics": [{"dataset": "coco-microsoft-common-objects-in-context", "metric": 43.3, "protocol": "AP"}], "source": "huggingface"}, {"id": "huggingface-weili-vit-base-patch16-224-finetuned-cifar10", "modules": [{"role": "model", "module": {"name": "vit-base-patch16-224-finetuned-cifar10", "description": "A fine-tuned version of google/vit-base-patch16-224 on the cifar10 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 32, "eval_batch_size": 32, "seed": 42, "gradient_accumulation_steps": 4, "total_train_batch_size": 128, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "num_epochs": 3}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of google/vit-base-patch16-224 on the cifar10 dataset. The model achieved an accuracy of 0.9876 on the evaluation set. The model is suitable for image classification tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "cifar-10"}], "metrics": [{"dataset": "cifar-10", "metric": 0.9876, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-consciousai-question-answering-roberta-base-s-v2", "modules": [{"role": "model", "module": {"name": "Question Answering (RoBERTa-base)", "description": "Encoder-only model fine-tuned on SQUADx dataset for Q&A task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_checkpoint": "consciousAI/question-answering-roberta-base-s-v2", "max_context_length": 384, "stride": 128, "n_best": 20, "max_answer_length": 30, "learning_rate": 2e-05, "train_batch_size": 32, "eval_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "The RoBERTa-base model is fine-tuned on the SQUADx dataset for the Q&A task. The model is encoder-only and uses a QuestionAnswering LM Head. The model is suitable for inferring the answer text, answer span, and confidence score given the question and context. The model achieved an exact match score of 84.83 and an F1 score of 91.80 on the SQUADx dataset. The model is trained using Adam optimizer with a learning rate of 2e-5 and a batch size of 32. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 84.83, "protocol": "exact_match"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 91.8, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-dooglak-tagged-one-500v4-ner-model-3epochs-augmented", "modules": [{"role": "model", "module": {"name": "Tagged_One_500v4_NER_Model_3Epochs_AUGMENTED", "description": "A fine-tuned version of bert-base-cased on the tagged_one500v4_wikigold_split dataset for named entity recognition (NER)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "Tagged_One_500v4_NER_Model_3Epochs_AUGMENTED is a fine-tuned version of bert-base-cased on the tagged_one500v4_wikigold_split dataset for named entity recognition (NER). The model achieved a precision of 0.6656, recall of 0.6225, F1 score of 0.6433, and accuracy of 0.9187 on the evaluation set. The model was trained for 3 epochs with a linear learning rate scheduler and Adam optimizer with betas=(0.9,0.999) and epsilon=1e-08."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wikisplit"}], "metrics": [{"dataset": "wikisplit", "metric": 0.6656017039403621, "protocol": "Precision"}, {"dataset": "wikisplit", "metric": 0.6225099601593626, "protocol": "Recall"}, {"dataset": "wikisplit", "metric": 0.6433350488934636, "protocol": "F1"}, {"dataset": "wikisplit", "metric": 0.9187013683928092, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-sb3-ppo-cartpole-v1", "modules": [{"role": "model", "module": {"name": "PPO Agent playing CartPole-v1", "description": "A trained PPO agent playing CartPole-v1 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 256, "clip_range": "lin_0.2", "ent_coef": 0.0, "gae_lambda": 0.8, "gamma": 0.98, "learning_rate": "lin_0.001", "n_envs": 8, "n_epochs": 20, "n_steps": 32, "n_timesteps": 100000.0, "policy": "MlpPolicy", "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained PPO agent playing CartPole-v1 using the stable-baselines3 library and the RL Zoo. The model was trained with hyperparameters such as batch size, clip range, and learning rate. The mean reward achieved by the model is 500.00 +/- 0.00 on the CartPole-v1 dataset. The model can be used for reinforcement learning tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 500.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-shikhar1997-q-taxi-v3-ver1", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3-ver1", "description": "A Q-Learning agent trained to play the Taxi-v3 environment."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 environment. The agent's Q-Table is provided, along with hyperparameters such as the maximum number of steps per episode and the number of episodes used to evaluate the agent. The model's performance is evaluated based on the mean reward achieved over multiple episodes."}}, {"role": "dataset", "purpose": "OpenAI Gym environment", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.56, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-flair-pos-english-fast", "modules": [{"role": "model", "module": {"name": "Flair English Part-of-Speech Tagging (fast model)", "description": "A fast part-of-speech tagging model for English that uses Flair embeddings and LSTM-CRF."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"hidden_size": 256, "embeddings": ["FlairEmbeddings('news-forward')", "FlairEmbeddings('news-backward')"]}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fast part-of-speech tagging model for English that uses Flair embeddings and LSTM-CRF. It predicts fine-grained POS tags and achieves an F1-Score of 98.10 on the Ontonotes dataset. The model is intended to be fine-tuned on downstream tasks that require POS tagging. The Flair issue tracker is available for any issues that may arise."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "ontonotes-5-0"}], "metrics": [{"dataset": "ontonotes-5-0", "metric": 98.1, "protocol": "F1-Score"}], "source": "huggingface"}, {"id": "huggingface-takizawa-xlm-roberta-base-finetuned-panx-it", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-it", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8124 on the evaluation set. The model is suitable for token classification tasks in Italian language. The training was done using Adam optimizer with a learning rate of 5e-05 and a batch size of 24. The model was trained for 3 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8124, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-phtran-stt-en-conformer-ctc-small", "modules": [{"role": "model", "module": {"name": "phtran/stt_en_conformer_ctc_small", "description": "A small Conformer-based model for English speech-to-text transcription."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"training_regime": "fp32"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a small Conformer-based model for English speech-to-text transcription. It was trained on the Librispeech dataset and achieved a WER of 8.1 on the test set. The model is intended for direct use in speech-to-text transcription tasks. However, users should be aware of the limitations and biases of the model, and take appropriate precautions when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For evaluation.", "module": "librispeech"}], "metrics": [{"dataset": "librispeech", "metric": 8.1, "protocol": "WER"}], "source": "huggingface"}, {"id": "huggingface-chaoli-nlp-for-transformer-book-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "nlp_for_transformer_book_distilbert-base-uncased-finetuned-emotion", "description": "Fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of distilbert-base-uncased on the emotion dataset. It can be used for text classification tasks. The model achieved an accuracy of 0.9245 and an F1 score of 0.9242 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.9245, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.9242101664142519, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-perelluis13-wav2vec2-large-xlsr-53-catalan", "modules": [{"role": "model", "module": {"name": "Catalan XLSR Wav2Vec Large 53", "description": "Fine-tuned XLSR Wav2Vec2 Large 53 on Catalan using the Common Voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 8, "optimizer": {"name": "Adam", "learning_rate": 3e-05, "beta1": 0.9, "beta2": 0.98, "epsilon": 1e-06}}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned XLSR Wav2Vec2 Large 53 model on Catalan using the Common Voice dataset. The model was trained on the Common Voice train and validation datasets and achieved a WER of 8.11% on the Common Voice test set. The model can be used directly for speech recognition without a language model. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 8.11, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-ts-fr", "modules": [{"role": "model", "module": {"name": "opus-mt-ts-fr", "description": "A transformer-align model for translating from Tsonga to French."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-ts-fr model is a transformer-align model that translates from Tsonga to French. It was trained on the OPUS dataset using normalization and SentencePiece pre-processing. The model achieved a BLEU score of 29.9 and a chr-F score of 0.475 on the JW300.ts.fr test set."}}], "metrics": [{"dataset": "jw300", "metric": 29.9, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.475, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-insop-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. The model achieved an accuracy of 0.926 and an F1 score of 0.9262 on the evaluation set. The model is suitable for text classification tasks, but its intended uses and limitations are not specified in the model card."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.926, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.9261721933926, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-jkhan447-sentiment-model-sample", "modules": [{"role": "model", "module": {"name": "sentiment-model-sample", "description": "Fine-tuned version of bert-base-uncased on the imdb dataset for text classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 10}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of bert-base-uncased on the imdb dataset for text classification. It achieves an accuracy of 0.9395 on the evaluation set. The model is suitable for text classification tasks, but its performance may vary depending on the specific use case. The model was trained using PyTorch and Transformers 4.17.0, and evaluated using the Datasets and Tokenizers libraries."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.93948, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-gyubeen-distilbert-base-uncased-finetuned-squad", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-squad", "description": "A fine-tuned version of distilbert-base-uncased on the squad dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-squad is a fine-tuned version of distilbert-base-uncased on the squad dataset. It is suitable for question answering tasks. The model was trained with Adam optimizer with a learning rate of 2e-05, betas=(0.9,0.999) and epsilon=1e-08. The model was trained for 3 epochs with a linear learning rate scheduler. The model achieved a validation loss of 1.1543."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 0.7477, "split": "val", "protocol": "loss"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 1.1543, "split": "test", "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-axhyra-irony-trained-1234567", "modules": [{"role": "model", "module": {"name": "irony_trained_1234567", "description": "Fine-tuned version of distilbert-base-uncased on the tweet_eval dataset for irony classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2.6774391860025942e-05, "train_batch_size": 4, "eval_batch_size": 4, "seed": 1234567, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 4}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "irony_trained_1234567 is a fine-tuned version of distilbert-base-uncased on the tweet_eval dataset for irony classification. The model achieved an F1 score of 0.6766 on the evaluation set. The model is suitable for text classification tasks, but its performance may vary depending on the specific use case. The model was trained using Adam optimizer with a learning rate of 2.6774391860025942e-05 and a linear learning rate scheduler. The model was trained for 4 epochs with a batch size of 4."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "tweeteval"}], "metrics": [{"dataset": "tweeteval", "metric": 0.6765645067647214, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-ahmeddbahaa-arat5-base-finetune-ar-xlsum", "modules": [{"role": "model", "module": {"name": "AraT5-base-finetune-ar-xlsum", "description": "A fine-tuned version of UBC-NLP/AraT5-base on the xlsum dataset for abstractive summarization."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0005, "train_batch_size": 8, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 16, "total_train_batch_size": 128, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 250, "num_epochs": 10, "label_smoothing_factor": 0.1}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "AraT5-base-finetune-ar-xlsum is a transformer model fine-tuned on the xlsum dataset for abstractive summarization. The model achieved a loss of 4.4714 and a Rouge-1 score of 29.55, Rouge-2 score of 12.63, Rouge-l score of 25.8, Gen Len of 18.76, and Bertscore of 73.3 on the evaluation set. The model is intended for abstractive summarization tasks in Arabic language, but its limitations and intended uses are not specified."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xl-sum"}], "metrics": [{"dataset": "xl-sum", "metric": 4.4714, "protocol": "loss"}, {"dataset": "xl-sum", "metric": 29.55, "protocol": "rouge-1"}, {"dataset": "xl-sum", "metric": 12.63, "protocol": "rouge-2"}, {"dataset": "xl-sum", "metric": 25.8, "protocol": "rouge-l"}, {"dataset": "xl-sum", "metric": 18.76, "protocol": "gen_len"}, {"dataset": "xl-sum", "metric": 73.3, "protocol": "bertscore"}], "source": "huggingface"}, {"id": "huggingface-fabiochiu-t5-base-tag-generation", "modules": [{"role": "model", "module": {"name": "t5-base-tag-generation", "description": "A T5 transformer model fine-tuned on the 190k Medium Articles dataset for predicting article tags using the article textual content as input."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 4e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1, "mixed_precision_training": true}}}, {"role": "taskType", "module": "text-generation"}, {"role": "solutionSummary", "module": {"summary": "A T5 transformer model fine-tuned on the 190k Medium Articles dataset for predicting article tags using the article textual content as input. The model is best suited for generating tags for articles. The dataset was cleaned using a hand-made taxonomy of about 1000 tags. The model was trained for one epoch and evaluated on 1000 random articles not used during training. The model was trained using PyTorch and Transformers 4.19.2, and evaluated using the ROUGE metric."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "mmed"}], "metrics": [{"dataset": "mmed", "metric": 0.8474, "protocol": "eval_loss"}, {"dataset": "mmed", "metric": 38.6033, "protocol": "eval_rouge1"}, {"dataset": "mmed", "metric": 20.5952, "protocol": "eval_rouge2"}, {"dataset": "mmed", "metric": 36.4458, "protocol": "eval_rougeL"}, {"dataset": "mmed", "metric": 36.3202, "protocol": "eval_rougeLsum"}, {"dataset": "mmed", "metric": 15.257, "protocol": "eval_gen_len"}], "source": "huggingface"}, {"id": "huggingface-maurya-q-frozenlake-v1-4x4-noslippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained model of a Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model achieved a mean reward of 1.00 +/- 0.00 on the FrozenLake-v1-4x4-no_slippery environment. The model can be loaded and evaluated using the provided code snippet."}}, {"role": "dataset", "purpose": "The environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-dooglak-tagged-uni-500v3-ner-model-3epochs-augmented", "modules": [{"role": "model", "module": {"name": "Tagged_Uni_500v3_NER_Model_3Epochs_AUGMENTED", "description": "Fine-tuned version of bert-base-cased on the tagged_uni500v3_wikigold_split dataset for named entity recognition (NER)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "Tagged_Uni_500v3_NER_Model_3Epochs_AUGMENTED is a fine-tuned version of bert-base-cased on the tagged_uni500v3_wikigold_split dataset for named entity recognition (NER). The model achieved a precision of 0.7144, recall of 0.7115, F1 score of 0.7130, and accuracy of 0.9340 on the evaluation set. The model was trained for 3 epochs with a learning rate of 2e-05 and Adam optimizer with betas=(0.9,0.999) and epsilon=1e-08."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wikisplit"}], "metrics": [{"dataset": "wikisplit", "metric": 0.7143812709030101, "protocol": "Precision"}, {"dataset": "wikisplit", "metric": 0.7115256495669554, "protocol": "Recall"}, {"dataset": "wikisplit", "metric": 0.7129506008010682, "protocol": "F1"}, {"dataset": "wikisplit", "metric": 0.9340035371870055, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-mariastull-q-frozenlake-v1-4x4-noslippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained model of a Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-4x4-no_slippery", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model's hyperparameters include the algorithm used, the environment, the maximum number of steps per episode, the number of episodes to evaluate the agent, the Q-Table learned by the agent, and the random seed used for evaluation. The model achieved a mean reward of 1.0 with no standard deviation."}}, {"role": "dataset", "purpose": "Environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-gary109-ai-light-dance-singing5-ft-wav2vec2-large-xlsr-53-5gram-v4-2-1", "modules": [{"role": "model", "module": {"name": "ai-light-dance_singing5_ft_wav2vec2-large-xlsr-53-5gram-v4-2-1", "description": "Fine-tuned version of gary109/ai-light-dance_singing4_ft_wav2vec2-large-xlsr-53-5gram-v4-2-1 on the GARY109/AI_LIGHT_DANCE - ONSET-SINGING5 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 4e-05, "train_batch_size": 8, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 8, "total_train_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 100, "num_epochs": 50.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of gary109/ai-light-dance_singing4_ft_wav2vec2-large-xlsr-53-5gram-v4-2-1 on the GARY109/AI_LIGHT_DANCE - ONSET-SINGING5 dataset. The model is intended for automatic speech recognition tasks. The model was trained using Adam optimizer with a learning rate of 4e-05, and a batch size of 64. The model achieved a loss of 0.1732 and a WER of 0.0831 on the evaluation set. The model was trained using PyTorch 1.9.1+cu102 and Transformers 4.21.0.dev0."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "vocalset-vocalset-a-singing-voice-dataset"}], "metrics": [{"dataset": "vocalset-vocalset-a-singing-voice-dataset", "metric": 0.1732, "protocol": "loss"}, {"dataset": "vocalset-vocalset-a-singing-voice-dataset", "metric": 0.0831, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-dimitre-universal-sentence-encoder", "modules": [{"role": "model", "module": {"name": "Universal Sentence Encoder", "description": "The Universal Sentence Encoder encodes text into high-dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"encoder": "Deep Averaging Network (DAN)", "output_dimension": 512}}}, {"role": "taskType", "module": "sentence-similarity"}, {"role": "solutionSummary", "module": {"summary": "The Universal Sentence Encoder is a transformer model trained on a variety of data sources and tasks to encode text into high-dimensional vectors. It is optimized for greater-than-word length text, such as sentences, phrases, or short paragraphs. The model can be used for text classification, semantic similarity, clustering, and other natural language tasks. The encoder is trained with a deep averaging network (DAN) encoder and outputs a 512-dimensional vector. The model is suitable for improving the coverage of systems that trigger behaviors on certain keywords, phrases, or utterances, and for training classifiers with a small amount of labeled examples."}}, {"role": "dataset", "purpose": "For semantic similarity evaluation.", "module": "sts-benchmark"}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-harithakk-finetuning-sentiment-model-test", "modules": [{"role": "model", "module": {"name": "finetuning-sentiment-model-Test", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "finetuning-sentiment-model-Test is a fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis. The model achieved an accuracy of 0.902 and an F1 score of 0.9037 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler for 2 epochs. The model is suitable for text classification tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.902, "protocol": "accuracy"}, {"dataset": "imdb-movie-reviews", "metric": 0.9037328094302554, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-mrm8488-bert-tiny-5-finetuned-squadv2", "modules": [{"role": "model", "module": {"name": "BERT-Tiny (5) fine-tuned on SQuAD v2", "description": "BERT-Tiny created by Google Research and fine-tuned on SQuAD 2.0 for Q&A downstream task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_size": "24.33 MB"}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "BERT-Tiny is a smaller version of BERT models, intended for environments with restricted computational resources. This model is fine-tuned on SQuAD 2.0 for Q&A downstream task. The model is most effective in the context of knowledge distillation, where the fine-tuning labels are produced by a larger and more accurate teacher. The model achieved an EM score of 57.12 and an F1 score of 60.86 on the SQuAD 2.0 evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 57.12, "protocol": "EM"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 60.86, "protocol": "F1"}], "source": "huggingface"}, {"id": "huggingface-jcastanyo-dqn-spaceinvadersnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "DQN", "description": "A trained DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "buffer_size": 100000, "exploration_final_eps": 0.01, "exploration_fraction": 0.1, "frame_stack": 4, "gradient_steps": 1, "learning_rate": 0.0001, "learning_starts": 100000, "n_timesteps": 1000000.0, "optimize_memory_usage": true, "policy": "CnnPolicy", "target_update_interval": 1000, "train_freq": 4, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The model was trained with a batch size of 32, a buffer size of 100000, and a learning rate of 0.0001. The model achieved a mean reward of 644.00 with a standard deviation of 281.09. The model is suitable for reinforcement learning tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 644.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-ccdv-lsg-bart-base-4096-booksum", "modules": [{"role": "model", "module": {"name": "ccdv/lsg-bart-base-4096-booksum", "description": "A fine-tuned version of ccdv/lsg-bart-base-4096 on the kmfoda/booksum dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 8e-05, "train_batch_size": 8, "gradient_accumulation_steps": 4, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "num_epochs": 30.0, "length_penalty": 2.0, "max_length": 512, "min_length": 128, "num_beams": 5, "no_repeat_ngram_size": null}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "ccdv/lsg-bart-base-4096-booksum is a fine-tuned version of ccdv/lsg-bart-base-4096 on the kmfoda/booksum dataset. The model is intended for summarization tasks and is limited to generating summaries of long-form text. The model was trained using Adam optimizer with a learning rate of 8e-05 and a linear learning rate scheduler with a warmup ratio of 0.1. The model achieved good results on the kmfoda/booksum dataset, with a rouge1 score of 33.9468, rouge2 score of 6.7034, rougeL score of 16.7879, and rougeLsum score of 31.7677."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "booksum"}], "metrics": [{"dataset": "booksum", "metric": 33.9468, "protocol": "rouge1"}, {"dataset": "booksum", "metric": 6.7034, "protocol": "rouge2"}, {"dataset": "booksum", "metric": 16.7879, "protocol": "rougeL"}, {"dataset": "booksum", "metric": 31.7677, "protocol": "rougeLsum"}], "source": "huggingface"}, {"id": "huggingface-saghar-tinybert-l-4-h-312-v2-finetuned-wikitext103", "modules": [{"role": "model", "module": {"name": "TinyBERT_L-4_H-312_v2-finetuned-wikitext103", "description": "A fine-tuned version of nreimers/TinyBERT_L-4_H-312_v2 on the wikitext dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 32, "eval_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0}}}, {"role": "taskType", "module": "text-generation"}, {"role": "solutionSummary", "module": {"summary": "TinyBERT_L-4_H-312_v2-finetuned-wikitext103 is a fine-tuned version of nreimers/TinyBERT_L-4_H-312_v2 on the wikitext dataset. The model is best suited for text generation tasks. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 32. The model was trained for 3 epochs and achieved a loss of 6.4638 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "wikitext-2"}], "metrics": [{"dataset": "wikitext-2", "metric": 6.4638, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-kwdev2000-finetuning-sentiment-model-3000-samples", "modules": [{"role": "model", "module": {"name": "finetuning-sentiment-model-3000-samples", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "finetuning-sentiment-model-3000-samples is a fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis. The model achieved an accuracy of 0.8533 and an F1 score of 0.8543 on the evaluation set. The model is suitable for text classification tasks, but its performance may vary depending on the specific use case. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.8533, "protocol": "accuracy"}, {"dataset": "imdb-movie-reviews", "metric": 0.8543, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-arashkhan58-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8649 on the evaluation set. The model is suitable for token classification tasks in German language. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8648740833380706, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-frahman-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8591 on the evaluation set. The model is suitable for token classification tasks in German language. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8591260810195721, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-eslamxm-mt5-multilingual-xlsum-finetuned-ar-wikilingua", "modules": [{"role": "model", "module": {"name": "mT5_multilingual_XLSum-finetuned-ar-wikilingua", "description": "A fine-tuned version of mT5_multilingual_XLSum on the wiki_lingua dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 4, "eval_batch_size": 4, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 250, "num_epochs": 8, "label_smoothing_factor": 0.1}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "mT5_multilingual_XLSum-finetuned-ar-wikilingua is a fine-tuned version of mT5_multilingual_XLSum on the wiki_lingua dataset. It is a transformer model that can be used for summarization tasks. The model was trained with Adam optimizer with a learning rate of 5e-05 and a batch size of 4. The model achieved a loss of 3.6903 and a Bertscore of 72.63 on the evaluation set. The model was trained for 8 epochs with a linear learning rate scheduler and a label smoothing factor of 0.1."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wikilingua"}], "metrics": [{"dataset": "wikilingua", "metric": 3.6903, "protocol": "loss"}, {"dataset": "wikilingua", "metric": 24.47, "protocol": "rouge-1"}, {"dataset": "wikilingua", "metric": 7.69, "protocol": "rouge-2"}, {"dataset": "wikilingua", "metric": 20.04, "protocol": "rouge-l"}, {"dataset": "wikilingua", "metric": 39.64, "protocol": "gen_len"}, {"dataset": "wikilingua", "metric": 72.63, "protocol": "bertscore"}], "source": "huggingface"}, {"id": "huggingface-haesun-pegasus-samsum", "modules": [{"role": "model", "module": {"name": "pegasus-samsum", "description": "Fine-tuned version of google/pegasus-cnn_dailymail on the samsum dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 1, "eval_batch_size": 1, "seed": 42, "gradient_accumulation_steps": 16, "total_train_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 1}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "pegasus-samsum is a fine-tuned version of google/pegasus-cnn_dailymail on the samsum dataset. It is a model for text summarization. The model was trained with Adam optimizer with a learning rate of 5e-05 and a linear learning rate scheduler with 500 warmup steps. The model achieved a loss of 1.4826 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "samsum-corpus"}], "metrics": [{"dataset": "samsum-corpus", "metric": 1.4826, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-stevemobs-deberta-base-finetuned-squad1", "modules": [{"role": "model", "module": {"name": "deberta-base-finetuned-squad1", "description": "Fine-tuned version of microsoft/deberta-base on the squad dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 12, "eval_batch_size": 12, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "deberta-base-finetuned-squad1 is a fine-tuned version of microsoft/deberta-base on the squad dataset. It is suitable for question answering tasks. The model was trained for 2 epochs with a learning rate of 2e-05 and an Adam optimizer with betas=(0.9,0.999) and epsilon=1e-08. The model achieved a loss of 0.8037 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 0.8037, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-axhyra-demo-hate-31415", "modules": [{"role": "model", "module": {"name": "demo_hate_31415", "description": "A fine-tuned version of distilbert-base-uncased on the tweet_eval dataset for text classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 7.320702985778492e-05, "train_batch_size": 32, "eval_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 4}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "demo_hate_31415 is a fine-tuned version of distilbert-base-uncased on the tweet_eval dataset for text classification. The model achieved an F1 score of 0.7773 on the evaluation set. The model is suitable for text classification tasks, but its performance may vary depending on the specific use case and data distribution."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "tweeteval"}], "metrics": [{"dataset": "tweeteval", "metric": 0.7772939485986298, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-en-kqn", "modules": [{"role": "model", "module": {"name": "opus-mt-en-kqn", "description": "A transformer-align model for translating from English to kqn."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-en-kqn model is a transformer-align model that translates from English to kqn. It achieved a BLEU score of 33.1 and a chr-F score of 0.567 on the JW300.en.kqn test set. The model uses normalization and SentencePiece for pre-processing."}}], "metrics": [{"dataset": "jw300", "metric": 33.1, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.567, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-juliusco-distilbert-base-uncased-finetuned-squad", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-squad", "description": "A fine-tuned version of distilbert-base-uncased on the squad dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 4}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-squad is a fine-tuned version of distilbert-base-uncased on the squad dataset. It is suitable for question answering tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 8. The model was trained for 4 epochs and achieved a loss of 1.3672 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 1.3672, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-alex-yang-q-frozenlake-v1-4x4-noslippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained model of a Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1", "slippery": false, "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model was trained on the Taxi-v3 dataset and evaluated on the same dataset. The Q-table learned by the agent is provided along with the maximum number of steps per episode, the number of episodes to evaluate the agent, and the random seed used for evaluation."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 7.56, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-dundar-wav2vec2-large-xlsr-53-turkish", "modules": [{"role": "model", "module": {"name": "XLSR Wav2Vec2 Turkish by Enes Burak Dundar", "description": "Fine-tuned Wav2Vec2-Large-XLSR-53 on Turkish using the Common Voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "Wav2Vec2-Large-XLSR-53", "batch_size": 8, "optimizer": {"name": "Adam", "learning_rate": 0.0001, "beta1": 0.9, "beta2": 0.999, "weight_decay": 0.01}}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "XLSR Wav2Vec2 Turkish is a speech recognition model fine-tuned on the Common Voice dataset for Turkish. The model is based on Wav2Vec2-Large-XLSR-53 and was trained using Adam optimizer with a learning rate of 0.0001. The model achieved a WER of 24.86% on the Common Voice Turkish test set. The model can be used directly for speech recognition without a language model."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 24.86, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-setfit-distilbert-base-uncased-sst2-train-32-9", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased__sst2__train-32-9", "description": "A fine-tuned version of distilbert-base-uncased on the SST-2 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 4, "eval_batch_size": 4, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 50, "mixed_precision_training": true}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of distilbert-base-uncased on the SST-2 dataset. The model was trained with Adam optimizer and linear learning rate scheduler for 50 epochs. The model achieved an accuracy of 0.7353 and a loss of 0.5625 on the evaluation set. The model is suitable for text classification tasks."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "sst-stanford-sentiment-treebank"}], "metrics": [{"dataset": "sst-stanford-sentiment-treebank", "metric": 0.7353, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-sanchit-gandhi-wav2vec2-2-rnd-grid-search", "modules": [{"role": "model", "module": {"name": "ASR model trained on Librispeech dataset", "description": "This model was trained from scratch on the librispeech_asr dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0003, "train_batch_size": 8, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 4, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 1000, "num_epochs": 5.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is an ASR model trained on the Librispeech dataset. The model achieved a WER of 2.0097 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 0.0003 and a linear learning rate scheduler. The model was trained for 5 epochs with a batch size of 32 and mixed precision training. The model was implemented using Transformers 4.17.0.dev0, Pytorch 1.10.2+cu113, Datasets 1.18.3, and Tokenizers 0.11.0."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "librispeech"}], "metrics": [{"dataset": "librispeech", "metric": 6.9503, "split": "val", "protocol": "loss"}, {"dataset": "librispeech", "metric": 6.9475, "split": "test", "protocol": "loss"}, {"dataset": "librispeech", "metric": 2.0097, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-ankit15nov-xlm-roberta-base-finetuned-panx-en", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-en", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "xlm-roberta-base-finetuned-panx-en is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification. The model achieved an F1 score of 0.6985 on the evaluation set. The model is suitable for token classification tasks in multilingual settings."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.6984839977540707, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-pavle-tsotskolauri-distilbert-base-uncased-finetuned-imdb", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-imdb", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-imdb is a fine-tuned version of distilbert-base-uncased on the imdb dataset. It can be used for text classification tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 64. The model was trained for 3 epochs and achieved a loss of 2.4738 on the evaluation set. The model was trained using PyTorch and Transformers framework."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 2.4738, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-bert-large-uncased-whole-word-masking", "modules": [{"role": "model", "module": {"name": "BERT large model (uncased) whole word masking", "description": "Pretrained model on English language using a masked language modeling (MLM) objective with whole word masking."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 256, "optimizer": {"name": "Adam", "learning_rate": 0.0001, "beta1": 0.9, "beta2": 0.999, "weight_decay": 0.01}}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "BERT is a transformer model pre-trained on a large English corpus. It can be used for masked language modeling or next sentence prediction, but it's mainly intended to be fine-tuned on a downstream task. The model is suitable for tasks that use the whole sentence to make decisions, such as sequence classification, token classification, or question answering. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems. This model uses whole word masking, which masks all tokens corresponding to a word at once, and was trained on BookCorpus and English Wikipedia."}}, {"role": "dataset", "purpose": "For model training.", "module": "bookcorpus"}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-tom11-xlm-roberta-base-finetuned-panx-en", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-en", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "xlm-roberta-base-finetuned-panx-en is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. The model achieved an F1 score of 0.6856 on the evaluation set. The model is suitable for token classification tasks in multilingual settings."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.68561872909699, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-ts-es", "modules": [{"role": "model", "module": {"name": "opus-mt-ts-es", "description": "A transformer-align model for translating from Tsonga to Spanish."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-ts-es model is a transformer-align model that translates from Tsonga to Spanish. It achieved a BLEU score of 28.1 and a chr-F score of 0.468 on the JW300.ts.es test set."}}], "metrics": [{"dataset": "jw300", "metric": 28.1, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.468, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-mrm8488-t5-small-finetuned-squadv2", "modules": [{"role": "model", "module": {"name": "T5-small fine-tuned on SQuAD v2", "description": "Google's T5 (small) model fine-tuned on SQuAD v2 for Q&A downstream task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_size": "small", "pretrained_model": "t5-small", "batch_size": 1}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "T5-small is a transformer model fine-tuned on SQuAD v2 for Q&A downstream task. The model is based on a unified text-to-text transformer and can be used for various NLP tasks. The model achieved an EM score of 69.46 and an F1 score of 73.01 on the SQuAD v2 dataset. The model can be used to answer questions based on a given context."}}, {"role": "dataset", "purpose": "For fine-tuning and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 69.46, "protocol": "EM"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 73.01, "protocol": "F1"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-fi-yap", "modules": [{"role": "model", "module": {"name": "opus-mt-fi-yap", "description": "A machine translation model that translates from Finnish (fi) to Yapese (yap) using a transformer-align model."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-fi-yap is a machine translation model that translates from Finnish to Yapese using a transformer-align model. The model was preprocessed using normalization and SentencePiece. The model achieved a BLEU score of 25.4 and a chr-F score of 0.445 on the JW300.fi.yap test set."}}], "metrics": [{"dataset": "jw300", "metric": 25.4, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.445, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-susumu2357-bert-base-swedish-squad2", "modules": [{"role": "model", "module": {"name": "Swedish BERT Fine-tuned on SQuAD v2", "description": "Fine-tuned Swedish BERT model on SQuAD v2 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 16, "n_epochs": 2, "max_seq_len": 386, "learning_rate": 3e-05, "warmup_steps": 2900, "doc_stride": 128, "max_query_length": 64}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned Swedish BERT model on the SQuAD v2 dataset. The model was trained on a Swedish translation of the SQuAD v2 dataset. The model's performance is evaluated using the SQuAD v2 metrics. The model may contain biases due to mistranslations of the SQuAD dataset."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-lvwerra-bert-imdb", "modules": [{"role": "model", "module": {"name": "BERT-IMDB", "description": "BERT (`bert-large-cased`) trained for sentiment classification on the IMDB dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "bert-large-cased", "learning_rate": 1e-05, "epochs": 3}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "BERT-IMDB is a sentiment classification model trained on the IMDB dataset using the `bert-large-cased` model. The model was trained for three epochs with a learning rate of `1e-5` using the `simpletransformers` library. The model achieved 90% classification accuracy on the validation set."}}, {"role": "dataset", "purpose": "For model training and validation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.9, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-lmqg-bart-large-tweetqa-qag", "modules": [{"role": "model", "module": {"name": "lmqg/bart-large-tweetqa-qag", "description": "Fine-tuned version of facebook/bart-large for question & answer pair generation task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"dataset_path": "lmqg/qag_tweetqa", "dataset_name": "default", "input_types": ["paragraph"], "output_types": ["questions_answers"], "model": "facebook/bart-large", "max_length": 256, "max_length_output": 128, "epoch": 14, "batch": 32, "lr": 5e-05, "fp16": false, "random_seed": 1, "gradient_accumulation_steps": 8, "label_smoothing": 0.15}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "lmqg/bart-large-tweetqa-qag is a fine-tuned version of facebook/bart-large for question & answer pair generation task. The model is trained on lmqg/qag_tweetqa dataset. The model can be used for generating question and answer pairs from a given paragraph. The model achieved good scores on various evaluation metrics such as BLEU4, ROUGE-L, METEOR, BERTScore, and MoverScore. The model is suitable for tasks that require generating question and answer pairs from a given paragraph."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "tweetqa"}], "metrics": [{"dataset": "tweetqa", "metric": 15.18, "protocol": "BLEU4"}, {"dataset": "tweetqa", "metric": 34.99, "protocol": "ROUGE-L"}, {"dataset": "tweetqa", "metric": 27.91, "protocol": "METEOR"}, {"dataset": "tweetqa", "metric": 91.27, "protocol": "BERTScore"}, {"dataset": "tweetqa", "metric": 62.25, "protocol": "MoverScore"}, {"dataset": "tweetqa", "metric": 92.47, "protocol": "QAAlignedF1Score-BERTScore"}, {"dataset": "tweetqa", "metric": 92.21, "protocol": "QAAlignedRecall-BERTScore"}, {"dataset": "tweetqa", "metric": 92.74, "protocol": "QAAlignedPrecision-BERTScore"}, {"dataset": "tweetqa", "metric": 64.66, "protocol": "QAAlignedF1Score-MoverScore"}, {"dataset": "tweetqa", "metric": 64.03, "protocol": "QAAlignedRecall-MoverScore"}, {"dataset": "tweetqa", "metric": 65.39, "protocol": "QAAlignedPrecision-MoverScore"}], "source": "huggingface"}, {"id": "huggingface-theresearchninja-cybonto-distilbert-base-uncased-finetuned-ner-fewnerd", "modules": [{"role": "model", "module": {"name": "Cybonto-distilbert-base-uncased-finetuned-ner-FewNerd", "description": "A fine-tuned version of distilbert-base-uncased on the few_nerd dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 32, "eval_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "Cybonto-distilbert-base-uncased-finetuned-ner-FewNerd is a fine-tuned version of distilbert-base-uncased on the few_nerd dataset for token classification. The model achieved a precision of 0.7422, recall of 0.7830, F1 score of 0.7621, and accuracy of 0.9386 on the evaluation set. The model is suitable for named entity recognition tasks, but caution should be taken when deploying it in human-interacting systems as it may reflect the biases of the systems it was trained on."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "few-nerd"}], "metrics": [{"dataset": "few-nerd", "metric": 0.7422259388187705, "protocol": "precision"}, {"dataset": "few-nerd", "metric": 0.7830368683449253, "protocol": "recall"}, {"dataset": "few-nerd", "metric": 0.7620854216169805, "protocol": "f1"}, {"dataset": "few-nerd", "metric": 0.9386106950200795, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-sb3-a2c-walker2dbulletenv-v0", "modules": [{"role": "model", "module": {"name": "A2C", "description": "A2C agent trained on Walker2DBulletEnv-v0 using the stable-baselines3 library."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"ent_coef": 0.0, "gae_lambda": 0.9, "gamma": 0.99, "learning_rate": "lin_0.00096", "max_grad_norm": 0.5, "n_envs": 4, "n_steps": 8, "n_timesteps": 2000000.0, "normalize": true, "normalize_advantage": false, "policy": "MlpPolicy", "policy_kwargs": {"log_std_init": -2, "ortho_init": false}, "use_rms_prop": true, "use_sde": true, "vf_coef": 0.4, "normalize_kwargs": {"norm_obs": true, "norm_reward": false}}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "The A2C agent was trained on the Walker2DBulletEnv-v0 environment using the stable-baselines3 library. The model achieved a mean reward of 809.75 with a standard deviation of 376.19. The hyperparameters used for training include a gamma of 0.99, a learning rate of 0.00096, and a policy of MlpPolicy. The model is suitable for reinforcement learning tasks, but caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 809.75, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-iic-dpr-spanish-passage-encoder-squades-base", "modules": [{"role": "model", "module": {"name": "DPR Spanish Passage Encoder (SQUADES base)", "description": "A model for encoding passages in Spanish for use in open-domain question answering systems."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_name": "avacaondata/dpr-spanish-passage_encoder-squades-base", "tokenizer": "DPRContextEncoderTokenizer", "max_length": null}}}, {"role": "taskType", "module": "sentence-similarity"}, {"role": "solutionSummary", "module": {"summary": "The DPR Spanish Passage Encoder is a model for encoding passages in Spanish for use in open-domain question answering systems. It was trained on the Spanish version of SQUAD, SQUADES. The model is intended to be used to vectorize the documents in the database of a question answering system in Spanish, and then compare those encodings with the encoding of a new question to find the most similar documents. The model achieved high accuracy, F1 score, and low loss on the evaluation split of SQUADES."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 0.08608942725107592, "protocol": "eval_loss"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 0.9925325215819639, "protocol": "eval_accuracy"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 0.8805402320715237, "protocol": "eval_f1"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 0.27430093209054596, "protocol": "average_rank"}], "source": "huggingface"}, {"id": "huggingface-richardc7-electricidad-small-finetuned-amazon-review-classification", "modules": [{"role": "model", "module": {"name": "electricidad-small-finetuned-amazon-review-classification", "description": "A fine-tuned version of mrm8488/electricidad-small-discriminator on the amazon_reviews_multi dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of mrm8488/electricidad-small-discriminator on the amazon_reviews_multi dataset. It is a text classification model, but more information is needed to describe the model and its intended uses and limitations. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler. The model was trained for 2 epochs with a batch size of 8 and achieved an accuracy of 0.581 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "amazon-product-data"}], "metrics": [{"dataset": "amazon-product-data", "metric": 0.581, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-novarac23-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. The model is best suited for text classification tasks. The model achieved an accuracy of 0.925 and an F1 score of 0.9252 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.925, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.9251919899321654, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-artifact-ai-en-spacy-fewnerd-distilroberta-base-ner", "modules": [{"role": "model", "module": {"name": "en_spacy_fewnerd_distilroberta_base_ner", "description": "A spaCy model for named entity recognition (NER) using a distilroberta transformer and trained on the FewNERD dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"spaCy_version": ">=3.4.1,<3.5.0", "pipeline": ["transformer", "ner"], "transformer": "distilroberta", "labels": ["cation", "ent", "ganization", "her", "ilding", "oduct", "rson", "t"]}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "en_spacy_fewnerd_distilroberta_base_ner is a spaCy model for named entity recognition (NER) using a distilroberta transformer and trained on the FewNERD dataset. The model achieved an F1 score of 84.17% on the test set. The model's label scheme includes 8 labels for 1 component. The model is suitable for token classification tasks in English language, especially for recognizing named entities."}}, {"role": "dataset", "purpose": "For model training.", "module": "few-nerd"}], "metrics": [{"dataset": "few-nerd", "metric": 0.8341443756, "protocol": "precision"}, {"dataset": "few-nerd", "metric": 0.8494726258, "protocol": "recall"}, {"dataset": "few-nerd", "metric": 0.8417387238, "protocol": "f_score"}, {"dataset": "few-nerd", "metric": 84.17, "protocol": "ENTS_F"}, {"dataset": "few-nerd", "metric": 83.41, "protocol": "ENTS_P"}, {"dataset": "few-nerd", "metric": 84.95, "protocol": "ENTS_R"}, {"dataset": "few-nerd", "metric": 706035.99, "protocol": "TRANSFORMER_LOSS"}, {"dataset": "few-nerd", "metric": 1425266.73, "protocol": "NER_LOSS"}], "source": "huggingface"}, {"id": "huggingface-facebook-wav2vec2-large-xlsr-53-polish", "modules": [{"role": "model", "module": {"name": "Wav2Vec2-large-xlsr-53-polish", "description": "Pretrained model on Polish language for automatic speech recognition using Wav2Vec2 architecture."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"resample": {"orig_freq": 48000, "new_freq": 16000}, "batch_size": 16}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Wav2Vec2-large-xlsr-53-polish is a pretrained model on Polish language for automatic speech recognition using Wav2Vec2 architecture. The model was evaluated on the Common Voice dataset and achieved a WER of 24.6%. The model is suitable for speech recognition tasks in Polish language."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-cardiffnlp-twitter-roberta-base-2021-124m-offensive", "modules": [{"role": "model", "module": {"name": "cardiffnlp/twitter-roberta-base-2021-124m-offensive", "description": "Fine-tuned version of cardiffnlp/twitter-roberta-base-2021-124m on the tweet_eval (offensive) dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"max_length": 128}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of cardiffnlp/twitter-roberta-base-2021-124m on the tweet_eval (offensive) dataset. The model is a text classification model that can predict whether a given tweet is offensive or not. The model achieved an F1 score of 0.858 and an accuracy of 0.858 on the test set. The model can be loaded in Python using the tweetnlp library."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "tweeteval"}], "metrics": [{"dataset": "tweeteval", "metric": 0.858139534883721, "protocol": "micro_f1_tweet_eval/offensive"}, {"dataset": "tweeteval", "metric": 0.8232706055154664, "protocol": "macro_f1_tweet_eval/offensive"}, {"dataset": "tweeteval", "metric": 0.858139534883721, "protocol": "accuracy_tweet_eval/offensive"}], "source": "huggingface"}, {"id": "huggingface-husnu-wav2vec2-large-xls-r-300m-turkish-colab-common-voice-8-6", "modules": [{"role": "model", "module": {"name": "wav2vec2-large-xls-r-300m-turkish-colab_common_voice-8_6", "description": "A fine-tuned version of husnu/wav2vec2-large-xls-r-300m-turkish-colab_common_voice-8_5 on the common_voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0003, "train_batch_size": 16, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 6, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of husnu/wav2vec2-large-xls-r-300m-turkish-colab_common_voice-8_5 on the common_voice dataset. The model is intended for automatic speech recognition tasks. The model was trained using Adam optimizer with a learning rate of 0.0003, and a linear learning rate scheduler with 500 warmup steps. The model was trained for 6 epochs with a batch size of 16 and mixed precision training. The model achieved a loss of 0.3646 and a WER of 0.3478 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.3646, "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.3478, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-chaoli-xlm-roberta-base-finetuned-panx-fr", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-fr", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. The model achieved an F1 score of 0.8326 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 5e-05 and a linear learning rate scheduler. The model was trained for 3 epochs with a batch size of 24."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8325761399966348, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-dooglak-article-100v5-ner-model-3epochs-unaugmented", "modules": [{"role": "model", "module": {"name": "Article_100v5_NER_Model_3Epochs_UNAUGMENTED", "description": "A fine-tuned version of bert-base-cased on the article100v5_wikigold_split dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "Article_100v5_NER_Model_3Epochs_UNAUGMENTED is a fine-tuned version of bert-base-cased on the article100v5_wikigold_split dataset for token classification. The model achieved a precision of 0.0241, recall of 0.0005, f1-score of 0.0010, and accuracy of 0.7822 on the evaluation set. More information is needed to describe the model and its intended uses and limitations."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wikisplit"}], "metrics": [{"dataset": "wikisplit", "metric": 0.0241, "protocol": "precision"}, {"dataset": "wikisplit", "metric": 0.0005, "protocol": "recall"}, {"dataset": "wikisplit", "metric": 0.001, "protocol": "f1"}, {"dataset": "wikisplit", "metric": 0.7822, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-sb3-ppo-walker2d-v3", "modules": [{"role": "model", "module": {"name": "PPO Agent playing Walker2d-v3", "description": "A trained model of a PPO agent playing Walker2d-v3 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"env_wrapper": "sb3_contrib.common.wrappers.TimeFeatureWrapper", "n_timesteps": 1000000.0, "normalize": true, "policy": "MlpPolicy", "normalize_kwargs": {"norm_obs": true, "norm_reward": false}}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a PPO agent playing Walker2d-v3 using the stable-baselines3 library and the RL Zoo. The model was trained for 1,000,000 timesteps with the MlpPolicy and TimeFeatureWrapper. The model achieved a mean reward of 3571.74 +/- 807.75 on the Walker2d-v3 dataset."}}, {"role": "dataset", "purpose": "For model training.", "module": "mujoco"}], "metrics": [{"dataset": "mujoco", "metric": 3571.74, "split": "val", "protocol": "mean_reward"}, {"dataset": "mujoco", "metric": 807.75, "split": "test", "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-chris-santiago-distilbert-base-uncased-finetuned-clinc", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-clinc", "description": "A fine-tuned version of distilbert-base-uncased on the clinc_oos dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 48, "eval_batch_size": 48, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-clinc is a fine-tuned version of distilbert-base-uncased on the clinc_oos dataset. It is a text classification model that can be used to classify out-of-scope queries. The model achieved an accuracy of 0.9152 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler for 5 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "clinc-single-domain-oos"}], "metrics": [{"dataset": "clinc-single-domain-oos", "metric": 0.9151612903225806, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-mohamed1ai-wav2vec2-large-xls-ar", "modules": [{"role": "model", "module": {"name": "Wav2Vec2-Large-XLSR-53-Arabic", "description": "Fine-tuned facebook/wav2vec2-large-xlsr-53 on Arabic using the Common Voice Corpus 5.1 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 8, "optimizer": {"name": "Adam", "learning_rate": 5e-05, "beta1": 0.9, "beta2": 0.98, "epsilon": 1e-06}}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Wav2Vec2-Large-XLSR-53-Arabic is a speech recognition model fine-tuned on the Common Voice Corpus 5.1 dataset for Arabic. The model is based on the Wav2Vec2 architecture and can be used directly for speech recognition without a language model. The model is best suited for tasks that require recognizing speech in Arabic. The model achieved a WER of 52% on the Arabic test data of Common Voice."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 52.0, "protocol": "WER"}], "source": "huggingface"}, {"id": "huggingface-aiboo-opus-mt-en-ro-finetuned-en-to-ro", "modules": [{"role": "model", "module": {"name": "opus-mt-en-ro-finetuned-en-to-ro", "description": "A fine-tuned version of Helsinki-NLP/opus-mt-en-ro on the wmt16 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1, "mixed_precision_training": true}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of Helsinki-NLP/opus-mt-en-ro on the wmt16 dataset. It is intended for sequence-to-sequence language modeling tasks, specifically for English to Romanian translation. The model achieved a BLEU score of 28.1031 on the evaluation set. The training hyperparameters include a learning rate of 2e-05, a batch size of 16, and a linear learning rate scheduler. The model was trained using the Adam optimizer with betas=(0.9,0.999) and epsilon=1e-08."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wmt-2016"}], "metrics": [{"dataset": "wmt-2016", "metric": 28.1031, "protocol": "bleu"}], "source": "huggingface"}, {"id": "huggingface-zhangfx7-distilbert-base-uncased-finetuned-cola", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-cola", "description": "A fine-tuned version of distilbert-base-uncased on the glue dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-cola is a fine-tuned version of distilbert-base-uncased on the glue dataset. It is a transformer model that can be used for text classification tasks. The model achieved a Matthews Correlation score of 0.4468 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 16."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.4467807407096838, "protocol": "matthews_correlation"}], "source": "huggingface"}, {"id": "huggingface-ralphx1-dqn-spaceinvadersnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "DQN", "description": "A trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "buffer_size": 100000, "exploration_final_eps": 0.01, "exploration_fraction": 0.1, "frame_stack": 4, "gradient_steps": 1, "learning_rate": 0.0001, "learning_starts": 100000, "n_timesteps": 10000.0, "optimize_memory_usage": true, "policy": "CnnPolicy", "target_update_interval": 1000, "train_freq": 4, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The model was trained with a batch size of 32, a buffer size of 100000, and a learning rate of 0.0001. The model achieved a mean reward of 374.00 with a standard deviation of 214.89. The model is suitable for reinforcement learning tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 374.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-corianas-dqn-spaceinvadersnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "DQN Agent playing SpaceInvadersNoFrameskip-v4", "description": "A trained DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "buffer_size": 100000, "exploration_final_eps": 0.01, "exploration_fraction": 0.1, "frame_stack": 4, "gradient_steps": 1, "learning_rate": 0.0001, "learning_starts": 100000, "n_timesteps": 10000000.0, "optimize_memory_usage": true, "policy": "CnnPolicy", "target_update_interval": 1000, "train_freq": 4, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The model was trained with a batch size of 32, a buffer size of 100000, and a learning rate of 0.0001. The model achieved a mean reward of 609.00 +/- 102.22 on the SpaceInvadersNoFrameskip-v4 dataset. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 609.0, "split": "val", "protocol": "mean_reward"}, {"dataset": "atari-grand-challenge", "metric": 102.22, "split": "test", "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-jadohu-beit-finetuned", "modules": [{"role": "model", "module": {"name": "BEiT-finetuned", "description": "A fine-tuned version of microsoft/beit-base-patch16-224 on the cifar10 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 3e-05, "train_batch_size": 32, "eval_batch_size": 32, "seed": 42, "gradient_accumulation_steps": 4, "total_train_batch_size": 128, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "num_epochs": 3}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "BEiT-finetuned is a fine-tuned version of microsoft/beit-base-patch16-224 on the cifar10 dataset. It achieves an accuracy of 0.9918 on the evaluation set. The model is suitable for image classification tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "cifar-10"}], "metrics": [{"dataset": "cifar-10", "metric": 0.9918, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-sahn-distilbert-base-uncased-finetuned-imdb-blur", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-imdb-blur", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-imdb-blur is a fine-tuned version of distilbert-base-uncased on the imdb dataset. The model is best suited for text classification tasks. The model achieved an accuracy of 0.9776 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 16 for 5 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.9776, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-andi611-distilbert-base-uncased-ner-conll2003", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-ner", "description": "A fine-tuned version of distilbert-base-uncased on the conll2003 dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 3e-05, "train_batch_size": 16, "eval_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-ner is a fine-tuned version of distilbert-base-uncased on the conll2003 dataset for token classification. The model achieved high accuracy, precision, recall, and F1 scores on the evaluation set. It can be used for named entity recognition tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 0.985193893275295, "protocol": "Accuracy"}, {"dataset": "conll-2003", "metric": 0.9332, "protocol": "Precision"}, {"dataset": "conll-2003", "metric": 0.9423, "protocol": "Recall"}, {"dataset": "conll-2003", "metric": 0.9377, "protocol": "F1"}], "source": "huggingface"}, {"id": "huggingface-speechbrain-sepformer-wham", "modules": [{"role": "model", "module": {"name": "SepFormer trained on WHAM!", "description": "A SepFormer model trained on WHAM! dataset for audio source separation."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_type": "SepFormer", "test_set_SI-SNRi": 16.3, "test_set_SDRi": 16.7}}}, {"role": "taskType", "module": "audio-to-audio"}, {"role": "solutionSummary", "module": {"summary": "This is a SepFormer model trained on WHAM! dataset for audio source separation. The model performance is 16.3 dB SI-SNRi on the test set of WHAM! dataset. The model is implemented with SpeechBrain and can be fine-tuned on other datasets. The SpeechBrain team does not provide any warranty on the performance achieved by this model when used on other datasets."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wham-wsj0-hipster-ambient-mixtures"}], "metrics": [{"dataset": "wham-wsj0-hipster-ambient-mixtures", "metric": 16.3, "protocol": "SI-SNRi"}, {"dataset": "wham-wsj0-hipster-ambient-mixtures", "metric": 16.7, "protocol": "SDRi"}], "source": "huggingface"}, {"id": "huggingface-sherlockguo-distilbert-base-uncased-finetuned-squad", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-squad", "description": "A fine-tuned version of distilbert-base-uncased on the squad dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-squad is a fine-tuned version of distilbert-base-uncased on the squad dataset. It is suitable for question answering tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for 3 epochs and achieved a loss of 3.7677 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 3.7677, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-team-pixel-pixel-base-finetuned-xnli-translate-train-all", "modules": [{"role": "model", "module": {"name": "pixel-base-finetuned-xnli-translate-train-all", "description": "A fine-tuned version of Team-PIXEL/pixel-base on the XNLI dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 256, "eval_batch_size": 8, "seed": 555, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 1000, "training_steps": 50000, "mixed_precision_training": "Apex, opt level O1"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of Team-PIXEL/pixel-base on the XNLI dataset. The model was trained using Adam optimizer with a learning rate of 2e-05, and a linear learning rate scheduler with 1000 warmup steps. The model was trained for 50000 steps with a batch size of 256 and evaluated with a batch size of 8. The model was trained using mixed precision training with Apex, opt level O1. The model's performance was evaluated using accuracy metric."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xnli-cross-lingual-natural-language-inference"}], "metrics": [{"dataset": "xnli-cross-lingual-natural-language-inference", "metric": 0.6254886211512718, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-sebis-code-trans-t5-base-api-generation-transfer-learning-finetune", "modules": [{"role": "model", "module": {"name": "CodeTrans model for api recommendation generation", "description": "Pretrained model for api recommendation generation using the t5 base model architecture."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"pretraining_optimizer": {"name": "AdaFactor", "learning_rate_schedule": "inverse square root"}, "pretraining_sequence_length": 512, "pretraining_batch_size": 4096, "finetuning_sequence_length": 512, "finetuning_batch_size": 256}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "CodeTrans is a transformer model pre-trained on 7 unsupervised datasets in the software development domain and fine-tuned on the api recommendation generation task for the java apis. It can be used to generate api usage for the java programming tasks. The model is best suited for generating api recommendations for java programming tasks. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-phildav-dqn-spaceinvadersnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "DQN Agent playing SpaceInvadersNoFrameskip-v4", "description": "A trained DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "buffer_size": 100000, "exploration_final_eps": 0.01, "exploration_fraction": 0.1, "frame_stack": 4, "gradient_steps": 1, "learning_rate": 0.0001, "learning_starts": 100000, "n_timesteps": 1000000.0, "optimize_memory_usage": false, "policy": "CnnPolicy", "target_update_interval": 1000, "train_freq": 4, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The model was trained with a batch size of 32, a buffer size of 100000, and a learning rate of 0.0001. The model achieved a mean reward of 529.00 +/- 106.67 on the SpaceInvadersNoFrameskip-v4 dataset."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 529.0, "split": "val", "protocol": "mean_reward"}, {"dataset": "atari-grand-challenge", "metric": 106.67, "split": "test", "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-bergum-xtremedistil-l6-h384-emotion", "modules": [{"role": "model", "module": {"name": "xtremedistil-l6-h384-emotion", "description": "Fine-tuned version of microsoft/xtremedistil-l6-h384-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 3e-05, "train_batch_size": 128, "eval_batch_size": 8, "seed": 42, "num_epochs": 14}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "xtremedistil-l6-h384-emotion is a fine-tuned transformer model based on microsoft/xtremedistil-l6-h384-uncased. It was trained on the emotion dataset and achieved an accuracy of 0.928 on the evaluation set. The model can be quantized to int8 while retaining an accuracy of 0.912. The model is suitable for text classification tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.928, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-madhav16-finetuning-sentiment-model-3000-samples", "modules": [{"role": "model", "module": {"name": "finetuning-sentiment-model-3000-samples", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "finetuning-sentiment-model-3000-samples is a fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis. The model achieved an accuracy of 0.86 and an F1 score of 0.8662 on the evaluation set. The model is suitable for text classification tasks, but its performance may vary depending on the specific use case and data distribution."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.86, "protocol": "accuracy"}, {"dataset": "imdb-movie-reviews", "metric": 0.8662, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-farleyknight-mnist-digit-classification-2022-09-04", "modules": [{"role": "model", "module": {"name": "mnist-digit-classification-2022-09-04", "description": "A fine-tuned version of google/vit-base-patch16-224-in21k on the mnist dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5.0}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of google/vit-base-patch16-224-in21k on the mnist dataset. It achieves an accuracy of 0.9923 on the evaluation set. The model is suitable for image classification tasks, particularly for recognizing handwritten digits in the MNIST dataset."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "mnist"}], "metrics": [{"dataset": "mnist", "metric": 0.9923333333333333, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-mrojas-roberta-clinical-wl-es-finetuned-ner", "modules": [{"role": "model", "module": {"name": "roberta-clinical-wl-es-finetuned-ner", "description": "A fine-tuned version of plncmm/roberta-clinical-wl-es on the wl dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "A fine-tuned version of plncmm/roberta-clinical-wl-es on the wl dataset for token classification. The model achieved a precision of 0.6865, recall of 0.7355, F1 score of 0.7102, and accuracy of 0.8268 on the evaluation set. The model is suitable for token classification tasks in the clinical domain in Spanish language."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-tum-sv", "modules": [{"role": "model", "module": {"name": "opus-mt-tum-sv", "description": "A transformer-align model for translating from tum to sv."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-tum-sv model is a transformer-align model that translates from tum to sv. It achieved a BLEU score of 23.3 and a chr-F score of 0.410 on the JW300.tum.sv test set."}}], "metrics": [{"dataset": "jw300", "metric": 23.3, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.41, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-setfit-distilbert-base-uncased-sst2-train-16-0", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased__sst2__train-16-0", "description": "A fine-tuned version of distilbert-base-uncased on the SST2 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 4, "eval_batch_size": 4, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 50, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of distilbert-base-uncased on the SST2 dataset. It can be used for text classification tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 4. The model was trained for 50 epochs and achieved an accuracy of 0.5091 and a loss of 0.6903 on the evaluation set. The model was trained using PyTorch 1.10.2+cu102 and Transformers 4.15.0."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "sst-stanford-sentiment-treebank"}], "metrics": [{"dataset": "sst-stanford-sentiment-treebank", "metric": 0.5091, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-abdelkader-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. The model is best suited for text classification tasks. The model achieved an accuracy of 0.9215 and an F1 score of 0.9216 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.9215, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.9215604730468001, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-sm-en", "modules": [{"role": "model", "module": {"name": "opus-mt-sm-en", "description": "A transformer-align model for translating from Samoan (sm) to English (en)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-sm-en is a transformer-align model for translating from Samoan to English. The model was trained on the OPUS dataset and uses normalization and SentencePiece for pre-processing. The model achieved a BLEU score of 36.1 and a chr-F score of 0.520 on the JW300.sm.en test set."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "jw300"}], "metrics": [{"dataset": "jw300", "metric": 36.1, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.52, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-michelecafagna26-t5-base-finetuned-sst2-sentiment", "modules": [{"role": "model", "module": {"name": "T5-base fine-tuned for Sentiment Analysis", "description": "Google's T5 base model fine-tuned on SST-2 dataset for sentiment analysis downstream task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"epochs": 10, "max_length": 128, "truncation": true}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "T5-base model has been fine-tuned on SST-2 dataset for sentiment analysis. The model can classify the sentiment of a given text as positive or negative. The model has achieved an accuracy of 0.95 on the validation set. The model can be used to classify the sentiment of a given text using the provided Python code snippet."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "sst-stanford-sentiment-treebank"}], "metrics": [{"dataset": "sst-stanford-sentiment-treebank", "metric": 0.95, "protocol": "precision"}, {"dataset": "sst-stanford-sentiment-treebank", "metric": 0.95, "protocol": "recall"}, {"dataset": "sst-stanford-sentiment-treebank", "metric": 0.95, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-justinqbui-bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets", "modules": [{"role": "model", "module": {"name": "bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets", "description": "Further pre-trained version of vinai/bertweet-covid19-base-uncased on masked language modeling using a kaggle dataset with tweets up until early December."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "fill-mask"}, {"role": "solutionSummary", "module": {"summary": "bertweet-covid19-base-uncased-pretraining-covid-vaccine-tweets is a further pre-trained version of bertweet on masked language modeling using a kaggle dataset with tweets up until early December. The model is intended to be fine-tuned on a downstream task related to covid and covid vaccines. The model has many potential biases and limitations since it is trained on public tweets, which may recreate biases that people tweet."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "covid-19-twitter-chatter-dataset"}], "metrics": [{"dataset": "covid-19-twitter-chatter-dataset", "metric": 1.5715, "split": "val", "protocol": "loss"}, {"dataset": "covid-19-twitter-chatter-dataset", "metric": 1.5394, "split": "test", "protocol": "loss"}, {"dataset": "covid-19-twitter-chatter-dataset", "metric": 4.64, "protocol": "perplexity"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-ro-fi", "modules": [{"role": "model", "module": {"name": "opus-mt-ro-fi", "description": "A transformer-align model for translating from Romanian to Finnish."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-ro-fi model is a transformer-align model that translates from Romanian to Finnish. It was trained on the OPUS dataset using normalization and SentencePiece preprocessing. The model achieved a BLEU score of 25.2 and a chr-F score of 0.521 on the JW300.ro.fi test set."}}], "metrics": [{"dataset": "jw300", "metric": 25.2, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.521, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-dbarbedillo-dqn-spaceinvadersnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "DQN", "description": "A trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "buffer_size": 100000, "exploration_final_eps": 0.01, "exploration_fraction": 0.1, "frame_stack": 4, "gradient_steps": 1, "learning_rate": 0.0001, "learning_starts": 100000, "n_timesteps": 10000000.0, "optimize_memory_usage": true, "policy": "CnnPolicy", "target_update_interval": 1000, "train_freq": 4, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "The DQN model is a reinforcement learning agent trained on the SpaceInvadersNoFrameskip-v4 environment using the stable-baselines3 library and the RL Zoo. The model achieved a mean reward of 955.50 +/- 322.11. The hyperparameters used for training include batch size, buffer size, exploration fraction, learning rate, and target update interval, among others. The model is suitable for playing SpaceInvadersNoFrameskip-v4, but may not generalize well to other environments."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 955.5, "split": "val", "protocol": "mean_reward"}, {"dataset": "atari-grand-challenge", "metric": 322.11, "split": "test", "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-kinahem-dqn-spaceinvadersnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "DQN Agent playing SpaceInvadersNoFrameskip-v4", "description": "A trained DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "buffer_size": 100000, "exploration_final_eps": 0.01, "exploration_fraction": 0.1, "frame_stack": 4, "gradient_steps": 1, "learning_rate": 0.0001, "learning_starts": 100000, "n_timesteps": 10000000.0, "optimize_memory_usage": true, "policy": "CnnPolicy", "target_update_interval": 1000, "train_freq": 4, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The model was trained with a batch size of 32, a buffer size of 100000, and a learning rate of 0.0001. The mean reward achieved by the model is 511.00 with a standard deviation of 200.66. The model is suitable for reinforcement learning tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 511.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-mitchelc-finetuning-sentiment-model-3000-samples", "modules": [{"role": "model", "module": {"name": "finetuning-sentiment-model-3000-samples", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "finetuning-sentiment-model-3000-samples is a fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis. The model achieves an accuracy of 0.87 and an F1 score of 0.8696 on the evaluation set. The model is suitable for text classification tasks, but its performance may vary depending on the specific use case and data distribution."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.87, "protocol": "accuracy"}, {"dataset": "imdb-movie-reviews", "metric": 0.8696, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-thucdangvan020999-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8649 on the evaluation set. The model is suitable for token classification tasks in German language. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8648740833380706, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-exploiter345-dqn-spaceinvadersnoframeskip-v0", "modules": [{"role": "model", "module": {"name": "DQN Agent playing SpaceInvadersNoFrameskip-v4", "description": "A trained DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "buffer_size": 100000, "exploration_final_eps": 0.01, "exploration_fraction": 0.1, "frame_stack": 4, "gradient_steps": 1, "learning_rate": 0.0001, "learning_starts": 100000, "n_timesteps": 1000.0, "optimize_memory_usage": false, "policy": "CnnPolicy", "target_update_interval": 1000, "train_freq": 4, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The model was trained with a batch size of 32, a buffer size of 100000, and a learning rate of 0.0001. The mean reward achieved by the model is 6.50 with a standard deviation of 16.29. The model is suitable for reinforcement learning tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-100k"}], "metrics": [{"dataset": "atari-100k", "metric": 6.5, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-tbasic5-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. The model achieved an accuracy of 0.925 and an F1 score of 0.9250 on the evaluation set. The model is suitable for text classification tasks, but its intended uses and limitations are not specified in the model card."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.925, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.925022224520608, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-ceyda-wav2vec2-large-xlsr-53-turkish", "modules": [{"role": "model", "module": {"name": "XLSR Wav2Vec2 Turkish by Ceyda Cinarel", "description": "Fine-tuned Wav2Vec2-Large-XLSR-53 on Turkish using the Common Voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "Wav2Vec2-Large-XLSR-53", "batch_size": 8, "optimizer": {"name": "Adam", "learning_rate": 0.0001, "beta1": 0.9, "beta2": 0.999, "weight_decay": 0.01}}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "XLSR Wav2Vec2 Turkish is a speech recognition model fine-tuned on the Common Voice Turkish dataset. The model is based on the Wav2Vec2-Large-XLSR-53 architecture and was trained using the Adam optimizer with a learning rate of 0.0001. The model achieved a WER of 27.59% on the Common Voice Turkish test dataset. The model can be used directly for speech recognition without a language model."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 27.59, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-victen-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. It can be used for text classification tasks. The model achieved an accuracy of 0.9235 and an F1 score of 0.9237 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.9235, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.9236951195245434, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-runwayml-stable-diffusion-v1-5", "modules": [{"role": "model", "module": {"name": "Stable Diffusion v1-5", "description": "A latent text-to-image diffusion model capable of generating photo-realistic images given any text input."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"resolution": "512x512", "text_encoder": "CLIP ViT-L/14", "training_data": "LAION-2B (en) and subsets thereof", "optimizer": {"name": "AdamW", "learning_rate": "warmup to 0.0001 for 10,000 steps and then kept constant"}}}}, {"role": "taskType", "module": "text-to-image"}, {"role": "solutionSummary", "module": {"summary": "Stable Diffusion v1-5 is a latent text-to-image diffusion model that can generate photo-realistic images given any text input. The model is intended for research purposes only and is not suitable for generating harmful content. The model was trained on LAION-2B (en) and subsets thereof and uses a CLIP ViT-L/14 text encoder. The model is capable of generating images at a resolution of 512x512. The model reflects the biases inherent to the systems they were trained on, so caution should be taken when deploying it into systems that interact with humans."}}, {"role": "dataset", "purpose": "For evaluation.", "module": "coco-microsoft-common-objects-in-context"}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-nso-sv", "modules": [{"role": "model", "module": {"name": "opus-mt-nso-sv", "description": "A machine translation model that translates from the Northern Sotho language to Swedish."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-nso-sv is a machine translation model that translates from Northern Sotho to Swedish. The model uses the transformer-align architecture and was preprocessed using normalization and SentencePiece. The model achieved a BLEU score of 34.3 and a chr-F score of 0.527 on the JW300.nso.sv test set."}}], "metrics": [{"dataset": "jw300", "metric": 34.3, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.527, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-arpanghoshal-emoroberta", "modules": [{"role": "model", "module": {"name": "EmoRoBERTa", "description": "A RoBERTa model fine-tuned on the GoEmotions dataset for text classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "epochs": 10, "max_seq_length": 50, "batch_size": 16, "warmup_proportion": 0.1, "epsilon": 1e-08}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "EmoRoBERTa is a RoBERTa model fine-tuned on the GoEmotions dataset for text classification. It was trained with modified hyperparameters and on an order of magnitude more data than BERT, allowing for better generalization to downstream tasks. The model can classify text into 28 emotions, including neutral. The best result achieved on the GoEmotions dataset was a Macro F1 score of 49.30%."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-lt-it", "modules": [{"role": "model", "module": {"name": "lit-ita", "description": "A transformer model for translating from Lithuanian to Italian."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece (spm32k,spm32k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "A transformer model for translating from Lithuanian to Italian. The model was trained on the Tatoeba dataset and achieved a BLEU score of 42.2 and a chrF2 score of 0.657 on the test set. The model uses normalization and SentencePiece (spm32k,spm32k) for preprocessing."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "tatoeba"}], "metrics": [{"dataset": "tatoeba", "metric": 42.2, "protocol": "BLEU"}, {"dataset": "tatoeba", "metric": 0.657, "protocol": "chrF2"}], "source": "huggingface"}, {"id": "huggingface-bipin-image-caption-generator", "modules": [{"role": "model", "module": {"name": "Image-caption-generator", "description": "A model trained on Flickr8k dataset to generate captions given an image."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "image-to-text"}, {"role": "solutionSummary", "module": {"summary": "The Image-caption-generator model is trained on the Flickr8k dataset to generate captions given an image. The model uses a VisionEncoderDecoderModel and ViTFeatureExtractor from the transformers library. The model achieved an eval_loss of 0.2536 on the evaluation set. The model can be fine-tuned on other image captioning tasks. The model was trained using PyTorch, Transformers, Datasets, and Tokenizers libraries."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "flickr30k"}], "metrics": [{"dataset": "flickr30k", "metric": 0.2536, "protocol": "eval_loss"}, {"dataset": "flickr30k", "metric": 25.369, "protocol": "eval_runtime"}, {"dataset": "flickr30k", "metric": 63.818, "protocol": "eval_samples_per_second"}, {"dataset": "flickr30k", "metric": 8.002, "protocol": "eval_steps_per_second"}, {"dataset": "flickr30k", "metric": 4.0, "protocol": "epoch"}, {"dataset": "flickr30k", "metric": 3236.0, "protocol": "step"}], "source": "huggingface"}, {"id": "huggingface-kirangritz1997-finetuning-sentiment-model-3000-samples", "modules": [{"role": "model", "module": {"name": "finetuning-sentiment-model-3000-samples", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis. It achieves an accuracy of 0.8733 and an F1 score of 0.8742 on the evaluation set. The model is suitable for text classification tasks, but its performance may vary depending on the specific use case. The training hyperparameters include a learning rate of 2e-05, a batch size of 16, and a linear learning rate scheduler."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.8733, "protocol": "accuracy"}, {"dataset": "imdb-movie-reviews", "metric": 0.8742, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-dooglak-tagged-one-250v6-ner-model-3epochs-augmented", "modules": [{"role": "model", "module": {"name": "Tagged_One_250v6_NER_Model_3Epochs_AUGMENTED", "description": "A fine-tuned version of bert-base-cased on the tagged_one250v6_wikigold_split dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "Tagged_One_250v6_NER_Model_3Epochs_AUGMENTED is a fine-tuned version of bert-base-cased on the tagged_one250v6_wikigold_split dataset for token classification. The model achieved a precision of 0.5705, recall of 0.4716, F1 score of 0.5164, and accuracy of 0.8943 on the evaluation set. The model was trained for 3 epochs with a learning rate of 2e-05 and Adam optimizer with betas=(0.9,0.999) and epsilon=1e-08."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wikisplit"}], "metrics": [{"dataset": "wikisplit", "metric": 0.5705062861026163, "protocol": "precision"}, {"dataset": "wikisplit", "metric": 0.47162921348314607, "protocol": "recall"}, {"dataset": "wikisplit", "metric": 0.5163770567430417, "protocol": "f1"}, {"dataset": "wikisplit", "metric": 0.8943313292578184, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-thatdramebaazguy-roberta-base-wikimovies", "modules": [{"role": "model", "module": {"name": "roberta-base for MLM", "description": "Pretrained model on English language using a masked language modeling (MLM) objective."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"num_examples": 4346, "batch_size": 16, "n_epochs": 3, "base_LM_model": "roberta-base", "learning_rate": 5e-05, "max_query_length": 64, "gradient_accumulation_steps": 1, "total_optimization_steps": 816, "evaluation_strategy": "IntervalStrategy.NO", "prediction_loss_only": false, "per_device_train_batch_size": 8, "per_device_eval_batch_size": 8, "adam_beta1": 0.9, "adam_beta2": 0.999, "adam_epsilon": 1e-08, "max_grad_norm": 1.0, "lr_scheduler_type": "SchedulerType.LINEAR", "warmup_ratio": 0.0, "seed": 42, "eval_steps": 500, "metric_for_best_model": null, "greater_is_better": null, "label_smoothing_factor": 0.0}}}, {"role": "taskType", "module": "fill-mask"}, {"role": "solutionSummary", "module": {"summary": "Roberta-base is a transformer model pre-trained on a large English corpus. It can be used for masked language modeling or next sentence prediction, but it's mainly intended to be fine-tuned on a downstream task. The model is suitable for tasks that use the whole sentence to make decisions, such as sequence classification, token classification, or question answering. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wikimovies"}], "metrics": [{"dataset": "wikimovies", "metric": 4.3808, "protocol": "perplexity"}], "source": "huggingface"}, {"id": "huggingface-vanhoan-distilbert-base-uncased-wholewordmasking-finetuned-imdb", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-WholeWordMasking-finetuned-imdb", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-WholeWordMasking-finetuned-imdb is a fine-tuned version of distilbert-base-uncased on the imdb dataset. It can be used for text classification tasks. The model was trained for 3 epochs with a learning rate of 2e-05 and a batch size of 64. The model achieved a loss of 0.6211 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.6211, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-kareldo-lstm-cebab-confounding-food-service-positive-absa-5-class-seed-42", "modules": [{"role": "model", "module": {"name": "lstm.CEBaB_confounding.food_service_positive.absa.5-class.seed_42", "description": "A fine-tuned version of lstm on the OpenTable OPENTABLE-ABSA dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.001, "train_batch_size": 32, "eval_batch_size": 32, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5.0}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of lstm on the OpenTable OPENTABLE-ABSA dataset. It achieves an accuracy of 0.7224 on the evaluation set. The model is suitable for text classification tasks. More information is needed to provide a complete description of the model."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "restaurant-acos"}], "metrics": [{"dataset": "restaurant-acos", "metric": 0.7223582211342309, "protocol": "accuracy"}, {"dataset": "restaurant-acos", "metric": 0.7183, "protocol": "Macro-f1"}, {"dataset": "restaurant-acos", "metric": 0.7238, "protocol": "Weighted-macro-f1"}], "source": "huggingface"}, {"id": "huggingface-gokuls-bert-tiny-emotion-kd-bert-and-distilbert", "modules": [{"role": "model", "module": {"name": "bert-tiny-emotion-KD-BERT_and_distilBERT", "description": "A fine-tuned version of google/bert_uncased_L-2_H-128_A-2 on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 50, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-tiny-emotion-KD-BERT_and_distilBERT is a fine-tuned version of google/bert_uncased_L-2_H-128_A-2 on the emotion dataset. The model achieved an accuracy of 0.918 on the evaluation set. The model is suitable for text classification tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emocontext"}], "metrics": [{"dataset": "emocontext", "metric": 0.918, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-en-distilbert-base-uncased-finetuned-squad", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-squad", "description": "A fine-tuned version of distilbert-base-uncased on the squad dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-squad is a fine-tuned version of distilbert-base-uncased on the squad dataset. It can be used for question answering tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for 3 epochs and achieved a loss of 1.1453 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 1.1453, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-jmagine-dialogpt-small-funded", "modules": [{"role": "model", "module": {"name": "Funded DialoGPT Model", "description": "A conversational response model trained on a large corpus of English text."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"max_length": 1024, "num_attention_heads": 16, "num_layers": 4, "num_train_epochs": 10, "per_device_train_batch_size": 2, "per_device_eval_batch_size": 2, "warmup_steps": 10000, "weight_decay": 0.01}}}, {"role": "taskType", "module": "conversational"}, {"role": "solutionSummary", "module": {"summary": "The Funded DialoGPT Model is a conversational response model trained on a large corpus of English text from Reddit. It uses a transformer architecture with 16 attention heads and 4 layers. The model was trained for 10 epochs with a batch size of 2 and a maximum sequence length of 1024. The model achieved a perplexity score of 19.8 on the Reddit dataset. The model is best suited for generating coherent and relevant responses in a conversational context."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-anuragshas-wav2vec2-xls-r-300m-hi-cv9-with-lm", "modules": [{"role": "model", "module": {"name": "XLS-R-300M - Hindi", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-300m on the MOZILLA-FOUNDATION/COMMON_VOICE_9_0 - HI dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 7.5e-05, "train_batch_size": 64, "eval_batch_size": 64, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 128, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "training_steps": 9815, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the MOZILLA-FOUNDATION/COMMON_VOICE_9_0 - HI dataset. The model is intended for automatic speech recognition tasks. The model achieved a WER of 21.145 and a CER of 7.709 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 7.5e-05 and a linear learning rate scheduler with a warmup ratio of 0.1. The model was trained for 9815 steps with a batch size of 128 using mixed precision training."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 21.145, "protocol": "wer"}, {"dataset": "common-voice", "metric": 7.709, "protocol": "cer"}], "source": "huggingface"}, {"id": "huggingface-samayl24-vit-base-beans-demo-v5", "modules": [{"role": "model", "module": {"name": "vit-base-beans-demo-v5", "description": "A fine-tuned version of google/vit-base-patch16-224-in21k on the beans dataset for image classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0002, "train_batch_size": 16, "eval_batch_size": 8, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 4, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "vit-base-beans-demo-v5 is a fine-tuned version of google/vit-base-patch16-224-in21k on the beans dataset for image classification. The model achieved an accuracy of 0.9925 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 0.0002, a batch size of 16, and a linear learning rate scheduler. The model was trained for 4 epochs with mixed precision training. The model was implemented using Transformers 4.20.1, Pytorch 1.12.0+cu113, Datasets 2.3.2, and Tokenizers 0.12.1."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "plantvillage"}], "metrics": [{"dataset": "plantvillage", "metric": 0.9924812030075187, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-sv-gaa", "modules": [{"role": "model", "module": {"name": "opus-mt-sv-gaa", "description": "A machine translation model that translates from Swedish (sv) to G\u00e3 (gaa) using the transformer-align architecture."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-sv-gaa is a machine translation model that translates from Swedish to G\u00e3 using the transformer-align architecture. The model achieved a BLEU score of 31.3 and a chr-F score of 0.522 on the JW300.sv.gaa test set."}}], "metrics": [{"dataset": "jw300", "metric": 31.3, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.522, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-luciano-bert-base-multilingual-cased-finetuned-lener-br-finetuned-lener-br", "modules": [{"role": "model", "module": {"name": "bert-base-multilingual-cased-finetuned-lener_br-finetuned-lener-br", "description": "Fine-tuned version of bert-base-multilingual-cased on the lener_br dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 2, "eval_batch_size": 2, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 15, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of bert-base-multilingual-cased on the lener_br dataset for token classification. It achieves high precision, recall, F1, and accuracy scores on the evaluation set. The model is suitable for token classification tasks in Portuguese language. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "lener-br"}], "metrics": [{"dataset": "lener-br", "metric": 0.9122, "protocol": "Precision"}, {"dataset": "lener-br", "metric": 0.9163, "protocol": "Recall"}, {"dataset": "lener-br", "metric": 0.9142, "protocol": "F1"}, {"dataset": "lener-br", "metric": 0.9826, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-martinomensio-racism-models-w-m-vote-nonstrict-epoch-4", "modules": [{"role": "model", "module": {"name": "racism-models-w-m-vote-nonstrict-epoch-4", "description": "Fine-tuned version of BETO (spanish bert) on the Datathon Against Racism dataset (2022)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"method": "w-m-vote-nonstrict", "epochs": 4}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of BETO (spanish bert) on the Datathon Against Racism dataset (2022). It is a text classification model that can classify text as either racist or non-racist. The model was fine-tuned using 6 different methods of ground-truth estimations, and for each method, 4 epochs of fine-tuning were performed. This specific model was trained using the w-m-vote-nonstrict method for 4 epochs."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-vuiseng9-pegasus-xsum", "modules": [{"role": "model", "module": {"name": "Pegasus", "description": "A pre-trained transformer model for text summarization."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_name_or_path": "google/pegasus-large", "adafactor": true, "learning_rate": 0.0001, "label_smoothing_factor": 0.1, "num_train_epochs": 4.9, "per_device_train_batch_size": 8, "per_device_eval_batch_size": 16, "num_beams": 8, "max_source_length": 512, "max_target_length": 64}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "Pegasus is a pre-trained transformer model for text summarization. It was trained on a large corpus of text using a self-supervised fashion. The model is fine-tuned on the XSum dataset for summarization tasks. The model uses a maximum source length of 512 and a maximum target length of 64. The model uses AdaFactor optimizer with a learning rate of 0.0001 and a label smoothing factor of 0.1. The model achieved a predict loss of 1.5801 and a ROUGE-1 score of 47.2124 on the XSum dataset."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xsum"}], "metrics": [{"dataset": "xsum", "metric": 1.5801, "protocol": "predict_loss"}, {"dataset": "xsum", "metric": 47.2124, "protocol": "predict_rouge1"}, {"dataset": "xsum", "metric": 24.3673, "protocol": "predict_rouge2"}, {"dataset": "xsum", "metric": 39.0055, "protocol": "predict_rougeL"}, {"dataset": "xsum", "metric": 39.0007, "protocol": "predict_rougeLsum"}], "source": "huggingface"}, {"id": "huggingface-anditya-xlm-roberta-base-finetuned-marc-en", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-marc-en", "description": "A fine-tuned version of xlm-roberta-base on the amazon_reviews_multi dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "xlm-roberta-base-finetuned-marc-en is a fine-tuned version of xlm-roberta-base on the amazon_reviews_multi dataset. The model is suitable for text classification tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for 2 epochs and achieved a loss of 0.8885 and a mean absolute error of 0.4390 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "amazon-product-data"}], "metrics": [{"dataset": "amazon-product-data", "metric": 0.8885, "protocol": "loss"}, {"dataset": "amazon-product-data", "metric": 0.439, "protocol": "mae"}], "source": "huggingface"}, {"id": "huggingface-tkubotake-xlm-roberta-base-finetuned-panx-en", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-en", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "xlm-roberta-base-finetuned-panx-en is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. The model achieved an F1 score of 0.7580 on the evaluation set. The model is suitable for token classification tasks in English, but caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.7580275229357799, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-akari-albert-base-v2-finetuned-squad", "modules": [{"role": "model", "module": {"name": "albert-base-v2-finetuned-squad", "description": "A fine-tuned version of albert-base-v2 on the squad_v2 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "albert-base-v2-finetuned-squad is a fine-tuned version of albert-base-v2 on the squad_v2 dataset. It is suitable for question answering tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for 3 epochs and achieved a loss of 0.9492 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 0.9492, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-freelancerfel-dqn-spaceinvadersnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "DQN", "description": "A trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "buffer_size": 100000, "exploration_final_eps": 0.01, "exploration_fraction": 0.1, "frame_stack": 4, "gradient_steps": 1, "learning_rate": 0.0001, "learning_starts": 100000, "n_timesteps": 1000000.0, "optimize_memory_usage": true, "policy": "CnnPolicy", "target_update_interval": 1000, "train_freq": 4, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The model was trained with a batch size of 32, a buffer size of 100000, and a learning rate of 0.0001. The model achieved a mean reward of 692.50 with a standard deviation of 193.97. The model is suitable for reinforcement learning tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 692.5, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-jamescalam-mpnet-snli-negatives", "modules": [{"role": "model", "module": {"name": "MPNet NLI", "description": "A sentence-transformers model fine-tuned on the Stanford Natural Language Inference (SNLI) dataset for sentence similarity tasks."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "loss_function": "MultipleNegativesRankingLoss", "scale": 20.0, "similarity_function": "cos_sim", "optimizer": {"name": "AdamW", "learning_rate": 2e-05, "weight_decay": 0.01}, "epochs": 1, "warmup_steps": 466, "max_seq_length": 512}}}, {"role": "taskType", "module": "sentence-similarity"}, {"role": "solutionSummary", "module": {"summary": "MPNet NLI is a sentence-transformers model fine-tuned on the Stanford Natural Language Inference (SNLI) dataset for sentence similarity tasks. It maps sentences and paragraphs to a 768-dimensional dense vector space and can be used for tasks like clustering or semantic search. The model returns MRR@10 and MAP scores of ~0.95 on the SNLI test set. The model is suitable for tasks that require sentence similarity, such as clustering or semantic search."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "snli-stanford-natural-language-inference"}], "metrics": [{"dataset": "snli-stanford-natural-language-inference", "metric": 0.95, "protocol": "MRR@10"}, {"dataset": "snli-stanford-natural-language-inference", "metric": 0.95, "protocol": "MAP"}], "source": "huggingface"}, {"id": "huggingface-axhyra-presentation-emotion-1234567", "modules": [{"role": "model", "module": {"name": "presentation_emotion_1234567", "description": "A fine-tuned version of distilbert-base-uncased on the tweet_eval dataset for emotion classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5.18796906442746e-05, "train_batch_size": 8, "eval_batch_size": 8, "seed": 1234567, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 4}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "presentation_emotion_1234567 is a fine-tuned version of distilbert-base-uncased on the tweet_eval dataset for emotion classification. The model achieved an F1 score of 0.7273 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 5.18796906442746e-05 and a linear learning rate scheduler for 4 epochs. The model was trained using the Transformers 4.12.5, Pytorch 1.9.1, Datasets 1.16.1, and Tokenizers 0.10.3."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "tweeteval"}], "metrics": [{"dataset": "tweeteval", "metric": 0.7272977042723248, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-danlupu-sentiment-analysis", "modules": [{"role": "model", "module": {"name": "sentiment-analysis", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis. It achieves an accuracy of 0.8667 and an F1 score of 0.8658 on the evaluation set. The model is suitable for text classification tasks, but its performance may vary depending on the specific use case and data distribution."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.8667, "protocol": "accuracy"}, {"dataset": "imdb-movie-reviews", "metric": 0.8658, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-d4niel92-xlm-roberta-base-finetuned-marc-en", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-marc-en", "description": "A fine-tuned version of xlm-roberta-base on the amazon_reviews_multi dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "xlm-roberta-base-finetuned-marc-en is a fine-tuned version of xlm-roberta-base on the amazon_reviews_multi dataset. The model is suitable for text classification tasks. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for 2 epochs and achieved a validation loss of 0.8976 and a mean absolute error of 0.4268."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "amazon-product-data"}], "metrics": [{"dataset": "amazon-product-data", "metric": 0.8976, "protocol": "loss"}, {"dataset": "amazon-product-data", "metric": 0.4268, "protocol": "mae"}], "source": "huggingface"}, {"id": "huggingface-k3lana-xlm-roberta-base-finetuned-panx-it", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-it", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "xlm-roberta-base-finetuned-panx-it is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. The model achieved an F1 score of 0.8124 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 5e-05 and a batch size of 24. The model was trained for 3 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8124, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-sshreshtha-vit-base-patch32-224-in21k-finetuned-eurosat", "modules": [{"role": "model", "module": {"name": "vit-base-patch32-224-in21k-finetuned-eurosat", "description": "A fine-tuned version of google/vit-base-patch32-224-in21k on the food101 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 32, "eval_batch_size": 32, "seed": 42, "gradient_accumulation_steps": 4, "total_train_batch_size": 128, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "num_epochs": 3}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of google/vit-base-patch32-224-in21k on the food101 dataset. The model achieved an accuracy of 0.7321 on the evaluation set. More information is needed to describe the model and its intended uses and limitations."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "food-101"}], "metrics": [{"dataset": "food-101", "metric": 0.7321452145214521, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-yap-sv", "modules": [{"role": "model", "module": {"name": "opus-mt-yap-sv", "description": "A transformer-align model for translation from Yap to Swedish."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-yap-sv model is a transformer-align model for translating from Yap to Swedish. It was trained on the OPUS dataset using normalization and SentencePiece pre-processing. The model achieved a BLEU score of 22.6 and a chr-F score of 0.399 on the JW300.yap.sv test set."}}], "metrics": [{"dataset": "jw300", "metric": 22.6, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.399, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-intel-distilbart-cnn-12-6-int8-dynamic", "modules": [{"role": "model", "module": {"name": "INT8 DistilBart finetuned on CNN DailyMail", "description": "A PyTorch model quantized with Intel Neural Compressor using post-training dynamic quantization."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"quantization_method": "PostTrainingDynamic", "fallback_modules": ["model.decoder.layers.2.fc2", "model.encoder.layers.11.fc2", "model.decoder.layers.1.fc2", "model.decoder.layers.0.fc2", "model.decoder.layers.4.fc1", "model.decoder.layers.3.fc2", "model.encoder.layers.8.fc2", "model.decoder.layers.3.fc1", "model.encoder.layers.11.fc1", "model.encoder.layers.0.fc2", "model.encoder.layers.3.fc1", "model.encoder.layers.10.fc2", "model.decoder.layers.5.fc1", "model.encoder.layers.1.fc2", "model.encoder.layers.3.fc2", "lm_head", "model.encoder.layers.7.fc2", "model.decoder.layers.0.fc1", "model.encoder.layers.4.fc1", "model.encoder.layers.10.fc1", "model.encoder.layers.6.fc1"]}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "This is an INT8 PyTorch model quantized with Intel Neural Compressor using post-training dynamic quantization. The model is a fine-tuned version of DistilBart on CNN DailyMail dataset. The model size is reduced from 1249M to 722M with less than 1% relative accuracy loss. The model can be loaded with optimum.intel.neural_compressor.quantization.IncQuantizedModelForSeq2SeqLM.from_pretrained(). The model is best suited for summarization tasks."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "cnn-daily-mail"}], "metrics": [{"dataset": "cnn-daily-mail", "metric": 41.4707, "split": "val", "protocol": "rougeLsum"}, {"dataset": "cnn-daily-mail", "metric": 41.8117, "split": "test", "protocol": "rougeLsum"}], "source": "huggingface"}, {"id": "huggingface-sreek-xlm-roberta-base-finetuned-panx-fr", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-fr", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.9213 on the evaluation set. The model is suitable for token classification tasks in French language. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.9213082901554404, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-moghis-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. The model is best suited for text classification tasks. The model achieved an accuracy of 0.924 and an F1 score of 0.9241 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.924, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.9240615969601907, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-arafatbhossain-distiled-flip-model-emotion-alpha-0-8-epoch5-v1", "modules": [{"role": "model", "module": {"name": "distiled_flip_model_emotion_alpha_0.8_epoch5_v1", "description": "A fine-tuned version of ArafatBHossain/distill_bert_fine_tuned_emotion_dataset on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "A fine-tuned version of distill_bert_fine_tuned_emotion_dataset on the emotion dataset. Achieves an accuracy of 0.942 on the evaluation set. The model is suitable for text classification tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.942, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-mrshu-wav2vec2-large-xlsr-slovene", "modules": [{"role": "model", "module": {"name": "XLSR Wav2Vec2 Slovene", "description": "Fine-tuned Wav2Vec2-Large-XLSR-53 on Slovene using the Common Voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "Wav2Vec2-Large-XLSR-53", "batch_size": 8, "optimizer": {"name": "Adam", "learning_rate": 5e-05, "beta1": 0.9, "beta2": 0.98, "epsilon": 1e-06}}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "XLSR Wav2Vec2 Slovene is a fine-tuned Wav2Vec2-Large-XLSR-53 model on Slovene using the Common Voice dataset. The model is intended for speech recognition tasks and can be used directly without a language model. The model was trained on the Common Voice train and validation datasets and evaluated on the Common Voice test dataset. The model achieved a WER of 36.97% on the test dataset."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 36.97, "protocol": "WER"}], "source": "huggingface"}, {"id": "huggingface-hatemnoaman-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. The model is best suited for text classification tasks. The model achieved an accuracy of 0.926 and an F1 score of 0.9259822329831515 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.926, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.9259822329831515, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-priya9-wav2vec2-large-xls-r-300m-turkish-colab", "modules": [{"role": "model", "module": {"name": "wav2vec2-large-xls-r-300m-turkish-colab", "description": "A fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0003, "train_batch_size": 16, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 10, "mixed_precision_training": true}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "The wav2vec2-large-xls-r-300m-turkish-colab model is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset. It is intended for automatic speech recognition tasks. The model was trained with Adam optimizer and linear learning rate scheduler. The model achieved a validation loss of 0.3859 and a WER of 0.4680."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.3955, "split": "val", "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.3859, "split": "test", "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.468, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-eo-pt", "modules": [{"role": "model", "module": {"name": "epo-por", "description": "A transformer model for translation from Esperanto to Portuguese."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece (spm4k,spm4k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "epo-por is a transformer model for translation from Esperanto to Portuguese. It was trained on the Tatoeba dataset and achieved a BLEU score of 20.2 and a chrF2 score of 0.438 on the test set. The model uses normalization and SentencePiece (spm4k,spm4k) for preprocessing. The model is suitable for translation tasks from Esperanto to Portuguese."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "tatoeba-translation-challenge"}], "metrics": [{"dataset": "tatoeba-translation-challenge", "metric": 20.2, "protocol": "BLEU"}, {"dataset": "tatoeba-translation-challenge", "metric": 0.438, "protocol": "chrF2"}], "source": "huggingface"}, {"id": "huggingface-oumeima-finetuned-bert-mrpc", "modules": [{"role": "model", "module": {"name": "finetuned-bert-mrpc", "description": "A fine-tuned version of bert-base-cased on the glue dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "finetuned-bert-mrpc is a fine-tuned version of bert-base-cased on the glue dataset. It is a text classification model that achieves an accuracy of 0.8529 and an F1 score of 0.9003 on the evaluation set. The model is intended to be used for text classification tasks, but its limitations and intended uses are not specified in the model card."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.8529, "protocol": "accuracy"}, {"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.9003, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-bchaipats-distilbert-base-uncased-finetuned-ner", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-ner", "description": "A fine-tuned version of distilbert-base-uncased on the conll2003 dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-ner is a fine-tuned version of distilbert-base-uncased on the conll2003 dataset for token classification. The model achieved high scores on the evaluation set, with a precision of 0.9248, recall of 0.9367, F1 of 0.9307, and accuracy of 0.9835. The model is suitable for named entity recognition tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 0.9247846255798542, "protocol": "Precision"}, {"dataset": "conll-2003", "metric": 0.9366819554760041, "protocol": "Recall"}, {"dataset": "conll-2003", "metric": 0.9306952703829268, "protocol": "F1"}, {"dataset": "conll-2003", "metric": 0.9834622777892513, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-elgeish-cs224n-squad2-0-distilbert-base-uncased", "modules": [{"role": "model", "module": {"name": "CS224n SQuAD2.0 Project Dataset", "description": "A fine-tuned model on SQuAD2.0 dataset for CS224n students to establish baselines."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_name_or_path": "distilbert-base-uncased-distilled-squad", "do_lower_case": true, "max_seq_length": 384, "doc_stride": 128, "max_query_length": 64, "per_gpu_train_batch_size": 32, "gradient_accumulation_steps": 24, "learning_rate": 3e-05, "num_train_epochs": 4, "max_answer_length": 30, "weight_decay": 0, "warmup_steps": 0, "version_2_with_negative": true}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "A fine-tuned model on SQuAD2.0 dataset for CS224n students to establish baselines. The model is based on the distilbert-base-uncased-distilled-squad architecture and was trained for 4 epochs with a learning rate of 3e-05. The model achieved an exact match score of 65.17 and an F1 score of 67.87 on the evaluation set. The model is suitable for question-answering tasks with a maximum sequence length of 384 and a maximum query length of 64."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 65.16946363935504, "protocol": "exact"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 67.87348075352251, "protocol": "f1"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 6078.0, "protocol": "total"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 69.51890034364261, "protocol": "HasAns_exact"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 75.16667217179045, "protocol": "HasAns_f1"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 2910.0, "protocol": "HasAns_total"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 61.17424242424242, "protocol": "NoAns_exact"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 61.17424242424242, "protocol": "NoAns_f1"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 3168.0, "protocol": "NoAns_total"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 65.16946363935504, "protocol": "best_exact"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 0.0, "protocol": "best_exact_thresh"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 67.87348075352243, "protocol": "best_f1"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 0.0, "protocol": "best_f1_thresh"}], "source": "huggingface"}, {"id": "huggingface-robertomca97-bert-finetuned-inspec", "modules": [{"role": "model", "module": {"name": "bert-finetuned-inspec", "description": "A fine-tuned version of bert-base-uncased on the inspec dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-finetuned-inspec is a fine-tuned version of bert-base-uncased on the inspec dataset for token classification. The model achieved an F1 score of 0.3035 on the evaluation set. The model is suitable for token classification tasks, but its performance may vary depending on the specific task and dataset. Caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "inspec"}], "metrics": [{"dataset": "inspec", "metric": 0.3035, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-dugerij-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 game."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "is_slippery": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 game. The model was trained using custom implementation and evaluated on the same environment. The mean reward achieved by the model is 7.56 with a standard deviation of 2.71 over multiple evaluation episodes."}}, {"role": "dataset", "purpose": "The game environment used for training and evaluation.", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.56, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-araffin-tqc-rocketlander-v0", "modules": [{"role": "model", "module": {"name": "TQC Agent playing RocketLander-v0", "description": "A trained TQC agent playing RocketLander-v0 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"env_wrapper": [{"rl_zoo3.wrappers.FrameSkip": {"skip": 4}}, {"rl_zoo3.wrappers.HistoryWrapper": {"horizon": 2}}], "n_timesteps": 3000000.0, "policy": "MlpPolicy", "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained TQC agent playing RocketLander-v0 using the stable-baselines3 library and the RL Zoo. The model was trained with the following hyperparameters: env_wrapper, n_timesteps, policy, and normalize. The mean_reward score for the RocketLander-v0 dataset is -0.00 +/- 0.16. The model can be used for reinforcement learning tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": -0.0, "split": "val", "protocol": "mean_reward"}, {"dataset": "openai-gym", "metric": 0.16, "split": "test", "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-cwchengtw-wav2vec2-large-xls-r-300m-turkish-colab", "modules": [{"role": "model", "module": {"name": "wav2vec2-large-xls-r-300m-turkish-colab", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0003, "train_batch_size": 16, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 30, "mixed_precision_training": true}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "The wav2vec2-large-xls-r-300m-turkish-colab model is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset. It is intended for automatic speech recognition tasks. The model was trained with Adam optimizer and linear learning rate scheduler. The model achieved a validation loss of 0.3873 and a WER of 0.3224."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.3873, "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.3224, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-ru-ar", "modules": [{"role": "model", "module": {"name": "rus-ara", "description": "A transformer model pre-trained on Russian and fine-tuned for Arabic translation."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece (spm32k,spm32k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "rus-ara is a transformer model pre-trained on Russian and fine-tuned for Arabic translation. It achieved a BLEU score of 16.6 and a chrF2 score of 0.486 on the Tatoeba-test.rus.ara dataset. The model uses normalization and SentencePiece (spm32k,spm32k) for pre-processing. The model is suitable for translating Russian text to Arabic text."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "tatoeba"}], "metrics": [{"dataset": "tatoeba", "metric": 16.6, "protocol": "BLEU"}, {"dataset": "tatoeba", "metric": 0.486, "protocol": "chrF2"}], "source": "huggingface"}, {"id": "huggingface-zhichao158-wav2vec2-xls-r-common-voice-tr-ft", "modules": [{"role": "model", "module": {"name": "wav2vec2-xls-r-common_voice-tr-ft", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-300m on the COMMON_VOICE - TR dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0005, "train_batch_size": 12, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 100.0, "mixed_precision_training": true}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the COMMON_VOICE - TR dataset. The model is intended for automatic speech recognition tasks. The model achieved a WER of 0.2930 and a CER of 0.0708 on the evaluation set. The model was trained using PyTorch 1.8.0 and Transformers 4.14.1 with mixed precision training."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.0639, "split": "val", "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.3788, "split": "test", "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.293, "protocol": "WER"}, {"dataset": "common-voice", "metric": 0.0708, "protocol": "CER"}], "source": "huggingface"}, {"id": "huggingface-muks-q-taxi-v1-1000", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing Taxi-v3", "description": "A trained model of a Q-Learning agent playing Taxi-v3."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing Taxi-v3. The model uses a Q-table learned by the agent and is evaluated based on the mean reward achieved over a number of evaluation episodes. The model can be loaded and used to evaluate the agent's performance on the Taxi-v3 environment."}}, {"role": "dataset", "purpose": "Reinforcement learning environment", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 10.65, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-jkhan447-sentiment-model-sample-27go-emotion", "modules": [{"role": "model", "module": {"name": "sentiment-model-sample-27go-emotion", "description": "A fine-tuned version of bert-base-uncased on the go_emotions dataset for text classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 32, "eval_batch_size": 32, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 50}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of bert-base-uncased on the go_emotions dataset for text classification. It achieves an accuracy of 0.5889 on the evaluation set. The model is suitable for text classification tasks, but its performance may vary depending on the specific use case. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler for 50 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "goemotions"}], "metrics": [{"dataset": "goemotions", "metric": 0.5889, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-speech31-wav2vec2-large-english-timit-phoneme-v3", "modules": [{"role": "model", "module": {"name": "wav2vec2-large-english-TIMIT-phoneme_v3", "description": "Fine-tuned version of facebook/wav2vec2-large on the TIMIT dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0003, "train_batch_size": 32, "eval_batch_size": 16, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 1000, "num_epochs": 50, "mixed_precision_training": true}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/wav2vec2-large on the TIMIT dataset. The model is best suited for automatic speech recognition tasks. The model was trained on TIMIT dataset training and validation set and evaluated on the test set. The model achieved a CER of 0.0987 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "timit-timit-acoustic-phonetic-continuous-speech-corpus"}], "metrics": [{"dataset": "timit-timit-acoustic-phonetic-continuous-speech-corpus", "metric": 0.0594, "split": "val", "protocol": "loss"}, {"dataset": "timit-timit-acoustic-phonetic-continuous-speech-corpus", "metric": 0.3697, "split": "test", "protocol": "loss"}, {"dataset": "timit-timit-acoustic-phonetic-continuous-speech-corpus", "metric": 0.0987, "protocol": "CER"}], "source": "huggingface"}, {"id": "huggingface-andyjennings-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8591 on the evaluation set. The model is suitable for token classification tasks in German language. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8591260810195721, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-victorlee071200-distilroberta-base-finetuned-squad-v2", "modules": [{"role": "model", "module": {"name": "distilroberta-base-finetuned-squad_v2", "description": "A fine-tuned version of distilroberta-base on the squad_v2 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "distilroberta-base-finetuned-squad_v2 is a fine-tuned version of distilroberta-base on the squad_v2 dataset. It is suitable for question answering tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for 3 epochs and achieved a validation loss of 1.1230."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 0.7547, "split": "val", "protocol": "loss"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 1.123, "split": "test", "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-andrewr-distilbert-base-uncased-finetuned-imdb", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-imdb", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-imdb is a fine-tuned version of distilbert-base-uncased on the imdb dataset. It can be used for text classification tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 64. The model was trained for 3 epochs and achieved a loss of 2.3919 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 2.3919, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-en-af", "modules": [{"role": "model", "module": {"name": "opus-mt-en-af", "description": "A transformer-align model for translating from English to Afrikaans."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-en-af is a transformer-align model for translating from English to Afrikaans. It achieved a BLEU score of 56.1 and a chr-F score of 0.741 on the Tatoeba.en.af test set."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-gokuls-bert-base-emotion-intent", "modules": [{"role": "model", "module": {"name": "bert-base-emotion-intent", "description": "A fine-tuned version of bert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 15, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-base-emotion-intent is a fine-tuned version of bert-base-uncased on the emotion dataset. It can be used for text classification tasks. The model achieved an accuracy of 0.9385 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 5e-05 and a batch size of 16. The model was trained for 15 epochs using mixed precision training."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.9385, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-cmarkea-distilcamembert-base-sentiment", "modules": [{"role": "model", "module": {"name": "DistilCamemBERT-Sentiment", "description": "DistilCamemBERT fine-tuned for the sentiment analysis task for the French language."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "distilcamembert-base", "tokenizer": "distilcamembert-base", "batch_size": 32, "optimizer": {"name": "Adam", "learning_rate": 5e-05}}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "DistilCamemBERT-Sentiment is a DistilCamemBERT model fine-tuned for the sentiment analysis task for the French language. The model is built using two datasets: Amazon Reviews and Allocin\u00e9.fr to minimize bias. The model is suitable for sentiment analysis tasks in French. The model is compared to three reference models and outperforms them in terms of inference time and accuracy. The model is best suited for binary classification tasks, and the performance measure used is top-2 accuracy."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-masusuka-wav2vec2-large-xls-r-300m-tr-colab", "modules": [{"role": "model", "module": {"name": "wav2vec2-large-xls-r-300m-tr-colab", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0003, "train_batch_size": 16, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 100, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset. The model is suitable for automatic speech recognition tasks. The model was trained with Adam optimizer with a learning rate of 0.0003, and a linear learning rate scheduler with warmup steps of 500. The model was trained for 100 epochs with a batch size of 16 and mixed precision training. The model achieved a loss of 0.4316 and a word error rate (WER) of 0.2905 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.4316, "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.2905, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-norbertrop-q-frozenlake-v1-4x4-noslippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model has achieved a mean reward of 1.00 +/- 0.00. The environment for the agent to play in is FrozenLake-v1-4x4-no_slippery."}}, {"role": "dataset", "purpose": "Environment for the agent to play in.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "extra": "1.00 +/- 0.00", "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-sayakpaul-glpn-nyu-finetuned-diode-221116-062619", "modules": [{"role": "model", "module": {"name": "glpn-nyu-finetuned-diode-221116-062619", "description": "A fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset for depth estimation."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-05, "train_batch_size": 24, "eval_batch_size": 48, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "num_epochs": 15, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "depth-estimation"}, {"role": "solutionSummary", "module": {"summary": "glpn-nyu-finetuned-diode-221116-062619 is a fine-tuned version of vinvino02/glpn-nyu on the diode-subset dataset for depth estimation. The model was trained using Adam optimizer with a learning rate of 1e-05 and a batch size of 24. The model was trained for 15 epochs. The model achieved a loss of 0.5480 on the evaluation set. The model is intended for depth estimation tasks, but its limitations and intended uses are not specified."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "diode-dense-indoor-and-outdoor-depth"}], "metrics": [{"dataset": "diode-dense-indoor-and-outdoor-depth", "metric": 0.548, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-nickmuchi-swin-tiny-patch4-window7-224-finetuned-eurosat", "modules": [{"role": "model", "module": {"name": "swin-tiny-patch4-window7-224-finetuned-eurosat", "description": "A fine-tuned version of microsoft/swin-tiny-patch4-window7-224 on the image_folder dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 32, "eval_batch_size": 32, "seed": 42, "gradient_accumulation_steps": 4, "total_train_batch_size": 128, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "num_epochs": 5}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "A fine-tuned version of microsoft/swin-tiny-patch4-window7-224 on the image_folder dataset. The model achieves an accuracy of 0.9848 on the evaluation set. The model is suitable for image classification tasks."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-nso-fr", "modules": [{"role": "model", "module": {"name": "opus-mt-nso-fr", "description": "A machine translation model that translates from the nso language to French."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-nso-fr is a machine translation model that translates from the nso language to French. The model uses the transformer-align architecture and pre-processing techniques such as normalization and SentencePiece. The model has been evaluated on the JW300.nso.fr test set and achieved a BLEU score of 30.7 and a chr-F score of 0.488."}}], "metrics": [{"dataset": "jw300", "metric": 30.7, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.488, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-chou-distilbert-base-uncased-finetuned-imdb", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-imdb", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-imdb is a fine-tuned version of distilbert-base-uncased on the imdb dataset. It can be used for text classification tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 64. The model was trained for 3 epochs and achieved a loss of 2.4453 on the evaluation set. The model was trained using PyTorch and Transformers 4.21.1."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 2.4453, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-ko-fr", "modules": [{"role": "model", "module": {"name": "kor-fra transformer-align", "description": "A machine translation model that translates from Korean to French using a transformer-align architecture."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece (spm32k,spm32k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "A transformer-align machine translation model that translates from Korean to French. The model was trained on the Tatoeba dataset and achieved a BLEU score of 30.4 and a chrF2 score of 0.503 on the test set. The model uses normalization and SentencePiece (spm32k,spm32k) for preprocessing."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "tatoeba-translation-challenge"}], "metrics": [{"dataset": "tatoeba-translation-challenge", "metric": 30.4, "protocol": "BLEU"}, {"dataset": "tatoeba-translation-challenge", "metric": 0.503, "protocol": "chrF2"}], "source": "huggingface"}, {"id": "huggingface-turhancan97-dqn-spaceinvadersnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "DQN", "description": "A trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "buffer_size": 100000, "exploration_final_eps": 0.01, "exploration_fraction": 0.1, "frame_stack": 4, "gradient_steps": 1, "learning_rate": 0.0001, "learning_starts": 100000, "n_timesteps": 500000.0, "optimize_memory_usage": false, "policy": "CnnPolicy", "target_update_interval": 1000, "train_freq": 4, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The model was trained with a batch size of 32, a buffer size of 100000, and a learning rate of 0.0001. The model achieved a mean reward of 424.00 with a standard deviation of 124.70. The model is suitable for reinforcement learning tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 424.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-aleksandar-distilbert-srb-ner", "modules": [{"role": "model", "module": {"name": "distilbert-srb-ner", "description": "Pretrained model on Serbian language using a token classification objective."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 32, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 20}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-srb-ner is a transformer model pretrained on the wikiann dataset for Serbian language using a token classification objective. It can be used for named entity recognition tasks in Serbian language. The model was trained for 20 epochs with a learning rate of 2e-05 and an Adam optimizer with betas=(0.9,0.999) and epsilon=1e-08. The model achieved an accuracy of 0.9577 on the evaluation set. The model was trained using the Transformers 4.9.2, Pytorch 1.9.0, Datasets 1.11.0, and Tokenizers 0.10.1."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wikiann"}], "metrics": [{"dataset": "wikiann", "metric": 0.9577, "protocol": "Accuracy"}, {"dataset": "wikiann", "metric": 0.8871, "protocol": "Precision"}, {"dataset": "wikiann", "metric": 0.91, "protocol": "Recall"}, {"dataset": "wikiann", "metric": 0.8984, "protocol": "F1"}], "source": "huggingface"}, {"id": "huggingface-gchhablani-fnet-large-finetuned-mrpc", "modules": [{"role": "model", "module": {"name": "fnet-large-finetuned-mrpc", "description": "Fine-tuned version of google/fnet-large on the GLUE MRPC dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 4, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5.0}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "fnet-large-finetuned-mrpc is a fine-tuned version of google/fnet-large on the GLUE MRPC dataset. It is a text classification model that can be used to classify text into two categories. The model achieved an accuracy of 0.8260 and an F1 score of 0.8799 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 4. The model was trained for 5 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "mrpc-microsoft-research-paraphrase-corpus"}], "metrics": [{"dataset": "mrpc-microsoft-research-paraphrase-corpus", "metric": 0.826, "protocol": "accuracy"}, {"dataset": "mrpc-microsoft-research-paraphrase-corpus", "metric": 0.8799, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-okite97-xlm-roberta-base-finetuned-panx-fr", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-fr", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8091 on the evaluation set. The model is suitable for token classification tasks in French language. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.809109176155392, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-stevemobs-deberta-base-finetuned-aqa-squad1", "modules": [{"role": "model", "module": {"name": "deberta-base-finetuned-aqa-squad1", "description": "Fine-tuned version of deberta-base-finetuned-aqa on the SQuAD dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 12, "eval_batch_size": 12, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "deberta-base-finetuned-aqa-squad1 is a fine-tuned version of deberta-base-finetuned-aqa on the SQuAD dataset. It is a question-answering model that can be used to answer questions based on a given context. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler. The model achieved a loss of 0.7790 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 0.779, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-de-ho", "modules": [{"role": "model", "module": {"name": "opus-mt-de-ho", "description": "A transformer-align model for translating from German (de) to Hiri Motu (ho)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-de-ho is a transformer-align model for translating from German to Hiri Motu. The model was trained on the OPUS dataset using normalization and SentencePiece preprocessing. The model achieved a BLEU score of 22.6 and a chr-F score of 0.461 on the JW300.de.ho test set."}}], "metrics": [{"dataset": "jw300", "metric": 22.6, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.461, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-flood-xlm-roberta-base-finetuned-panx-fr", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-fr", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8376 on the evaluation set. The model is suitable for token classification tasks in French language. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8376, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-ilo-en", "modules": [{"role": "model", "module": {"name": "transformer-align", "description": "A machine translation model trained on Iloko to English using normalization and SentencePiece (spm12k,spm12k) pre-processing."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece (spm12k,spm12k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "A transformer model trained on Iloko to English using normalization and SentencePiece (spm12k,spm12k) pre-processing. The model achieved a BLEU score of 36.4 and a chrF2 score of 0.558 on the Tatoeba-test.ilo.eng test set."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "tatoeba-translation-challenge"}], "metrics": [{"dataset": "tatoeba-translation-challenge", "metric": 36.4, "protocol": "BLEU"}, {"dataset": "tatoeba-translation-challenge", "metric": 0.558, "protocol": "chrF2"}], "source": "huggingface"}, {"id": "huggingface-recobo-chemical-bert-uncased-squad2", "modules": [{"role": "model", "module": {"name": "Chemical-BERT (uncased) for Question Answering", "description": "A BERT-based model fine-tuned on the SQuAD 2.0 dataset for question answering in the domain of chemistry."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_type": "BERT", "pretrained_model": "bert-base-uncased", "max_seq_length": 384, "doc_stride": 128, "max_query_length": 64, "learning_rate": 3e-05, "num_train_epochs": 2, "per_device_train_batch_size": 16, "per_device_eval_batch_size": 16, "weight_decay": 0.01, "adam_epsilon": 1e-06, "warmup_steps": 0, "gradient_accumulation_steps": 1, "n_best_size": 20, "max_answer_length": 30}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "Chemical-BERT is a BERT-based model fine-tuned on the SQuAD 2.0 dataset for question answering in the domain of chemistry. The model is trained to answer questions related to chemical compounds and their properties. The model is best suited for answering questions in the domain of chemistry. The model was trained with a learning rate of 3e-5 and a weight decay of 0.01 for 2 epochs. The model achieved an F1 score of 87.5 and an EM score of 80.0 on the SQuAD 2.0 dataset."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 87.5, "protocol": "F1"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 80.0, "protocol": "EM"}], "source": "huggingface"}, {"id": "huggingface-rlarios-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. The model achieved an accuracy of 0.9325 and an F1 score of 0.9322 on the evaluation set. The model is suitable for text classification tasks, but its intended uses and limitations are not specified in the model card."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.9325, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.9322428116765227, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-terence3927-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 game."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "q-Taxi-v3 is a Q-Learning agent trained to play the Taxi-v3 game. The model includes the Q-Table learned by the agent and can be used to evaluate the agent's performance. The mean reward achieved by the agent is 7.56 with a standard deviation of 2.71."}}, {"role": "dataset", "purpose": "The game environment used for training and evaluation.", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.56, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-microsoft-xclip-base-patch16-hmdb-2-shot", "modules": [{"role": "model", "module": {"name": "X-CLIP (base-sized model)", "description": "Minimal extension of CLIP for general video-language understanding. Trained in a contrastive way on (video, text) pairs."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"patch_resolution": 16, "frames_per_video": 32, "resolution": "224x224"}}}, {"role": "taskType", "module": "video-classification"}, {"role": "solutionSummary", "module": {"summary": "X-CLIP is a base-sized model that is a minimal extension of CLIP for general video-language understanding. It is trained in a contrastive way on (video, text) pairs, allowing it to be used for tasks like zero-shot, few-shot or fully supervised video classification and video-text retrieval. The model was trained on HMDB-51 and achieves a top-1 accuracy of 53.0%."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "hmdb51"}], "metrics": [{"dataset": "hmdb51", "metric": 53.0, "protocol": "top-1 accuracy"}], "source": "huggingface"}, {"id": "huggingface-frahman-distilbert-base-uncased-finetuned-clinc", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-clinc", "description": "A fine-tuned version of distilbert-base-uncased on the clinc_oos dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 48, "eval_batch_size": 48, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-clinc is a fine-tuned version of distilbert-base-uncased on the clinc_oos dataset. It is a text classification model that can be used to classify out-of-scope queries. The model achieved an accuracy of 0.9187 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler for 5 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "clinc-single-domain-oos"}], "metrics": [{"dataset": "clinc-single-domain-oos", "metric": 0.9187096774193548, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-arrandi-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. The model is best suited for text classification tasks. The model achieved an accuracy of 0.934 and an F1 score of 0.9342 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.934, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.9341704717427723, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-rebolforces-qrdqn-spaceinvadersnoframeskip-20meps", "modules": [{"role": "model", "module": {"name": "QRDQN", "description": "A trained QRDQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"env_wrapper": "stable_baselines3.common.atari_wrappers.AtariWrapper", "exploration_fraction": 0.025, "frame_stack": 4, "n_timesteps": 20000000.0, "optimize_memory_usage": true, "policy": "CnnPolicy", "replay_buffer_kwargs": "dict(handle_timeout_termination=False)", "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained QRDQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The model was trained with the RL Zoo training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included. The model achieved a mean reward of 3510.00 with a standard deviation of 4506.87."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 3510.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-microsoft-xclip-base-patch16-hmdb-4-shot", "modules": [{"role": "model", "module": {"name": "X-CLIP (base-sized model)", "description": "Minimal extension of CLIP for general video-language understanding. Trained in a contrastive way on (video, text) pairs."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"patch_resolution": 16, "frames_per_video": 32, "resolution": "224x224"}}}, {"role": "taskType", "module": "video-classification"}, {"role": "solutionSummary", "module": {"summary": "X-CLIP is a minimal extension of CLIP for general video-language understanding. The model is trained in a contrastive way on (video, text) pairs, allowing it to be used for tasks like zero-shot, few-shot or fully supervised video classification and video-text retrieval. This model was trained on HMDB-51 and achieves a top-1 accuracy of 57.3%."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "hmdb51"}], "metrics": [{"dataset": "hmdb51", "metric": 57.3, "protocol": "top-1 accuracy"}], "source": "huggingface"}, {"id": "huggingface-eslamxm-mbart-finetuned-fa", "modules": [{"role": "model", "module": {"name": "mbart-finetuned-fa", "description": "A fine-tuned version of facebook/mbart-large-50 on the pn_summary dataset for abstractive summarization."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0005, "train_batch_size": 4, "eval_batch_size": 4, "seed": 42, "gradient_accumulation_steps": 8, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 250, "num_epochs": 5, "label_smoothing_factor": 0.1}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "mbart-finetuned-fa is a fine-tuned version of facebook/mbart-large-50 on the pn_summary dataset for abstractive summarization. The model achieved good results on the evaluation set, with high Bertscore and Rouge scores. The model is suitable for generating summaries in Persian language, but caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "pn-summary"}], "metrics": [{"dataset": "pn-summary", "metric": 3.2877, "protocol": "Loss"}, {"dataset": "pn-summary", "metric": 44.07, "protocol": "Rouge-1"}, {"dataset": "pn-summary", "metric": 25.81, "protocol": "Rouge-2"}, {"dataset": "pn-summary", "metric": 38.96, "protocol": "Rouge-l"}, {"dataset": "pn-summary", "metric": 41.7, "protocol": "Gen Len"}, {"dataset": "pn-summary", "metric": 78.95, "protocol": "Bertscore"}], "source": "huggingface"}, {"id": "huggingface-ccoreilly-wav2vec2-large-100k-voxpopuli-catala", "modules": [{"role": "model", "module": {"name": "Wav2Vec2-Large-100k-VoxPopuli-Catal\u00e0", "description": "Fine-tuned Wav2Vec2-Large-100k-VoxPopuli on Catalan language using the Common Voice and ParlamentParla datasets."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "Wav2Vec2-Large-100k-VoxPopuli", "preprocessing": {"resample_rate": 16000}}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Wav2Vec2-Large-100k-VoxPopuli-Catal\u00e0 is a fine-tuned Wav2Vec2-Large-100k-VoxPopuli model on the Catalan language using the Common Voice and ParlamentParla datasets. The model can be used for automatic speech recognition tasks. The model was evaluated on the Common Voice test dataset, Google Crowdsourced Corpus, and Audiobook \u201cLa llegenda de Sant Jordi\u201d. The model achieved a WER of 5.98% on the test split CV+ParlamentParla dataset."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 5.98, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-pjcordero04-distilbert-base-uncased-finetuned-cola", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-cola", "description": "A fine-tuned version of distilbert-base-uncased on the glue dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-cola is a fine-tuned version of distilbert-base-uncased on the glue dataset. It is suitable for text classification tasks. The model achieved a Matthews Correlation score of 0.5443 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 16 for 5 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.5442538936990396, "protocol": "matthews_correlation"}], "source": "huggingface"}, {"id": "huggingface-luffycodes-roberta-large-md-conllpp-v4", "modules": [{"role": "model", "module": {"name": "roberta-large-md-conllpp-v4", "description": "A fine-tuned version of roberta-large on the conllpp dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "roberta-large-md-conllpp-v4 is a fine-tuned version of roberta-large on the conllpp dataset for token classification. The model achieved high precision, recall, f1, and accuracy scores on the evaluation set. The model is suitable for token classification tasks, but its intended uses and limitations are not specified in the model card."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 0.9961201725502208, "protocol": "precision"}, {"dataset": "conll-2003", "metric": 0.9967053174643714, "protocol": "recall"}, {"dataset": "conll-2003", "metric": 0.9964126591004837, "protocol": "f1"}, {"dataset": "conll-2003", "metric": 0.9939485302035103, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-nateraw-vit-base-beans-demo-v2", "modules": [{"role": "model", "module": {"name": "vit-base-beans-demo-v2", "description": "A fine-tuned version of google/vit-base-patch16-224-in21k on the beans dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0002, "train_batch_size": 16, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "vit-base-beans-demo-v2 is a fine-tuned version of google/vit-base-patch16-224-in21k on the beans dataset. The model achieves 100% accuracy on the evaluation set. The model is suitable for image classification tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "plantvillage"}], "metrics": [{"dataset": "plantvillage", "metric": 1.0, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-mhf-xlm-roberta-base-finetuned-panx-fr", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-fr", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8353 on the evaluation set. The model is suitable for token classification tasks in French language. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8353494623655915, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-tr-eo", "modules": [{"role": "model", "module": {"name": "tur-epo", "description": "A transformer model for translating from Turkish to Esperanto."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece (spm4k,spm4k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "tur-epo is a transformer model trained on Turkish to Esperanto translation task. The model uses normalization and SentencePiece (spm4k,spm4k) for preprocessing. The model achieved a BLEU score of 17.0 and a chrF2 score of 0.373 on the Tatoeba-test.tur.epo dataset."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "tatoeba"}], "metrics": [{"dataset": "tatoeba", "metric": 17.0, "protocol": "BLEU"}, {"dataset": "tatoeba", "metric": 0.373, "protocol": "chrF2"}], "source": "huggingface"}, {"id": "huggingface-lighteternal-gpt2-finetuned-greek", "modules": [{"role": "model", "module": {"name": "Greek (el) GPT2 model", "description": "A text generation (autoregressive) model, using Huggingface transformers and fastai based on the English GPT-2. Finetuned with gradual layer unfreezing."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_type": "GPT2", "num_layers": 12, "hidden_size": 768, "num_heads": 12, "total_params": 117000000, "preprocessing": "tokenization + BPE segmentation", "max_length": "len(text.split(' '))+15", "do_sample": true, "top_k": 50, "repetition_penalty": 1.2, "add_special_tokens": false, "num_return_sequences": 5, "temperature": 0.95, "top_p": 0.95}}}, {"role": "taskType", "module": "text-generation"}, {"role": "solutionSummary", "module": {"summary": "The Greek (el) GPT2 model is a text generation model that uses Huggingface transformers and fastai based on the English GPT-2. It was finetuned with gradual layer unfreezing on a 23.4GB sample from a consolidated Greek corpus from CC100, Wikimatrix, Tatoeba, Books, SETIMES, and GlobalVoices. The model is best suited for text generation tasks in Greek. The research work was supported by the Hellenic Foundation for Research and Innovation (HFRI) under the HFRI PhD Fellowship grant."}}, {"role": "dataset", "purpose": "For model training.", "module": "cc100"}, {"role": "dataset", "purpose": "For model training.", "module": "tatoeba"}], "metrics": [{"dataset": "cc100", "metric": 3.67, "protocol": "Train Loss"}, {"dataset": "tatoeba", "metric": 3.67, "protocol": "Train Loss"}, {"dataset": "cc100", "metric": 3.83, "protocol": "Validation Loss"}, {"dataset": "tatoeba", "metric": 3.83, "protocol": "Validation Loss"}, {"dataset": "cc100", "metric": 39.12, "protocol": "Perplexity"}, {"dataset": "tatoeba", "metric": 39.12, "protocol": "Perplexity"}], "source": "huggingface"}, {"id": "huggingface-flair-ner-german-legal", "modules": [{"role": "model", "module": {"name": "Flair NER for German Legal Text (default model)", "description": "Named Entity Recognition model for German legal text in Flair using LSTM-CRF."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"embedding_types": ["WordEmbeddings('de')", "FlairEmbeddings('de-forward')", "FlairEmbeddings('de-backward')"], "hidden_size": 256, "tag_type": "ner", "max_epochs": 150, "train_with_dev": true}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a named entity recognition (NER) model for German legal text in Flair using LSTM-CRF. It predicts 19 tags, including AN, EUN, GS, GRT, INN, LD, LDS, LIT, MRK, ORG, PER, RR, RS, ST, STR, UN, VO, VS, and VT. The model is trained on the LER_GERMAN dataset and achieves an F1-Score of 96.35. The model is intended to be fine-tuned on a downstream task and is suitable for tasks that require NER on German legal text."}}, {"role": "dataset", "purpose": "For model training.", "module": "legal-ner"}], "metrics": [{"dataset": "legal-ner", "metric": 96.35, "protocol": "F1-Score"}], "source": "huggingface"}, {"id": "huggingface-sudo-s-exper4-mesum5", "modules": [{"role": "model", "module": {"name": "exper4_mesum5", "description": "A fine-tuned version of google/vit-base-patch16-224-in21k on the sudo-s/herbier_mesuem5 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 4, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "exper4_mesum5 is a fine-tuned version of google/vit-base-patch16-224-in21k on the sudo-s/herbier_mesuem5 dataset. The model is best suited for image classification tasks. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for 4 epochs and achieved an accuracy of 0.1331 and a loss of 3.4389 on the evaluation set. The model was trained using PyTorch 1.12.0+cu113 and Transformers 4.20.1."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "herbarium-2021-half-earth"}], "metrics": [{"dataset": "herbarium-2021-half-earth", "metric": 3.4389, "protocol": "loss"}, {"dataset": "herbarium-2021-half-earth", "metric": 0.1331, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-andreaschandra-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8621 on the evaluation set. The model is suitable for token classification tasks in German language. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8621, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-ar-tr", "modules": [{"role": "model", "module": {"name": "ara-tur", "description": "A transformer model for translating from Arabic to Turkish."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer", "preprocessing": "normalization + SentencePiece (spm32k,spm32k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "ara-tur is a transformer model trained on a large corpus of Arabic and Turkish data. It is intended for translating from Arabic to Turkish. The model uses normalization and SentencePiece preprocessing. The model has been evaluated on the Tatoeba-test.ara.tur dataset and achieved a BLEU score of 33.1 and a chrF2 score of 0.619."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "tatoeba-translation-challenge"}], "metrics": [{"dataset": "tatoeba-translation-challenge", "metric": 33.1, "protocol": "BLEU"}, {"dataset": "tatoeba-translation-challenge", "metric": 0.619, "protocol": "chrF2"}], "source": "huggingface"}, {"id": "huggingface-123tarunanand-roberta-base-finetuned", "modules": [{"role": "model", "module": {"name": "roberta-base-finetuned-squad2", "description": "A fine-tuned version of roberta-base on the squad_v2 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "roberta-base-finetuned-squad2 is a fine-tuned version of roberta-base on the squad_v2 dataset. It can be used for question answering tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for 3 epochs and achieved a loss of 0.9325 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 0.9325, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-alex-apostolo-legal-bert-small-filtered-cuad", "modules": [{"role": "model", "module": {"name": "legal-bert-small-uncased-filtered-filtered-cuad", "description": "A fine-tuned version of nlpaueb/legal-bert-small-uncased on the cuad dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "legal-bert-small-uncased-filtered-filtered-cuad is a fine-tuned version of nlpaueb/legal-bert-small-uncased on the cuad dataset. It is intended for text classification tasks in the legal domain. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64. The model was trained for 3 epochs and achieved a loss of 0.0604 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "cuad-contract-understanding-atticus-dataset"}], "metrics": [{"dataset": "cuad-contract-understanding-atticus-dataset", "metric": 0.0604, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-pratultandon-recipe-nlg-gpt2", "modules": [{"role": "model", "module": {"name": "recipe-nlg-gpt2", "description": "Fine-tuned GPT-2 model on the RecipeNLG dataset for recipe generation."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 200, "num_epochs": 1, "mixed_precision_training": true}}}, {"role": "taskType", "module": "text-generation"}, {"role": "solutionSummary", "module": {"summary": "The recipe-nlg-gpt2 model is a fine-tuned version of GPT-2 on the RecipeNLG dataset for recipe generation. The model is best used with special tokens in the input to prompt the model, and it should stick to the recipe format to complete the rest. The model was trained on a RTX 3090 with a batch size of 8 and f16 enabled. The model reflects the biases inherent to the systems they were trained on, so caution should be taken when deploying it into systems that interact with humans."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "recipe1m"}], "metrics": [{"dataset": "recipe1m", "metric": 1.1872143745422363, "protocol": "eval_loss"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-ty-fi", "modules": [{"role": "model", "module": {"name": "opus-mt-ty-fi", "description": "A transformer-align model for translating from the Ty language to Finnish."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-ty-fi is a transformer-align model that translates from the Ty language to Finnish. The model was trained on the OPUS dataset using normalization and SentencePiece preprocessing. The model achieved a BLEU score of 21.7 and a chr-F score of 0.451 on the JW300.ty.fi test set."}}], "metrics": [{"dataset": "jw300", "metric": 21.7, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.451, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-linker81-qlearning-frozenlake-v1", "modules": [{"role": "model", "module": {"name": "QLearning-FrozenLake-v1", "description": "A Q-Learning agent trained to play FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-4x4-no_slippery", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play FrozenLake-v1. The agent was trained using the Q-Learning algorithm and the FrozenLake-v1-4x4-no_slippery environment. The model's performance is evaluated using the mean reward metric, which has a value of 1.0 with no standard deviation."}}, {"role": "dataset", "purpose": "Environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-corianas-dqn-spaceinvadersnoframeskip-v4-21-6-22", "modules": [{"role": "model", "module": {"name": "DQN Agent playing SpaceInvadersNoFrameskip-v4", "description": "A trained DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "buffer_size": 100000, "exploration_final_eps": 0.01, "exploration_fraction": 0.25, "frame_stack": 4, "gradient_steps": 1, "learning_rate": 0.0001, "learning_starts": 100000, "n_timesteps": 3000000.0, "optimize_memory_usage": true, "policy": "CnnPolicy", "target_update_interval": 1000, "train_freq": 4, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The model was trained with a batch size of 32, a buffer size of 100000, and a learning rate of 0.0001. The model achieved a mean reward of 866.50 with a standard deviation of 274.13 on the SpaceInvadersNoFrameskip-v4 dataset. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 866.5, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-hossay-biobert-base-cased-v1-2-finetuned-ner", "modules": [{"role": "model", "module": {"name": "biobert-base-cased-v1.2-finetuned-ner", "description": "A fine-tuned version of dmis-lab/biobert-base-cased-v1.2 on the ncbi_disease dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "biobert-base-cased-v1.2-finetuned-ner is a fine-tuned version of dmis-lab/biobert-base-cased-v1.2 on the ncbi_disease dataset. It is a token classification model that can identify disease mentions in text. The model achieved high precision, recall, and F1 scores on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler. The model was trained for 3 epochs with a batch size of 16."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "ncbi-disease"}], "metrics": [{"dataset": "ncbi-disease", "metric": 0.8396334478808706, "protocol": "precision"}, {"dataset": "ncbi-disease", "metric": 0.8731387730792138, "protocol": "recall"}, {"dataset": "ncbi-disease", "metric": 0.856058394160584, "protocol": "f1"}, {"dataset": "ncbi-disease", "metric": 0.9824805769647444, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-peter2000-wav2vec2-large-xls-r-300m-kinyarwanda", "modules": [{"role": "model", "module": {"name": "wav2vec2-large-xls-r-300m-kinyarwanda", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 7e-05, "train_batch_size": 12, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 400, "num_epochs": 8, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset for the task of automatic speech recognition. The model achieved a loss of 0.3917 and a WER of 0.3246 on the evaluation set. The model is intended to be used for speech recognition tasks in Kinyarwanda language. The model was trained using PyTorch and Transformers libraries with mixed precision training. The model reflects the biases inherent to the systems they were trained on, so caution should be taken when deploying it into systems that interact with humans."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.3917, "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.3246, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-anikethash-dialogpt-medium-character", "modules": [{"role": "model", "module": {"name": "character DialoGPT Model", "description": "A conversational response model that generates text that is relevant, coherent, and knowledgeable given a prompt. The model is based on the DialoGPT architecture and is trained on character-level data."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"max_length": 1024, "num_layers": 12, "num_heads": 12, "hidden_size": 768, "dropout": 0.1, "batch_size": 2, "learning_rate": 5e-05, "num_epochs": 3}}}, {"role": "taskType", "module": "conversational"}, {"role": "solutionSummary", "module": {"summary": "The character DialoGPT model is a conversational response model that generates text that is relevant, coherent, and knowledgeable given a prompt. The model is based on the DialoGPT architecture and is trained on character-level data from Reddit comments. The model's hyperparameters include max_length, num_layers, num_heads, hidden_size, dropout, batch_size, learning_rate, and num_epochs. The model achieved a perplexity score of 10.5 on the Reddit comments dataset."}}, {"role": "dataset", "purpose": "For model training.", "module": "reddit-corpus"}], "metrics": [{"dataset": "reddit-corpus", "metric": 10.5, "protocol": "Perplexity"}], "source": "huggingface"}, {"id": "huggingface-philschmid-bert-mini-sst2-distilled", "modules": [{"role": "model", "module": {"name": "bert-mini-sst2-distilled", "description": "A fine-tuned version of google/bert_uncased_L-4_H-256_A-4 on the glue dataset for text classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.00021185586235152412, "train_batch_size": 1024, "eval_batch_size": 1024, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 8, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-mini-sst2-distilled is a fine-tuned version of google/bert_uncased_L-4_H-256_A-4 on the glue dataset for text classification. The model achieved an accuracy of 0.8567 on the evaluation set. The model is suitable for text classification tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.856651376146789, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-wonscha-my-awesome-model", "modules": [{"role": "model", "module": {"name": "my-awesome-model", "description": "A fine-tuned version of bert-base-cased on the yelp_review_full dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 8, "eval_batch_size": 8, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "my-awesome-model is a fine-tuned version of bert-base-cased on the yelp_review_full dataset. It is a text classification model that achieves an accuracy of 0.559 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 5e-05 and a linear learning rate scheduler. The model was trained for 3 epochs with a batch size of 8. The model was implemented using Transformers 4.11.3, Pytorch 1.11.0+cu113, Datasets 2.2.2, and Tokenizers 0.10.3."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "yelp2018"}], "metrics": [{"dataset": "yelp2018", "metric": 0.559, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-is-es", "modules": [{"role": "model", "module": {"name": "isl-spa", "description": "A transformer-align model for translating from Icelandic to Spanish."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece (spm32k,spm32k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "isl-spa is a transformer-align model trained on Icelandic and Spanish parallel data. It achieved a BLEU score of 51.2 and a chrF2 score of 0.665 on the Tatoeba-test.isl.spa dataset. The model uses normalization and SentencePiece (spm32k,spm32k) for preprocessing. The model is suitable for translating from Icelandic to Spanish."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "tatoeba"}], "metrics": [{"dataset": "tatoeba", "metric": 51.2, "protocol": "BLEU"}, {"dataset": "tatoeba", "metric": 0.665, "protocol": "chrF2"}], "source": "huggingface"}, {"id": "huggingface-yokoe-distilbert-base-uncased-finetuned-clinc", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-clinc", "description": "A fine-tuned version of distilbert-base-uncased on the clinc_oos dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 48, "eval_batch_size": 48, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-clinc is a fine-tuned version of distilbert-base-uncased on the clinc_oos dataset. It is a text classification model that can be used to classify out-of-scope queries. The model achieved an accuracy of 0.9184 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler. The model was trained for 5 epochs with a batch size of 48."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "clinc-single-domain-oos"}], "metrics": [{"dataset": "clinc-single-domain-oos", "metric": 0.9183870967741935, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-az-tr", "modules": [{"role": "model", "module": {"name": "aze-tur", "description": "A transformer model for translating Azerbaijani to Turkish."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece (spm4k,spm4k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "This is a transformer model for translating Azerbaijani to Turkish. It was trained on the Tatoeba dataset and achieved a BLEU score of 24.4 and a chrF2 score of 0.529 on the test set. The model uses normalization and SentencePiece (spm4k,spm4k) for preprocessing."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "tatoeba-translation-challenge"}], "metrics": [{"dataset": "tatoeba-translation-challenge", "metric": 24.4, "protocol": "BLEU"}, {"dataset": "tatoeba-translation-challenge", "metric": 0.529, "protocol": "chrF2"}], "source": "huggingface"}, {"id": "huggingface-sciarrilli-biobert-base-cased-v1-2-finetuned-ner", "modules": [{"role": "model", "module": {"name": "biobert-base-cased-v1.2-finetuned-ner", "description": "A fine-tuned version of dmis-lab/biobert-base-cased-v1.2 on the jnlpba dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "biobert-base-cased-v1.2-finetuned-ner is a fine-tuned version of dmis-lab/biobert-base-cased-v1.2 on the jnlpba dataset for token classification. The model achieved a precision of 0.7151, recall of 0.8301, F1 score of 0.7683, and accuracy of 0.9050 on the evaluation set. The model is suitable for named entity recognition tasks in the biomedical domain."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "jnlpba"}], "metrics": [{"dataset": "jnlpba", "metric": 0.7150627220423177, "protocol": "precision"}, {"dataset": "jnlpba", "metric": 0.8300729927007299, "protocol": "recall"}, {"dataset": "jnlpba", "metric": 0.7682875335686659, "protocol": "f1"}, {"dataset": "jnlpba", "metric": 0.90497239665345, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-dooglak-tagged-uni-500v6-ner-model-3epochs-augmented", "modules": [{"role": "model", "module": {"name": "Tagged_Uni_500v6_NER_Model_3Epochs_AUGMENTED", "description": "A fine-tuned version of bert-base-cased on the tagged_uni500v6_wikigold_split dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "Tagged_Uni_500v6_NER_Model_3Epochs_AUGMENTED is a fine-tuned version of bert-base-cased on the tagged_uni500v6_wikigold_split dataset for token classification. The model achieved a precision of 0.6992, recall of 0.6987, f1-score of 0.6989, and accuracy of 0.9318 on the evaluation set. The model was trained for 3 epochs with a learning rate of 2e-05 and a batch size of 8."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wikineural"}], "metrics": [{"dataset": "wikineural", "metric": 0.699155524278677, "protocol": "precision"}, {"dataset": "wikineural", "metric": 0.6986638537271449, "protocol": "recall"}, {"dataset": "wikineural", "metric": 0.6989096025325361, "protocol": "f1"}, {"dataset": "wikineural", "metric": 0.9317908843795436, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-slauw87-bart-summarisation", "modules": [{"role": "model", "module": {"name": "bart-large-cnn-samsum", "description": "A BART model fine-tuned on the SAMSum Corpus for abstractive text summarization."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_name_or_path": "facebook/bart-large-cnn", "learning_rate": 5e-05, "num_train_epochs": 3, "per_device_train_batch_size": 4, "per_device_eval_batch_size": 4, "fp16": true, "seed": 7}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "The bart-large-cnn-samsum model is a BART model fine-tuned on the SAMSum Corpus for abstractive text summarization. It was trained using Amazon SageMaker and the Hugging Face Deep Learning container. The model is best suited for summarizing human-annotated dialogues. The hyperparameters used for training include a learning rate of 5e-05, 3 epochs, and a batch size of 4. The model achieved a ROUGE-1 score of 43.2111 and a ROUGE-2 score of 22.3519 on the validation set, and a ROUGE-1 score of 41.8283 and a ROUGE-2 score of 20.9857 on the test set."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-karelito00-beit-base-patch16-224-pt22k-ft22k-finetuned-mnist", "modules": [{"role": "model", "module": {"name": "beit-base-patch16-224-pt22k-ft22k-finetuned-mnist", "description": "A fine-tuned version of microsoft/beit-base-patch16-224-pt22k-ft22k on the mnist dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "gradient_accumulation_steps": 4, "total_train_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "num_epochs": 3}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of microsoft/beit-base-patch16-224-pt22k-ft22k on the mnist dataset. The model achieved an accuracy of 0.9935 on the evaluation set. More information is needed to describe the model and its intended uses and limitations."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "mnist"}], "metrics": [{"dataset": "mnist", "metric": 0.9935, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-mgreenbe-607-demo-model", "modules": [{"role": "model", "module": {"name": "Yelp polarity classification", "description": "Demo model for predicting the polarity of Yelp reviews."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"epochs": 1, "reviews": 4096}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a demo model for predicting the polarity of Yelp reviews. The model was trained for 1 epoch on 4096 reviews and evaluated using accuracy metric. The model can be used for text classification tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "yelp2018"}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-eo-fi", "modules": [{"role": "model", "module": {"name": "epo-fin transformer-align", "description": "A machine translation model that translates from Esperanto to Finnish."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece (spm4k,spm4k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "This is a machine translation model that translates from Esperanto to Finnish. It was trained on the Tatoeba dataset and uses a transformer-align architecture. The model achieved a BLEU score of 15.9 and a chrF2 score of 0.371 on the Tatoeba-test.epo.fin test set."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "tatoeba-translation-challenge"}], "metrics": [{"dataset": "tatoeba-translation-challenge", "metric": 15.9, "protocol": "BLEU"}, {"dataset": "tatoeba-translation-challenge", "metric": 0.371, "protocol": "chrF2"}], "source": "huggingface"}, {"id": "huggingface-popolin52-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 game."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 game. The model includes the Q-Table learned by the agent and can be used to evaluate the agent's performance. The mean reward achieved by the agent is 7.56 with a standard deviation of 2.71."}}, {"role": "dataset", "purpose": "The game environment used for training and evaluation.", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.56, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-sasha-autotrain-distilbert-imdb-1275448782", "modules": [{"role": "model", "module": {"name": "AutoTrain DistilBERT", "description": "A binary classification model trained using AutoTrain on the IMDB dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_id": 1275448782, "pretrained_model": "distilbert-base-uncased", "problem_type": "binary classification"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a binary classification model trained using AutoTrain on the IMDB dataset. The model uses the DistilBERT architecture and achieved high accuracy, precision, recall, and AUC on the validation set. The model can be accessed through cURL or the Python API."}}, {"role": "dataset", "purpose": "For model training and validation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.256, "protocol": "loss"}, {"dataset": "imdb-movie-reviews", "metric": 0.9, "protocol": "accuracy"}, {"dataset": "imdb-movie-reviews", "metric": 0.891, "protocol": "precision"}, {"dataset": "imdb-movie-reviews", "metric": 0.913, "protocol": "recall"}, {"dataset": "imdb-movie-reviews", "metric": 0.965, "protocol": "auc"}, {"dataset": "imdb-movie-reviews", "metric": 0.902, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-flood-distilbert-base-uncased-finetuned-clinc", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-clinc", "description": "A fine-tuned version of distilbert-base-uncased on the clinc_oos dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 48, "eval_batch_size": 48, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-clinc is a fine-tuned version of distilbert-base-uncased on the clinc_oos dataset. It is a text classification model that can be used to classify out-of-scope queries. The model achieved an accuracy of 0.9161 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler. The model was trained for 5 epochs with a batch size of 48."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "clinc-single-domain-oos"}], "metrics": [{"dataset": "clinc-single-domain-oos", "metric": 0.9161290322580645, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-qanastek-pos-french", "modules": [{"role": "model", "module": {"name": "POET: A French Extended Part-of-Speech Tagger", "description": "A French extended part-of-speech tagger based on Bi-LSTM-CRF architecture."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"architecture": "Bi-LSTM-CRF", "embeddings": "FastText", "number_of_epochs": 115}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "POET is a French extended part-of-speech tagger based on Bi-LSTM-CRF architecture. It was trained on the ANTILLES corpus, which is based on the UD_French-GSD corpus. The model is case and punctuation sensitive and can be used for sequence tagging tasks. The model achieved an F-score of 0.952 and an accuracy of 0.952 on the test set. The model was trained and evaluated on French language only."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "antilles-antilles-an-open-french-linguistically-enriched-part-of-speech-corpus"}], "metrics": [{"dataset": "antilles-antilles-an-open-french-linguistically-enriched-part-of-speech-corpus", "metric": 0.952, "protocol": "F-score (micro)"}, {"dataset": "antilles-antilles-an-open-french-linguistically-enriched-part-of-speech-corpus", "metric": 0.8644, "protocol": "F-score (macro)"}, {"dataset": "antilles-antilles-an-open-french-linguistically-enriched-part-of-speech-corpus", "metric": 0.952, "protocol": "Accuracy (incl. no class)"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-eo-sv", "modules": [{"role": "model", "module": {"name": "epo-swe", "description": "A transformer model for translation from Esperanto to Swedish."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece (spm4k,spm4k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "A transformer model for translating from Esperanto to Swedish. The model was trained on the Tatoeba dataset and achieved a BLEU score of 29.5 on the test set. The model uses normalization and SentencePiece (spm4k,spm4k) for preprocessing."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "tatoeba-translation-challenge"}], "metrics": [{"dataset": "tatoeba-translation-challenge", "metric": 29.5, "protocol": "BLEU"}, {"dataset": "tatoeba-translation-challenge", "metric": 0.463, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-intel-xlm-roberta-base-mrpc", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-mrpc", "description": "Fine-tuned version of xlm-roberta-base on the GLUE MRPC dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5.0}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "xlm-roberta-base-mrpc is a fine-tuned version of xlm-roberta-base on the GLUE MRPC dataset. It is a transformer model that can be used for text classification tasks. The model achieved an accuracy of 0.8578 and an F1 score of 0.9010 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 16 for 5 epochs."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "mrpc-microsoft-research-paraphrase-corpus"}], "metrics": [{"dataset": "mrpc-microsoft-research-paraphrase-corpus", "metric": 0.8578431372549019, "protocol": "accuracy"}, {"dataset": "mrpc-microsoft-research-paraphrase-corpus", "metric": 0.901023890784983, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-en-bi", "modules": [{"role": "model", "module": {"name": "opus-mt-en-bi", "description": "A transformer-align model for translating from English to Bislama."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-en-bi is a transformer-align model that translates from English to Bislama. The model was trained on the OPUS dataset using normalization and SentencePiece preprocessing. The model achieved a BLEU score of 36.4 and a chr-F score of 0.543 on the JW300.en.bi test set."}}, {"role": "dataset", "purpose": "Test set for benchmarking.", "module": "jw300"}], "metrics": [{"dataset": "jw300", "metric": 36.4, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.543, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-clboetticher-xlm-roberta-base-finetuned-panx-fr", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-fr", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "xlm-roberta-base-finetuned-panx-fr is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. The model achieved an F1 score of 0.9213 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 5e-05 and a batch size of 24. The model was trained for 3 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.9213082901554404, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-toshifumi-bert-base-multilingual-cased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "bert-base-multilingual-cased-finetuned-emotion", "description": "A fine-tuned version of bert-base-multilingual-cased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of bert-base-multilingual-cased on the emotion dataset. It can be used for text classification tasks in multiple languages. The model achieved an accuracy of 0.9195 and an F1 score of 0.9205 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emocontext"}], "metrics": [{"dataset": "emocontext", "metric": 0.9195, "protocol": "accuracy"}, {"dataset": "emocontext", "metric": 0.9204823251325381, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-jonatasgrosman-wav2vec2-large-xlsr-53-russian", "modules": [{"role": "model", "module": {"name": "XLSR Wav2Vec2 Russian by Jonatas Grosman", "description": "Fine-tuned facebook/wav2vec2-large-xlsr-53 on Russian using the train and validation splits of Common Voice 6.1 and CSS10."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_id": "jonatasgrosman/wav2vec2-large-xlsr-53-russian", "batch_size": 1, "sampling_rate": 16000}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "XLSR Wav2Vec2 Russian by Jonatas Grosman is a fine-tuned model based on facebook/wav2vec2-large-xlsr-53 for speech recognition in Russian. The model was trained on Common Voice 6.1 and CSS10 datasets. The model can be used directly for speech recognition without a language model. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}, {"role": "dataset", "purpose": "For model training.", "module": "css10"}], "metrics": [{"dataset": "common-voice", "metric": 13.3, "protocol": "Test WER"}, {"dataset": "common-voice", "metric": 2.88, "protocol": "Test CER"}, {"dataset": "common-voice", "metric": 9.57, "protocol": "Test WER (+LM)"}, {"dataset": "common-voice", "metric": 2.24, "protocol": "Test CER (+LM)"}], "source": "huggingface"}, {"id": "huggingface-ramos-ramos-emb-gam-vit", "modules": [{"role": "model", "module": {"name": "Emb-GAM-ViT", "description": "LogisticRegressionCV model trained on averages of patch embeddings from the Imagenette dataset. This forms the GAM of an Emb-GAM extended to images. Patch embeddings are meant to be extracted with the google/vit-base-patch16-224 ViT checkpoint."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"Cs": 10, "class_weight": null, "cv": "StratifiedKFold(n_splits=5, random_state=1, shuffle=True)", "dual": false, "fit_intercept": true, "intercept_scaling": 1.0, "l1_ratios": null, "max_iter": 100, "multi_class": "auto", "n_jobs": null, "penalty": "l2", "random_state": 1, "refit": false, "scoring": null, "solver": "lbfgs", "tol": 0.0001, "verbose": 0}}}, {"role": "taskType", "module": "tabular-classification"}, {"role": "solutionSummary", "module": {"summary": "Emb-GAM-ViT is a logistic regression model trained on averages of patch embeddings from the Imagenette dataset. The patch embeddings are extracted with the google/vit-base-patch16-224 ViT checkpoint. The model is not intended to be used in production. The model is suitable for tabular classification tasks. The model is trained with LogisticRegressionCV with Cs=10, penalty=l2, and solver=lbfgs. The model achieves an accuracy of 0.99465 and an f1 score of 0.99465."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-abhinaiky-finetuning-sentiment-model-3000-samples", "modules": [{"role": "model", "module": {"name": "finetuning-sentiment-model-3000-samples", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "finetuning-sentiment-model-3000-samples is a fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis. The model achieved an accuracy of 0.8733 and an F1 score of 0.875 on the evaluation set. The model is suitable for text classification tasks, but its performance may vary depending on the specific use case and data distribution."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.8733, "protocol": "accuracy"}, {"dataset": "imdb-movie-reviews", "metric": 0.875, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-sb3-a2c-asteroidsnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "A2C", "description": "A trained model of an A2C agent playing AsteroidsNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"ent_coef": 0.01, "frame_stack": 4, "n_envs": 16, "n_timesteps": 10000000.0, "policy": "CnnPolicy", "policy_kwargs": {"optimizer_class": "RMSpropTFLike", "optimizer_kwargs": {"eps": 1e-05}}, "vf_coef": 0.25, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of an A2C agent playing AsteroidsNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The model was trained with the RL Zoo training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included. The model achieved a mean reward of 1614.00 +/- 630.75. The RL Zoo provides scripts for downloading and using the model, as well as for training new models."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-100k"}], "metrics": [{"dataset": "atari-100k", "metric": 1614.0, "split": "val", "protocol": "mean_reward"}, {"dataset": "atari-100k", "metric": 630.75, "split": "test", "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-lakshya-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 game."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 game. The agent's Q-Table is provided, along with hyperparameters such as the maximum number of steps per episode and the number of episodes used for evaluation. The model achieved a mean reward of 7.46 with a standard deviation of 2.73."}}, {"role": "dataset", "purpose": "The game environment used for training and evaluation.", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.46, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-facebook-deit-base-distilled-patch16-224", "modules": [{"role": "model", "module": {"name": "Distilled Data-efficient Image Transformer (base-sized model)", "description": "Distilled Vision Transformer (ViT) model pre-trained and fine-tuned on ImageNet-1k (1 million images, 1,000 classes) at resolution 224x224."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": {"image_resolution": "224x224", "normalization": "ImageNet mean and standard deviation"}, "training": {"batch_size": "refer to table 9 of the original paper", "learning_rate": "refer to table 9 of the original paper"}}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "Distilled Data-efficient Image Transformer (DeiT) is a Vision Transformer (ViT) model pre-trained and fine-tuned on ImageNet-1k. It uses a distillation token to learn from a teacher (CNN) during both pre-training and fine-tuning. The model is suitable for image classification tasks. The model was trained on a single 8-GPU node for 3 days. At inference time, images are resized/rescaled to the same resolution (256x256), center-cropped at 224x224 and normalized across the RGB channels with the ImageNet mean and standard deviation."}}, {"role": "dataset", "purpose": "For model pre-training and fine-tuning.", "module": "imagenet"}], "metrics": [{"dataset": "imagenet", "metric": 83.4, "protocol": "ImageNet top-1 accuracy"}, {"dataset": "imagenet", "metric": 96.5, "protocol": "ImageNet top-5 accuracy"}], "source": "huggingface"}, {"id": "huggingface-btsas-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 game."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 game. The agent's Q-Table is provided, along with hyperparameters such as the maximum number of steps per episode and the number of episodes used for evaluation. The model's performance is evaluated based on the mean reward achieved over the evaluation episodes."}}, {"role": "dataset", "purpose": "The game environment used for training and evaluation.", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.56, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-manirathinam21-bert-emo-classifier", "modules": [{"role": "model", "module": {"name": "bert_emo_classifier", "description": "A fine-tuned version of bert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 4}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "bert_emo_classifier is a fine-tuned version of bert-base-uncased on the emotion dataset. It can be used for text classification tasks to predict the emotion of a given text. The model was trained with Adam optimizer and linear learning rate scheduler for 4 epochs. The model achieved a loss of 0.3768 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emocontext"}], "metrics": [{"dataset": "emocontext", "metric": 0.3768, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-fadhilarkan-distilbert-base-uncased-finetuned-squad", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-squad", "description": "A fine-tuned version of distilbert-base-uncased on the squad dataset for question answering."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-squad is a fine-tuned version of distilbert-base-uncased on the squad dataset for question answering. The model achieved a loss of 1.1523 on the evaluation set. The model is suitable for question answering tasks, but its performance may be limited to the domain it was trained on. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 1.1523, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-turhancan97-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 environment."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "is_slippery": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 environment. The model achieved a mean reward of 7.56 with a standard deviation of 2.71 over a number of evaluation episodes. The model can be loaded from the Hugging Face model hub and used to evaluate the agent in the environment."}}, {"role": "dataset", "purpose": "OpenAI Gym environment", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.56, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-swc-es", "modules": [{"role": "model", "module": {"name": "opus-mt-swc-es", "description": "A machine translation model that translates from the Swahili language (swc) to Spanish (es)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-swc-es is a machine translation model that translates from Swahili to Spanish. The model uses the transformer-align architecture and was preprocessed using normalization and SentencePiece. The model achieved a BLEU score of 27.4 and a chr-F score of 0.458 on the JW300.swc.es test set."}}], "metrics": [{"dataset": "jw300", "metric": 27.4, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.458, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-bem-en", "modules": [{"role": "model", "module": {"name": "opus-mt-bem-en", "description": "A machine translation model that translates from Bemba to English."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-bem-en is a machine translation model that translates from Bemba to English. It uses a transformer-align model and pre-processing techniques such as normalization and SentencePiece. The model achieves a BLEU score of 33.4 and a chr-F score of 0.491 on the JW300.bem.en test set."}}], "metrics": [{"dataset": "jw300", "metric": 33.4, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.491, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-mbeukman-xlm-roberta-base-finetuned-ner-swahili", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-ner-swahili", "description": "A token classification model fine-tuned on the MasakhaNER dataset for named entity recognition (NER) in Swahili."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_name": "xlm-roberta-base", "max_seq_length": 200, "batch_size": 32, "learning_rate": 5e-05, "epochs": 50}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a transformer-based token classification model fine-tuned on the MasakhaNER dataset for named entity recognition (NER) in Swahili. The model was fine-tuned for 50 epochs with a maximum sequence length of 200, 32 batch size, and 5e-5 learning rate. The model is intended for NLP research into interpretability or transfer learning and is not designed for production use. The model's limitations include being trained on a relatively small dataset covering one task (NER) in one domain (news articles) and in a set span of time, and may perform badly or in an unfair/biased way if used on other tasks. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training, evaluation, and testing.", "module": "masakhaner"}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-es-af", "modules": [{"role": "model", "module": {"name": "spa-afr", "description": "A transformer model for translating from Spanish to Afrikaans."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece (spm32k,spm32k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "spa-afr is a transformer model trained on Spanish to Afrikaans translation task. The model uses normalization and SentencePiece (spm32k,spm32k) for preprocessing. The model achieved a BLEU score of 55.0 and a chr-F score of 0.718 on the Tatoeba-test.spa.afr dataset."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "tatoeba-translation-challenge"}], "metrics": [{"dataset": "tatoeba-translation-challenge", "metric": 55.0, "protocol": "BLEU"}, {"dataset": "tatoeba-translation-challenge", "metric": 0.718, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-gauthamb-dqn-spaceinvadersnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "DQN", "description": "A trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "buffer_size": 100000, "exploration_final_eps": 0.01, "exploration_fraction": 0.1, "frame_stack": 4, "gradient_steps": 1, "learning_rate": 0.0001, "learning_starts": 100000, "n_timesteps": 1000000.0, "optimize_memory_usage": true, "policy": "CnnPolicy", "target_update_interval": 1000, "train_freq": 4, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "The DQN model is a reinforcement learning agent trained on the SpaceInvadersNoFrameskip-v4 environment using the stable-baselines3 library and the RL Zoo. The model achieved a mean reward of 606.50 with a standard deviation of 150.03. The hyperparameters used for training include batch size, buffer size, exploration fraction, learning rate, and target update interval, among others. The RL Zoo provides a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 606.5, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-meghazisofiane-opus-mt-en-ar-evaluated-en-to-ar-4000instances-opus-leaningrate2e-05-batchsize8-11-action-1", "modules": [{"role": "model", "module": {"name": "opus-mt-en-ar-evaluated-en-to-ar-4000instances-opus-leaningRate2e-05-batchSize8-11-action-1", "description": "A fine-tuned version of Helsinki-NLP/opus-mt-en-ar on the opus100 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 11}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of Helsinki-NLP/opus-mt-en-ar on the opus100 dataset. It is intended for English to Arabic translation tasks. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 8. The model achieved a Bleu score of 26.8232 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "opus-100"}], "metrics": [{"dataset": "opus-100", "metric": 26.8232, "protocol": "bleu"}], "source": "huggingface"}, {"id": "huggingface-gchhablani-bert-base-cased-finetuned-mrpc", "modules": [{"role": "model", "module": {"name": "bert-base-cased-finetuned-mrpc", "description": "Fine-tuned version of bert-base-cased on the GLUE MRPC dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "num_epochs": 5.0}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-base-cased-finetuned-mrpc is a fine-tuned version of bert-base-cased on the GLUE MRPC dataset. It is intended for text classification tasks. The model achieved an accuracy of 0.8603 and an F1 score of 0.9026 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 16 for 5 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "mrpc-microsoft-research-paraphrase-corpus"}], "metrics": [{"dataset": "mrpc-microsoft-research-paraphrase-corpus", "metric": 0.8602941176470589, "protocol": "accuracy"}, {"dataset": "mrpc-microsoft-research-paraphrase-corpus", "metric": 0.9025641025641027, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-jdang-distilbert-base-uncased-finetuned-clinc", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-clinc", "description": "A fine-tuned version of distilbert-base-uncased on the clinc_oos dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 48, "eval_batch_size": 48, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-clinc is a fine-tuned version of distilbert-base-uncased on the clinc_oos dataset. It is a text classification model that can be used to classify out-of-scope queries. The model achieved an accuracy of 0.9184 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler for 5 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "clinc-single-domain-oos"}], "metrics": [{"dataset": "clinc-single-domain-oos", "metric": 0.9183870967741935, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-ad7-finetuning-sentiment-model-3000-samples", "modules": [{"role": "model", "module": {"name": "finetuning-sentiment-model-3000-samples", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "finetuning-sentiment-model-3000-samples is a fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis. The model achieved an accuracy of 0.77 and an F1 score of 0.7562 on the evaluation set. The model is suitable for text classification tasks, but its performance may vary depending on the specific use case and data distribution."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.77, "protocol": "accuracy"}, {"dataset": "imdb-movie-reviews", "metric": 0.7561837455830389, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-dkleczek-papugapt2", "modules": [{"role": "model", "module": {"name": "papuGaPT2 - Polish GPT2 language model", "description": "Polish language model pretrained on a large corpus of Polish data in a self-supervised fashion."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"tokenizer": "byte-level BPE", "vocabulary_size": 50257, "token_length": 512, "batch_size": 64, "optimizer": {"name": "Adam", "learning_rate": 0.0002, "beta1": 0.9, "beta2": 0.999, "weight_decay": 0.01}}}}, {"role": "taskType", "module": "text-generation"}, {"role": "solutionSummary", "module": {"summary": "papuGaPT2 is a transformer model pre-trained on a large Polish corpus. It can be used for text generation or fine-tuned for a downstream task. The model has been trained on data scraped from the web, and can generate text containing intense violence, sexual situations, coarse language and drug use. It also reflects the biases from the dataset. The model is suitable for research purposes only."}}, {"role": "dataset", "purpose": "For model training.", "module": "oscar"}], "metrics": [{"dataset": "oscar", "metric": 3.082, "protocol": "Evaluation loss"}, {"dataset": "oscar", "metric": 21.79, "protocol": "Perplexity"}], "source": "huggingface"}, {"id": "huggingface-drabreu-biobert-ner-ncbi-disease", "modules": [{"role": "model", "module": {"name": "bioBERT-NER-NCBI_disease", "description": "A fine-tuned version of dmis-lab/biobert-base-cased-v1.2 on the ncbi_disease dataset for named entity recognition (NER) of disease names."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "bioBERT-NER-NCBI_disease is a fine-tuned version of dmis-lab/biobert-base-cased-v1.2 on the ncbi_disease dataset for named entity recognition (NER) of disease names. The model achieved high precision, recall, and F1 scores on the evaluation set. It can be used for NER tasks related to disease names, but caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "ncbi-disease"}], "metrics": [{"dataset": "ncbi-disease", "metric": 0.8136, "protocol": "precision"}, {"dataset": "ncbi-disease", "metric": 0.8653, "protocol": "recall"}, {"dataset": "ncbi-disease", "metric": 0.8387, "protocol": "f1"}, {"dataset": "ncbi-disease", "metric": 0.985, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-temur-wav2vec2-georgian-daytona", "modules": [{"role": "model", "module": {"name": "Wav2Vec2-Large-XLSR-53-Georgian", "description": "Fine-tuned model on Georgian using the Common Voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "facebook/wav2vec2-large-xlsr-53", "batch_size": 8, "optimizer": {"name": "Adam", "learning_rate": 5e-05, "beta1": 0.9, "beta2": 0.98, "epsilon": 1e-06}}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Wav2Vec2-Large-XLSR-53-Georgian is a fine-tuned model on Georgian using the Common Voice dataset. The model is intended for automatic speech recognition tasks and can be used directly without a language model. The model was trained on the Common Voice train, validation, and test datasets. The model achieved a WER of 48.34% on the Common Voice ka test dataset."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 48.34, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-winson-distilbert-base-uncased-finetuned-imdb", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-imdb", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0, "mixed_precision_training": true}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-imdb is a fine-tuned version of distilbert-base-uncased on the imdb dataset. It can be used for text classification tasks. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64. The model was trained for 3 epochs with mixed precision training. The evaluation loss on the evaluation set was 3.1139."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 3.1139, "protocol": "eval_loss"}, {"dataset": "imdb-movie-reviews", "metric": 1.8873, "protocol": "eval_runtime"}, {"dataset": "imdb-movie-reviews", "metric": 529.866, "protocol": "eval_samples_per_second"}, {"dataset": "imdb-movie-reviews", "metric": 8.478, "protocol": "eval_steps_per_second"}, {"dataset": "imdb-movie-reviews", "metric": 0.0, "protocol": "step"}], "source": "huggingface"}, {"id": "huggingface-xrverse-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. The model is best suited for text classification tasks. The model achieved an accuracy of 0.9235 and an F1 score of 0.9233 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.9235, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.9233497845071853, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-leeyujin-distilbert-base-uncased-finetuned-cola", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-cola", "description": "A fine-tuned version of distilbert-base-uncased on the glue dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-cola is a fine-tuned version of distilbert-base-uncased on the glue dataset. It is suitable for text classification tasks. The model achieved a Matthews Correlation score of 0.5062 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 5 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.5062, "protocol": "matthews_correlation"}], "source": "huggingface"}, {"id": "huggingface-skr1125-distilbert-base-uncased-finetuned-clinc", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-clinc", "description": "A fine-tuned version of distilbert-base-uncased on the clinc_oos dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 48, "eval_batch_size": 48, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-clinc is a fine-tuned version of distilbert-base-uncased on the clinc_oos dataset. It is a text classification model that can be used to classify out-of-scope queries. The model achieved an accuracy of 0.9177 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler for 5 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "clinc-single-domain-oos"}], "metrics": [{"dataset": "clinc-single-domain-oos", "metric": 0.917741935483871, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-mbeukman-xlm-roberta-base-finetuned-ner-kinyarwanda", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-ner-kinyarwanda", "description": "A token classification model fine-tuned on the MasakhaNER dataset for named entity recognition in Kinyarwanda."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"max_seq_length": 200, "batch_size": 32, "learning_rate": 5e-05, "epochs": 50}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a transformer-based token classification model fine-tuned on the MasakhaNER dataset for named entity recognition in Kinyarwanda. The model was fine-tuned for 50 epochs with a maximum sequence length of 200, 32 batch size, and 5e-5 learning rate. The model is intended for NLP research into interpretability or transfer learning and is not designed for production use. The model's limitations include being trained on a relatively small dataset covering one task in one domain and may perform poorly on other tasks. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "masakhaner"}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-anirudh21-electra-base-discriminator-finetuned-rte", "modules": [{"role": "model", "module": {"name": "electra-base-discriminator-finetuned-rte", "description": "Fine-tuned version of google/electra-base-discriminator on the glue dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "electra-base-discriminator-finetuned-rte is a fine-tuned version of google/electra-base-discriminator on the glue dataset. The model is suitable for text classification tasks. The model achieved an accuracy of 0.8231 on the RTE dataset of the GLUE benchmark. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler for 5 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.8231046931407943, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-michael20at-q-frozenlake-v1-4x4-noslippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained model of a Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-4x4-no_slippery"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model achieved a mean reward of 1.00 +/- 0.00 on the FrozenLake-v1-4x4-no_slippery environment. The model can be loaded and used to evaluate the agent's performance on the environment."}}, {"role": "dataset", "purpose": "The environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "extra": "1.00 +/- 0.00", "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-fi-ro", "modules": [{"role": "model", "module": {"name": "opus-mt-fi-ro", "description": "A machine translation model that translates from Finnish to Romanian."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-fi-ro is a machine translation model that translates from Finnish to Romanian. It uses a transformer-align model and pre-processing techniques such as normalization and SentencePiece. The model achieves a BLEU score of 27.0 and a chr-F score of 0.49 on the JW300.fi.ro test set."}}], "metrics": [{"dataset": "jw300", "metric": 27.0, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.49, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-xsy-albert-base-v2-fakenews-discriminator", "modules": [{"role": "model", "module": {"name": "albert-base-v2-fakenews-discriminator", "description": "A fine-tuned version of albert-base-v2 on a dataset of fake and real news articles."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 1}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of albert-base-v2 on a dataset of fake and real news articles. It can be used to classify news articles as either fake or real. The model achieved an accuracy of 0.9758 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 5e-05 and a linear learning rate scheduler with 500 warmup steps."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "fakenewsnet"}], "metrics": [{"dataset": "fakenewsnet", "metric": 0.0452, "split": "val", "protocol": "loss"}, {"dataset": "fakenewsnet", "metric": 0.091, "split": "test", "protocol": "loss"}, {"dataset": "fakenewsnet", "metric": 0.9758, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-fumakurata-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 192, "eval_batch_size": 192, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. It can be used for text classification tasks. The model achieved an accuracy of 0.834 and an F1 score of 0.8172 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 192 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.834, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.8171742650957551, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-ayamerushia-roberta-base-indonesian-sentiment-analysis-smsa", "modules": [{"role": "model", "module": {"name": "roberta-base-indonesian-sentiment-analysis-smsa", "description": "A fine-tuned version of flax-community/indonesian-roberta-base on the indonlu dataset for sentiment analysis."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 2000, "num_epochs": 10}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of flax-community/indonesian-roberta-base on the indonlu dataset for sentiment analysis. The model achieved an accuracy of 0.9349 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 1e-05 and a linear learning rate scheduler with 2000 warmup steps. The model was trained for 10 epochs with a batch size of 16."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "indonlu-benchmark"}], "metrics": [{"dataset": "indonlu-benchmark", "metric": 0.9349206349206349, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-pig4431-sentiment140-distilbert-5e", "modules": [{"role": "model", "module": {"name": "Sentiment140_DistilBERT_5E", "description": "Fine-tuned version of distilbert-base-uncased on the sentiment140 dataset for text classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-05, "train_batch_size": 16, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "Sentiment140_DistilBERT_5E is a fine-tuned version of distilbert-base-uncased on the sentiment140 dataset for text classification. The model achieved an accuracy of 0.8333 on the evaluation set. The model is suitable for text classification tasks, but caution should be taken when deploying it in human-interacting systems as it may reflect the biases of the systems it was trained on."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "sentiment140"}], "metrics": [{"dataset": "sentiment140", "metric": 0.8333333333333334, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-shebna-distilbert-base-uncased-finetuned-cola", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-cola", "description": "A fine-tuned version of distilbert-base-uncased on the glue dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-cola is a fine-tuned version of distilbert-base-uncased on the glue dataset. It is suitable for text classification tasks. The model achieved a Matthews Correlation score of 0.5422 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 16 for 5 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.542244787638552, "protocol": "matthews_correlation"}], "source": "huggingface"}, {"id": "huggingface-btjiong-robbert-twitter-sentiment", "modules": [{"role": "model", "module": {"name": "robbert-twitter-sentiment", "description": "A fine-tuned version of pdelobelle/robbert-v2-dutch-base on the dutch_social dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "robbert-twitter-sentiment is a fine-tuned version of pdelobelle/robbert-v2-dutch-base on the dutch_social dataset. It is a text classification model that can be used to classify Dutch social media sentiment. The model was trained using Adam optimizer with a learning rate of 5e-05 and a batch size of 16. The model achieved an accuracy of 0.749 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "dbrd-dutch-book-reviews-dataset"}], "metrics": [{"dataset": "dbrd-dutch-book-reviews-dataset", "metric": 0.749, "protocol": "accuracy"}, {"dataset": "dbrd-dutch-book-reviews-dataset", "metric": 0.7491844724992662, "protocol": "f1"}, {"dataset": "dbrd-dutch-book-reviews-dataset", "metric": 0.7493911755249737, "protocol": "precision"}, {"dataset": "dbrd-dutch-book-reviews-dataset", "metric": 0.749, "protocol": "recall"}], "source": "huggingface"}, {"id": "huggingface-alekseykorshuk-amazon-reviews-input-output-13b", "modules": [{"role": "model", "module": {"name": "amazon-reviews-input-output-13b", "description": "Fine-tuned version of facebook/opt-13b on the AlekseyKorshuk/amazon-reviews-input-output dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 1, "eval_batch_size": 8, "seed": 42, "distributed_type": "multi-GPU", "num_devices": 8, "gradient_accumulation_steps": 8, "total_train_batch_size": 64, "total_eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1.0}}}, {"role": "taskType", "module": "text-generation"}, {"role": "solutionSummary", "module": {"summary": "amazon-reviews-input-output-13b is a fine-tuned version of facebook/opt-13b on the AlekseyKorshuk/amazon-reviews-input-output dataset. The model is suitable for text generation tasks. The model achieved an accuracy of 0.0404 on the evaluation set. The training hyperparameters include a learning rate of 5e-05, a batch size of 1, and an optimizer of Adam with betas=(0.9,0.999) and epsilon=1e-08. The model was trained for 1 epoch."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "amazon-product-data"}], "metrics": [{"dataset": "amazon-product-data", "metric": 0.040426829268292684, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-transformersbook-xlm-roberta-base-finetuned-panx-fr", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-fr", "description": "A fine-tuned version of xlm-roberta-base on the PAN-X dataset for multilingual named entity recognition."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "xlm-roberta-base-finetuned-panx-fr is a fine-tuned version of xlm-roberta-base on the PAN-X dataset for multilingual named entity recognition. The model achieved an F1 score of 0.8455 on the evaluation set. The model is suitable for token classification tasks, but its intended uses and limitations are not specified in the model card."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-mohammedbriman-distilroberta-base-finetuned-cola", "modules": [{"role": "model", "module": {"name": "distilroberta-base-finetuned-cola", "description": "A fine-tuned version of distilroberta-base on the glue dataset for text classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilroberta-base-finetuned-cola is a fine-tuned version of distilroberta-base on the glue dataset for text classification. The model achieved a Matthews Correlation score of 0.5788 on the evaluation set. The model is suitable for text classification tasks, but its performance may vary depending on the specific task and dataset. Caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.5788207437251082, "protocol": "matthews_correlation"}], "source": "huggingface"}, {"id": "huggingface-tianle-distilbert-base-uncased-finetuned-squad", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-squad", "description": "A fine-tuned version of distilbert-base-uncased on the squad dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-squad is a fine-tuned version of distilbert-base-uncased on the squad dataset. It is suitable for question answering tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for 1 epoch and achieved a validation loss of 1.2169."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 1.2631, "split": "val", "protocol": "loss"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 1.2169, "split": "test", "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-huggingbase-xlm-roberta-base-finetuned-panx-it", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-it", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8124 on the evaluation set. The model is suitable for token classification tasks in Italian language. The training was done using Adam optimizer with a learning rate of 5e-05 and a batch size of 24 for 3 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8124, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-nobody138-xlm-roberta-base-finetuned-panx-en", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-en", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "xlm-roberta-base-finetuned-panx-en is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. The model achieved an F1 score of 0.6886 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 5e-05 and a batch size of 24. The model was trained for 3 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.6886160714285715, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-dooglak-tagged-one-250v2-ner-model-3epochs-augmented", "modules": [{"role": "model", "module": {"name": "Tagged_One_250v2_NER_Model_3Epochs_AUGMENTED", "description": "A fine-tuned version of bert-base-cased on the tagged_one250v2_wikigold_split dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "Tagged_One_250v2_NER_Model_3Epochs_AUGMENTED is a fine-tuned version of bert-base-cased on the tagged_one250v2_wikigold_split dataset for token classification. The model achieved a precision of 0.5859, recall of 0.5074, F1 score of 0.5439, and accuracy of 0.8980 on the evaluation set. The model was trained for 3 epochs with a learning rate of 2e-05 and Adam optimizer with betas=(0.9,0.999) and epsilon=1e-08."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wikisplit"}], "metrics": [{"dataset": "wikisplit", "metric": 0.5859220092531394, "protocol": "precision"}, {"dataset": "wikisplit", "metric": 0.5074413279908414, "protocol": "recall"}, {"dataset": "wikisplit", "metric": 0.5438650306748466, "protocol": "f1"}, {"dataset": "wikisplit", "metric": 0.8979617609173338, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-no-es", "modules": [{"role": "model", "module": {"name": "nor-spa", "description": "A transformer model for translating Norwegian (nno, nob) to Spanish (spa)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece (spm12k,spm12k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "nor-spa is a transformer model trained on a large corpus of Norwegian and Spanish data. It uses normalization and SentencePiece (spm12k,spm12k) for preprocessing. The model is best suited for translating Norwegian (nno, nob) to Spanish (spa). The model achieved a BLEU score of 34.2 and a chrF2 score of 0.565 on the Tatoeba-test.nor.spa dataset."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "tatoeba-translation-challenge"}], "metrics": [{"dataset": "tatoeba-translation-challenge", "metric": 34.2, "protocol": "BLEU"}, {"dataset": "tatoeba-translation-challenge", "metric": 0.565, "protocol": "chrF2"}], "source": "huggingface"}, {"id": "huggingface-atatavana-layoutlmv3-matriculas", "modules": [{"role": "model", "module": {"name": "layoutlm_csvmodel_largetoken2", "description": "A fine-tuned version of microsoft/layoutlmv3-base on the sroie dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-05, "train_batch_size": 2, "eval_batch_size": 2, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "training_steps": 500}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "layoutlm_csvmodel_largetoken2 is a fine-tuned version of microsoft/layoutlmv3-base on the sroie dataset for token classification. The model achieved perfect precision, recall, F1, and accuracy on the evaluation set. The model is intended for token classification tasks, but more information is needed to determine its limitations and intended uses. The model was trained using PyTorch 1.12.1+cu113, Transformers 4.25.0.dev0, Datasets 2.2.2, and Tokenizers 0.13.2."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "sroie"}], "metrics": [{"dataset": "sroie", "metric": 1.0, "protocol": "Precision"}, {"dataset": "sroie", "metric": 1.0, "protocol": "Recall"}, {"dataset": "sroie", "metric": 1.0, "protocol": "F1"}, {"dataset": "sroie", "metric": 1.0, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-mrm8488-t5-small-finetuned-text2log", "modules": [{"role": "model", "module": {"name": "T5 (small) fine-tuned on Text2Log", "description": "A fine-tuned version of T5 (small) on a Text2Log dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 6}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of T5 (small) on a Text2Log dataset. The model can be used to translate natural language to first-order logic and vice versa. The model was trained with Adam optimizer with a learning rate of 5e-05 and a batch size of 8. The model achieved a loss of 0.0313 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "logic2text"}], "metrics": [{"dataset": "logic2text", "metric": 0.0313, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-agvelu-xlm-roberta-base-finetuned-panx-en", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-en", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "xlm-roberta-base-finetuned-panx-en is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification. The model achieved an F1 score of 0.6886 on the evaluation set. The model is suitable for token classification tasks in multilingual settings."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.6886160714285715, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-schoenml-swin-tiny-patch4-window7-224-finetuned-eurosat", "modules": [{"role": "model", "module": {"name": "swin-tiny-patch4-window7-224-finetuned-eurosat", "description": "A fine-tuned version of microsoft/swin-tiny-patch4-window7-224 on the image_folder dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 32, "eval_batch_size": 32, "seed": 42, "gradient_accumulation_steps": 4, "total_train_batch_size": 128, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "num_epochs": 3}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "swin-tiny-patch4-window7-224-finetuned-eurosat is a fine-tuned version of microsoft/swin-tiny-patch4-window7-224 on the image_folder dataset. The model is suitable for image classification tasks. The training hyperparameters include learning rate, batch size, optimizer, and number of epochs. The model achieved an evaluation accuracy of 0.9474 and an evaluation loss of 0.1551."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "objectfolder"}], "metrics": [{"dataset": "objectfolder", "metric": 0.1551, "protocol": "eval_loss"}, {"dataset": "objectfolder", "metric": 0.9474, "protocol": "eval_accuracy"}, {"dataset": "objectfolder", "metric": 13.1569, "protocol": "eval_runtime"}, {"dataset": "objectfolder", "metric": 205.216, "protocol": "eval_samples_per_second"}, {"dataset": "objectfolder", "metric": 6.46, "protocol": "eval_steps_per_second"}, {"dataset": "objectfolder", "metric": 1.0, "protocol": "epoch"}, {"dataset": "objectfolder", "metric": 190.0, "protocol": "step"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-en-toi", "modules": [{"role": "model", "module": {"name": "opus-mt-en-toi", "description": "A machine translation model that translates from English to Toi."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-en-toi is a machine translation model that translates from English to Toi. It uses a transformer-align model and pre-processing techniques such as normalization and SentencePiece. The model achieves a BLEU score of 32.8 and a chr-F score of 0.598 on the JW300.en.toi test set."}}], "metrics": [{"dataset": "jw300", "metric": 32.8, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.598, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-sammy786-wav2vec2-xlsr-chuvash", "modules": [{"role": "model", "module": {"name": "sammy786/wav2vec2-xlsr-chuvash", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-1b on the Common Voice 8 dataset for Automatic Speech Recognition."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 4.56379946629835e-05, "train_batch_size": 8, "eval_batch_size": 16, "seed": 13, "gradient_accumulation_steps": 4, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "cosine_with_restarts", "lr_scheduler_warmup_steps": 500, "num_epochs": 30, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/wav2vec2-xls-r-1b on the Common Voice 8 dataset for Automatic Speech Recognition. The model was trained using Adam optimizer with a learning rate of 0.000045637994662983496, cosine_with_restarts learning rate scheduler, and Native AMP mixed precision training. The model achieved a Test WER of 29.22 and Test CER of 5.79. The model is suitable for Automatic Speech Recognition tasks, but caution should be taken when deploying it in human-interacting systems as it may reflect the biases of the systems it was trained on."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 29.22, "protocol": "WER"}, {"dataset": "common-voice", "metric": 5.79, "protocol": "CER"}], "source": "huggingface"}, {"id": "huggingface-youngya-layoutlmv3-finetuned-cord-100", "modules": [{"role": "model", "module": {"name": "layoutlmv3-finetuned-cord_100", "description": "A fine-tuned version of microsoft/layoutlmv3-base on the cord-layoutlmv3 dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-05, "train_batch_size": 5, "eval_batch_size": 5, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "training_steps": 2500}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of microsoft/layoutlmv3-base on the cord-layoutlmv3 dataset for token classification. The model achieved a precision of 0.9023, recall of 0.9192, F1 score of 0.9106, and accuracy of 0.9202 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 1e-05 and a linear learning rate scheduler. The model was trained for 2500 steps with a batch size of 5. The model was trained using Transformers 4.22.1, Pytorch 1.12.1+cu113, Datasets 2.5.1, and Tokenizers 0.12.1."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "cord-19"}], "metrics": [{"dataset": "cord-19", "metric": 0.9022777369581191, "protocol": "precision"}, {"dataset": "cord-19", "metric": 0.9191616766467066, "protocol": "recall"}, {"dataset": "cord-19", "metric": 0.9106414534668149, "protocol": "f1"}, {"dataset": "cord-19", "metric": 0.9202037351443124, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-shahm-t5-small-german", "modules": [{"role": "model", "module": {"name": "t5-seven-epoch-base-german", "description": "A fine-tuned version of t5-small on the mlsum de dataset for summarization task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 6, "eval_batch_size": 6, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 7.0}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "t5-seven-epoch-base-german is a fine-tuned version of t5-small on the mlsum de dataset for summarization task. The model achieved a Rouge1 score of 42.3787 on the evaluation set. The model is suitable for summarizing German texts, but its performance may vary depending on the input data. The model was trained using Adam optimizer with a learning rate of 5e-05 and a linear learning rate scheduler for 7 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "mlsum-multilingual-summarization"}], "metrics": [{"dataset": "mlsum-multilingual-summarization", "metric": 42.3787, "protocol": "rouge-1"}, {"dataset": "mlsum-multilingual-summarization", "metric": 32.0253, "protocol": "rouge-2"}, {"dataset": "mlsum-multilingual-summarization", "metric": 38.9529, "protocol": "rouge-l"}, {"dataset": "mlsum-multilingual-summarization", "metric": 40.4544, "protocol": "rouge-lsum"}], "source": "huggingface"}, {"id": "huggingface-setfit-distilbert-base-uncased-sst2-train-16-6", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased__sst2__train-16-6", "description": "A fine-tuned version of distilbert-base-uncased on the SST-2 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 4, "eval_batch_size": 4, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 50, "mixed_precision_training": true}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of distilbert-base-uncased on the SST-2 dataset. It can be used for text classification tasks. The model was trained with Adam optimizer with a learning rate of 2e-05, and a batch size of 4. The model was trained for 50 epochs with mixed precision training. The model achieved an accuracy of 0.6480 and a loss of 0.8356 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "sst-stanford-sentiment-treebank"}], "metrics": [{"dataset": "sst-stanford-sentiment-treebank", "metric": 0.8356, "protocol": "loss"}, {"dataset": "sst-stanford-sentiment-treebank", "metric": 0.648, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-whatisthissignupform-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 game."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "is_slippery": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 game. The model was trained using custom implementation and evaluated using the mean reward metric. The model can be loaded and used to play the game using the provided code snippet."}}, {"role": "dataset", "purpose": "The game environment used for training and evaluation.", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.56, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-textattack-albert-base-v2-imdb", "modules": [{"role": "model", "module": {"name": "albert-base-v2", "description": "A transformer model fine-tuned for sequence classification using TextAttack and the imdb dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "learning_rate": 2e-05, "num_epochs": 5, "loss_function": "cross-entropy", "max_seq_length": 128}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "The albert-base-v2 model was fine-tuned for sequence classification using TextAttack and the imdb dataset. The model was trained with a cross-entropy loss function and achieved an accuracy of 0.89236 on the eval set after 3 epochs. The model is suitable for text classification tasks."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.89236, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-mk-fr", "modules": [{"role": "model", "module": {"name": "opus-mt-mk-fr", "description": "A machine translation model that translates from Macedonian (mk) to French (fr) using the transformer-align architecture."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-mk-fr model is a machine translation model that translates from Macedonian to French using the transformer-align architecture. The model was preprocessed using normalization and SentencePiece. The model achieved a BLEU score of 22.3 and a chr-F score of 0.492 on the GlobalVoices.mk.fr test set."}}, {"role": "dataset", "purpose": "For benchmarking.", "module": "global-voices"}], "metrics": [{"dataset": "global-voices", "metric": 22.3, "protocol": "BLEU"}, {"dataset": "global-voices", "metric": 0.492, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-santoshvutukuri-xlm-roberta-base-esg-ner", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-esg-ner", "description": "A fine-tuned version of xlm-roberta-base on the conll2003 dataset for named entity recognition."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "xlm-roberta-base-esg-ner is a fine-tuned version of xlm-roberta-base on the conll2003 dataset for named entity recognition. The model achieved a precision of 0.5073, recall of 0.4847, F1 score of 0.4957, and accuracy of 0.8927 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 0.5073101990487934, "protocol": "precision"}, {"dataset": "conll-2003", "metric": 0.4846852911477617, "protocol": "recall"}, {"dataset": "conll-2003", "metric": 0.4957397366382649, "protocol": "f1"}, {"dataset": "conll-2003", "metric": 0.8926532053923588, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-alekseykorshuk-amazon-reviews-input-output-350m", "modules": [{"role": "model", "module": {"name": "amazon-reviews-input-output-350m", "description": "A fine-tuned version of facebook/opt-350m on the AlekseyKorshuk/amazon-reviews-input-output dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "num_epochs": 1.0}}}, {"role": "taskType", "module": "text-generation"}, {"role": "solutionSummary", "module": {"summary": "amazon-reviews-input-output-350m is a fine-tuned version of facebook/opt-350m on the AlekseyKorshuk/amazon-reviews-input-output dataset. The model is suitable for text generation tasks. The model achieved an accuracy of 0.0374 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "amazon-review"}], "metrics": [{"dataset": "amazon-review", "metric": 0.0373780487804878, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-sania67-fine-tunning-on-cv-urdu-dataset", "modules": [{"role": "model", "module": {"name": "Fine_Tunning_on_CV_Urdu_dataset", "description": "A fine-tuned version of facebook/wav2vec2-large-xlsr-53 on the common_voice_8_0 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0001, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 100, "num_epochs": 30, "mixed_precision_training": true}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Fine_Tunning_on_CV_Urdu_dataset is a fine-tuned version of facebook/wav2vec2-large-xlsr-53 on the common_voice_8_0 dataset. The model is intended for automatic speech recognition tasks in Urdu. The model was trained using Adam optimizer with a learning rate of 0.0001, and a batch size of 8. The model was trained for 30 epochs and achieved a loss of 1.2389 and a WER of 0.7380 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 1.2389, "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.738, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-xliu128-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. The model is best suited for text classification tasks. The model achieved an accuracy of 0.925 and an F1 score of 0.9247 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.925, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.924714869006902, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-matemato-dqn-spaceinvadersnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "DQN Agent playing SpaceInvadersNoFrameskip-v4", "description": "A trained DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "buffer_size": 100000, "exploration_final_eps": 0.01, "exploration_fraction": 0.1, "frame_stack": 4, "gradient_steps": 1, "learning_rate": 0.0001, "learning_starts": 100000, "n_timesteps": 1000000.0, "optimize_memory_usage": false, "policy": "CnnPolicy", "target_update_interval": 1000, "train_freq": 4, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The model was trained with a batch size of 32, a buffer size of 100000, and a learning rate of 0.0001. The mean reward achieved by the model on the SpaceInvadersNoFrameskip-v4 dataset is 512.00 with a standard deviation of 131.55. The model is suitable for reinforcement learning tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 512.0, "split": "val", "protocol": "mean_reward"}, {"dataset": "atari-grand-challenge", "metric": 131.55, "split": "test", "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-sakonii-deberta-base-nepali", "modules": [{"role": "model", "module": {"name": "deberta-base-nepali", "description": "Pretrained model on Nepali language using a masked language modeling (MLM) objective."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 6, "optimizer": {"name": "Adam", "learning_rate": 5e-05, "betas": [0.9, 0.999], "epsilon": 1e-08}, "num_epochs": 5, "mixed_precision_training": true}}}, {"role": "taskType", "module": "fill-mask"}, {"role": "solutionSummary", "module": {"summary": "DeBERTa is a transformer model pre-trained on a large Nepali corpus. It can be used for masked language modeling or fine-tuned on a downstream task. The model is suitable for tasks that use the whole sentence to make decisions, such as sequence classification, token classification, or question answering. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training.", "module": "cc100"}, {"role": "dataset", "purpose": "For model training.", "module": "wikitext-2"}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-cj-mills-xlm-roberta-base-finetuned-panx-it", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-it", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "xlm-roberta-base-finetuned-panx-it is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. The model achieved an F1 score of 0.7730 on the evaluation set. The model is suitable for token classification tasks in Italian language."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.7730210016155089, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-liyijing024-swin-base-patch4-window7-224-in22k-finetuned", "modules": [{"role": "model", "module": {"name": "swin-base-patch4-window7-224-in22k-finetuned", "description": "A fine-tuned version of microsoft/swin-base-patch4-window7-224-in22k on the imagefolder dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 128, "eval_batch_size": 128, "seed": 42, "gradient_accumulation_steps": 4, "total_train_batch_size": 512, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "num_epochs": 3}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "A fine-tuned version of microsoft/swin-base-patch4-window7-224-in22k on the imagefolder dataset. The model achieved an accuracy of 0.9993 on the evaluation set. More information is needed to describe the model and its intended uses and limitations."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "objectfolder"}], "metrics": [{"dataset": "objectfolder", "metric": 0.9993279702725674, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-ckb-en-toki-mt", "modules": [{"role": "model", "module": {"name": "en-toki-mt", "description": "A fine-tuned version of Helsinki-NLP/opus-mt-en-ROMANCE on the English - toki pona translation dataset on Tatoeba."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 10, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "en-toki-mt is a fine-tuned model based on Helsinki-NLP/opus-mt-en-ROMANCE for translating English to toki pona, a minimalist constructed language. The model was trained on all En-Toki sentence pairs on Tatoeba without any filtering. The model may produce inaccurate results when encountering more complex words due to the limited vocabulary of toki pona. The model achieved a BLEU score of 54 on the testing set."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-jayantapaul888-vit-base-patch16-224-finetuned-memes-v2", "modules": [{"role": "model", "module": {"name": "vit-base-patch16-224-finetuned-memes-v2", "description": "A fine-tuned version of google/vit-base-patch16-224 on the imagefolder dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.00012, "train_batch_size": 64, "eval_batch_size": 64, "seed": 42, "gradient_accumulation_steps": 4, "total_train_batch_size": 256, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "num_epochs": 4}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "vit-base-patch16-224-finetuned-memes-v2 is a fine-tuned version of google/vit-base-patch16-224 on the imagefolder dataset. The model achieved an accuracy of 0.8377 on the evaluation set. More information is needed to describe the model and its intended uses and limitations."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "objectfolder"}], "metrics": [{"dataset": "objectfolder", "metric": 0.8377, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-mdround-dqn-spaceinvadersnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "DQN", "description": "A trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "buffer_size": 100000, "exploration_final_eps": 0.01, "exploration_fraction": 0.1, "frame_stack": 4, "gradient_steps": 1, "learning_rate": 0.0001, "learning_starts": 100000, "n_timesteps": 1000000.0, "optimize_memory_usage": false, "policy": "CnnPolicy", "target_update_interval": 1000, "train_freq": 4, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The model was trained with a batch size of 32, a buffer size of 100000, and a learning rate of 0.0001. The model achieved a mean reward of 525.00 with a standard deviation of 135.70. The model is suitable for reinforcement learning tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 525.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-ibombonato-swin-age-classifier", "modules": [{"role": "model", "module": {"name": "swin-age-classifier", "description": "A PyTorch model trained on 80 epochs for age prediction using data from Ai Crowd - Blitz."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"epochs": 80}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "The swin-age-classifier is a PyTorch model trained on 80 epochs for age prediction using data from Ai Crowd - Blitz. The model is an image classifier that can be used for age prediction. The model achieved an accuracy of 0.8174999952316284 on the Image Classification task."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "ffhq-aging"}], "metrics": [{"dataset": "ffhq-aging", "metric": 0.8174999952316284, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-guhuawuli-distilbert-imdb", "modules": [{"role": "model", "module": {"name": "distilbert-imdb", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 64, "eval_batch_size": 64, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-imdb is a fine-tuned version of distilbert-base-uncased on the imdb dataset. The model is suitable for text classification tasks. The model was trained with Adam optimizer with a learning rate of 5e-05 and a batch size of 64. The model achieved an accuracy of 0.9288 on the validation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.9288, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-tsrivatsav-wav2vec2-large-xls-r-300m-en-libri-more-steps", "modules": [{"role": "model", "module": {"name": "wav2vec2-large-xls-r-300m-en-libri-more-steps", "description": "A fine-tuned version of facebook/wav2vec2-xls-r-300m on the librispeech_asr dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.001, "train_batch_size": 16, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 100, "num_epochs": 20}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "The wav2vec2-large-xls-r-300m-en-libri-more-steps model is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the librispeech_asr dataset. It is intended for automatic speech recognition tasks. The model achieved a WER of 0.8772 and a CER of 0.3762 on the evaluation set. The model was trained using PyTorch 1.11.0+cpu and Transformers 4.20.1."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "librispeech"}], "metrics": [{"dataset": "librispeech", "metric": 0.7946, "split": "val", "protocol": "loss"}, {"dataset": "librispeech", "metric": 1.7624, "split": "test", "protocol": "loss"}, {"dataset": "librispeech", "metric": 0.8772, "protocol": "WER"}, {"dataset": "librispeech", "metric": 0.3762, "protocol": "CER"}], "source": "huggingface"}, {"id": "huggingface-vuiseng9-roberta-l-squadv1-1", "modules": [{"role": "model", "module": {"name": "run05-roberta-large-squadv1.1-sl384-ds128-e2-tbs16", "description": "Fine-tuned version of roberta-large on the SQuAD dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 3e-05, "train_batch_size": 16, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2.0, "mixed_precision_training": true, "max_seq_length": 384, "doc_stride": 128}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of the roberta-large model on the SQuAD dataset. The model is intended for question-answering tasks. The model was trained for 2 epochs with a batch size of 16 and a learning rate of 3e-05. The model achieved an exact match score of 88.4674 and an F1 score of 94.3001 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 88.4674, "protocol": "exact_match"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 94.3001, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-ghpkishore-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. It can be used for text classification tasks related to emotions. The model achieved an accuracy of 0.9285 and an F1 score of 0.9285 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.9285, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.9285439912301902, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-michael20at-dqn-spaceinvadersnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "DQN Agent playing SpaceInvadersNoFrameskip-v4", "description": "A trained DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "buffer_size": 100000, "exploration_final_eps": 0.01, "exploration_fraction": 0.1, "frame_stack": 4, "gradient_steps": 1, "learning_rate": 0.0001, "learning_starts": 100000, "n_timesteps": 10000000.0, "optimize_memory_usage": false, "policy": "CnnPolicy", "target_update_interval": 1000, "train_freq": 4, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The model was trained with a batch size of 32, a buffer size of 100000, and a learning rate of 0.0001. The mean reward achieved by the model on the SpaceInvadersNoFrameskip-v4 dataset is 246.00 with a standard deviation of 104.47. The model is suitable for reinforcement learning tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 246.0, "split": "val", "protocol": "mean_reward"}, {"dataset": "atari-grand-challenge", "metric": 104.47, "split": "test", "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-it-ms", "modules": [{"role": "model", "module": {"name": "ita-msa", "description": "A machine translation model that translates Italian to Malay (macrolanguage) using the transformer-align architecture."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece (spm32k,spm32k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "ita-msa is a machine translation model that translates Italian to Malay (macrolanguage) using the transformer-align architecture. The model was trained on the Tatoeba dataset and achieved a BLEU score of 26.0 and a chrF2 score of 0.536 on the test set. The model uses normalization and SentencePiece (spm32k,spm32k) for preprocessing."}}, {"role": "dataset", "purpose": "Test set used for evaluation.", "module": "tatoeba"}], "metrics": [{"dataset": "tatoeba", "metric": 26.0, "protocol": "BLEU"}, {"dataset": "tatoeba", "metric": 0.536, "protocol": "chrF2_score"}], "source": "huggingface"}, {"id": "huggingface-kaisuke-finetuning-sentiment-model-3000-samples", "modules": [{"role": "model", "module": {"name": "finetuning-sentiment-model-3000-samples", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "finetuning-sentiment-model-3000-samples is a fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis. The model achieved an accuracy of 0.87 and an F1 score of 0.8696 on the evaluation set. The model is suitable for text classification tasks, but its performance may vary depending on the specific use case and data distribution."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.87, "protocol": "accuracy"}, {"dataset": "imdb-movie-reviews", "metric": 0.8696, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-jdang-distilbert-base-uncased-finetuned-imdb", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-imdb", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-imdb is a fine-tuned version of distilbert-base-uncased on the imdb dataset. It can be used for text classification tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 64. The model was trained for 3 epochs and achieved a loss of 2.4721 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 2.4721, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-mrm8488-flan-t5-base-finetuned-gsm8k", "modules": [{"role": "model", "module": {"name": "flan-t5-base-finetuned-gsm8k", "description": "A fine-tuned version of google/flan-t5-base on the gsm8k dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 4, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "flan-t5-base-finetuned-gsm8k is a fine-tuned version of google/flan-t5-base on the gsm8k dataset. It is suitable for question-answering tasks. The model was trained with Adam optimizer with a learning rate of 5e-05 and a batch size of 4. The model was trained for 5 epochs and achieved a loss of 0.3652 and a Rouge2 Fmeasure of 0.1308 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "gsm8k"}], "metrics": [{"dataset": "gsm8k", "metric": 0.3652, "protocol": "loss"}, {"dataset": "gsm8k", "metric": 0.3914, "protocol": "rouge2_precision"}, {"dataset": "gsm8k", "metric": 0.0816, "protocol": "rouge2_recall"}, {"dataset": "gsm8k", "metric": 0.1308, "protocol": "rouge2_fmeasure"}], "source": "huggingface"}, {"id": "huggingface-napatswift-wp-th-cv-run-1", "modules": [{"role": "model", "module": {"name": "Whisper Tiny Thai", "description": "A fine-tuned version of openai/whisper-tiny on the Common Voice 11.0 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-05, "train_batch_size": 64, "eval_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "training_steps": 5000, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Whisper Tiny Thai is a fine-tuned version of openai/whisper-tiny on the Common Voice 11.0 dataset. It is a speech recognition model for the Thai language. The model was trained using Transformers 4.26.0.dev0, Pytorch 1.13.0+cu117, Datasets 2.7.1.dev0, and Tokenizers 0.13.2. The model achieved an evaluation loss of 0.4077 and a word error rate of 92.7519 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.4077, "protocol": "eval_loss"}, {"dataset": "common-voice", "metric": 92.7519, "protocol": "eval_wer"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-rnd-en", "modules": [{"role": "model", "module": {"name": "opus-mt-rnd-en", "description": "A transformer-align model for translating from a random source language to English."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-rnd-en model is a transformer-align model that translates from a random source language to English. It achieved a BLEU score of 37.8 and a chr-F score of 0.531 on the JW300.rnd.en test set. The model uses normalization and SentencePiece for pre-processing. The original weights can be downloaded from the provided link."}}, {"role": "dataset", "purpose": "Test set for benchmarking.", "module": "jw300"}], "metrics": [{"dataset": "jw300", "metric": 37.8, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.531, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-fi-zne", "modules": [{"role": "model", "module": {"name": "opus-mt-fi-zne", "description": "A machine translation model that translates from Finnish (fi) to an unspecified language (zne)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-fi-zne is a machine translation model that translates from Finnish to an unspecified language. The model uses the transformer-align architecture and pre-processing techniques such as normalization and SentencePiece. The model achieved a BLEU score of 22.7 and a chr-F score of 0.464 on the JW300.fi.zne test set."}}], "metrics": [{"dataset": "jw300", "metric": 22.7, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.464, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-anuragshas-wav2vec2-large-xlsr-53-hsb", "modules": [{"role": "model", "module": {"name": "Anurag Singh XLSR Wav2Vec2 Large 53 Sorbian, Upper", "description": "Fine-tuned Wav2Vec2-Large-XLSR-53 on Sorbian, Upper using the Common Voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "Wav2Vec2-Large-XLSR-53", "batch_size": 8, "optimizer": {"name": "Adam", "learning_rate": 0.0005, "beta1": 0.9, "beta2": 0.98, "weight_decay": 0.01}}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Anurag Singh fine-tuned the Wav2Vec2-Large-XLSR-53 model on Sorbian, Upper using the Common Voice dataset. The model can be used for automatic speech recognition tasks in Sorbian, Upper. The model was trained on the Common Voice train and validation datasets and evaluated on the Common Voice test dataset. The model achieved a WER score of 65.05%."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 65.05, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-fi-hr", "modules": [{"role": "model", "module": {"name": "opus-mt-fi-hr", "description": "A machine translation model that translates from Finnish to Croatian."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-fi-hr is a machine translation model that translates from Finnish to Croatian. It uses the transformer-align model and pre-processing techniques such as normalization and SentencePiece. The model achieves a BLEU score of 23.5 and a chr-F score of 0.476 on the JW300.fi.hr test set."}}], "metrics": [{"dataset": "jw300", "metric": 23.5, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.476, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-willheld-roberta-base-stsb", "modules": [{"role": "model", "module": {"name": "roberta-base-stsb", "description": "A fine-tuned version of roberta-base on the GLUE STSB dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.06, "num_epochs": 10.0}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "roberta-base-stsb is a fine-tuned version of roberta-base on the GLUE STSB dataset. It is intended for text classification tasks. The model achieved a Spearmanr score of 0.9092 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05, and a linear learning rate scheduler with a warmup ratio of 0.06."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "semantic-textual-similarity-2012-2016-sts"}], "metrics": [{"dataset": "semantic-textual-similarity-2012-2016-sts", "metric": 0.9092158650855444, "protocol": "Spearmanr"}], "source": "huggingface"}, {"id": "huggingface-rhiga-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 game."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "q-Taxi-v3 is a Q-Learning agent trained to play the Taxi-v3 game. The model achieved a mean reward of 7.50 with a standard deviation of 2.72. The model can be loaded and evaluated using the provided code snippet."}}, {"role": "dataset", "purpose": "The game environment used for training and evaluation.", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.5, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-es-lus", "modules": [{"role": "model", "module": {"name": "opus-mt-es-lus", "description": "A machine translation model that translates from Spanish (es) to Lushootseed (lus) language."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-es-lus is a machine translation model that translates from Spanish to Lushootseed language. The model uses transformer-align architecture and pre-processing techniques such as normalization and SentencePiece. The model has been evaluated on JW300.es.lus test set and achieved a BLEU score of 20.9 and a chr-F score of 0.414."}}], "metrics": [{"dataset": "jw300", "metric": 20.9, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.414, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-nates-test-org-convit-small", "modules": [{"role": "model", "module": {"name": "convit_small", "description": "Convolutional Vision Transformer (ConViT) is a transformer-based model for image classification tasks. The 'small' version of the model has 12 transformer layers and 4 convolutional layers."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"image_size": 224, "patch_size": 16, "num_classes": 1000, "num_transformer_layers": 12, "num_conv_layers": 4, "hidden_size": 384, "mlp_ratio": 4, "dropout_rate": 0.1, "attention_dropout_rate": 0.1, "classifier_dropout_rate": 0.1, "weight_decay": 0.05, "learning_rate": 0.001, "batch_size": 64, "num_epochs": 100}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "Convit_small is a transformer-based model for image classification tasks. It has 12 transformer layers and 4 convolutional layers. The model was trained on the ImageNet dataset and achieved a top-1 accuracy of 0.77 and a top-5 accuracy of 0.93. The model's hyperparameters include image size, patch size, number of transformer layers, number of convolutional layers, hidden size, MLP ratio, dropout rate, attention dropout rate, classifier dropout rate, weight decay, learning rate, batch size, and number of epochs."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-seongkyu-bert-base-cased-finetuned-squad", "modules": [{"role": "model", "module": {"name": "bert-base-cased-finetuned-squad", "description": "Fine-tuned version of bert-base-cased on the squad dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "bert-base-cased-finetuned-squad is a fine-tuned version of bert-base-cased on the squad dataset. It can be used for question answering tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for 3 epochs and achieved a loss of 1.0458 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 1.0458, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-mwong-albert-base-climate-claim-related", "modules": [{"role": "model", "module": {"name": "ClimateAlbert", "description": "A classifier model that predicts if climate related evidence is related to query claim."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"base_model": "albert-base-v2", "training_dataset": "Fever", "adaptation_dataset": "ClimateFever", "metric": "F1 score", "metric_value": 0.8533}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "ClimateAlbert is a classifier model that predicts if climate related evidence is related to query claim. The model is based on the albert-base-v2 model and was trained on the Fever dataset and adapted to the climate domain using the ClimateFever dataset. The model achieved an F1 score of 85.33% on the test dataset mwong/climate-claim-related."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-cheese7858-stance-detection", "modules": [{"role": "model", "module": {"name": "stance_detection", "description": "Fine-tuned version of bert-base-cased towards 26 US SPAC stock mergers on Twitter."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 32, "eval_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "The stance_detection model is a fine-tuned version of bert-base-cased towards 26 US SPAC stock mergers on Twitter. The model achieved an accuracy of 0.8409 and an F1w score of 0.8574 on the evaluation set. The model is intended for text classification tasks and reflects the biases inherent to the systems it was trained on, so caution should be taken when deploying it into systems that interact with humans."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "stocknet"}], "metrics": [{"dataset": "stocknet", "metric": 0.4906, "protocol": "loss"}, {"dataset": "stocknet", "metric": 0.8409, "protocol": "accuracy"}, {"dataset": "stocknet", "metric": 0.8574, "protocol": "F1w"}, {"dataset": "stocknet", "metric": 0.8293, "protocol": "Acc0"}, {"dataset": "stocknet", "metric": 0.6, "protocol": "Acc1"}, {"dataset": "stocknet", "metric": 0.7652, "protocol": "Acc2"}, {"dataset": "stocknet", "metric": 0.8637, "protocol": "Acc3"}], "source": "huggingface"}, {"id": "huggingface-victorlee071200-distilbert-base-cased-finetuned-squad-v2", "modules": [{"role": "model", "module": {"name": "distilbert-base-cased-finetuned-squad_v2", "description": "A fine-tuned version of distilbert-base-cased on the squad_v2 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-cased-finetuned-squad_v2 is a fine-tuned version of distilbert-base-cased on the squad_v2 dataset. It is suitable for question answering tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for 3 epochs and achieved a loss of 1.4225 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 1.4225, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-sun1638650145-q-frozenlake-v1-4x4-noslippery", "modules": [{"role": "model", "module": {"name": "q-FrozenLake-v1-4x4-noSlippery", "description": "A Q-Learning agent trained to play FrozenLake-v1-4x4-no_slippery."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a Q-Learning agent trained to play FrozenLake-v1-4x4-no_slippery. The model is evaluated based on the mean reward obtained over a number of evaluation episodes. The Q-Table learned by the agent is provided as a hyperparameter. The model is intended to be used for reinforcement learning tasks."}}, {"role": "dataset", "purpose": "Environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-timmychanga-dialogpt-small-ashley", "modules": [{"role": "model", "module": {"name": "Ashley DialoGPT Model", "description": "A conversational response model trained on a large corpus of English dialogues."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_size": "medium", "max_sequence_length": 512, "batch_size": 4, "learning_rate": 5e-05, "num_epochs": 3}}}, {"role": "taskType", "module": "conversational"}, {"role": "solutionSummary", "module": {"summary": "The Ashley DialoGPT Model is a conversational response model trained on a large corpus of English dialogues, specifically the Cornell Movie Dialogs Corpus. The model is of medium size and has a maximum sequence length of 512. It was trained for 3 epochs with a batch size of 4 and a learning rate of 5e-5. The model achieved a perplexity score of 12.3 on the training dataset. The model can be used for generating conversational text that is relevant, coherent, and knowledgeable given a prompt, with applications in chatbots and voice assistants."}}, {"role": "dataset", "purpose": "For model training.", "module": "cmu-movie-summary-corpus"}], "metrics": [{"dataset": "cmu-movie-summary-corpus", "metric": 12.3, "protocol": "Perplexity"}], "source": "huggingface"}, {"id": "huggingface-sb3-a2c-bipedalwalker-v3", "modules": [{"role": "model", "module": {"name": "A2C", "description": "A reinforcement learning agent trained on BipedalWalker-v3 using the stable-baselines3 library."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"ent_coef": 0.0, "gae_lambda": 0.9, "gamma": 0.99, "learning_rate": "lin_0.00096", "max_grad_norm": 0.5, "n_envs": 16, "n_steps": 8, "n_timesteps": 5000000.0, "normalize": true, "normalize_advantage": false, "policy": "MlpPolicy", "policy_kwargs": {"log_std_init": -2, "ortho_init": false}, "use_rms_prop": true, "use_sde": true, "vf_coef": 0.4, "normalize_kwargs": {"norm_obs": true, "norm_reward": false}}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "A2C is a reinforcement learning agent trained on BipedalWalker-v3 using the stable-baselines3 library. The model was trained using the RL Zoo training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included. The model achieved a mean reward of 300.85 with a standard deviation of 1.44. The hyperparameters used for training are provided in the model card."}}, {"role": "dataset", "purpose": "For model training.", "module": "bipedal-skills-bipedal-skills-benchmark-for-reinforcement-learning"}], "metrics": [{"dataset": "bipedal-skills-bipedal-skills-benchmark-for-reinforcement-learning", "metric": 300.85, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-dfsj-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8675 on the evaluation set. The model is suitable for token classification tasks in German language. The training was done using Adam optimizer with a learning rate of 5e-05 and a batch size of 24. The model was trained for 3 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8675, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-sq-en", "modules": [{"role": "model", "module": {"name": "opus-mt-sq-en", "description": "A machine translation model that translates from Albanian (sq) to English (en)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-sq-en is a machine translation model that translates from Albanian to English. It uses a transformer-align model and normalization + SentencePiece for pre-processing. The model achieves a BLEU score of 58.4 and a chr-F score of 0.732 on the Tatoeba.sq.en test set."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "tatoeba"}], "metrics": [{"dataset": "tatoeba", "metric": 58.4, "protocol": "BLEU"}, {"dataset": "tatoeba", "metric": 0.732, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-taltechnlp-voxlingua107-epaca-tdnn", "modules": [{"role": "model", "module": {"name": "VoxLingua107 ECAPA-TDNN Spoken Language Identification Model", "description": "A spoken language recognition model trained on the VoxLingua107 dataset using SpeechBrain."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"architecture": "ECAPA-TDNN"}}}, {"role": "taskType", "module": "audio-classification"}, {"role": "solutionSummary", "module": {"summary": "The VoxLingua107 ECAPA-TDNN Spoken Language Identification Model is a model trained on the VoxLingua107 dataset using SpeechBrain. It can classify a speech utterance according to the language spoken, covering 107 different languages. The model can be used as is for spoken language recognition or as an utterance-level feature (embedding) extractor for creating a dedicated language ID model on your own data. The model has limitations and biases, such as limited accuracy on smaller languages, worse performance on female speech than male speech, and poor performance on speech with a foreign accent, children's speech, and persons with speech disorders."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-infinitejoy-wav2vec2-large-xls-r-300m-arabic", "modules": [{"role": "model", "module": {"name": "XLS-R-300m-SV", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-300m on the MOZILLA-FOUNDATION/COMMON_VOICE_7_0 - AR dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 7.5e-05, "train_batch_size": 8, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 4, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 2000, "num_epochs": 50.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "XLS-R-300m-SV is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the MOZILLA-FOUNDATION/COMMON_VOICE_7_0 - AR dataset. The model is intended for automatic speech recognition tasks. The model was trained using Adam optimizer with a learning rate of 7.5e-05, and a linear learning rate scheduler with 2000 warmup steps. The model was trained for 50 epochs with mixed precision training. The evaluation results are not available."}}, {"role": "dataset", "purpose": "For model training.", "module": "common-voice"}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-jayanta-swin-large-patch4-window7-224-fv-finetuned-memes", "modules": [{"role": "model", "module": {"name": "swin-large-patch4-window7-224-fv-finetuned-memes", "description": "Fine-tuned version of microsoft/swin-large-patch4-window7-224 on the imagefolder dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.00012, "train_batch_size": 64, "eval_batch_size": 64, "seed": 42, "gradient_accumulation_steps": 4, "total_train_batch_size": 256, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "num_epochs": 20}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of microsoft/swin-large-patch4-window7-224 on the imagefolder dataset. The model is best suited for image classification tasks. The model achieved an accuracy of 0.8601 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 0.00012 and a linear learning rate scheduler with a warmup ratio of 0.1. The model was trained for 20 epochs with a batch size of 256."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "objectfolder"}], "metrics": [{"dataset": "objectfolder", "metric": 0.8601236476043277, "protocol": "Accuracy"}, {"dataset": "objectfolder", "metric": 0.8582306285016578, "protocol": "Precision"}, {"dataset": "objectfolder", "metric": 0.8601236476043277, "protocol": "Recall"}, {"dataset": "objectfolder", "metric": 0.8582797853944862, "protocol": "F1"}], "source": "huggingface"}, {"id": "huggingface-aimanlameesa-wav2vec2-xls-r-bengali-v1", "modules": [{"role": "model", "module": {"name": "wav2vec2-xls-r-bengali_v1", "description": "A fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 3e-05, "train_batch_size": 16, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 6, "mixed_precision_training": true}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset for automatic speech recognition. The model achieved a validation loss of 3.2973 and a WER of 1.0. The model was trained using PyTorch 1.11.0 and Transformers 4.18.0 with mixed precision training. The model reflects the biases inherent to the systems they were trained on, so caution should be taken when deploying it into systems that interact with humans."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 3.3226, "split": "val", "protocol": "loss"}, {"dataset": "common-voice", "metric": 3.2973, "split": "test", "protocol": "loss"}, {"dataset": "common-voice", "metric": 1.0, "protocol": "WER"}], "source": "huggingface"}, {"id": "huggingface-sb3-qrdqn-roadrunnernoframeskip-v4", "modules": [{"role": "model", "module": {"name": "QRDQN Agent playing RoadRunnerNoFrameskip-v4", "description": "A trained model of a QRDQN agent playing RoadRunnerNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"env_wrapper": "stable_baselines3.common.atari_wrappers.AtariWrapper", "exploration_fraction": 0.025, "frame_stack": 4, "n_timesteps": 10000000.0, "optimize_memory_usage": true, "policy": "CnnPolicy", "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained QRDQN agent model playing RoadRunnerNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The model was trained with hyperparameters such as exploration_fraction of 0.025, frame_stack of 4, and n_timesteps of 10000000.0. The model achieved a mean_reward of 920.00 +/- 107.70 on the RoadRunnerNoFrameskip-v4 dataset."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 920.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-sasha-autotrain-distilbert-tweeteval-1281148994", "modules": [{"role": "model", "module": {"name": "AutoTrain DistilBERT", "description": "A multi-class classification model trained using AutoTrain on the TweetEval dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_id": 1281148994, "problem_type": "multi-class classification", "tokenizer": "DistilBERT"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a multi-class classification model trained using AutoTrain on the TweetEval dataset. The model uses DistilBERT as the tokenizer. The model achieved an accuracy of 0.745 and can be used for text classification tasks."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-munggok-xlsr-indonesia", "modules": [{"role": "model", "module": {"name": "Wav2Vec2ForCTC", "description": "A pre-trained speech recognition model fine-tuned on Common Voice ID dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_name": "munggok/xlsr_indonesia", "chars_to_ignore_regex": "[\\,\\?\\.\\!\\-\\;\\:\"]", "batch_size": 16}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Wav2Vec2ForCTC is a pre-trained speech recognition model fine-tuned on the Common Voice ID dataset. The model uses the Wav2Vec2 architecture and Connectionist Temporal Classification (CTC) loss function. The model was fine-tuned with a batch size of 16 and achieved a Word Error Rate (WER) of 25.7% on the Common Voice ID test set."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 25.7, "protocol": "WER"}], "source": "huggingface"}, {"id": "huggingface-research-backup-t5-large-tweetqa-qag-np", "modules": [{"role": "model", "module": {"name": "research-backup/t5-large-tweetqa-qag-np", "description": "Fine-tuned version of t5-large for question & answer pair generation task on the lmqg/qag_tweetqa dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "t5-large", "max_length": 256, "max_length_output": 128, "epoch": 16, "batch": 16, "lr": 0.0001, "fp16": false, "random_seed": 1, "gradient_accumulation_steps": 4, "label_smoothing": 0.15}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of t5-large for question & answer pair generation task on the lmqg/qag_tweetqa dataset. The model is intended to generate question and answer pairs from a given paragraph. The model achieved good scores on various metrics such as BLEU4, ROUGE-L, METEOR, BERTScore, and MoverScore. The model was trained with a batch size of 16, a learning rate of 0.0001, and a label smoothing of 0.15. The model was fine-tuned for 16 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "tweetqa"}], "metrics": [{"dataset": "tweetqa", "metric": 14.14, "protocol": "BLEU4"}, {"dataset": "tweetqa", "metric": 31.49, "protocol": "METEOR"}, {"dataset": "tweetqa", "metric": 37.45, "protocol": "ROUGE-L"}, {"dataset": "tweetqa", "metric": 90.95, "protocol": "BERTScore"}, {"dataset": "tweetqa", "metric": 62.62, "protocol": "MoverScore"}, {"dataset": "tweetqa", "metric": 92.64, "protocol": "QAAlignedF1Score-BERTScore"}, {"dataset": "tweetqa", "metric": 92.27, "protocol": "QAAlignedRecall-BERTScore"}, {"dataset": "tweetqa", "metric": 93.03, "protocol": "QAAlignedPrecision-BERTScore"}, {"dataset": "tweetqa", "metric": 65.47, "protocol": "QAAlignedF1Score-MoverScore"}, {"dataset": "tweetqa", "metric": 64.68, "protocol": "QAAlignedRecall-MoverScore"}, {"dataset": "tweetqa", "metric": 66.36, "protocol": "QAAlignedPrecision-MoverScore"}], "source": "huggingface"}, {"id": "huggingface-xaeroq-ppo-mspacman-v5", "modules": [{"role": "model", "module": {"name": "PPO Agent playing ALE/MsPacman-v5", "description": "A trained PPO agent playing ALE/MsPacman-v5 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 256, "clip_range": "lin_0.1", "ent_coef": 0.01, "frame_stack": 4, "learning_rate": "lin_2.5e-4", "n_envs": 8, "n_epochs": 4, "n_steps": 128, "n_timesteps": 10000000.0, "policy": "CnnPolicy", "vf_coef": 0.5, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained PPO agent playing ALE/MsPacman-v5 using the stable-baselines3 library and the RL Zoo. The model was trained with a batch size of 256, 4 epochs, and 128 steps per epoch. The model achieved a mean reward of 2934.00 with a standard deviation of 982.27. The hyperparameters used for training include a clip range of lin_0.1, an entropy coefficient of 0.01, a learning rate of lin_2.5e-4, and a value function coefficient of 0.5. The model reflects the biases inherent to the systems they were trained on, so caution should be taken when deploying it into systems that interact with humans."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "arcade-learning-environment"}], "metrics": [{"dataset": "arcade-learning-environment", "metric": 2934.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-andi611-roberta-base-ner-conll2003", "modules": [{"role": "model", "module": {"name": "roberta-base-ner", "description": "A fine-tuned version of roberta-base on the conll2003 dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 32, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 4.0}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "roberta-base-ner is a fine-tuned version of roberta-base on the conll2003 dataset for token classification. The model is best suited for named entity recognition tasks. The model was trained using Adam optimizer with a learning rate of 5e-05 and a batch size of 32. The model achieved an F1 score of 0.9217 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 0.0814, "protocol": "eval_loss"}, {"dataset": "conll-2003", "metric": 0.9101, "protocol": "eval_precision"}, {"dataset": "conll-2003", "metric": 0.9336, "protocol": "eval_recall"}, {"dataset": "conll-2003", "metric": 0.9217, "protocol": "eval_f1"}, {"dataset": "conll-2003", "metric": 0.9799, "protocol": "eval_accuracy"}, {"dataset": "conll-2003", "metric": 10.2964, "protocol": "eval_runtime"}, {"dataset": "conll-2003", "metric": 315.646, "protocol": "eval_samples_per_second"}, {"dataset": "conll-2003", "metric": 39.529, "protocol": "eval_steps_per_second"}, {"dataset": "conll-2003", "metric": 1.14, "protocol": "epoch"}, {"dataset": "conll-2003", "metric": 500.0, "protocol": "step"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-es-he", "modules": [{"role": "model", "module": {"name": "Spanish to Hebrew translation model", "description": "A transformer model trained on Spanish to Hebrew translation task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece (spm32k,spm32k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "This is a transformer model trained on Spanish to Hebrew translation task. The model achieved a BLEU score of 43.6 and a chrF2 score of 0.636 on the Tatoeba-test.spa.heb dataset. The model uses normalization and SentencePiece (spm32k,spm32k) for preprocessing. The model is suitable for Spanish to Hebrew translation tasks."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "tatoeba-translation-challenge"}], "metrics": [{"dataset": "tatoeba-translation-challenge", "metric": 43.6, "protocol": "BLEU"}, {"dataset": "tatoeba-translation-challenge", "metric": 0.636, "protocol": "chrF2"}], "source": "huggingface"}, {"id": "huggingface-idea-ccnl-taiyi-stable-diffusion-1b-chinese-en-v0-1", "modules": [{"role": "model", "module": {"name": "Taiyi-Stable-Diffusion-1B-Chinese-EN-v0.1", "description": "The first open source Chinese&English Bilingual Stable diffusion, which was trained on 20M filtered Chinese image-text pairs."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_type": "Stable Diffusion", "parameters": "1B", "language": "Chinese and English"}}}, {"role": "taskType", "module": "text-to-image"}, {"role": "solutionSummary", "module": {"summary": "Taiyi-Stable-Diffusion-1B-Chinese-EN-v0.1 is the first open source Chinese&English Bilingual Stable diffusion model, which was trained on 20M filtered Chinese image-text pairs. The model is based on stable diffusion and is suitable for text-to-image tasks. The model was trained on Noah-Wukong and Zero datasets and was fine-tuned for two stages. The first stage only trained the text encoder, while the second stage trained both the text encoder and the diffusion model. The model is a preliminary version and will be updated continuously and open-sourced. The model authors have specified usage restrictions in the CreativeML OpenRAIL-M license, which must be agreed to before accessing the model."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-thorduragust-xlmr-enis-finetuned-ner", "modules": [{"role": "model", "module": {"name": "XLMR-ENIS-finetuned-ner", "description": "A fine-tuned version of vesteinn/XLMR-ENIS on the mim_gold_ner dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "XLMR-ENIS-finetuned-ner is a fine-tuned version of vesteinn/XLMR-ENIS on the mim_gold_ner dataset. It is a token classification model that can be used to identify named entities in text. The model achieved high precision, recall, F1 score, and accuracy on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler for 3 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "mimic-iii-the-medical-information-mart-for-intensive-care-iii"}], "metrics": [{"dataset": "mimic-iii-the-medical-information-mart-for-intensive-care-iii", "metric": 0.8707943925233644, "protocol": "precision"}, {"dataset": "mimic-iii-the-medical-information-mart-for-intensive-care-iii", "metric": 0.8475270039795338, "protocol": "recall"}, {"dataset": "mimic-iii-the-medical-information-mart-for-intensive-care-iii", "metric": 0.8590031691155287, "protocol": "f1"}, {"dataset": "mimic-iii-the-medical-information-mart-for-intensive-care-iii", "metric": 0.982856184128243, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-tner-deberta-v3-large-bc5cdr", "modules": [{"role": "model", "module": {"name": "tner/deberta-v3-large-bc5cdr", "description": "Fine-tuned version of microsoft/deberta-v3-large on the tner/bc5cdr dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"dataset": "tner/bc5cdr", "model": "microsoft/deberta-v3-large", "crf": true, "max_length": 128, "epoch": 15, "batch_size": 16, "lr": 1e-05, "gradient_accumulation_steps": 4, "weight_decay": 1e-07, "lr_warmup_step_ratio": 0.1}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of microsoft/deberta-v3-large on the tner/bc5cdr dataset for token classification. The model achieved an F1 score of 0.890 on the test set. It can be used through the tner library or transformers library, but CRF layer is not supported at the moment. The model was trained with a batch size of 16, a learning rate of 1e-5, and a maximum sequence length of 128. The model reflects the biases inherent to the systems they were trained on, so caution should be taken when deploying it into systems that interact with humans."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "bc5cdr-biocreative-v-cdr-corpus"}], "metrics": [{"dataset": "bc5cdr-biocreative-v-cdr-corpus", "metric": 0.8902493653874869, "protocol": "f1"}, {"dataset": "bc5cdr-biocreative-v-cdr-corpus", "metric": 0.8697724178175452, "protocol": "precision"}, {"dataset": "bc5cdr-biocreative-v-cdr-corpus", "metric": 0.9117137322866755, "protocol": "recall"}, {"dataset": "bc5cdr-biocreative-v-cdr-corpus", "metric": 0.8863403908610603, "protocol": "f1_macro"}, {"dataset": "bc5cdr-biocreative-v-cdr-corpus", "metric": 0.8657302393432342, "protocol": "precision_macro"}, {"dataset": "bc5cdr-biocreative-v-cdr-corpus", "metric": 0.9080747413030301, "protocol": "recall_macro"}, {"dataset": "bc5cdr-biocreative-v-cdr-corpus", "metric": 0.8929371360310587, "protocol": "f1_entity_span"}, {"dataset": "bc5cdr-biocreative-v-cdr-corpus", "metric": 0.8723983660766388, "protocol": "precision_entity_span"}, {"dataset": "bc5cdr-biocreative-v-cdr-corpus", "metric": 0.9144663064532572, "protocol": "recall_entity_span"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-tll-sv", "modules": [{"role": "model", "module": {"name": "opus-mt-tll-sv", "description": "A machine translation model that translates from TLL to SV using the transformer-align architecture."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-tll-sv is a machine translation model that translates from TLL to SV using the transformer-align architecture. The model was preprocessed using normalization and SentencePiece. The model achieved a BLEU score of 25.6 and a chr-F score of 0.436 on the JW300.tll.sv test set."}}], "metrics": [{"dataset": "jw300", "metric": 25.6, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.436, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-jihyun22-bert-base-finetuned-nli", "modules": [{"role": "model", "module": {"name": "bert-base-finetuned-nli", "description": "Fine-tuned version of klue/bert-base on the klue dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 128, "eval_batch_size": 128, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-base-finetuned-nli is a fine-tuned version of klue/bert-base on the klue dataset. It is a transformer model that can be used for text classification tasks. The model achieved an accuracy of 0.756 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 128 for 5 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "klue-korean-language-understanding-evaluation"}], "metrics": [{"dataset": "klue-korean-language-understanding-evaluation", "metric": 0.756, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-aindrakumar26-distilbert-base-uncased-finetuned-squad", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-squad", "description": "A fine-tuned version of distilbert-base-uncased on the squad dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.001, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-squad is a fine-tuned version of distilbert-base-uncased on the squad dataset. It is suitable for question answering tasks. The model was trained with Adam optimizer with a learning rate of 0.001 and a batch size of 16. The model was trained for 5 epochs and achieved a loss of 5.9506 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 5.9506, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-dimedrolza-dialogpt-small-cyberpunk", "modules": [{"role": "model", "module": {"name": "V DialoGPT Model", "description": "A transformer-based conversational AI model that generates responses to text prompts."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"max_length": 1024, "num_attention_heads": 16, "num_layers": 6, "num_training_steps": 1000000, "per_device_train_batch_size": 1, "per_device_eval_batch_size": 1, "warmup_steps": 10000, "learning_rate": 5e-05}}}, {"role": "taskType", "module": "conversational"}, {"role": "solutionSummary", "module": {"summary": "V DialoGPT is a transformer-based conversational AI model that generates responses to text prompts. It was trained on a large corpus of Reddit data using a maximum likelihood estimation objective. The model has 6 layers and 16 attention heads, and was trained for 1 million steps with a learning rate of 5e-5. The model achieved a perplexity score of 12.3 on the Reddit dataset. The model can be fine-tuned on other conversational tasks or used as a general-purpose conversational AI model."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-sv-he", "modules": [{"role": "model", "module": {"name": "opus-mt-sv-he", "description": "A machine translation model that translates from Swedish (sv) to Hebrew (he) using a transformer-align model."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-sv-he is a machine translation model that translates from Swedish to Hebrew using a transformer-align model. The model was trained on the OPUS dataset and uses normalization and SentencePiece for pre-processing. The model achieved a BLEU score of 23.1 and a chr-F score of 0.44 on the JW300.sv.he test set."}}], "metrics": [{"dataset": "jw300", "metric": 23.1, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.44, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-khizon-bert-unreliable-news-eng", "modules": [{"role": "model", "module": {"name": "Unreliable News Classifier (English)", "description": "A model trained to classify news articles as reliable or unreliable using a subset of the NELA-GT-2018 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"pretrained_model": "bert-base-cased", "accuracy": 0.84}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "The Unreliable News Classifier is a model trained to classify news articles as reliable or unreliable using a subset of the NELA-GT-2018 dataset. The model uses the pre-trained weights of `bert-base-cased` as a starting point and achieved an accuracy of 84% on the test set. The model can be used to classify news articles as reliable or unreliable, but it should be noted that the model's performance may be limited to the specific dataset it was trained on."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-course5i-sead-l-6-h-256-a-8-stsb", "modules": [{"role": "model", "module": {"name": "SEAD-L-6_H-256_A-8-stsb", "description": "A student model distilled from BERT base as teacher by using SEAD framework on stsb task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"num_layers": 6, "hidden_size": 256, "num_attention_heads": 8, "training_args": {"learning_rate": 5e-05, "per_device_train_batch_size": 32, "per_device_eval_batch_size": 64, "num_train_epochs": 3, "weight_decay": 0.01, "warmup_steps": 500, "logging_steps": 500, "save_steps": 500, "evaluation_strategy": "steps", "eval_steps": 500, "metric_for_best_model": "eval_pearson", "load_best_model_at_end": true}}}}, {"role": "taskType", "module": "sentence-similarity"}, {"role": "solutionSummary", "module": {"summary": "SEAD-L-6_H-256_A-8-stsb is a student model distilled from BERT base as teacher by using SEAD framework on stsb task. The model is intended for sentence similarity tasks and achieves high performance on the STS benchmark. The model is trained with PyTorch and Transformers library and can be fine-tuned for other sentence similarity tasks."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-af-fr", "modules": [{"role": "model", "module": {"name": "opus-mt-af-fr", "description": "A machine translation model that translates from Afrikaans to French."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-af-fr is a machine translation model that translates from Afrikaans to French. It was trained on the OPUS dataset using a transformer-align model with normalization and SentencePiece preprocessing. The model achieved a BLEU score of 35.3 and a chr-F score of 0.543 on the JW300.af.fr test set."}}], "metrics": [{"dataset": "jw300", "metric": 35.3, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.543, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-speech-seq2seq-wav2vec2-2-gpt2-medium", "modules": [{"role": "model", "module": {"name": "Unnamed ASR model", "description": "A speech recognition model trained on the librispeech_asr dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0001, "train_batch_size": 8, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 3.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "An automatic speech recognition model trained on the librispeech_asr dataset. The model was trained from scratch using the Adam optimizer with a learning rate of 0.0001 and a linear learning rate scheduler. The model achieved a loss of 3.5264 and a WER of 1.7073 on the evaluation set. The model was trained using PyTorch 1.10.2+cu113 and Transformers 4.17.0.dev0."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "librispeech"}], "metrics": [{"dataset": "librispeech", "metric": 3.7737, "split": "val", "protocol": "loss"}, {"dataset": "librispeech", "metric": 3.5264, "split": "test", "protocol": "loss"}, {"dataset": "librispeech", "metric": 1.7454, "split": "val", "protocol": "wer"}, {"dataset": "librispeech", "metric": 1.7073, "split": "test", "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-ganchengguang-roberta-base-japanese-sentencepiece", "modules": [{"role": "model", "module": {"name": "RoBERTa", "description": "Pretrained model on Japanese language using a robustly optimized BERT pretraining approach."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"tokenizer": "sentencepiece", "max_len": 510}}}, {"role": "taskType", "module": "fill-mask"}, {"role": "solutionSummary", "module": {"summary": "RoBERTa is a transformer model pretrained on a large corpus of Japanese texts. It uses a robustly optimized BERT pretraining approach and the sentencepiece tokenizer. The model is mainly intended to be fine-tuned on a downstream task. The model is suitable for tasks that use the whole sentence to make decisions, such as sequence classification, token classification, or question answering. The model has achieved high accuracy in binary sentiment classification on the JGLUE-marc_ja-v1.0 dataset."}}, {"role": "dataset", "purpose": "For model training.", "module": "wikitext-2"}, {"role": "dataset", "purpose": "For evaluation.", "module": "jglue"}], "metrics": [{"dataset": "jglue", "metric": 95.4, "protocol": "binary sentiment classification"}], "source": "huggingface"}, {"id": "huggingface-sebis-legal-t5-small-summ-it", "modules": [{"role": "model", "module": {"name": "legal_t5_small_summ_it", "description": "Model for summarization of legal text written in Italian."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_size": "t5-small", "dmodel": 512, "dff": 2048, "num_heads": 8, "num_layers": 6, "batch_size": 64, "optimizer": {"name": "AdaFactor", "learning_rate_schedule": "inverse square root"}}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "legal_t5_small_summ_it is a transformer model based on the t5-small model and was trained on a large corpus of parallel text. It is intended for summarization of legal texts written in Italian. The model was trained on JRC-ACQUIS dataset consisting of 22 thousand texts. The model has approximately 220M parameters and was trained using the encoder-decoder architecture. The model achieved a Rouge1 score of 75.07, Rouge2 score of 65.53, and Rouge Lsum score of 73.85."}}, {"role": "dataset", "purpose": "For model training.", "module": "europarl-european-parliament-proceedings-parallel-corpus"}], "metrics": [{"dataset": "europarl-european-parliament-proceedings-parallel-corpus", "metric": 75.07, "protocol": "Rouge1"}, {"dataset": "europarl-european-parliament-proceedings-parallel-corpus", "metric": 65.53, "protocol": "Rouge2"}, {"dataset": "europarl-european-parliament-proceedings-parallel-corpus", "metric": 73.85, "protocol": "Rouge Lsum"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-fi-uk", "modules": [{"role": "model", "module": {"name": "opus-mt-fi-uk", "description": "A machine translation model that translates from Finnish to Ukrainian."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-fi-uk is a machine translation model that translates from Finnish to Ukrainian. It uses a transformer-align model and pre-processing techniques such as normalization and SentencePiece. The model achieves a BLEU score of 23.3 and a chr-F score of 0.445 on the JW300.fi.uk test set."}}], "metrics": [{"dataset": "jw300", "metric": 23.3, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.445, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-sanchit-gandhi-wav2vec2-2-rnd-2-layer", "modules": [{"role": "model", "module": {"name": "ASR model trained on Librispeech dataset", "description": "This model was trained from scratch on the librispeech_asr dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 3e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "gradient_accumulation_steps": 8, "total_train_batch_size": 128, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 1000, "num_epochs": 20.0, "mixed_precision_training": true}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is an ASR model trained on the Librispeech dataset. The model was trained from scratch and achieved a WER of 0.9238 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 3e-05 and a linear learning rate scheduler. The model was trained for 20 epochs with mixed precision training. The model was implemented using Transformers 4.17.0.dev0, Pytorch 1.10.2+cu113, Datasets 1.18.3, and Tokenizers 0.11.0."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "librispeech"}], "metrics": [{"dataset": "librispeech", "metric": 5.642, "split": "val", "protocol": "loss"}, {"dataset": "librispeech", "metric": 5.2188, "split": "test", "protocol": "loss"}, {"dataset": "librispeech", "metric": 0.9238, "protocol": "WER"}], "source": "huggingface"}, {"id": "huggingface-nobody138-xlm-roberta-base-finetuned-panx-it", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-it", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8124 on the evaluation set. The model is suitable for token classification tasks in Italian language."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8124, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-haotieu-en-vi-mt-model", "modules": [{"role": "model", "module": {"name": "Helsinki-NLP/opus-mt-en-vi", "description": "A fine-tuned model checkpoint for English to Vietnamese machine translation."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0001, "batch_size": 4, "num_train_epochs": 3.0}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "Helsinki-NLP/opus-mt-en-vi is a fine-tuned model checkpoint for English to Vietnamese machine translation. It was fine-tuned on the IWSLT'15 English-Vietnamese dataset and achieved a BLEU score of 33.086 on the test set. The model's hyperparameters include a learning rate of 0.0001, a batch size of 4, and 3 epochs of training. The model is suitable for English to Vietnamese translation tasks."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "iwslt2015"}], "metrics": [{"dataset": "iwslt2015", "metric": 33.086, "protocol": "BLEU"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-ru-et", "modules": [{"role": "model", "module": {"name": "rus-est", "description": "A transformer model for translating from Russian to Estonian."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece (spm32k,spm32k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "rus-est is a transformer model trained on a large corpus of Russian and Estonian data for translation from Russian to Estonian. The model uses normalization and SentencePiece (spm32k,spm32k) for preprocessing. The model achieved a BLEU score of 57.5 and a chrF2 score of 0.749 on the Tatoeba-test.rus.est dataset."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "tatoeba"}], "metrics": [{"dataset": "tatoeba", "metric": 57.5, "protocol": "BLEU"}, {"dataset": "tatoeba", "metric": 0.749, "protocol": "chrF2"}], "source": "huggingface"}, {"id": "huggingface-rossanez-t5-small-finetuned-de-en-64", "modules": [{"role": "model", "module": {"name": "t5-small-finetuned-de-en-64", "description": "A fine-tuned version of t5-small on the wmt14 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1, "mixed_precision_training": true}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "t5-small-finetuned-de-en-64 is a fine-tuned version of t5-small on the wmt14 dataset. It is intended for translation tasks from German to English. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for one epoch and achieved a validation loss of 2.3808. The model was trained using mixed precision training."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wmt-2014"}], "metrics": [{"dataset": "wmt-2014", "metric": 2.3808, "protocol": "Validation Loss"}, {"dataset": "wmt-2014", "metric": 3.1482, "protocol": "Bleu"}, {"dataset": "wmt-2014", "metric": 17.8019, "protocol": "Gen Len"}], "source": "huggingface"}, {"id": "huggingface-thientran-bert-finetuned-ner", "modules": [{"role": "model", "module": {"name": "bert-finetuned-ner", "description": "A fine-tuned version of bert-base-cased on the conll2003 dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-finetuned-ner is a fine-tuned version of bert-base-cased on the conll2003 dataset for token classification. The model achieved a precision of 0.8333, recall of 0.9322, F1 score of 0.8800, and accuracy of 0.9725 on the evaluation set. The model is suitable for named entity recognition tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 0.8333, "protocol": "precision"}, {"dataset": "conll-2003", "metric": 0.9322, "protocol": "recall"}, {"dataset": "conll-2003", "metric": 0.88, "protocol": "f1"}, {"dataset": "conll-2003", "metric": 0.9725, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-ro-fr", "modules": [{"role": "model", "module": {"name": "opus-mt-ro-fr", "description": "A transformer-align model for translating from Romanian to French."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-ro-fr model is a transformer-align model that translates from Romanian to French. It achieved a BLEU score of 54.5 and a chr-F score of 0.697 on the Tatoeba.ro.fr test set."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-alishaker-layoutlmv3-finetuned-wildreceipt", "modules": [{"role": "model", "module": {"name": "layoutlmv3-finetuned-wildreceipt", "description": "A fine-tuned version of microsoft/layoutlmv3-base on the wildreceipt dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-05, "train_batch_size": 4, "eval_batch_size": 4, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "training_steps": 4000}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of microsoft/layoutlmv3-base on the wildreceipt dataset. It can be used for token classification tasks. The model achieved a precision of 0.8779, recall of 0.8870, F1 score of 0.8825, and accuracy of 0.9265 on the evaluation set. The model was trained with Adam optimizer with a learning rate of 1e-05 and a batch size of 4. The model was trained for 4000 steps."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wildreceipt"}], "metrics": [{"dataset": "wildreceipt", "metric": 0.877962408063198, "protocol": "precision"}, {"dataset": "wildreceipt", "metric": 0.8870235310306867, "protocol": "recall"}, {"dataset": "wildreceipt", "metric": 0.8824697104524608, "protocol": "f1"}, {"dataset": "wildreceipt", "metric": 0.9265109136777449, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-scjones-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8649 on the evaluation set. The model is suitable for token classification tasks in German language. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8648740833380706, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-fofer-distilbert-base-uncased-finetuned-squad", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-squad", "description": "A fine-tuned version of distilbert-base-uncased on the squad_v2 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-squad is a fine-tuned version of distilbert-base-uncased on the squad_v2 dataset. It is suitable for question answering tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for 3 epochs and achieved a loss of 1.4306 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 1.4306, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-sebis-code-trans-t5-base-code-documentation-generation-java-multitask", "modules": [{"role": "model", "module": {"name": "CodeTrans model for code documentation generation java", "description": "Pretrained model on programming language java using the t5 base model architecture."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 4096, "optimizer": {"name": "AdaFactor", "learning_rate_schedule": "inverse square root"}}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "CodeTrans is a transformer model based on the t5-base architecture, pre-trained on a large corpus of tokenized Java code functions. It can be used to generate descriptions for Java functions or fine-tuned for other Java code tasks. The model is suitable for unparsed and untokenized Java code, but performance is better with tokenized code. The model was trained using multi-task training on 13 supervised tasks in the software development domain and 7 unsupervised datasets. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-es-gl", "modules": [{"role": "model", "module": {"name": "spa-glg", "description": "A transformer model for translating from Spanish to Galician."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece (spm4k,spm4k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "spa-glg is a transformer model pre-trained on a large corpus of Spanish and Galician data. It can be used for translating Spanish text to Galician. The model achieved a BLEU score of 67.6 on the Tatoeba-test.spa.glg dataset. The model uses normalization and SentencePiece (spm4k,spm4k) for pre-processing. The model was trained on the Tatoeba-Challenge dataset and is licensed under Apache-2.0."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "tatoeba-translation-challenge"}], "metrics": [{"dataset": "tatoeba-translation-challenge", "metric": 67.6, "protocol": "BLEU"}, {"dataset": "tatoeba-translation-challenge", "metric": 0.808, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-mayorov-s-dqn-spaceinvadersnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "DQN", "description": "A trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "buffer_size": 100000, "exploration_final_eps": 0.01, "exploration_fraction": 0.1, "frame_stack": 4, "gradient_steps": 1, "learning_rate": 0.0001, "learning_starts": 100000, "n_timesteps": 1000000.0, "optimize_memory_usage": false, "policy": "CnnPolicy", "target_update_interval": 1000, "train_freq": 4, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The model was trained with a batch size of 32, a buffer size of 100000, and a learning rate of 0.0001. The model achieved a mean reward of 612.00 with a standard deviation of 154.62. The model is suitable for reinforcement learning tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 612.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-ha-es", "modules": [{"role": "model", "module": {"name": "opus-mt-ha-es", "description": "A machine translation model that translates from the Hausa language to Spanish."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-ha-es is a machine translation model that translates from the Hausa language to Spanish. The model was trained on the OPUS dataset using the transformer-align architecture and pre-processing techniques such as normalization and SentencePiece. The model achieved a BLEU score of 21.8 and a chr-F score of 0.394 on the JW300.ha.es test set."}}], "metrics": [{"dataset": "jw300", "metric": 21.8, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.394, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-htermotto-distilbert-base-uncased-finetuned-squad-seed-42", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-squad-seed-42", "description": "A fine-tuned version of distilbert-base-uncased on the squad_v2 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-squad-seed-42 is a fine-tuned version of distilbert-base-uncased on the squad_v2 dataset. It is suitable for question answering tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for 3 epochs and achieved a loss of 1.4364 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 1.4364, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-comcom-gpt2-small", "modules": [{"role": "model", "module": {"name": "GPT-2", "description": "Pretrained model on English language using a causal language modeling (CLM) objective."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"tokenizer": "byte-level BPE", "vocabulary_size": 50257, "token_length": 1024}}}, {"role": "taskType", "module": "text-generation"}, {"role": "solutionSummary", "module": {"summary": "GPT-2 is a transformer model pretrained on a large corpus of English data in a self-supervised fashion. It can be used for text generation or fine-tuned for downstream tasks. The model is best at generating texts from a prompt. The training data used for this model has not been released as a dataset one can browse. The model reflects the biases inherent to the systems they were trained on, so caution should be taken when deploying it into systems that interact with humans."}}, {"role": "dataset", "purpose": "For model training.", "module": "webtext"}, {"role": "dataset", "purpose": "For evaluation.", "module": "lambada"}], "metrics": [{"dataset": "lambada", "metric": 35.13, "protocol": "PPL"}, {"dataset": "lambada", "metric": 45.99, "protocol": "ACC"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-sv-crs", "modules": [{"role": "model", "module": {"name": "opus-mt-sv-crs", "description": "A machine translation model that translates from Swedish (sv) to Seselwa Creole French (crs)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-sv-crs is a machine translation model that translates from Swedish to Seselwa Creole French. The model uses the transformer-align architecture and was preprocessed using normalization and SentencePiece. The model achieved a BLEU score of 32.4 and a chr-F score of 0.512 on the JW300.sv.crs test set."}}], "metrics": [{"dataset": "jw300", "metric": 32.4, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.512, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-mahmoud7-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 game."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "is_slippery": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 game. The model was trained using a custom implementation of the Q-Learning algorithm. The model's performance is evaluated using the mean reward metric, which is 7.56 with a standard deviation of 2.71."}}, {"role": "dataset", "purpose": "The game environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 7.56, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-ovillan-distilbert-finetuning-fakenews", "modules": [{"role": "model", "module": {"name": "distilbert-finetuning-fakenews", "description": "A fine-tuned version of distilbert-base-uncased on an external dataset to detect fake news in Spanish."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-finetuning-fakenews is a fine-tuned version of distilbert-base-uncased on an external dataset to detect fake news in Spanish. The model achieved an accuracy of 0.8833 and an F1 score of 0.9014 on the evaluation set. The model is suitable for text classification tasks in Spanish, but caution should be taken when deploying it in human-interacting systems as the model reflects the biases of the systems it was trained on."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "fakenewsnet"}], "metrics": [{"dataset": "fakenewsnet", "metric": 0.8833, "protocol": "accuracy"}, {"dataset": "fakenewsnet", "metric": 0.9014, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-google-tapas-mini-finetuned-sqa", "modules": [{"role": "model", "module": {"name": "TAPAS mini model fine-tuned on Sequential Question Answering (SQA)", "description": "A BERT-like transformers model fine-tuned on SQA dataset for answering questions related to a table in a conversational set-up."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": {"tokenizer": "WordPiece", "vocabulary_size": 30000, "sequence_format": "[CLS] Question [SEP] Flattened table [SEP]"}, "fine_tuning": {"optimizer": {"name": "Adam", "learning_rate": 1.25e-05, "warmup_ratio": 0.2}, "batch_size": 128, "max_seq_length": 512, "inductive_bias": "select_one_column"}}}}, {"role": "taskType", "module": "table-question-answering"}, {"role": "solutionSummary", "module": {"summary": "TAPAS is a BERT-like transformers model fine-tuned on SQA dataset for answering questions related to a table in a conversational set-up. The model was pre-trained on MLM and intermediate pre-training, and then fine-tuned on SQA. The model uses relative position embeddings and an inductive bias is added such that the model only selects cells of the same column. The model is best suited for answering questions related to a table in a conversational set-up. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "sqa-sequentialqa"}], "metrics": [{"dataset": "sqa-sequentialqa", "metric": 0.5148, "split": "val", "protocol": "Dev Accuracy"}, {"dataset": "sqa-sequentialqa", "metric": 0.4574, "split": "test", "protocol": "Dev Accuracy"}], "source": "huggingface"}, {"id": "huggingface-m3hrdadfi-albert-fa-base-v2-clf-persiannews", "modules": [{"role": "model", "module": {"name": "ALBERT Persian", "description": "A Lite BERT for Self-supervised Learning of Language Representations for the Persian Language."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_version": "ALBERT BASE Version 2.0", "training_data": {"documents": 3900000, "sentences": 73000000, "words": 1300000000}}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "ALBERT Persian is a Lite BERT model for self-supervised learning of language representations for the Persian language. The model was trained on various writing styles from numerous subjects, including scientific, novels, and news. The model is best suited for text classification tasks, such as labeling texts in a supervised manner in existing datasets like Persian News. The model achieves high F1 scores compared to other models and architectures."}}, {"role": "dataset", "purpose": "A dataset of various news articles scraped from different online news agencies' websites. The total number of articles is 16,438, spread over eight different classes.", "module": "perkey"}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-philschmid-bert-base-banking77-pt2", "modules": [{"role": "model", "module": {"name": "bert-base-banking77-pt2", "description": "A fine-tuned version of bert-base-uncased on the banking77 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 16, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-base-banking77-pt2 is a fine-tuned version of bert-base-uncased on the banking77 dataset. It is best suited for text classification tasks. The model was trained for 3 epochs with a learning rate of 5e-05 and an Adam optimizer with betas=(0.9,0.999) and epsilon=1e-08. The model achieved an F1 score of 0.9318 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "banking77"}], "metrics": [{"dataset": "banking77", "metric": 0.9317731421465705, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-autoevaluate-binary-classification-not-evaluated", "modules": [{"role": "model", "module": {"name": "binary-classification", "description": "Fine-tuned version of distilbert-base-uncased on the glue dataset for binary classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of distilbert-base-uncased on the glue dataset for binary classification. The model achieved an accuracy of 0.8968 and a validation loss of 0.3009. It can be used for text classification tasks, but the intended uses and limitations are not specified. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for one epoch."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.175, "split": "val", "protocol": "loss"}, {"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.3009, "split": "test", "protocol": "loss"}, {"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.8968, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-paul-vinh-bert-base-multilingual-cased-finetuned-squad", "modules": [{"role": "model", "module": {"name": "bert-base-multilingual-cased-finetuned-squad", "description": "A fine-tuned version of bert-base-multilingual-cased on the squad dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "bert-base-multilingual-cased-finetuned-squad is a fine-tuned version of bert-base-multilingual-cased on the squad dataset. It can be used for question answering tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for 3 epochs and achieved a loss of 1.0122 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 1.0122, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-kohama1988-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. It can be used for text classification tasks. The model achieved an accuracy of 0.9235 and an F1 score of 0.9236 on the evaluation set. The model was trained for 2 epochs with a learning rate of 2e-05 and an Adam optimizer with betas=(0.9,0.999) and epsilon=1e-08."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.9235, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.9236, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-sv-pag", "modules": [{"role": "model", "module": {"name": "opus-mt-sv-pag", "description": "A machine translation model that translates from Swedish (sv) to Pangasinan (pag) language."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-sv-pag is a machine translation model that translates from Swedish to Pangasinan language. The model is based on the transformer-align architecture and was preprocessed using normalization and SentencePiece. The model achieved a BLEU score of 29.3 and a chr-F score of 0.522 on the JW300.sv.pag test set."}}], "metrics": [{"dataset": "jw300", "metric": 29.3, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.522, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-drishtisharma-layoutlmv3-finetuned-cord-100", "modules": [{"role": "model", "module": {"name": "LayoutLMv3-Finetuned-CORD_100", "description": "A fine-tuned version of microsoft/layoutlmv3-base on the cord-layoutlmv3 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1.1e-05, "train_batch_size": 5, "eval_batch_size": 5, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "training_steps": 3000}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "LayoutLMv3-Finetuned-CORD_100 is a fine-tuned version of microsoft/layoutlmv3-base on the cord-layoutlmv3 dataset. It is a token classification model that can identify and classify tokens in a document layout. The model was trained with a learning rate of 1.1e-05, a batch size of 5, and the Adam optimizer with betas=(0.9,0.999) and epsilon=1e-08. The model achieved a precision of 0.9525, recall of 0.9603, F1 score of 0.9564, and accuracy of 0.9648 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "cord-19"}], "metrics": [{"dataset": "cord-19", "metric": 0.9524870081662955, "protocol": "precision"}, {"dataset": "cord-19", "metric": 0.9603293413173652, "protocol": "recall"}, {"dataset": "cord-19", "metric": 0.9563920983973164, "protocol": "f1"}, {"dataset": "cord-19", "metric": 0.9647707979626485, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-etch-distilbert-base-uncased-finetuned-sst-2-english-finetuned-sst2", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-sst-2-english-finetuned-sst2", "description": "A fine-tuned version of distilbert-base-uncased-finetuned-sst-2-english on the glue dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of distilbert-base-uncased-finetuned-sst-2-english on the glue dataset. It is suitable for text classification tasks. The model achieved an accuracy of 0.9060 on the evaluation set. The training was done with Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for 1 epoch."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.906, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-research-backup-bart-large-subjqa-vanilla-electronics-qg", "modules": [{"role": "model", "module": {"name": "research-backup/bart-large-subjqa-vanilla-electronics-qg", "description": "Fine-tuned version of facebook/bart-large for question generation task on the lmqg/qg_subjqa (dataset_name: electronics) via lmqg."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "facebook/bart-large", "max_length": 512, "max_length_output": 32, "epoch": 1, "batch": 8, "lr": 1e-05, "fp16": false, "random_seed": 1, "gradient_accumulation_steps": 8, "label_smoothing": 0.15}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of facebook/bart-large for question generation task on the lmqg/qg_subjqa (dataset_name: electronics) via lmqg. The model is best suited for generating questions from a given context and answer. The model was trained with a batch size of 8, a learning rate of 1e-05, and a maximum sequence length of 512. The model achieved good performance on various evaluation metrics such as BERTScore, BLEU4, METEOR, MoverScore, and ROUGE-L."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "subjqa"}], "metrics": [{"dataset": "subjqa", "metric": 85.69, "protocol": "BERTScore (Question Generation)"}, {"dataset": "subjqa", "metric": 0.34, "protocol": "BLEU4 (Question Generation)"}, {"dataset": "subjqa", "metric": 11.35, "protocol": "METEOR (Question Generation)"}, {"dataset": "subjqa", "metric": 54.66, "protocol": "MoverScore (Question Generation)"}, {"dataset": "subjqa", "metric": 13.67, "protocol": "ROUGE-L (Question Generation)"}], "source": "huggingface"}, {"id": "huggingface-fabiochiu-q-frozenlake-v1-8x8-no-slippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained model of a Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-8x8-no_slippery"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model achieved a mean reward of 1.00 +/- 0.00. The model can be loaded and evaluated using the provided code snippet."}}, {"role": "dataset", "purpose": "The environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-suonbo-bert-finetuned-ner", "modules": [{"role": "model", "module": {"name": "bert-finetuned-ner", "description": "A fine-tuned version of bert-base-cased on the conll2003 dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-finetuned-ner is a fine-tuned version of bert-base-cased on the conll2003 dataset for token classification. The model achieved high precision, recall, F1 score, and accuracy on the evaluation set. It can be used for named entity recognition tasks, but caution should be taken when deploying it in human-interacting systems as the model reflects the biases of the systems it was trained on."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 0.9335982778605729, "protocol": "Precision"}, {"dataset": "conll-2003", "metric": 0.9488387748232918, "protocol": "Recall"}, {"dataset": "conll-2003", "metric": 0.9411568316501127, "protocol": "F1"}, {"dataset": "conll-2003", "metric": 0.9854447518690763, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-sl-fi", "modules": [{"role": "model", "module": {"name": "opus-mt-sl-fi", "description": "A transformer-align model for translating from Slovenian (sl) to Finnish (fi)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-sl-fi model is a transformer-align model that translates from Slovenian to Finnish. It achieved a BLEU score of 23.4 and a chr-F score of 0.517 on the JW300.sl.fi test set. The model uses normalization and SentencePiece for pre-processing. The original weights can be downloaded from the provided link."}}, {"role": "dataset", "purpose": "Test set for benchmarking.", "module": "jw300"}], "metrics": [{"dataset": "jw300", "metric": 23.4, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.517, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-pierreguillou-bert-large-cased-pt-lenerbr", "modules": [{"role": "model", "module": {"name": "bert-large-cased-pt-lenerbr", "description": "Language model in the legal domain in Portuguese that was finetuned on the LeNER-Br language modeling dataset using a MASK objective."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"num_epochs": 5, "batch_size_per_device": 2, "total_train_batch_size": 8, "gradient_accumulation_steps": 4, "total_optimization_steps": 2015, "optimizer": {"name": "Adam", "learning_rate": null, "beta1": 0.9, "beta2": 0.999, "weight_decay": 0.01}}}}, {"role": "taskType", "module": "fill-mask"}, {"role": "solutionSummary", "module": {"summary": "bert-large-cased-pt-lenerbr is a language model in the legal domain in Portuguese that was finetuned on the LeNER-Br language modeling dataset using a MASK objective. It can be used for tasks such as sequence classification, token classification, or question answering. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-kapilchauhan-bert-base-uncased-cola-finetuned-cola", "modules": [{"role": "model", "module": {"name": "bert-base-uncased-CoLA-finetuned-cola", "description": "A fine-tuned version of textattack/bert-base-uncased-CoLA on the glue dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of textattack/bert-base-uncased-CoLA on the glue dataset. It can be used for text classification tasks. The model achieved a Matthews Correlation score of 0.5755 on the evaluation set. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.5755298089385917, "protocol": "matthews_correlation"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-aed-es", "modules": [{"role": "model", "module": {"name": "opus-mt-aed-es", "description": "A machine translation model that translates from AED to Spanish using the transformer-align architecture."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-aed-es is a machine translation model that translates from AED to Spanish using the transformer-align architecture. The model achieved a BLEU score of 89.1 and a chr-F score of 0.915 on the JW300.aed.es test set."}}], "metrics": [{"dataset": "jw300", "metric": 89.1, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.915, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-atomsspawn-dialogpt-small-dumbledore", "modules": [{"role": "model", "module": {"name": "Dumbledore DialoGPT Model", "description": "A conversational response model trained on a large corpus of text data."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_type": "DialoGPT", "num_layers": 12, "num_heads": 12, "hidden_size": 7744, "dropout": 0.1, "max_length": 1024, "batch_size": 1, "learning_rate": 6.25e-05, "num_epochs": 3}}}, {"role": "taskType", "module": "conversational"}, {"role": "solutionSummary", "module": {"summary": "The Dumbledore DialoGPT Model is a conversational response model trained on a large corpus of text data from Reddit. It uses the DialoGPT architecture with 12 layers, 12 heads, and a hidden size of 7744. The model was trained for 3 epochs with a batch size of 1 and a learning rate of 6.25e-5. The model achieved a perplexity score of 12.3 on the training data. The model can be used for generating conversational text that is relevant, coherent, and knowledgeable given a prompt, with applications in chatbots and voice assistants."}}, {"role": "dataset", "purpose": "For model training.", "module": "reddit"}], "metrics": [{"dataset": "reddit", "metric": 12.3, "protocol": "Perplexity"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-sv-chk", "modules": [{"role": "model", "module": {"name": "opus-mt-sv-chk", "description": "A machine translation model that translates from Swedish (sv) to Chukchi (chk) using a transformer-align model."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-sv-chk is a machine translation model that translates from Swedish to Chukchi using a transformer-align model. The model was trained on the OPUS dataset and uses normalization and SentencePiece for pre-processing. The model achieved a BLEU score of 20.7 and a chr-F score of 0.421 on the JW300.sv.chk test set."}}, {"role": "dataset", "purpose": "Test set for benchmarking.", "module": "jw300"}], "metrics": [{"dataset": "jw300", "metric": 20.7, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.421, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-shoneran-bert-emotion", "modules": [{"role": "model", "module": {"name": "bert-emotion", "description": "A fine-tuned version of distilbert-base-cased on the tweet_eval dataset for emotion classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 4, "eval_batch_size": 4, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-emotion is a fine-tuned version of distilbert-base-cased on the tweet_eval dataset for emotion classification. The model achieved a precision of 0.7262 and a recall of 0.7255 on the evaluation set. The model is suitable for text classification tasks, but its performance may vary depending on the specific use case and data distribution."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "tweeteval"}], "metrics": [{"dataset": "tweeteval", "metric": 0.7262254187805659, "protocol": "Precision"}, {"dataset": "tweeteval", "metric": 0.725549671319356, "protocol": "Recall"}, {"dataset": "tweeteval", "metric": 0.7253, "protocol": "Fscore"}], "source": "huggingface"}, {"id": "huggingface-christabel-finetuning-sentiment-model-3000-samples", "modules": [{"role": "model", "module": {"name": "finetuning-sentiment-model-3000-samples", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 32, "eval_batch_size": 32, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "finetuning-sentiment-model-3000-samples is a fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis. The model achieves an accuracy of 0.86 and an F1 score of 0.8636 on the evaluation set. The model is suitable for text classification tasks, but its performance may vary depending on the specific use case and data distribution."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.86, "protocol": "accuracy"}, {"dataset": "imdb-movie-reviews", "metric": 0.8636, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-mrm8488-t5-base-finetuned-cuad", "modules": [{"role": "model", "module": {"name": "T5-base fine-tuned on CUAD for Legal Contract Review (via QA)", "description": "A fine-tuned version of T5-base on the cuad dataset for legal contract review via QA."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 4, "eval_batch_size": 4, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 10}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "T5-base fine-tuned on the cuad dataset for legal contract review via QA. The model achieved a loss of 0.2209 on the evaluation set. The model is intended for legal contract review via QA, but its limitations and intended uses are not specified. The model was trained using Adam optimizer with a learning rate of 5e-05 and a linear learning rate scheduler. The model was trained for 10 epochs with a batch size of 4."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "cuad-contract-understanding-atticus-dataset"}], "metrics": [{"dataset": "cuad-contract-understanding-atticus-dataset", "metric": 0.2209, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-fr-srn", "modules": [{"role": "model", "module": {"name": "opus-mt-fr-srn", "description": "A transformer-align model for translating from French to Sranan Tongo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-fr-srn model is a transformer-align model that translates from French to Sranan Tongo. It was trained on the OPUS dataset using normalization and SentencePiece preprocessing. The model achieved a BLEU score of 27.4 and a chr-F score of 0.459 on the JW300.fr.srn test set."}}, {"role": "dataset", "purpose": "Test set for benchmarking.", "module": "jw300"}], "metrics": [{"dataset": "jw300", "metric": 27.4, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.459, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-andreaschandra-xlm-roberta-base-finetuned-panx-it", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-it", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8289 on the evaluation set. The model is suitable for token classification tasks in Italian language. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8288879770209273, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-harveenchadha-vakyansh-wav2vec2-punjabi-pam-10", "modules": [{"role": "model", "module": {"name": "Wav2Vec2 Vakyansh Punjabi Model by Harveen Chadha", "description": "Fine-tuned on Multilingual Pretrained Model [CLSRIL-23](#)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"input_sampling_rate": "16kHz"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "The Wav2Vec2 Vakyansh Punjabi Model by Harveen Chadha is a fine-tuned model on the Multilingual Pretrained Model [CLSRIL-23](#) for automatic speech recognition. The model is trained on Punjabi speech data and evaluated on the Common Voice hi dataset. The model is suitable for speech recognition tasks in Punjabi language, but the result may be higher in some cases as it does not use a language model."}}, {"role": "dataset", "purpose": "For evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 33.17, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-artifact-ai-en-spacy-ontonotes-distilroberta-base-ner", "modules": [{"role": "model", "module": {"name": "en_spacy_ontonotes_distilroberta_base_ner", "description": "A spaCy model for named entity recognition (NER) using the OntoNotes 5.0 corpus and a DistilRoBERTa base transformer."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"spaCy_version": ">=3.4.1,<3.5.0", "pipeline": ["transformer", "ner"], "transformer": "DistilRoBERTa base", "vector_dimensions": 0}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "en_spacy_ontonotes_distilroberta_base_ner is a spaCy model for named entity recognition (NER) using the OntoNotes 5.0 corpus and a DistilRoBERTa base transformer. The model achieved an F1 score of 85.92 on the test set. The model is suitable for token classification tasks, such as identifying entities in text. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-philschmid-distilbert-neuron", "modules": [{"role": "model", "module": {"name": "DistilBERT base cased distilled SQuAD", "description": "Fine-tuned model on SQuAD v1.1 using knowledge distillation on DistilBERT-base-cased."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"architecture": "DistilBERT-base-cased", "fine_tuning_dataset": "SQuAD v1.1", "knowledge_distillation": true}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "DistilBERT base cased distilled SQuAD is a fine-tuned model on SQuAD v1.1 using knowledge distillation on DistilBERT-base-cased. The model achieves an F1 score of 87.1 on the dev set, which is lower than the BERT bert-base-cased version. The model is suitable for question answering tasks."}}, {"role": "dataset", "purpose": "For fine-tuning and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 87.1, "protocol": "F1"}], "source": "huggingface"}, {"id": "huggingface-dantesparda17-t5-small-finetuned-ta-to-en", "modules": [{"role": "model", "module": {"name": "t5-small-finetuned-ta-to-en", "description": "A fine-tuned version of t5-small on the opus100 dataset for translation from Tamil to English."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "t5-small-finetuned-ta-to-en is a transformer model fine-tuned on the opus100 dataset for translation from Tamil to English. The model uses a sequence-to-sequence architecture and achieves a loss of 3.6087 on the evaluation set. The model is intended for translation tasks and may have limitations when used for other tasks. The model was trained using PyTorch and Transformers 4.24.0, and the training hyperparameters include a learning rate of 2e-05, a batch size of 16, and a linear learning rate scheduler."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "opus-100"}], "metrics": [{"dataset": "opus-100", "metric": 3.6087, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-husnu-bert-base-turkish-128k-cased-finetuned-lr-2e-05-epochs-3", "modules": [{"role": "model", "module": {"name": "bert-base-turkish-128k-cased-finetuned_lr-2e-05_epochs-3", "description": "A fine-tuned version of dbmdz/bert-base-turkish-128k-cased on the Turkish SQuAD dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "bert-base-turkish-128k-cased-finetuned_lr-2e-05_epochs-3 is a fine-tuned version of dbmdz/bert-base-turkish-128k-cased on the Turkish SQuAD dataset. It is suitable for question answering tasks in Turkish. The model was trained for 3 epochs with a batch size of 8 and a learning rate of 2e-05. The model achieved a loss of 1.4724 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 1.4724, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-krinal214-bert-all", "modules": [{"role": "model", "module": {"name": "bert-all", "description": "Fine-tuned version of bert-base-multilingual-cased on the tydiqa dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "bert-all is a fine-tuned version of bert-base-multilingual-cased on the tydiqa dataset. It is best suited for question answering tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for 1 epoch and achieved a loss of 0.5985 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "tydi-qa-typologically-diverse-question-answering"}], "metrics": [{"dataset": "tydi-qa-typologically-diverse-question-answering", "metric": 0.5985, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-minenine-distilbert-base-uncased-finetuned-imdb", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-imdb", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-imdb is a fine-tuned version of distilbert-base-uncased on the imdb dataset. It can be used for text classification tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 64. The model was trained for 3 epochs and achieved a loss of 2.4721 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 2.4721, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-praveenkishore-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 environment."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 environment. The agent's Q-Table is provided, along with hyperparameters such as the maximum number of steps per episode and the number of episodes used to evaluate the agent. The mean reward achieved by the agent is 7.52 with a standard deviation of 2.70, but this has not been verified."}}, {"role": "dataset", "purpose": "OpenAI Gym environment", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.52, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-fi-sk", "modules": [{"role": "model", "module": {"name": "opus-mt-fi-sk", "description": "A machine translation model that translates from Finnish to Slovakian."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-fi-sk is a machine translation model that translates from Finnish to Slovakian. It uses a transformer-align model and pre-processing techniques such as normalization and SentencePiece. The model achieves a BLEU score of 28.1 and a chr-F score of 0.501 on the JW300.fi.sk test set."}}], "metrics": [{"dataset": "jw300", "metric": 28.1, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.501, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-immanuelraja-layoutlmv3-finetuned-cord-100", "modules": [{"role": "model", "module": {"name": "layoutlmv3-finetuned-cord_100", "description": "A fine-tuned version of microsoft/layoutlmv3-base on the cord-layoutlmv3 dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-05, "train_batch_size": 5, "eval_batch_size": 5, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "training_steps": 2500}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of microsoft/layoutlmv3-base on the cord-layoutlmv3 dataset for token classification. The model achieved a precision of 0.9479, recall of 0.9528, F1 score of 0.9504, and accuracy of 0.9542 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 1e-05 and a linear learning rate scheduler. The model was trained for 2500 steps with a batch size of 5. The model was implemented using Transformers 4.22.1, Pytorch 1.12.1+cu113, Datasets 2.5.1, and Tokenizers 0.12.1."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "cord-19"}], "metrics": [{"dataset": "cord-19", "metric": 0.9478778853313478, "protocol": "Precision"}, {"dataset": "cord-19", "metric": 0.9528443113772455, "protocol": "Recall"}, {"dataset": "cord-19", "metric": 0.950354609929078, "protocol": "F1"}, {"dataset": "cord-19", "metric": 0.9541595925297114, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-pkr-swin-tiny-patch4-window7-224-finetuned-eurosat", "modules": [{"role": "model", "module": {"name": "swin-tiny-patch4-window7-224-finetuned-eurosat", "description": "A fine-tuned version of microsoft/swin-tiny-patch4-window7-224 on the imagefolder dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 32, "eval_batch_size": 32, "seed": 42, "gradient_accumulation_steps": 4, "total_train_batch_size": 128, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "num_epochs": 3}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "A fine-tuned version of microsoft/swin-tiny-patch4-window7-224 on the imagefolder dataset. Achieves an accuracy of 0.9815 on the evaluation set. The model is suitable for image classification tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "objectfolder"}], "metrics": [{"dataset": "objectfolder", "metric": 0.9814814814814815, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-willcai-wav2vec2-common-voice-accents-6", "modules": [{"role": "model", "module": {"name": "wav2vec2_common_voice_accents_6", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0003, "train_batch_size": 48, "eval_batch_size": 4, "seed": 42, "distributed_type": "multi-GPU", "num_devices": 8, "total_train_batch_size": 384, "total_eval_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 30, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "wav2vec2_common_voice_accents_6 is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset. The model is suitable for automatic speech recognition tasks. The model was trained using Adam optimizer with a learning rate of 0.0003 and a linear learning rate scheduler with 500 warmup steps. The model was trained for 30 epochs with a batch size of 48 and evaluated with a batch size of 4. The model was trained using mixed precision training with Native AMP. The model achieved a validation loss of 0.3711."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 3.8539, "split": "val", "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.3711, "split": "test", "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-wietsedv-wav2vec2-large-xlsr-53-dutch", "modules": [{"role": "model", "module": {"name": "Wav2Vec2-Large-XLSR-53-Dutch", "description": "Fine-tuned Wav2Vec2-Large-XLSR-53 on Dutch using the Common Voice dataset for automatic speech recognition."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "facebook/wav2vec2-large-xlsr-53", "batch_size": 8, "optimizer": {"name": "Adam", "learning_rate": 5e-05}}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Wav2Vec2-Large-XLSR-53-Dutch is a fine-tuned model on Dutch using the Common Voice dataset for automatic speech recognition. The model can be used directly without a language model. The model is best suited for speech recognition tasks and can be evaluated using the word error rate (WER) metric. The model was trained on the Common Voice train and validation datasets."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 17.09, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-mbeukman-xlm-roberta-base-finetuned-yoruba-finetuned-ner-yoruba", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-yoruba-finetuned-ner-yoruba", "description": "A token classification model fine-tuned on the MasakhaNER dataset for named entity recognition (NER) in Yoruba."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"max_seq_length": 200, "batch_size": 32, "learning_rate": 5e-05, "epochs": 50}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a token classification model fine-tuned on the MasakhaNER dataset for named entity recognition (NER) in Yoruba. The model is transformer-based and was fine-tuned for 50 epochs with a maximum sequence length of 200, 32 batch size, and 5e-5 learning rate. The model is intended for NLP research into interpretability or transfer learning and is not designed for production use. The model's limitations include being trained on a relatively small dataset covering one task (NER) in one domain (news articles) and in a set span of time. The model may perform badly or in an unfair/biased way if used on other tasks. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "masakhaner"}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-cahya-wav2vec2-large-xlsr-turkish-artificial-cv", "modules": [{"role": "model", "module": {"name": "Wav2Vec2-Large-XLSR-Turkish", "description": "Fine-tuned model on Turkish Common Voice dataset using Wav2Vec2-Large-XLSR-Turkish-Artificial-CV."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "Wav2Vec2-Large-XLSR-Turkish-Artificial-CV", "batch_size": 8, "optimizer": {"name": "Adam", "learning_rate": 5e-05}}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Wav2Vec2-Large-XLSR-Turkish is a fine-tuned model on Turkish Common Voice dataset using Wav2Vec2-Large-XLSR-Turkish-Artificial-CV. The model is suitable for automatic speech recognition tasks in Turkish. The model was trained using Adam optimizer with a learning rate of 5e-5 and a batch size of 8. The model achieved a WER score of 14.61% on the Common Voice tr dataset."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 14.61, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-lucdi90-dialogpt-medium-xiaobot", "modules": [{"role": "model", "module": {"name": "XiaoBot for Discord", "description": "A conversational response model designed for Discord chatbot."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_type": "GPT-2", "model_size": "small", "learning_rate": 5e-05, "batch_size": 1, "num_epochs": 3}}}, {"role": "taskType", "module": "conversational"}, {"role": "solutionSummary", "module": {"summary": "XiaoBot for Discord is a conversational response model designed for Discord chatbot. It is based on the GPT-2 model and was trained on Discord chat logs. The model has a small size and was trained for 3 epochs with a learning rate of 5e-5 and a batch size of 1. The model achieved a perplexity score of 25.3 on the training data. The model can be used to generate relevant, coherent, and knowledgeable responses to prompts in Discord chat."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-adoublelen-q-frozenlake-v1-4x4-noslippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained model of a Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-4x4-no_slippery", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model's hyperparameters include the algorithm used, the environment, the maximum number of steps per episode, the number of episodes to evaluate the agent, the Q-Table learned by the agent, and the random seed used for evaluation. The model achieved a mean reward of 1.00 with no standard deviation."}}, {"role": "dataset", "purpose": "Environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-ljh1-bert-base-uncased-finetuned-conll2003", "modules": [{"role": "model", "module": {"name": "ljh1/bert-base-uncased-finetuned-conll2003", "description": "Fine-tuned version of bert-base-uncased on the conll2003 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"optimizer": {"name": "Adam", "weight_decay": null, "clipnorm": null, "global_clipnorm": 1.0, "clipvalue": null, "use_ema": false, "ema_momentum": 0.99, "ema_overwrite_frequency": null, "jit_compile": true, "is_legacy_optimizer": false, "learning_rate": {"class_name": "PolynomialDecay", "config": {"initial_learning_rate": 5e-05, "decay_steps": 1755, "end_learning_rate": 0.0, "power": 1.0, "cycle": false, "name": null}}, "beta_1": 0.9, "beta_2": 0.999, "epsilon": 1e-08, "amsgrad": false}, "training_precision": "float32"}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of bert-base-uncased on the conll2003 dataset. The model is best suited for token classification tasks. The model was trained using Adam optimizer with a polynomial decay learning rate schedule. The model achieved a train loss of 0.0867 and a validation loss of 0.0477 after one epoch."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 0.0867, "protocol": "Train Loss"}, {"dataset": "conll-2003", "metric": 0.0477, "protocol": "Validation Loss"}, {"dataset": "conll-2003", "metric": 0.0, "protocol": "Epoch"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-es-norway", "modules": [{"role": "model", "module": {"name": "opus-mt-es-NORWAY", "description": "A machine translation model that translates from Spanish to Norwegian (nb_NO,nb,nn_NO,nn,nog,no)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece", "initial_language_token": ">>id<<"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-es-NORWAY is a machine translation model that translates from Spanish to Norwegian (nb_NO,nb,nn_NO,nn,nog,no). The model uses the transformer-align architecture and preprocessing techniques such as normalization and SentencePiece. The model achieved a BLEU score of 31.6 on the JW300.es.no test set."}}], "metrics": [{"dataset": "jw300", "metric": 31.6, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.523, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-en-run", "modules": [{"role": "model", "module": {"name": "opus-mt-en-run", "description": "A machine translation model that translates from English to Runyankore (run)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-en-run is a machine translation model that translates from English to Runyankore (run). The model uses the transformer-align architecture and pre-processing techniques such as normalization and SentencePiece. The model achieved a BLEU score of 34.2 and a chr-F score of 0.591 on the JW300.en.run test set."}}], "metrics": [{"dataset": "jw300", "metric": 34.2, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.591, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-lemming-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. The model is best suited for text classification tasks. The model achieved an accuracy of 0.9215 and an F1 score of 0.9216 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.9215, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.9216499948953181, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-uk-sv", "modules": [{"role": "model", "module": {"name": "opus-mt-uk-sv", "description": "A machine translation model that translates from Ukrainian to Swedish."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-uk-sv is a machine translation model that translates from Ukrainian to Swedish. It was trained on the OPUS dataset using a transformer-align model with normalization and SentencePiece preprocessing. The model achieved a BLEU score of 27.8 and a chr-F score of 0.474 on the JW300.uk.sv test set."}}], "metrics": [{"dataset": "jw300", "metric": 27.8, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.474, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-patrickvonplaten-unispeech-large-1500h-cv-timit", "modules": [{"role": "model", "module": {"name": "unispeech-large-1500h-cv-timit", "description": "Fine-tuned version of microsoft/unispeech-large-1500h-cv on the TIMIT_ASR - NA dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0001, "train_batch_size": 32, "eval_batch_size": 1, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 1000, "num_epochs": 20.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "unispeech-large-1500h-cv-timit is a fine-tuned version of microsoft/unispeech-large-1500h-cv on the TIMIT_ASR - NA dataset. The model is suitable for automatic speech recognition tasks. The model was trained using Adam optimizer with a learning rate of 0.0001, and a batch size of 32. The model was trained for 20 epochs with a linear learning rate scheduler and a warmup of 1000 steps. The model achieved a loss of 0.3099 and a WER of 0.2196 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "timit-timit-acoustic-phonetic-continuous-speech-corpus"}], "metrics": [{"dataset": "timit-timit-acoustic-phonetic-continuous-speech-corpus", "metric": 0.3099, "protocol": "loss"}, {"dataset": "timit-timit-acoustic-phonetic-continuous-speech-corpus", "metric": 0.2196, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-qisan-whisper-small-hi", "modules": [{"role": "model", "module": {"name": "my_tuned_whisper_cn", "description": "A fine-tuned version of openai/whisper-small on the Common Voice 11.0 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-05, "train_batch_size": 8, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "training_steps": 4000, "mixed_precision_training": true}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "my_tuned_whisper_cn is a fine-tuned version of openai/whisper-small on the Common Voice 11.0 dataset. The model is suitable for automatic speech recognition tasks. The training hyperparameters include a learning rate of 1e-05, a batch size of 8, and a total training batch size of 16. The model was trained for 4000 steps with mixed precision training. The evaluation results show an eval_loss of 0.5297 and an eval_wer of 80.2457."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.5297, "protocol": "eval_loss"}, {"dataset": "common-voice", "metric": 80.2457, "protocol": "eval_wer"}, {"dataset": "common-voice", "metric": 457.7207, "protocol": "eval_runtime"}, {"dataset": "common-voice", "metric": 2.311, "protocol": "eval_samples_per_second"}, {"dataset": "common-voice", "metric": 0.291, "protocol": "eval_steps_per_second"}, {"dataset": "common-voice", "metric": 2.02, "protocol": "epoch"}, {"dataset": "common-voice", "metric": 1000.0, "protocol": "step"}], "source": "huggingface"}, {"id": "huggingface-tner-roberta-large-tweetner7-selflabel2021-continuous", "modules": [{"role": "model", "module": {"name": "tner/roberta-large-tweetner7-selflabel2021-continuous", "description": "A fine-tuned version of tner/roberta-large-tweetner-2020 on the tner/tweetner7 dataset (train split) and self-labeled dataset (extra_2021 split of the tner/tweetner7 annotated by tner/roberta-large)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"dataset": "tner/tweetner7", "max_length": 128, "batch_size": 32, "learning_rate": 1e-05, "weight_decay": 1e-07, "epoch": 30, "crf": true}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "tner/roberta-large-tweetner7-selflabel2021-continuous is a fine-tuned version of tner/roberta-large-tweetner-2020 on the tner/tweetner7 dataset (train split) and self-labeled dataset (extra_2021 split of the tner/tweetner7 annotated by tner/roberta-large). The model is fine-tuned on self-labeled dataset which is the extra_2021 split of the tner/tweetner7 annotated by tner/roberta-large. The model is suitable for token classification tasks such as named entity recognition (NER) on tweets. The model achieved an F1 score of 0.6448 on the test set of 2021."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "twitter-sentiment-analysis-entity-level-twitter-sentiment-analysis-dataset"}], "metrics": [{"dataset": "twitter-sentiment-analysis-entity-level-twitter-sentiment-analysis-dataset", "metric": 0.644817329816488, "split": "val", "protocol": "f1"}, {"dataset": "twitter-sentiment-analysis-entity-level-twitter-sentiment-analysis-dataset", "metric": 0.6548100242522231, "split": "test", "protocol": "f1"}, {"dataset": "twitter-sentiment-analysis-entity-level-twitter-sentiment-analysis-dataset", "metric": 0.6264311416421328, "split": "val", "protocol": "precision"}, {"dataset": "twitter-sentiment-analysis-entity-level-twitter-sentiment-analysis-dataset", "metric": 0.6810538116591929, "split": "test", "protocol": "precision"}, {"dataset": "twitter-sentiment-analysis-entity-level-twitter-sentiment-analysis-dataset", "metric": 0.6643154486586494, "split": "val", "protocol": "recall"}, {"dataset": "twitter-sentiment-analysis-entity-level-twitter-sentiment-analysis-dataset", "metric": 0.6305137519460301, "split": "test", "protocol": "recall"}, {"dataset": "twitter-sentiment-analysis-entity-level-twitter-sentiment-analysis-dataset", "metric": 0.5941147287547678, "split": "val", "protocol": "f1_macro"}, {"dataset": "twitter-sentiment-analysis-entity-level-twitter-sentiment-analysis-dataset", "metric": 0.6141867781768393, "split": "test", "protocol": "f1_macro"}, {"dataset": "twitter-sentiment-analysis-entity-level-twitter-sentiment-analysis-dataset", "metric": 0.5756979462999651, "split": "val", "protocol": "precision_macro"}, {"dataset": "twitter-sentiment-analysis-entity-level-twitter-sentiment-analysis-dataset", "metric": 0.6354522364268572, "split": "test", "protocol": "precision_macro"}, {"dataset": "twitter-sentiment-analysis-entity-level-twitter-sentiment-analysis-dataset", "metric": 0.6198566504961354, "split": "val", "protocol": "recall_macro"}, {"dataset": "twitter-sentiment-analysis-entity-level-twitter-sentiment-analysis-dataset", "metric": 0.5987967256237715, "split": "test", "protocol": "recall_macro"}, {"dataset": "twitter-sentiment-analysis-entity-level-twitter-sentiment-analysis-dataset", "metric": 0.7835896284655965, "split": "val", "protocol": "f1_entity_span"}, {"dataset": "twitter-sentiment-analysis-entity-level-twitter-sentiment-analysis-dataset", "metric": 0.7649595687331536, "split": "test", "protocol": "f1_entity_span"}, {"dataset": "twitter-sentiment-analysis-entity-level-twitter-sentiment-analysis-dataset", "metric": 0.7612037945698397, "split": "val", "protocol": "precision_entity_span"}, {"dataset": "twitter-sentiment-analysis-entity-level-twitter-sentiment-analysis-dataset", "metric": 0.7958496915311273, "split": "test", "protocol": "precision_entity_span"}, {"dataset": "twitter-sentiment-analysis-entity-level-twitter-sentiment-analysis-dataset", "metric": 0.8073320226668209, "split": "val", "protocol": "recall_entity_span"}, {"dataset": "twitter-sentiment-analysis-entity-level-twitter-sentiment-analysis-dataset", "metric": 0.736377789309808, "split": "test", "protocol": "recall_entity_span"}], "source": "huggingface"}, {"id": "huggingface-lucio-wav2vec2-large-xlsr-luganda", "modules": [{"role": "model", "module": {"name": "Wav2Vec2-Large-XLSR-53-lg", "description": "Fine-tuned facebook/wav2vec2-large-xlsr-53 on Luganda using the Common Voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 8, "optimizer": {"name": "Adam", "learning_rate": 0.0003, "beta1": 0.9, "beta2": 0.98, "weight_decay": 0.005}, "epochs": 60}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Wav2Vec2-Large-XLSR-53-lg is a speech recognition model fine-tuned on Luganda using the Common Voice dataset. The model can be used directly for speech recognition without a language model. The model was trained on the Common Voice train, validation, and other datasets, excluding voices that are in both the other and test datasets. The data was augmented to twice the original size with added noise and manipulated pitch, phase, and intensity. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 29.52, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-nkkodelacruz-distilbert-base-uncased-finetuned-cola", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-cola", "description": "A fine-tuned version of distilbert-base-uncased on the glue dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-cola is a fine-tuned version of distilbert-base-uncased on the glue dataset. It is suitable for text classification tasks. The model achieved a Matthews Correlation score of 0.5596 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 16 for 5 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.5596, "protocol": "matthews_correlation"}], "source": "huggingface"}, {"id": "huggingface-edwardjross-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "xlm-roberta-base-finetuned-panx-de is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. The model achieved an F1 score of 0.8645 on the evaluation set. The model is suitable for token classification tasks in German language. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8644809364168419, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-msavel-prnt-distilbert-base-uncased-finetuned-clinc", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-clinc", "description": "A fine-tuned version of distilbert-base-uncased on the clinc_oos dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 48, "eval_batch_size": 48, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-clinc is a fine-tuned version of distilbert-base-uncased on the clinc_oos dataset. The model is best suited for text classification tasks. The model achieved an accuracy of 0.9181 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler. The model was trained for 5 epochs with a batch size of 48."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "clinc-single-domain-oos"}], "metrics": [{"dataset": "clinc-single-domain-oos", "metric": 0.9180645161290323, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-joelb-custom-handler-tutorial", "modules": [{"role": "model", "module": {"name": "Fork of distilbert-base-uncased-emotion", "description": "A fork of the DistilBERT model pre-trained on a large corpus of English data for text classification of emotions."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "DistilBERT", "tokenizer": "DistilBERT tokenizer", "learning_rate": 5e-05, "batch_size": 32, "epochs": 3}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fork of the DistilBERT model pre-trained on a large corpus of English data for text classification of emotions. The model is fine-tuned on the emotion dataset and can classify text into one of the following emotions: anger, fear, joy, love, sadness, or surprise. The model achieves an accuracy of 0.87 and an F1 score of 0.86. The model can be used for text classification tasks related to emotions."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emocontext"}], "metrics": [{"dataset": "emocontext", "metric": 0.87, "protocol": "Accuracy"}, {"dataset": "emocontext", "metric": 0.86, "protocol": "F1 Score"}], "source": "huggingface"}, {"id": "huggingface-mrm8488-deberta-v3-small-finetuned-mnli", "modules": [{"role": "model", "module": {"name": "DeBERTa v3 (small) fine-tuned on MNLI", "description": "Fine-tuned version of DeBERTa v3 (small) on the GLUE MNLI dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 3e-05, "train_batch_size": 16, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 1000, "num_epochs": 3.0}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "DeBERTa v3 (small) is a transformer model that improves upon BERT and RoBERTa models using disentangled attention and enhanced mask decoder. This model was fine-tuned on the GLUE MNLI dataset and achieved an accuracy of 0.8746. It is intended for use in text classification tasks, such as natural language inference, and is not suitable for text generation. The model was trained on the BookCorpus dataset and English Wikipedia, and the training hyperparameters include a learning rate of 3e-05, a batch size of 16, and a linear learning rate scheduler with warmup steps of 1000."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "multinli-multi-genre-natural-language-inference"}], "metrics": [{"dataset": "multinli-multi-genre-natural-language-inference", "metric": 0.874593165174939, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-raphaelg9-distilbert-base-uncased-finetuned-squad", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-squad", "description": "A fine-tuned version of distilbert-base-uncased on the squad_v2 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-squad is a fine-tuned version of distilbert-base-uncased on the squad_v2 dataset. It is suitable for question answering tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for 3 epochs and achieved a loss of 2.1323 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 2.1323, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-facebook-detr-resnet-50-dc5-panoptic", "modules": [{"role": "model", "module": {"name": "DETR (End-to-End Object Detection) model with ResNet-50 backbone (dilated C5 stage)", "description": "DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 panoptic (118k annotated images)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"backbone": "ResNet-50", "object_queries": 100, "loss_function": "bipartite matching loss", "optimizer": "AdamW", "learning_rate": 0.0001, "batch_size": 64, "num_epochs": 300}}}, {"role": "taskType", "module": "image-segmentation"}, {"role": "solutionSummary", "module": {"summary": "DETR is an encoder-decoder transformer with a convolutional backbone used for object detection and panoptic segmentation. The model uses object queries to detect objects in an image. The model is trained using a bipartite matching loss and can be extended to perform panoptic segmentation. The model was trained on COCO 2017 panoptic and achieves good results on COCO 2017 validation. The model is intended to be fine-tuned on a downstream task."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "coco-microsoft-common-objects-in-context"}], "metrics": [{"dataset": "coco-microsoft-common-objects-in-context", "metric": 40.2, "protocol": "box_AP"}, {"dataset": "coco-microsoft-common-objects-in-context", "metric": 31.9, "protocol": "segmentation_AP"}, {"dataset": "coco-microsoft-common-objects-in-context", "metric": 44.6, "protocol": "PQ"}], "source": "huggingface"}, {"id": "huggingface-alefarasin-dqn-spaceinvadersnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "DQN", "description": "A trained DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "buffer_size": 100000, "exploration_final_eps": 0.01, "exploration_fraction": 0.1, "frame_stack": 4, "gradient_steps": 1, "learning_rate": 0.0001, "learning_starts": 100000, "n_timesteps": 10000000.0, "optimize_memory_usage": true, "policy": "CnnPolicy", "target_update_interval": 1000, "train_freq": 4, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The model was trained with a batch size of 32, a buffer size of 100000, and a learning rate of 0.0001. The model achieved a mean reward of 209.50 with a standard deviation of 34.09 on the SpaceInvadersNoFrameskip-v4 dataset. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 209.5, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-chintagunta85-electramed-small-deid2014-ner-v4", "modules": [{"role": "model", "module": {"name": "electramed-small-deid2014-ner-v4", "description": "A fine-tuned version of giacomomiolo/electramed_small_scivocab on the i2b22014 dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 10}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "electramed-small-deid2014-ner-v4 is a fine-tuned version of giacomomiolo/electramed_small_scivocab on the i2b22014 dataset for token classification. The model achieved a Precision of 0.7571, Recall of 0.7854, F1 of 0.7710, and Accuracy of 0.9906 on the evaluation set. The model is suitable for named entity recognition tasks on medical text data."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "i2b2-de-identification-dataset-informatics-for-integrating-biology-and-the-bedside-i2b2-project-de-identification-dataset"}], "metrics": [{"dataset": "i2b2-de-identification-dataset-informatics-for-integrating-biology-and-the-bedside-i2b2-project-de-identification-dataset", "metric": 0.7571112095702259, "protocol": "precision"}, {"dataset": "i2b2-de-identification-dataset-informatics-for-integrating-biology-and-the-bedside-i2b2-project-de-identification-dataset", "metric": 0.7853663020498207, "protocol": "recall"}, {"dataset": "i2b2-de-identification-dataset-informatics-for-integrating-biology-and-the-bedside-i2b2-project-de-identification-dataset", "metric": 0.770979967514889, "protocol": "f1"}, {"dataset": "i2b2-de-identification-dataset-informatics-for-integrating-biology-and-the-bedside-i2b2-project-de-identification-dataset", "metric": 0.9906153616114308, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-aniltrkkn-wav2vec2-large-xlsr-53-turkish", "modules": [{"role": "model", "module": {"name": "Wav2Vec2-Large-XLSR-53-Turkish", "description": "Fine-tuned Wav2Vec2-Large-XLSR-53 on Turkish using the Common Voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"num_train_epochs": 30, "per_device_train_batch_size": 32, "activation_dropout": 0.055, "attention_dropout": 0.094, "feat_proj_dropout": 0.04, "hidden_dropout": 0.047, "layerdrop": 0.041, "learning_rate": 0.000234, "mask_time_prob": 0.082, "warmup_steps": 250}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Wav2Vec2-Large-XLSR-53-Turkish is a fine-tuned model based on Wav2Vec2-Large-XLSR-53, trained on the Common Voice dataset for Turkish. The model can be used for automatic speech recognition tasks in Turkish. The model was trained with a K-Fold approach and the best model out of the 5 trainings was uploaded. The model was trained with limited data, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 17.46, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-thejarmanitor-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 game."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 game. The agent's Q-Table is provided, along with hyperparameters such as the maximum number of steps per episode and the number of episodes used to evaluate the agent. The mean reward achieved by the agent is 7.56 with a standard deviation of 2.71."}}, {"role": "dataset", "purpose": "The game environment used for training and evaluation.", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.56, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-rotvderme-q-frozenlake-v1-4x4-noslippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained model of a Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model achieved a mean reward of 1.00 +/- 0.00 on the FrozenLake-v1-4x4-no_slippery environment. The model can be loaded and used to evaluate the agent's performance on the environment."}}, {"role": "dataset", "purpose": "The environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "extra": "1.00 +/- 0.00", "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-vicl-distilbert-base-uncased-finetuned-mrpc", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-mrpc", "description": "A fine-tuned version of distilbert-base-uncased on the GLUE dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-mrpc is a fine-tuned version of distilbert-base-uncased on the GLUE dataset. It is suitable for text classification tasks. The model achieved an accuracy of 0.8480 and an F1 score of 0.8942 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 16 for 5 epochs."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-bert-large-cased-whole-word-masking-finetuned-squad", "modules": [{"role": "model", "module": {"name": "BERT large model (cased) whole word masking finetuned on SQuAD", "description": "Pretrained model on English language using a masked language modeling (MLM) objective. This model is cased and was fine-tuned on the SQuAD dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 256, "optimizer": {"name": "Adam", "learning_rate": 0.0001, "beta1": 0.9, "beta2": 0.999, "weight_decay": 0.01}, "sequence_length": {"90%": 128, "10%": 512}, "masking": {"mask_rate": 0.15, "80%": "[MASK]", "10%": "no change"}}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "BERT is a transformer model pre-trained on a large English corpus. This model is cased and was fine-tuned on the SQuAD dataset. It is intended to be used as a question-answering model. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training.", "module": "wikiqa-wikipedia-open-domain-question-answering"}, {"role": "dataset", "purpose": "For fine-tuning.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 88.5, "protocol": "EM"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 94.6, "protocol": "F1"}], "source": "huggingface"}, {"id": "huggingface-faisito-xlm-roberta-base-finetuned-panx-fr", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-fr", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8357 on the evaluation set. The model is suitable for token classification tasks in French language. The training was done using Adam optimizer with a learning rate of 5e-05 and a batch size of 24. The model was trained for 3 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8357154868000672, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-21iridescent-roberta-base-finetuned-squad2-lwt", "modules": [{"role": "model", "module": {"name": "roberta-base-finetuned-squad2-lwt", "description": "A fine-tuned version of roberta-base on the squad_v2 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of roberta-base on the squad_v2 dataset. The model is best suited for question answering tasks. The model achieved an F1 score of 83.7387 on the evaluation set. The model was trained for 3 epochs with a learning rate of 2e-05 and a batch size of 16. The model was trained on a single V100 GPU."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 77.1255060728745, "protocol": "HasAns_exact"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 83.87812741260885, "protocol": "HasAns_f1"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 5928.0, "protocol": "HasAns_total"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 83.59966358284272, "protocol": "NoAns_exact"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 83.59966358284272, "protocol": "NoAns_f1"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 5945.0, "protocol": "NoAns_total"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 80.36721974227238, "protocol": "best_exact"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 0.0, "protocol": "best_exact_thresh"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 83.7386961426719, "protocol": "best_f1"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 0.0, "protocol": "best_f1_thresh"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 80.36721974227238, "protocol": "exact"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 83.738696142672, "protocol": "f1"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 11873.0, "protocol": "total"}], "source": "huggingface"}, {"id": "huggingface-muhtasham-bert-uncased-l-2-h-128-a-2-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "bert_uncased_L-2_H-128_A-2-finetuned-emotion", "description": "Fine-tuned version of google/bert_uncased_L-2_H-128_A-2 on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 3e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "num_epochs": 200}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "bert_uncased_L-2_H-128_A-2-finetuned-emotion is a fine-tuned version of google/bert_uncased_L-2_H-128_A-2 on the emotion dataset. The model is best suited for text classification tasks. The model achieved an accuracy of 0.913 and an F1 score of 0.9131 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 3e-05 for 200 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emocontext"}], "metrics": [{"dataset": "emocontext", "metric": 0.913, "protocol": "accuracy"}, {"dataset": "emocontext", "metric": 0.9131486432959599, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-tomo-xlm-roberta-base-finetuned-marc-en", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-marc-en", "description": "A fine-tuned version of xlm-roberta-base on the amazon_reviews_multi dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "xlm-roberta-base-finetuned-marc-en is a fine-tuned version of xlm-roberta-base on the amazon_reviews_multi dataset. The model is best suited for text classification tasks. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for 2 epochs and achieved a loss of 0.9237 and a mean absolute error of 0.5122 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "amazon-product-data"}], "metrics": [{"dataset": "amazon-product-data", "metric": 0.9237, "protocol": "loss"}, {"dataset": "amazon-product-data", "metric": 0.5122, "protocol": "mae"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-sv-tvl", "modules": [{"role": "model", "module": {"name": "opus-mt-sv-tvl", "description": "A machine translation model that translates from Swedish (sv) to Tuvalu (tvl) using the transformer-align architecture."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-sv-tvl model is a machine translation model that translates from Swedish to Tuvalu using the transformer-align architecture. It achieved a BLEU score of 34.4 and a chr-F score of 0.521 on the JW300.sv.tvl test set."}}], "metrics": [{"dataset": "jw300", "metric": 34.4, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.521, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-asapp-sew-d-mid-400k-ft-ls100h", "modules": [{"role": "model", "module": {"name": "SEW-D-mid", "description": "A pre-trained model architecture for automatic speech recognition (ASR) with significant improvements along both performance and efficiency dimensions across a variety of training setups."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"sampling_rate": 16000, "batch_size": 1, "padding": "longest"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "SEW-D-mid is a pre-trained model architecture for automatic speech recognition (ASR) that improves both performance and efficiency dimensions across a variety of training setups. The model is intended to be fine-tuned on a downstream task, such as ASR, speaker identification, intent classification, or emotion recognition. The model is trained on the LibriSpeech dataset and can transcribe audio files sampled at 16kHz."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "librispeech"}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-hackertec-roberta-base-bne-finetuned-amazon-reviews-multi-taller", "modules": [{"role": "model", "module": {"name": "roberta-base-bne-finetuned-amazon_reviews_multi-taller", "description": "A fine-tuned version of BSC-TeMU/roberta-base-bne on the amazon_reviews_multi dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of BSC-TeMU/roberta-base-bne on the amazon_reviews_multi dataset. It achieves an accuracy of 0.9113 on the evaluation set. The model is suitable for text classification tasks, but its intended uses and limitations are not specified. The training and evaluation data, as well as the model description, are not provided."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "amazon-review"}], "metrics": [{"dataset": "amazon-review", "metric": 0.91125, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-cgt-roberta-wwm-ext-large-qa", "modules": [{"role": "model", "module": {"name": "Roberta-wwm-ext-large-qa", "description": "A fine-tuned version of hfl/chinese-roberta-wwm-ext-large on the cmrc2018 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "Roberta-wwm-ext-large-qa is a fine-tuned version of hfl/chinese-roberta-wwm-ext-large on the cmrc2018 dataset. It is a question-answering model that can be used to answer questions in Chinese. The model was trained with Adam optimizer with a learning rate of 1e-05 and a batch size of 16. The model was trained for 1 epoch and achieved a loss of 1.1416 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "cmrc-chinese-machine-reading-comprehension-2018"}], "metrics": [{"dataset": "cmrc-chinese-machine-reading-comprehension-2018", "metric": 1.1416, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-gilparmentier-pokemon-gptj-model", "modules": [{"role": "model", "module": {"name": "GPT-J 6B", "description": "Transformer model trained using Ben Wang's Mesh Transformer JAX."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"n_parameters": 6053381344, "n_layers": 28, "d_model": 4096, "d_ff": 16384, "n_heads": 16, "d_head": 256, "n_ctx": 2048, "n_vocab": 50257, "positional_encoding": "Rotary Position Embedding (RoPE)", "rope_dimensions": 64}}}, {"role": "taskType", "module": "text-generation"}, {"role": "solutionSummary", "module": {"summary": "GPT-J 6B is a transformer model trained on The Pile dataset using Ben Wang's Mesh Transformer JAX. The model is best at generating text from a prompt. The model reflects the biases inherent to the systems they were trained on, so caution should be taken when deploying it into systems that interact with humans. The model is suitable for tasks that use the whole sentence to make decisions, such as sequence classification, token classification, or question answering."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-ty-sv", "modules": [{"role": "model", "module": {"name": "opus-mt-ty-sv", "description": "A transformer-align model for translating from Tahitian (ty) to Swedish (sv)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-ty-sv is a transformer-align model that translates from Tahitian to Swedish. The model was trained on the OPUS dataset using normalization and SentencePiece preprocessing. The model achieved a BLEU score of 28.9 and a chr-F score of 0.472 on the JW300.ty.sv test set."}}], "metrics": [{"dataset": "jw300", "metric": 28.9, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.472, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-kbalde-bert-finetuned-ner", "modules": [{"role": "model", "module": {"name": "bert-finetuned-ner", "description": "A fine-tuned version of bert-base-cased on the conll2003 dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-finetuned-ner is a fine-tuned version of bert-base-cased on the conll2003 dataset for token classification. The model achieved high precision, recall, F1 score, and accuracy on the evaluation set. The model is suitable for named entity recognition tasks, but caution should be taken when deploying it in human-interacting systems as it may reflect the biases of the systems it was trained on."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 0.9281121187139324, "protocol": "precision"}, {"dataset": "conll-2003", "metric": 0.9473241332884551, "protocol": "recall"}, {"dataset": "conll-2003", "metric": 0.9376197218289332, "protocol": "f1"}, {"dataset": "conll-2003", "metric": 0.9862689115205746, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-autoevaluate-natural-language-inference", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased", "description": "Fine-tuned model on the GLUE dataset for natural language inference."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of distilbert-base-uncased on the GLUE dataset for natural language inference. The model achieves an accuracy of 0.8284 and an F1 score of 0.8822 on the evaluation set. The model is suitable for text classification tasks."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-en-gl", "modules": [{"role": "model", "module": {"name": "opus-mt-en-gl", "description": "A machine translation model that translates from English to Galician."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-en-gl is a machine translation model that translates from English to Galician. It uses a transformer-align model and pre-processing techniques such as normalization and SentencePiece. The model achieves a BLEU score of 36.4 and a chr-F score of 0.572 on the Tatoeba.en.gl test set."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-yuriky-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 game."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 game. The agent's Q-Table is provided, along with hyperparameters such as the maximum number of steps per episode and the number of episodes used for evaluation. The agent achieved a mean reward of 7.56 with a standard deviation of 2.71."}}, {"role": "dataset", "purpose": "The game environment used for training and evaluation.", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.56, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-jhgan-ko-sroberta-sts", "modules": [{"role": "model", "module": {"name": "ko-sroberta-sts", "description": "A sentence-transformers model trained on Korean STS dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"max_seq_length": 128, "do_lower_case": false, "batch_size": 8, "loss": "CosineSimilarityLoss", "epochs": 5, "optimizer": {"name": "AdamW", "learning_rate": 2e-05}, "scheduler": "WarmupLinear", "warmup_steps": 360, "weight_decay": 0.01}}}, {"role": "taskType", "module": "sentence-similarity"}, {"role": "solutionSummary", "module": {"summary": "ko-sroberta-sts is a sentence-transformers model trained on Korean STS dataset. It maps sentences and paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search. The model was trained with the CosineSimilarityLoss and achieved good results on the KorSTS evaluation dataset. The model was trained with the RobertaModel transformer and uses mean pooling to generate sentence embeddings."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-ravenk-distilbert-base-uncased-finetuned-ner", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-ner", "description": "A fine-tuned version of distilbert-base-uncased on the conll2003 dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-ner is a fine-tuned version of distilbert-base-uncased on the conll2003 dataset for token classification. The model achieved high precision, recall, F1 score, and accuracy on the evaluation set. It can be used for named entity recognition tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 0.9273693534100974, "protocol": "Precision"}, {"dataset": "conll-2003", "metric": 0.9370175634858485, "protocol": "Recall"}, {"dataset": "conll-2003", "metric": 0.932168493684269, "protocol": "F1"}, {"dataset": "conll-2003", "metric": 0.9839070964462167, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-jkgrad-xlnet-base-squadv2", "modules": [{"role": "model", "module": {"name": "XLNet Fine-tuned on SQuAD 2.0 Dataset", "description": "XLNet model fine-tuned on SQuAD 2.0 dataset for question answering downstream task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_name": "xlnet-base-squadv2", "tokenizer_name": "xlnet-base-squadv2", "max_seq_length": 512, "doc_stride": 128, "max_query_length": 64, "n_best_size": 20, "max_answer_length": 30, "null_score_diff_threshold": 0.0}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "XLNet model fine-tuned on SQuAD 2.0 dataset for question answering downstream task. The model achieved an EM score of 75.68 and an F1 score of 79.16. The model can be used for question answering tasks, and the tokenizer can be used to preprocess the input text. Note that better fine-tuned models may be available in the future."}}, {"role": "dataset", "purpose": "For fine-tuning the model.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 75.68, "protocol": "EM"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 79.16, "protocol": "F1"}], "source": "huggingface"}, {"id": "huggingface-pritamdeka-biobert-pubmed200krct", "modules": [{"role": "model", "module": {"name": "BioBert-PubMed200kRCT", "description": "A fine-tuned version of dmis-lab/biobert-base-cased-v1.1 on the PubMed200kRCT dataset for text classification tasks of Randomized Controlled Trials."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "BioBert-PubMed200kRCT is a fine-tuned version of dmis-lab/biobert-base-cased-v1.1 on the PubMed200kRCT dataset for text classification tasks of Randomized Controlled Trials. The model can classify text into one of the following categories: BACKGROUND, CONCLUSIONS, METHODS, OBJECTIVE, RESULTS. The model is suitable for text classification tasks of Randomized Controlled Trials that do not have any structure. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "pubmed-rct-pubmed-200k-rct"}], "metrics": [{"dataset": "pubmed-rct-pubmed-200k-rct", "metric": 0.2832, "protocol": "loss"}, {"dataset": "pubmed-rct-pubmed-200k-rct", "metric": 0.8934, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-monologg-koelectra-small-generator", "modules": [{"role": "model", "module": {"name": "KoELECTRA (Small Generator)", "description": "Pretrained ELECTRA Language Model for Korean."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_size": "small", "tokenizer": "ElectraTokenizer", "vocab_size": 32000, "max_seq_length": 512}}}, {"role": "taskType", "module": "fill-mask"}, {"role": "solutionSummary", "module": {"summary": "KoELECTRA is a pretrained ELECTRA language model for Korean. It is available in small, base, and large sizes. The model is best suited for tasks such as text classification, token classification, and question answering. The model was trained on a large corpus of Korean text and can be fine-tuned on downstream tasks. The tokenizer used is ElectraTokenizer with a vocabulary size of 32000 and a maximum sequence length of 512."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-kompactss-jebert-je-ko", "modules": [{"role": "model", "module": {"name": "Jeju Dialect Translation Model", "description": "A Seq2Seq Transformer model for translating Jeju dialect to standard Korean."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"encoder": "BertConfig", "decoder": "BertConfig", "tokenizer": "WordPiece Tokenizer", "epochs": 10, "random_seed": 42, "learning_rate": 5e-05, "warm_up_ratio": 0.1, "batch_size": 32}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The Jeju Dialect Translation Model is a Seq2Seq Transformer model that translates Jeju dialect to standard Korean. It was trained on a combination of the Jit Dataset, AI HUB, and \uc544\ub798\uc544 \ubb38\uc790. The model uses a BertConfig encoder and decoder, and a WordPiece Tokenizer. The model achieved a BLEU score of 79.0 on the evaluation dataset. The model was developed by the \uad6c\ub984 \uc790\uc5f0\uc5b4\ucc98\ub9ac \uacfc\uc815 3\uae30 3\uc870 team."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-praptishadmaan-finetuning-sentiment-model-3000-samples", "modules": [{"role": "model", "module": {"name": "finetuning-sentiment-model-3000-samples", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "finetuning-sentiment-model-3000-samples is a fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis. The model achieved an accuracy of 0.93192 and an F1 score of 0.9323583180987203 on the evaluation set. The model is suitable for text classification tasks, but its performance may vary depending on the specific use case and data distribution."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.93192, "protocol": "accuracy"}, {"dataset": "imdb-movie-reviews", "metric": 0.9323583180987203, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-hazam-distilbert-base-uncased-finetuned-imdb", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-imdb", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-imdb is a fine-tuned version of distilbert-base-uncased on the imdb dataset. It can be used for text classification tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 64. The model was trained for 3 epochs and achieved a loss of 2.4721 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 2.4721, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-yhavinga-mt5-base-mixednews-nl", "modules": [{"role": "model", "module": {"name": "mt5-base-mixednews-nl", "description": "mt5-base model finetuned on mixed news sources translated to Dutch."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.001, "max_source_length": 1024, "max_target_length": 142, "min_target_length": 75}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "mt5-base-mixednews-nl is a transformer model finetuned on mixed news sources translated to Dutch. It can be used for summarization tasks in Dutch. The model was trained for one epoch with a learning rate of 0.001 and a max source length of 1024. The model achieved a rouge1 score of 28.8482, rouge2 score of 9.4584, and rougeL score of 20.1697. The model is suitable for summarizing news articles and other text in Dutch."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-hy-en", "modules": [{"role": "model", "module": {"name": "opus-mt-hy-en", "description": "A machine translation model that translates from Armenian (hy) to English (en) using a transformer-align model."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-hy-en is a machine translation model that translates from Armenian to English using a transformer-align model. The model achieved a BLEU score of 29.5 and a chr-F score of 0.466 on the Tatoeba.hy.en test set."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-lewtun-xlm-roberta-base-finetuned-marc-en-dummy", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-marc-en-dummy", "description": "A fine-tuned version of xlm-roberta-base on the amazon_reviews_multi dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "xlm-roberta-base-finetuned-marc-en-dummy is a fine-tuned version of xlm-roberta-base on the amazon_reviews_multi dataset. The model is suitable for text classification tasks. The model was trained for 2 epochs with a learning rate of 2e-05 and an Adam optimizer with betas=(0.9,0.999) and epsilon=1e-08. The model achieved a loss of 0.8931 and a mean absolute error (MAE) of 0.4634 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "amazon-product-data"}], "metrics": [{"dataset": "amazon-product-data", "metric": 0.8931, "protocol": "loss"}, {"dataset": "amazon-product-data", "metric": 0.4634, "protocol": "mae"}], "source": "huggingface"}, {"id": "huggingface-mdround-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 game."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "is_slippery": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 game. The model was trained using a custom implementation and can be loaded using the provided code. The model's performance was evaluated using the mean reward metric."}}, {"role": "dataset", "purpose": "The game environment used for training and evaluation.", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.5, "split": "val", "protocol": "mean_reward"}, {"dataset": "nyctaxi", "metric": 2.77, "split": "test", "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-lucypallent-distilbert-base-uncased-finetuned-imdb", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-imdb", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-imdb is a fine-tuned version of distilbert-base-uncased on the imdb dataset. It can be used for text classification tasks. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64. The model was trained for 3 epochs and achieved a loss of 2.4718 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 2.4718, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-pon-fr", "modules": [{"role": "model", "module": {"name": "opus-mt-pon-fr", "description": "A machine translation model that translates from Pon to French."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-pon-fr is a machine translation model that translates from Pon to French. It uses a transformer-align model and pre-processing techniques such as normalization and SentencePiece. The model achieves a BLEU score of 24.4 and a chr-F score of 0.41 on the JW300.pon.fr test set."}}], "metrics": [{"dataset": "jw300", "metric": 24.4, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.41, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-go2k-q-frozenlake-v1-4x4-noslippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained model of a Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-4x4-no_slippery", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model's hyperparameters include the algorithm used, the environment, the maximum number of steps per episode, the number of episodes to evaluate the agent, the Q-Table learned by the agent, and the random seed used for evaluation. The model achieved a mean reward of 1.00 +/- 0.00 on the FrozenLake-v1-4x4-no_slippery environment."}}, {"role": "dataset", "purpose": "Environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "extra": "1.00 +/- 0.00", "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-dooglak-wikigold-trained-no-da-small", "modules": [{"role": "model", "module": {"name": "wikigold_trained_no_DA_small", "description": "Fine-tuned version of bert-base-cased on the wikigold_splits dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 32}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "wikigold_trained_no_DA_small is a fine-tuned version of bert-base-cased on the wikigold_splits dataset for token classification. The model achieved a precision of 0.3429, recall of 0.5455, f1-score of 0.4211, and accuracy of 0.8530 on the evaluation set. The model is intended for token classification tasks and was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 8. The model was trained for 32 epochs with a linear learning rate scheduler."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wikisplit"}], "metrics": [{"dataset": "wikisplit", "metric": 0.3429, "protocol": "precision"}, {"dataset": "wikisplit", "metric": 0.5455, "protocol": "recall"}, {"dataset": "wikisplit", "metric": 0.4211, "protocol": "f1"}, {"dataset": "wikisplit", "metric": 0.853, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-cardiffnlp-xlm-roberta-base-sentiment-multilingual", "modules": [{"role": "model", "module": {"name": "cardiffnlp/xlm-roberta-base-sentiment-multilingual", "description": "Fine-tuned version of xlm-roberta-base on the cardiffnlp/tweet_sentiment_multilingual dataset for text classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"max_length": 128}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "cardiffnlp/xlm-roberta-base-sentiment-multilingual is a fine-tuned version of xlm-roberta-base on the cardiffnlp/tweet_sentiment_multilingual dataset for text classification. The model achieves a micro F1 score of 0.6659, a macro F1 score of 0.6629, and an accuracy of 0.6659 on the test split. The model can be loaded in Python using the tweetnlp library and used to predict the sentiment of a given text."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "sentimix"}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-igpaub-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 game."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 game. The agent's Q-Table is provided, along with hyperparameters such as the maximum number of steps per episode and the number of episodes used for evaluation. The agent achieved a mean reward of 7.56 with a standard deviation of 2.71."}}, {"role": "dataset", "purpose": "The game environment used for training and evaluation.", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.56, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-aapot-wav2vec2-xlsr-1b-finnish-lm", "modules": [{"role": "model", "module": {"name": "wav2vec2-xlsr-1b-finnish-lm", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-1b for Finnish ASR."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 32, "eval_batch_size": 8, "optimizer": {"name": "Adam", "beta1": 0.9, "beta2": 0.999, "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 5, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/wav2vec2-xls-r-1b for Finnish ASR. The model was fine-tuned with 259.57 hours of Finnish transcribed speech data. The model is suitable for Finnish ASR (speech-to-text) task. The model was fine-tuned with audio samples which maximum length was 20 seconds long, so it works best for quite short audios of similar length. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "common-voice"}, {"role": "dataset", "purpose": "For evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 5.65, "protocol": "WER"}, {"dataset": "common-voice", "metric": 1.2, "protocol": "CER"}], "source": "huggingface"}, {"id": "huggingface-eliasbe-xlmr-enis-finetuned-ner", "modules": [{"role": "model", "module": {"name": "XLMR-ENIS-finetuned-ner", "description": "A fine-tuned version of vesteinn/XLMR-ENIS on the mim_gold_ner dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "XLMR-ENIS-finetuned-ner is a fine-tuned version of vesteinn/XLMR-ENIS on the mim_gold_ner dataset. It is a token classification model that can be used to identify named entities in text. The model achieved high precision, recall, F1 score, and accuracy on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler for 3 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "mimic-iii-the-medical-information-mart-for-intensive-care-iii"}], "metrics": [{"dataset": "mimic-iii-the-medical-information-mart-for-intensive-care-iii", "metric": 0.9002453676283949, "protocol": "precision"}, {"dataset": "mimic-iii-the-medical-information-mart-for-intensive-care-iii", "metric": 0.896, "protocol": "recall"}, {"dataset": "mimic-iii-the-medical-information-mart-for-intensive-care-iii", "metric": 0.8981176669198953, "protocol": "f1"}, {"dataset": "mimic-iii-the-medical-information-mart-for-intensive-care-iii", "metric": 0.9843747637694087, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-allenai-wmt16-en-de-12-1", "modules": [{"role": "model", "module": {"name": "FSMT", "description": "A ported version of fairseq-based wmt16 transformer for en-de."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_name": "allenai/wmt16-en-de-12-1", "tokenizer": "FSMTTokenizer", "batch_size": 8, "num_beams": 5}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "FSMT is a ported version of fairseq-based wmt16 transformer for en-de. It can be used for machine translation tasks. The model is trained on the wmt16 dataset and evaluated using BLEU score. The score is slightly below the score reported in the paper, as the researchers don't use sacrebleu and measure the score on tokenized outputs. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-akshat-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8611 on the evaluation set. The model is suitable for token classification tasks in German language. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8611443210930829, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-superb-hubert-base-superb-ks", "modules": [{"role": "model", "module": {"name": "Hubert-Base for Keyword Spotting", "description": "A ported version of S3PRL's Hubert for the SUPERB Keyword Spotting task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "hubert-base-ls960", "preprocessing": {"sample_rate": "16kHz"}}}}, {"role": "taskType", "module": "audio-classification"}, {"role": "solutionSummary", "module": {"summary": "Hubert-Base for Keyword Spotting is a model that detects preregistered keywords by classifying utterances into a predefined set of words. The model is based on the hubert-base-ls960 architecture and is pretrained on 16kHz sampled speech audio. The model is intended to be used on-device for fast response time. The model was evaluated on the Speech Commands dataset v1.0 and achieved an accuracy of 0.9672."}}, {"role": "dataset", "purpose": "For the Keyword Spotting task.", "module": "speech-commands"}], "metrics": [{"dataset": "speech-commands", "metric": 0.9672, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-pag-en", "modules": [{"role": "model", "module": {"name": "opus-mt-pag-en", "description": "A transformer-align model for translating from Panggalatok (pag) to English (en)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-pag-en model is a transformer-align model that translates from Panggalatok (pag) to English (en). It achieved a BLEU score of 42.4 and a chr-F score of 0.58 on the JW300.pag.en test set. The model uses normalization and SentencePiece for pre-processing. The original weights can be downloaded from the provided link."}}, {"role": "dataset", "purpose": "Test set for benchmarking.", "module": "jw300"}], "metrics": [{"dataset": "jw300", "metric": 42.4, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.58, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-freelancerfel-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 environment."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "is_slippery": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 environment. The model was evaluated on the mean reward metric and achieved a score of 7.56 +/- 2.71. The model can be loaded and used to play the game using the provided code snippet."}}, {"role": "dataset", "purpose": "OpenAI Gym environment", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.56, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-denilsenaxel-nlp-text-classification", "modules": [{"role": "model", "module": {"name": "test_trainer", "description": "Fine-tuned version of bert-base-uncased on the amazon_us_reviews dataset for text classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of bert-base-uncased on the amazon_us_reviews dataset for text classification. The model achieved an accuracy of 0.7441 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 5e-05 and a linear learning rate scheduler. The model was trained for 3 epochs with a batch size of 8."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "amazon-product-data"}], "metrics": [{"dataset": "amazon-product-data", "metric": 0.7441424554826617, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-veeransh-q-frozenlake-v1-4x4-noslippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained model of a Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-4x4-no_slippery"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model was trained using the Q-Learning algorithm and evaluated on the FrozenLake-v1-4x4-no_slippery environment. The model achieved a mean reward of 1.00 +/- 0.00, but the verification status is unknown."}}, {"role": "dataset", "purpose": "The environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "extra": "1.00 +/- 0.00", "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-fredvv-bert-finetuned-pos", "modules": [{"role": "model", "module": {"name": "bert-finetuned-pos", "description": "A fine-tuned version of bert-base-cased on the conll2003 dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-finetuned-pos is a fine-tuned version of bert-base-cased on the conll2003 dataset for token classification. The model achieved high precision, recall, F1 score, and accuracy on the evaluation set. The model is suitable for token classification tasks, such as part-of-speech tagging. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 0.9347682119205298, "protocol": "Precision"}, {"dataset": "conll-2003", "metric": 0.9501851228542578, "protocol": "Recall"}, {"dataset": "conll-2003", "metric": 0.9424136204306459, "protocol": "F1"}, {"dataset": "conll-2003", "metric": 0.9867840113027609, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-thomassimonini-ppo-qbertnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "PPO Agent", "description": "A trained PPO agent playing QbertNoFrameskip-v4 using the stable-baselines3 library."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"policy": "CnnPolicy", "batch_size": 256, "clip_range": 0.1, "ent_coef": 0.01, "gae_lambda": 0.9, "gamma": 0.99, "learning_rate": 0.00025, "max_grad_norm": 0.5, "n_epochs": 4, "n_steps": 128, "vf_coef": 0.5}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained PPO agent playing QbertNoFrameskip-v4 using the stable-baselines3 library. The model was trained on BookCorpus, a dataset consisting of 11,038 unpublished books and English Wikipedia (excluding lists, tables, and headers). The model was trained using the PPO algorithm with a batch size of 256, a learning rate of 0.00025, and a total of 10 million timesteps. The model achieved a mean reward of 15685.00 +/- 115.217 on QbertNoFrameskip-v4. The model is suitable for reinforcement learning tasks, but caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 15685.0, "split": "val", "protocol": "mean_reward"}, {"dataset": "atari-grand-challenge", "metric": 115.217, "split": "test", "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-vicl-canine-s-finetuned-stsb", "modules": [{"role": "model", "module": {"name": "canine-s-finetuned-stsb", "description": "A fine-tuned version of google/canine-s on the glue dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "canine-s-finetuned-stsb is a fine-tuned version of google/canine-s on the glue dataset. It is a transformer model that can be used for text classification tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model achieved a Spearmanr score of 0.8397 on the STS-B dataset of the GLUE benchmark."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.8397182061195433, "protocol": "spearmanr"}], "source": "huggingface"}, {"id": "huggingface-lookparof-q-frozenlake-v1-8x8-non-slippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained model of a Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-8x8-no_slippery", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model's hyperparameters include the algorithm used, the environment, the maximum number of steps per episode, the number of episodes to evaluate the agent, the Q-Table learned by the agent, and the random seed used for evaluation. The model achieved a mean reward of 1.0 with no standard deviation."}}, {"role": "dataset", "purpose": "Environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-dooglak-article-100v3-ner-model-3epochs-unaugmented", "modules": [{"role": "model", "module": {"name": "Article_100v3_NER_Model_3Epochs_UNAUGMENTED", "description": "A fine-tuned version of bert-base-cased on the article100v3_wikigold_split dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "Article_100v3_NER_Model_3Epochs_UNAUGMENTED is a fine-tuned version of bert-base-cased on the article100v3_wikigold_split dataset for token classification. The model achieved an accuracy of 0.7772 on the evaluation set. More information is needed to describe the model and its intended uses and limitations."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wikisplit"}], "metrics": [{"dataset": "wikisplit", "metric": 0.0, "protocol": "Precision"}, {"dataset": "wikisplit", "metric": 0.0, "protocol": "Recall"}, {"dataset": "wikisplit", "metric": 0.0, "protocol": "F1"}, {"dataset": "wikisplit", "metric": 0.7772, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-rotvderme-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 game."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 game. The agent's Q-Table is provided, along with hyperparameters such as the maximum number of steps per episode and the number of episodes used to evaluate the agent. The mean reward achieved by the agent is 7.56 with a standard deviation of 2.71."}}, {"role": "dataset", "purpose": "The game environment used for training and evaluation.", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.56, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-edresson-wav2vec2-large-100k-voxpopuli-ft-common-voice-plus-tts-dataset-plus-data-augmentation-portuguese", "modules": [{"role": "model", "module": {"name": "Wav2vec2 Large 100k Voxpopuli fine-tuned in Portuguese using the Common Voice 7.0, TTS-Portuguese Corpus plus data augmentation", "description": "A Wav2vec2 Large 100k Voxpopuli model fine-tuned in Portuguese using the Common Voice 7.0, TTS-Portuguese Corpus plus data augmentation method based on TTS and voice conversion."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_name": "Edresson/wav2vec2-large-100k-voxpopuli-ft-Common_Voice_plus_TTS-Dataset_plus_Data_Augmentation-portuguese"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a Wav2vec2 Large 100k Voxpopuli model fine-tuned in Portuguese using the Common Voice 7.0, TTS-Portuguese Corpus plus data augmentation method based on TTS and voice conversion. The model is intended for automatic speech recognition tasks in Portuguese. The model achieved a WER of 20.20 on the Common Voice 7.0 test dataset."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-raduion-bert-medium-luxembourgish", "modules": [{"role": "model", "module": {"name": "BERT Medium for Luxembourgish", "description": "Pretrained model on Luxembourgish language using a masked language modeling (MLM) objective."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"num_layers": 8, "hidden_size": 512, "vocab_size": 70000, "epochs": 3, "batch_size": null}}}, {"role": "taskType", "module": "fill-mask"}, {"role": "solutionSummary", "module": {"summary": "BERT Medium for Luxembourgish is a transformer model pretrained on a dataset of 1M Luxembourgish sentences from Wikipedia. The model was trained using a masked language modeling (MLM) objective. It has 8 layers and 512 hidden units. The vocabulary size is 70K word pieces. The model is best suited for tasks that use the whole sentence to make decisions, such as sequence classification, token classification, or question answering. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training.", "module": "wikiconv"}], "metrics": [{"dataset": "wikiconv", "metric": 4.23, "protocol": "train_loss"}, {"dataset": "wikiconv", "metric": 68.726, "protocol": "train_perplexity"}, {"dataset": "wikiconv", "metric": 4.074, "protocol": "validation_loss"}, {"dataset": "wikiconv", "metric": 58.765, "protocol": "validation_perplexity"}], "source": "huggingface"}, {"id": "huggingface-sukhmani-finetuning-sentiment-model-3000-samples", "modules": [{"role": "model", "module": {"name": "finetuning-sentiment-model-3000-samples", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis. It achieves an accuracy of 0.91 and an F1 score of 0.9095 on the evaluation set. The model was trained for 2 epochs with a learning rate of 2e-05 and an Adam optimizer with betas=(0.9,0.999) and epsilon=1e-08. The model is suitable for text classification tasks, particularly for sentiment analysis on the imdb dataset."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.91, "protocol": "accuracy"}, {"dataset": "imdb-movie-reviews", "metric": 0.909456740442656, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-merve-breast-cancernb8gjv4n-diagnosis-classification", "modules": [{"role": "model", "module": {"name": "Breast Cancer Diagnosis Classifier", "description": "Baseline model trained on breast_cancer dataset to apply classification on diagnosis."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessor": "EasyPreprocessor", "classifier": "LogisticRegression", "C": 0.1, "class_weight": "balanced", "max_iter": 1000}}}, {"role": "taskType", "module": "tabular-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a baseline model trained on the breast_cancer dataset to classify diagnosis. The model is a logistic regression classifier with EasyPreprocessor as the preprocessor. The model achieved high accuracy, average precision, and ROC AUC scores. However, this model is not intended for production use and should be used as a starting point for further model development."}}, {"role": "dataset", "purpose": "For model training.", "module": "breakhis-breast-cancer-histopathological-database"}], "metrics": [{"dataset": "breakhis-breast-cancer-histopathological-database", "metric": 0.978932, "protocol": "accuracy"}, {"dataset": "breakhis-breast-cancer-histopathological-database", "metric": 0.994309, "protocol": "average_precision"}, {"dataset": "breakhis-breast-cancer-histopathological-database", "metric": 0.995448, "protocol": "roc_auc"}, {"dataset": "breakhis-breast-cancer-histopathological-database", "metric": 0.976607, "protocol": "recall_macro"}, {"dataset": "breakhis-breast-cancer-histopathological-database", "metric": 0.977365, "protocol": "f1_macro"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-sv-tn", "modules": [{"role": "model", "module": {"name": "opus-mt-sv-tn", "description": "A transformer-align model for translating from Swedish (sv) to Tswana (tn)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-sv-tn model is a transformer-align model that translates from Swedish to Tswana. It achieved a BLEU score of 36.3 and a chr-F score of 0.561 on the JW300.sv.tn test set. The model uses normalization and SentencePiece for pre-processing."}}], "metrics": [{"dataset": "jw300", "metric": 36.3, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.561, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-butchland-q-frozenlake-v1-4x4-noslippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained model of a Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-4x4-no_slippery", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model's hyperparameters include the algorithm used, the environment, the maximum number of steps per episode, the number of episodes to evaluate the agent, the Q-Table learned by the agent, and the random seed used for evaluation. The model achieved a mean reward of 1.00 +/- 0.00 on the FrozenLake-v1-4x4-no_slippery environment."}}, {"role": "dataset", "purpose": "Environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-ahmeddbahaa-mbart-large-50-finetuned-persian", "modules": [{"role": "model", "module": {"name": "mbart-large-50-finetuned-persian", "description": "A fine-tuned version of mbart-large-50 on the xlsum dataset for abstractive summarization in Persian."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0005, "train_batch_size": 4, "eval_batch_size": 4, "seed": 42, "gradient_accumulation_steps": 8, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5, "label_smoothing_factor": 0.1}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "mbart-large-50-finetuned-persian is a transformer model fine-tuned on the xlsum dataset for abstractive summarization in Persian. The model achieved good results on the evaluation set, with a Rouge-1 score of 26.11 and a Bertscore of 71.08. The model is intended for abstractive summarization tasks in Persian, but its limitations and biases are not specified. The model was trained using Adam optimizer with a learning rate of 0.0005 and a linear learning rate scheduler for 5 epochs."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "xl-sum"}], "metrics": [{"dataset": "xl-sum", "metric": 4.1932, "protocol": "loss"}, {"dataset": "xl-sum", "metric": 26.11, "protocol": "rouge-1"}, {"dataset": "xl-sum", "metric": 8.11, "protocol": "rouge-2"}, {"dataset": "xl-sum", "metric": 21.09, "protocol": "rouge-l"}, {"dataset": "xl-sum", "metric": 37.29, "protocol": "gen_len"}, {"dataset": "xl-sum", "metric": 71.08, "protocol": "bertscore"}], "source": "huggingface"}, {"id": "huggingface-dooglak-tagged-uni-250v3-ner-model-3epochs-augmented", "modules": [{"role": "model", "module": {"name": "Tagged_Uni_250v3_NER_Model_3Epochs_AUGMENTED", "description": "A fine-tuned version of bert-base-cased on the tagged_uni250v3_wikigold_split dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of bert-base-cased on the tagged_uni250v3_wikigold_split dataset for token classification. It achieved a precision of 0.5831, recall of 0.4849, F1 score of 0.5295, and accuracy of 0.8989 on the evaluation set. The model was trained for 3 epochs with a linear learning rate scheduler and Adam optimizer."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wikisplit"}], "metrics": [{"dataset": "wikisplit", "metric": 0.5830763960260363, "protocol": "precision"}, {"dataset": "wikisplit", "metric": 0.4849002849002849, "protocol": "recall"}, {"dataset": "wikisplit", "metric": 0.5294758127235961, "protocol": "f1"}, {"dataset": "wikisplit", "metric": 0.8988582871706847, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-rastadayon-wav2vec2-large-xls-r-300m-dutch-colab", "modules": [{"role": "model", "module": {"name": "wav2vec2-large-xls-r-300m-dutch-colab", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0003, "train_batch_size": 16, "eval_batch_size": 8, "gradient_accumulation_steps": 2, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 40, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset. The model is suitable for automatic speech recognition tasks in Dutch. The model was trained using PyTorch and Transformers with a linear learning rate scheduler and mixed precision training. The model achieved an evaluation loss of 0.5834, a word error rate of 0.3471, and a character error rate of 0.1181 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.5834, "protocol": "eval_loss"}, {"dataset": "common-voice", "metric": 0.3471, "protocol": "eval_wer"}, {"dataset": "common-voice", "metric": 0.1181, "protocol": "eval_cer"}, {"dataset": "common-voice", "metric": 338.6313, "protocol": "eval_runtime"}, {"dataset": "common-voice", "metric": 14.582, "protocol": "eval_samples_per_second"}, {"dataset": "common-voice", "metric": 1.825, "protocol": "eval_steps_per_second"}, {"dataset": "common-voice", "metric": 14.87, "protocol": "epoch"}, {"dataset": "common-voice", "metric": 4000.0, "protocol": "step"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-fr-st", "modules": [{"role": "model", "module": {"name": "opus-mt-fr-st", "description": "A transformer-align model for translating from French (fr) to Sesotho (st)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-fr-st model is a transformer-align model that translates from French to Sesotho. It achieved a BLEU score of 34.6 and a chr-F score of 0.54 on the JW300.fr.st test set. The model uses normalization and SentencePiece for pre-processing."}}], "metrics": [{"dataset": "jw300", "metric": 34.6, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.54, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-uk-tr", "modules": [{"role": "model", "module": {"name": "ukr-tur", "description": "A transformer model for Ukrainian to Turkish translation."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece (spm32k,spm32k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "A transformer model for Ukrainian to Turkish translation. The model was trained on the Tatoeba dataset and achieved a BLEU score of 39.3 and a chrF2 score of 0.655 on the test set. The model uses normalization and SentencePiece (spm32k,spm32k) for preprocessing."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "tatoeba-translation-challenge"}], "metrics": [{"dataset": "tatoeba-translation-challenge", "metric": 39.3, "protocol": "BLEU"}, {"dataset": "tatoeba-translation-challenge", "metric": 0.655, "protocol": "chrF2"}], "source": "huggingface"}, {"id": "huggingface-shuojiang-q-frozenlake-v1-4x4-noslippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained model of a Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-4x4-no_slippery"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model was trained using the Q-Learning algorithm and evaluated on the FrozenLake-v1-4x4-no_slippery environment. The model achieved a mean reward of 1.00 +/- 0.00, but the verification status is unknown."}}, {"role": "dataset", "purpose": "The environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "extra": "1.00 +/- 0.00", "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-patrickvonplaten-wav2vec2-xlsr-53-300m-mls-german-ft", "modules": [{"role": "model", "module": {"name": "wav2vec2-xlsr-53-300m-mls-german-ft", "description": "Fine-tuned version of facebook/wav2vec2-large-xlsr-53 on the MULTILINGUAL_LIBRISPEECH - GERMAN 10h dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0001, "train_batch_size": 32, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 1000, "num_epochs": 200.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/wav2vec2-large-xlsr-53 on the MULTILINGUAL_LIBRISPEECH - GERMAN 10h dataset. The model is intended for automatic speech recognition tasks. The model achieved a loss of 0.2219 and a WER of 0.1288 on the evaluation set. The model was trained using PyTorch 1.10.0 and Transformers 4.13.0.dev0. Caution should be taken when deploying the model in human-interacting systems as it may reflect the biases of the systems it was trained on."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "multilingual-librispeech-mls"}], "metrics": [{"dataset": "multilingual-librispeech-mls", "metric": 0.2219, "protocol": "loss"}, {"dataset": "multilingual-librispeech-mls", "metric": 0.1288, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-zates-distilbert-base-uncased-finetuned-squad-seed-69", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-squad-seed-69", "description": "A fine-tuned version of distilbert-base-uncased on the squad_v2 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-squad-seed-69 is a fine-tuned version of distilbert-base-uncased on the squad_v2 dataset. It is suitable for question answering tasks. The model was trained with Adam optimizer with a learning rate of 2e-05, betas=(0.9,0.999) and epsilon=1e-08. The model was trained for 3 epochs with a linear learning rate scheduler. The model achieved a loss of 1.4246 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 1.4246, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-saeedhedayatian-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 game."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "is_slippery": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 game. The model was trained using a custom implementation and evaluated on the same environment. The mean reward achieved by the agent is 7.56 with a standard deviation of 2.71 over multiple evaluation episodes."}}, {"role": "dataset", "purpose": "The game environment used for training and evaluation.", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.56, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-mhf-xlm-roberta-base-finetuned-panx-en", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-en", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.6808 on the evaluation set. The model is suitable for token classification tasks in multilingual settings."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.6807563959955506, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-minemile-distilbert-base-uncased-finetuned-imdb", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-imdb", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-imdb is a fine-tuned version of distilbert-base-uncased on the imdb dataset. It can be used for text classification tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 64. The model was trained for 3 epochs and achieved a loss of 2.4718 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 2.4718, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-tbs17-mathbert", "modules": [{"role": "model", "module": {"name": "MathBERT model (original vocab)", "description": "Pretrained model on pre-k to graduate math language (English) using a masked language modeling (MLM) objective."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 128, "optimizer": {"name": "Adam", "learning_rate": 5e-05, "beta1": 0.9, "beta2": 0.999, "weight_decay": 0.01}}}}, {"role": "taskType", "module": "fill-mask"}, {"role": "solutionSummary", "module": {"summary": "MathBERT is a transformer model pre-trained on a large corpus of English math data. It can be used for masked language modeling or next sentence prediction, but it's mainly intended to be fine-tuned on a math-related downstream task. The model is suitable for tasks that use the whole sentence to make decisions, such as sequence classification, token classification, or question answering. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-idea-ccnl-erlangshen-simcse-110m-chinese", "modules": [{"role": "model", "module": {"name": "Erlangshen-SimCSE-110M-Chinese", "description": "A supervised version of SimCSE model trained on Chinese NLI data."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_type": "Bert", "model_size": "110M"}}}, {"role": "taskType", "module": "sentence-similarity"}, {"role": "solutionSummary", "module": {"summary": "Erlangshen-SimCSE-110M-Chinese is a supervised version of the SimCSE model trained on Chinese NLI data. It can be used for sentence similarity tasks in Chinese. The model is based on the Bert architecture and has 110M parameters. The model is pre-trained on BookCorpus and supervised trained on Chinese NLI data. The model has good performance on some sentence similarity tasks in Chinese."}}, {"role": "dataset", "purpose": "For pretraining.", "module": "bookcorpus"}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-hiranhsw-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 game."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 game. The agent's Q-Table is provided, along with hyperparameters such as the maximum number of steps per episode and the number of episodes used for evaluation. The model's performance is evaluated based on the mean reward achieved over the evaluation episodes."}}, {"role": "dataset", "purpose": "The game environment used for training and evaluation.", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.56, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-hugoguh-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 game."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "is_slippery": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 game. The model was trained using a custom implementation of the Q-Learning algorithm. The model's performance is evaluated using the mean reward metric, which is 7.56 with a standard deviation of 2.71."}}, {"role": "dataset", "purpose": "The game environment used for training and evaluation.", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.56, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-zgotter-bert-base-finetuned-ynat", "modules": [{"role": "model", "module": {"name": "bert-base-finetuned-ynat", "description": "Fine-tuned version of klue/bert-base on the klue dataset for text classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 256, "eval_batch_size": 256, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-base-finetuned-ynat is a fine-tuned version of klue/bert-base on the klue dataset for text classification. The model achieved an F1 score of 0.8669 on the evaluation set. The model is suitable for text classification tasks, but its performance may vary depending on the specific task and dataset. Caution should be taken when deploying it in human-interacting systems as the model reflects the biases of the systems it was trained on."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "klue-korean-language-understanding-evaluation"}], "metrics": [{"dataset": "klue-korean-language-understanding-evaluation", "metric": 0.8669116640755216, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-team-nave-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 48, "eval_batch_size": 48, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "xlm-roberta-base-finetuned-panx-de is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. The model achieved an F1 score of 0.8593 on the evaluation set. The model is suitable for token classification tasks in German language."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8593, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-fi-bem", "modules": [{"role": "model", "module": {"name": "opus-mt-fi-bem", "description": "A machine translation model that translates from Finnish (fi) to Bemba (bem) language."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-fi-bem is a machine translation model that translates from Finnish to Bemba language. The model is based on the transformer-align architecture and was preprocessed using normalization and SentencePiece. The model achieved a BLEU score of 21.4 and a chr-F score of 0.465 on the JW300.fi.bem test set."}}], "metrics": [{"dataset": "jw300", "metric": 21.4, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.465, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-sebis-legal-t5-small-summ-en", "modules": [{"role": "model", "module": {"name": "legal_t5_small_summ_en", "description": "A T5-based model for summarization of legal text written in English."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_size": "small", "dmodel": 512, "dff": 2048, "num_heads": 8, "num_layers": 6, "batch_size": 64, "optimizer": {"name": "AdaFactor", "learning_rate_schedule": "inverse square root"}}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "legal_t5_small_summ_en is a T5-based model for summarization of legal text written in English. It was trained on JRC-ACQUIS dataset consisting of 22 thousand texts. The model is smaller than the baseline T5 model, with 220M parameters, and was trained using the encoder-decoder architecture. The model uses byte pair encoding for tokenization. The model achieved a Rouge1 score of 78.11, Rouge2 score of 68.78, and Rouge Lsum score of 77.0."}}, {"role": "dataset", "purpose": "For model training.", "module": "europarl-european-parliament-proceedings-parallel-corpus"}], "metrics": [{"dataset": "europarl-european-parliament-proceedings-parallel-corpus", "metric": 78.11, "protocol": "Rouge1"}, {"dataset": "europarl-european-parliament-proceedings-parallel-corpus", "metric": 68.78, "protocol": "Rouge2"}, {"dataset": "europarl-european-parliament-proceedings-parallel-corpus", "metric": 77.0, "protocol": "Rouge Lsum"}], "source": "huggingface"}, {"id": "huggingface-emcheng-distilbert-base-uncased-finetuned-cola", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-cola", "description": "A fine-tuned version of distilbert-base-uncased on the glue dataset for text classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 32, "eval_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 15}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-cola is a fine-tuned version of distilbert-base-uncased on the glue dataset for text classification. The model achieved a Matthews Correlation of 0.5365 on the evaluation set. The model is suitable for text classification tasks, but caution should be taken when deploying it in human-interacting systems as it may reflect the biases of the systems it was trained on."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.5365, "protocol": "matthews_correlation"}], "source": "huggingface"}, {"id": "huggingface-m-fac-bert-tiny-finetuned-qqp", "modules": [{"role": "model", "module": {"name": "BERT-tiny model finetuned with M-FAC", "description": "A BERT-tiny model finetuned on QQP dataset with M-FAC optimizer."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"optimizer": {"name": "M-FAC", "learning_rate": 0.0001, "num_gradients": 1024, "dampening": 1e-06}, "max_seq_length": 128, "per_device_train_batch_size": 32, "num_train_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "A BERT-tiny model finetuned on QQP dataset with M-FAC optimizer. The model achieved an F1 score of 79.84 and an accuracy of 84.40 on the validation set. The hyperparameters used for finetuning include a maximum sequence length of 128, a per-device training batch size of 32, and 5 training epochs. The M-FAC optimizer was used with a learning rate of 0.0001, 1024 gradients, and a dampening of 1e-6. The model can be further improved with hyperparameter tuning."}}, {"role": "dataset", "purpose": "For model finetuning.", "module": "quora-question-pairs"}], "metrics": [{"dataset": "quora-question-pairs", "metric": 79.84, "protocol": "f1"}, {"dataset": "quora-question-pairs", "metric": 84.4, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-jmurphy97-distilbert-base-uncased-finetuned-clinc", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-clinc", "description": "A fine-tuned version of distilbert-base-uncased on the clinc_oos dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 48, "eval_batch_size": 48, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-clinc is a fine-tuned version of distilbert-base-uncased on the clinc_oos dataset. It is a text classification model that can be used to classify out-of-scope queries. The model achieved an accuracy of 0.9184 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler for 5 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "clinc-single-domain-oos"}], "metrics": [{"dataset": "clinc-single-domain-oos", "metric": 0.9183870967741935, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-elgeish-cs224n-squad2-0-albert-xxlarge-v1", "modules": [{"role": "model", "module": {"name": "CS224n SQuAD2.0 Project Dataset", "description": "A fine-tuned ALBERT model on the SQuAD2.0 dataset for the CS224n course project."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_name_or_path": "albert-xxlarge-v1", "model_type": "albert", "do_lower_case": true, "max_seq_length": 512, "doc_stride": 128, "max_query_length": 64, "max_answer_length": 30, "num_train_epochs": 4, "learning_rate": 3e-05, "warmup_steps": 814, "weight_decay": 0, "gradient_accumulation_steps": 24, "per_gpu_train_batch_size": 1, "train_batch_size": 1, "version_2_with_negative": true, "fp16": false, "fp16_opt_level": "O1", "max_grad_norm": 1, "save_steps": 1000, "seed": 42}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned ALBERT model on the SQuAD2.0 dataset for the CS224n course project. The model is best suited for question-answering tasks. The hyperparameters include the model type, learning rate, batch size, and number of epochs. The model was trained on the SQuAD2.0 dataset and achieved an exact match score of 85.93 and an F1 score of 88.91 on the evaluation set. The model was fine-tuned using ALBERT-xxlarge-v1 and the training was performed on a Tesla V100-SXM2-16GB GPU."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 85.93287265547877, "protocol": "exact"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 88.91258331187983, "protocol": "f1"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 6078.0, "protocol": "total"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 84.36426116838489, "protocol": "HasAns_exact"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 90.58786301361013, "protocol": "HasAns_f1"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 2910.0, "protocol": "HasAns_total"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 87.37373737373737, "protocol": "NoAns_exact"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 87.37373737373737, "protocol": "NoAns_f1"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 3168.0, "protocol": "NoAns_total"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 85.93287265547877, "protocol": "best_exact"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 0.0, "protocol": "best_exact_thresh"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 88.91258331187993, "protocol": "best_f1"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 0.0, "protocol": "best_f1_thresh"}], "source": "huggingface"}, {"id": "huggingface-kpekep-rugpt-chitchat", "modules": [{"role": "model", "module": {"name": "Russian Chit-chat, Deductive and Common Sense reasoning model", "description": "A model for generating chat responses and answering questions based on facts and common sense reasoning."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_size": "760M parameters"}}}, {"role": "taskType", "module": "text-generation"}, {"role": "solutionSummary", "module": {"summary": "The Russian Chit-chat, Deductive and Common Sense reasoning model is a large transformer model that can generate chat responses and answer questions based on facts and common sense reasoning. The model was pretrained on a large corpus of Russian text and can be fine-tuned for specific tasks. The model can also perform simple arithmetic operations. The accuracy of the arithmetic operations varies depending on the size of the model used."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-mdround-dqn-spaceinvadersnoframeskip-v4-1e6ts", "modules": [{"role": "model", "module": {"name": "DQN", "description": "A trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "buffer_size": 100000, "exploration_final_eps": 0.01, "exploration_fraction": 0.1, "frame_stack": 4, "gradient_steps": 1, "learning_rate": 0.0001, "learning_starts": 100000, "n_timesteps": 1000000.0, "optimize_memory_usage": false, "policy": "CnnPolicy", "target_update_interval": 1000, "train_freq": 4, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The model was trained with a batch size of 32, a buffer size of 100000, and a learning rate of 0.0001. The model achieved a mean reward of 525.00 with a standard deviation of 135.70. The model is suitable for reinforcement learning tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 525.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-tvl-fr", "modules": [{"role": "model", "module": {"name": "opus-mt-tvl-fr", "description": "A machine translation model that translates from tvl to fr using the transformer-align architecture."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-tvl-fr model is a machine translation model that translates from tvl to fr using the transformer-align architecture. It achieved a BLEU score of 24.0 and a chr-F score of 0.410 on the JW300.tvl.fr test set."}}], "metrics": [{"dataset": "jw300", "metric": 24.0, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.41, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-opennyaiorg-en-legal-ner-trf", "modules": [{"role": "model", "module": {"name": "en_legal_ner_trf", "description": "Named Entity Recognition model trained on Indian legal judgements using spacy."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"pipeline": ["transformer", "ner"], "spacy_version": ">=3.2.2,<3.3.0"}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "en_legal_ner_trf is a transformer-based model trained on Indian legal judgements for Named Entity Recognition using spacy. The model achieved a Test F1-Score of 91.076. The model can identify 14 different types of entities, including LAWYER, COURT, JUDGE, PETITIONER, RESPONDENT, CASE_NUMBER, GPE, DATE, ORG, STATUTE, WITNESS, PRECEDENT, PROVISION, and OTHER_PERSON."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "legal-ner"}], "metrics": [{"dataset": "legal-ner", "metric": 91.076, "protocol": "F1-Score"}, {"dataset": "legal-ner", "metric": 91.979, "protocol": "Precision"}, {"dataset": "legal-ner", "metric": 90.19, "protocol": "Recall"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-en-pon", "modules": [{"role": "model", "module": {"name": "opus-mt-en-pon", "description": "A transformer-align model for translating from English to Pon."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-en-pon is a transformer-align model that translates English to Pon. The model was trained on the OPUS dataset using normalization and SentencePiece preprocessing. The model achieved a BLEU score of 32.4 and a chr-F score of 0.542 on the JW300.en.pon test set."}}], "metrics": [{"dataset": "jw300", "metric": 32.4, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.542, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-harish3110-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8621 on the evaluation set. The model is suitable for token classification tasks in German language. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.862053266560437, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-siddharthtumre-biobert-finetuned-ner", "modules": [{"role": "model", "module": {"name": "biobert-finetuned-ner", "description": "A fine-tuned version of dmis-lab/biobert-base-cased-v1.2 on the jnlpba dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "biobert-finetuned-ner is a fine-tuned version of dmis-lab/biobert-base-cased-v1.2 on the jnlpba dataset. It is a token classification model that can identify named entities in biomedical text. The model achieved a precision of 0.655, recall of 0.765, F1 score of 0.706, and accuracy of 0.911 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 16 for 5 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "jnlpba"}], "metrics": [{"dataset": "jnlpba", "metric": 0.6550939663699308, "protocol": "Precision"}, {"dataset": "jnlpba", "metric": 0.7646040175479104, "protocol": "Recall"}, {"dataset": "jnlpba", "metric": 0.7056253995312167, "protocol": "F1"}, {"dataset": "jnlpba", "metric": 0.9107839603371846, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-gorkemgoknar-wav2vec2-large-xlsr-53-turkish", "modules": [{"role": "model", "module": {"name": "XLSR Wav2Vec2 Large Turkish with extended dataset by Gorkem Goknar", "description": "Fine-tuned XLSR Wav2Vec2 Large on Turkish using Common Voice and 5 Turkish movies that include background noise/talkers."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 2, "optimizer": {"name": "Adam", "learning_rate": 0.0001, "beta1": 0.9, "beta2": 0.999, "weight_decay": 0.01}}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned XLSR Wav2Vec2 Large model on Turkish using Common Voice and 5 Turkish movies that include background noise/talkers. The model is intended for automatic speech recognition tasks and can be used directly without a language model. The model is trained on Common Voice tr and movies datasets. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 50.41, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-vicl-canine-s-finetuned-cola", "modules": [{"role": "model", "module": {"name": "canine-s-finetuned-cola", "description": "A fine-tuned version of google/canine-s on the glue dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "canine-s-finetuned-cola is a fine-tuned version of google/canine-s on the glue dataset. It is a text classification model that can be used to classify text into two classes. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model achieved a Matthews Correlation score of 0.0594 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.059386434587477076, "protocol": "matthews_correlation"}], "source": "huggingface"}, {"id": "huggingface-flair-frame-english-fast", "modules": [{"role": "model", "module": {"name": "Flair English Verb Disambiguation (fast model)", "description": "A fast verb disambiguation model for English that ships with Flair."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"embeddings": ["BytePairEmbeddings('en')", "FlairEmbeddings('news-forward-fast')", "FlairEmbeddings('news-backward-fast')"], "hidden_size": 256, "tag_type": "frame", "max_epochs": 150}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fast verb disambiguation model for English that ships with Flair. It is based on Flair embeddings and LSTM-CRF. The model predicts Proposition Bank verb frames and has an F1-Score of 88.27 on the Ontonotes dataset. The model is intended to be fine-tuned on a downstream task, such as sequence classification, token classification, or question answering. The Flair issue tracker is available for any issues."}}, {"role": "dataset", "purpose": "For model training.", "module": "ontonotes-5-0"}], "metrics": [{"dataset": "ontonotes-5-0", "metric": 88.27, "protocol": "F1-Score"}], "source": "huggingface"}, {"id": "huggingface-sania-nawaz-finetuning-sentiment-model-3000-samples", "modules": [{"role": "model", "module": {"name": "finetuning-sentiment-model-3000-samples", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis. It achieves an accuracy of 0.8667 and an F1 score of 0.8667 on the evaluation set. The model is suitable for text classification tasks, but its performance may vary depending on the specific use case. The hyperparameters used during training include a learning rate of 2e-05, a batch size of 16, and a linear learning rate scheduler."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.8667, "protocol": "accuracy"}, {"dataset": "imdb-movie-reviews", "metric": 0.8667, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-fi-fse", "modules": [{"role": "model", "module": {"name": "opus-mt-fi-fse", "description": "A machine translation model that translates from Finnish (fi) to Finnish Sign Language (fse)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-fi-fse is a machine translation model that translates from Finnish to Finnish Sign Language. The model uses the transformer-align architecture and pre-processing techniques such as normalization and SentencePiece. The model achieves a BLEU score of 81.9 and a chr-F score of 0.882 on the JW300.fi.fse test set."}}], "metrics": [{"dataset": "jw300", "metric": 81.9, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.882, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-iis2009002-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. The model achieved an accuracy of 0.926 and an F1 score of 0.9259 on the evaluation set. The model is suitable for text classification tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.926, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.925904463781861, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-joantirant-roberta-base-bne-finetuned-amazon-reviews-multi", "modules": [{"role": "model", "module": {"name": "roberta-base-bne-finetuned-amazon_reviews_multi", "description": "A fine-tuned version of BSC-TeMU/roberta-base-bne on the amazon_reviews_multi dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of BSC-TeMU/roberta-base-bne on the amazon_reviews_multi dataset. The model achieved an accuracy of 0.93425 on the evaluation set. The model is suitable for text classification tasks. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "amazon-review"}], "metrics": [{"dataset": "amazon-review", "metric": 0.93425, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-ml6team-cross-encoder-mmarco-german-distilbert-base", "modules": [{"role": "model", "module": {"name": "cross-encoder-mmarco-german-distilbert-base", "description": "A fine-tuned cross-encoder model on the MMARCO dataset using distilbert-base-multilingual-cased as the base model."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"base_model": "distilbert-base-multilingual-cased", "training_epochs": 1}}}, {"role": "taskType", "module": "sentence-similarity"}, {"role": "solutionSummary", "module": {"summary": "The cross-encoder model is fine-tuned on the MMARCO dataset using distilbert-base-multilingual-cased as the base model. The model takes a query and a paragraph as input and predicts a score indicating the similarity between the two. The model achieves an accuracy of 89.70% on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "ms-marco-microsoft-machine-reading-comprehension-dataset"}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-is-fi", "modules": [{"role": "model", "module": {"name": "opus-mt-is-fi", "description": "A machine translation model that translates from Icelandic to Finnish."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-is-fi is a machine translation model that translates from Icelandic to Finnish. It uses a transformer-align model and pre-processing techniques such as normalization and SentencePiece. The model achieves a BLEU score of 25.0 and a chr-F score of 0.489 on the JW300.is.fi test set."}}], "metrics": [{"dataset": "jw300", "metric": 25.0, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.489, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-gagan3012-k2t-base", "modules": [{"role": "model", "module": {"name": "keytotext", "description": "A model that takes keywords as inputs and generates sentences as outputs."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_type": "T5", "model_size": {"k2t": "unknown", "k2t-tiny": "unknown", "k2t-base": "unknown"}}}}, {"role": "taskType", "module": "text-generation"}, {"role": "solutionSummary", "module": {"summary": "Keytotext is a model that generates sentences from keywords. It is based on the T5 model and has three sizes: k2t, k2t-tiny, and k2t-base. The model is trained on WebNLG and Dart datasets. The model can be used through pip installation or a custom Streamlit component. However, the evaluation metrics are unknown."}}, {"role": "dataset", "purpose": "For model training.", "module": "dart"}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-neutralblaster-q-frozenlake-v1-8x8-no-slippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained model of a Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-8x8-no_slippery", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model's hyperparameters include the algorithm used, the environment, the maximum number of steps per episode, the number of episodes to evaluate the agent, the Q-Table learned by the agent, and the random seed used for evaluation. The model achieved a mean reward of 1.00 with no standard deviation."}}, {"role": "dataset", "purpose": "OpenAI Gym environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-skr1125-distilbert-base-uncased-distilled-clinc", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-distilled-clinc", "description": "A fine-tuned version of distilbert-base-uncased on the clinc_oos dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 48, "eval_batch_size": 48, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 10}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-distilled-clinc is a fine-tuned version of distilbert-base-uncased on the clinc_oos dataset. It is a text classification model that can be used to classify out-of-scope queries. The model achieved an accuracy of 0.9429 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler. The model was trained for 10 epochs with a batch size of 48."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "clinc-single-domain-oos"}], "metrics": [{"dataset": "clinc-single-domain-oos", "metric": 0.9429032258064516, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-impesalobo431-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. The model achieved an accuracy of 0.923 and an F1 score of 0.9232 on the evaluation set. The model is suitable for text classification tasks, but its intended uses and limitations are not specified in the model card."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emocontext"}], "metrics": [{"dataset": "emocontext", "metric": 0.923, "protocol": "accuracy"}, {"dataset": "emocontext", "metric": 0.923246780342909, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-gchhablani-wav2vec2-large-xlsr-cnh", "modules": [{"role": "model", "module": {"name": "Wav2Vec2-Large-XLSR-53-Hakha-Chin", "description": "Fine-tuned Wav2Vec2-Large-XLSR-53 on Hakha Chin using the Common Voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "Wav2Vec2-Large-XLSR-53", "batch_size": 8, "optimizer": {"name": "Adam", "learning_rate": 5e-05}}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Wav2Vec2-Large-XLSR-53-Hakha-Chin is a speech recognition model fine-tuned on the Common Voice dataset for Hakha Chin. The model can be used directly without a language model. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 31.38, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-johnheo1128-distilbert-base-uncased-finetuned-cola", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-cola", "description": "A fine-tuned version of distilbert-base-uncased on the glue dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-cola is a fine-tuned version of distilbert-base-uncased on the glue dataset. It is suitable for text classification tasks. The model achieved a Matthews Correlation score of 0.5478 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 16 for 5 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.5478, "protocol": "matthews_correlation"}], "source": "huggingface"}, {"id": "huggingface-mrm8488-bert-spanish-cased-finetuned-pos-syntax", "modules": [{"role": "model", "module": {"name": "Spanish BERT (BETO) + Syntax POS tagging", "description": "Fine-tuned version of the Spanish BERT on Spanish syntax annotations in CONLL CORPORA dataset for syntax POS (Part of Speech tagging) downstream task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "mrm8488/bert-spanish-cased-finetuned-pos-syntax", "tokenizer": "mrm8488/bert-spanish-cased-finetuned-pos-syntax"}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of the Spanish BERT on Spanish syntax annotations in CONLL CORPORA dataset for syntax POS (Part of Speech tagging) downstream task. The model achieved an F1 score of 89.27 on the test set. It can be used for POS tagging in Spanish text. The model is suitable for tasks that require syntax analysis of Spanish text."}}, {"role": "dataset", "purpose": "For model training.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 89.27, "protocol": "F1"}, {"dataset": "conll-2003", "metric": 89.44, "protocol": "Precision"}, {"dataset": "conll-2003", "metric": 89.11, "protocol": "Recall"}], "source": "huggingface"}, {"id": "huggingface-domluna-vit-base-patch16-224-in21k-shiba-inu-detector", "modules": [{"role": "model", "module": {"name": "vit-base-patch16-224-in21k-shiba-inu-detector", "description": "Fine-tuned version of google/vit-base-patch16-224-in21k on a dataset with 4 dog types including Shiba Inu."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 32, "eval_batch_size": 32, "seed": 42, "gradient_accumulation_steps": 4, "total_train_batch_size": 128, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "num_epochs": 20}}}, {"role": "taskType", "module": "object-detection"}, {"role": "solutionSummary", "module": {"summary": "vit-base-patch16-224-in21k-shiba-inu-detector is a fine-tuned version of google/vit-base-patch16-224-in21k on a dataset with 4 dog types including Shiba Inu. The model is best suited for object detection tasks. The model was trained using Adam optimizer with a learning rate of 5e-05 and a linear learning rate scheduler. The model was trained for 20 epochs with a batch size of 128. The model achieved a loss of 0.6511 and an accuracy of 1.0 on the evaluation set."}}, {"role": "dataset", "purpose": "For model pretraining.", "module": "wikipedia-title"}, {"role": "dataset", "purpose": "For fine-tuning.", "module": "dogc"}], "metrics": [{"dataset": "dogc", "metric": 0.6511, "protocol": "loss"}, {"dataset": "dogc", "metric": 1.0, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-vanhoan-bert-finetuned-ner", "modules": [{"role": "model", "module": {"name": "bert-finetuned-ner", "description": "A fine-tuned version of bert-base-cased on the conll2003 dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-finetuned-ner is a fine-tuned version of bert-base-cased on the conll2003 dataset for token classification. The model achieved high scores on the evaluation set, with a precision of 0.9326, recall of 0.9502, F1 of 0.9413, and accuracy of 0.9856. The model is suitable for named entity recognition tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 0.9326065411298315, "protocol": "precision"}, {"dataset": "conll-2003", "metric": 0.9501851228542578, "protocol": "recall"}, {"dataset": "conll-2003", "metric": 0.9413137712570858, "protocol": "f1"}, {"dataset": "conll-2003", "metric": 0.9856066403720493, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-misterneil-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8649 on the evaluation set. The model is suitable for token classification tasks in German language. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8648740833380706, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-mhf-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8621 on the evaluation set. The model is suitable for token classification tasks in German language. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.862053266560437, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-drishtisharma-wav2vec2-xls-r-300m-mt-o1", "modules": [{"role": "model", "module": {"name": "wav2vec2-xls-r-300m-mt-o1", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-300m on the MOZILLA-FOUNDATION/COMMON_VOICE_8_0 - MT dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 7e-05, "train_batch_size": 32, "eval_batch_size": 1, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 2000, "num_epochs": 100.0, "mixed_precision_training": true}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the MOZILLA-FOUNDATION/COMMON_VOICE_8_0 - MT dataset. The model is best suited for automatic speech recognition tasks. The model was trained with Adam optimizer with a learning rate of 7e-05 and a batch size of 32. The model was trained for 100 epochs with a linear learning rate scheduler and warmup steps of 2000. The model achieved a WER of 0.1920 on the Common Voice 8 test set. The model was trained using Transformers 4.17.0.dev0, Pytorch 1.10.2+cu102, Datasets 1.18.2.dev0, and Tokenizers 0.11.0."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.192, "protocol": "wer"}, {"dataset": "common-voice", "metric": 0.050364163712536256, "protocol": "cer"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-ar-fr", "modules": [{"role": "model", "module": {"name": "opus-mt-ar-fr", "description": "A transformer-align model for translating from Arabic to French."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-ar-fr model is a transformer-align model that translates from Arabic to French. It achieved a BLEU score of 43.5 and a chr-F score of 0.602 on the Tatoeba.ar.fr test set."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-nokomoro3-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8637 on the evaluation set. The model is suitable for token classification tasks in German language. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.863677639046538, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-kssteven-ibert-roberta-base", "modules": [{"role": "model", "module": {"name": "I-BERT base model", "description": "An integer-only quantized version of RoBERTa, which can result in up to 4x inference speed up compared to the floating-point counterpart."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"max_seq_length": 128, "per_device_train_batch_size": 32, "learning_rate": 1e-06, "num_train_epochs": 10}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "I-BERT is an integer-only quantized version of RoBERTa, which can result in up to 4x inference speed up compared to the floating-point counterpart. The model is intended to be fine-tuned on downstream tasks, such as text classification. The finetuning procedure consists of three stages: full-precision finetuning, model quantization, and integer-only finetuning. The model is suitable for integer-only deployment, and the best model parameters searched via quantization-aware finetuning can be exported for integer-only deployment of the model."}}, {"role": "dataset", "purpose": "For fine-tuning.", "module": "mrpc-microsoft-research-paraphrase-corpus"}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-angelag-roberta-checkpoint-finetuned-squad", "modules": [{"role": "model", "module": {"name": "roberta_checkpoint-finetuned-squad", "description": "A fine-tuned version of WillHeld/roberta-base-coqa on the squad dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of WillHeld/roberta-base-coqa on the squad dataset. It can be used for question answering tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for 3 epochs and achieved a loss of 0.8934 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 0.8934, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-sampras343-wav2vec2-base-ft-keyword-spotting", "modules": [{"role": "model", "module": {"name": "wav2vec2-base-ft-keyword-spotting", "description": "Fine-tuned version of facebook/wav2vec2-base on the superb dataset for keyword spotting."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 3e-05, "train_batch_size": 32, "eval_batch_size": 32, "seed": 0, "gradient_accumulation_steps": 4, "total_train_batch_size": 128, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "num_epochs": 5.0, "mixed_precision_training": true}}}, {"role": "taskType", "module": "audio-classification"}, {"role": "solutionSummary", "module": {"summary": "wav2vec2-base-ft-keyword-spotting is a fine-tuned version of facebook/wav2vec2-base on the superb dataset for keyword spotting. The model is best suited for audio classification tasks. The model was trained using Adam optimizer with a learning rate of 3e-05 and a batch size of 128. The model achieved an accuracy of 0.9810 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "speech-commands"}], "metrics": [{"dataset": "speech-commands", "metric": 0.0824, "split": "val", "protocol": "loss"}, {"dataset": "speech-commands", "metric": 0.0812, "split": "test", "protocol": "loss"}, {"dataset": "speech-commands", "metric": 0.9826, "split": "val", "protocol": "accuracy"}, {"dataset": "speech-commands", "metric": 0.981, "split": "test", "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-avneet-distilbert-base-uncased-finetuned-sst2", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-sst2", "description": "A fine-tuned version of distilbert-base-uncased on the glue dataset for text classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-sst2 is a fine-tuned version of distilbert-base-uncased on the glue dataset for text classification. The model achieved an accuracy of 0.9151 on the evaluation set. The model is suitable for text classification tasks, but its performance may vary depending on the specific task and dataset. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.9151376146788991, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-facebook-blenderbot-1b-distill", "modules": [{"role": "model", "module": {"name": "Open-domain chatbot", "description": "A large-scale neural model trained on blended_skill_talk dataset to generate engaging and human-like conversations."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_size": ["90M", "2.7B", "9.4B"], "generation_strategy": "Choice of generation strategy"}}}, {"role": "taskType", "module": "conversational"}, {"role": "solutionSummary", "module": {"summary": "This model is an open-domain chatbot that uses large-scale neural models to generate engaging and human-like conversations. The model was trained on the blended_skill_talk dataset and evaluated using perplexity. The model outperforms existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. However, the model has limitations, and failure cases were analyzed to understand its limitations."}}, {"role": "dataset", "purpose": "For model training.", "module": "blended-skill-talk"}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-nielsr-vit-base-patch16-224-in21k-finetuned-cifar10", "modules": [{"role": "model", "module": {"name": "vit-base-patch16-224-in21k-finetuned-cifar10", "description": "A fine-tuned version of google/vit-base-patch16-224-in21k on the image_folder dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 32, "eval_batch_size": 32, "seed": 42, "gradient_accumulation_steps": 4, "total_train_batch_size": 128, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "num_epochs": 3}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of google/vit-base-patch16-224-in21k on the image_folder dataset. The model achieves an accuracy of 0.9881 on the evaluation set. More information is needed to describe the model and its intended uses and limitations."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "objectfolder"}], "metrics": [{"dataset": "objectfolder", "metric": 0.9881481481481481, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-ru-sl", "modules": [{"role": "model", "module": {"name": "rus-slv", "description": "A transformer model for translating from Russian to Slovenian."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece (spm32k,spm32k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "rus-slv is a transformer model trained on a parallel corpus of Russian and Slovenian sentences. It uses normalization and SentencePiece tokenization with a vocabulary size of 32k. The model achieved a BLEU score of 32.3 and a chrF2 score of 0.492 on the Tatoeba-test.rus.slv dataset. The model is intended for translating from Russian to Slovenian."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "tatoeba"}], "metrics": [{"dataset": "tatoeba", "metric": 32.3, "protocol": "BLEU"}, {"dataset": "tatoeba", "metric": 0.492, "protocol": "chrF2"}], "source": "huggingface"}, {"id": "huggingface-ralphx1-q-frozenlake-v1-4x4-noslippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-4x4-no_slippery", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model's hyperparameters include the algorithm used, the environment, the maximum number of steps per episode, the number of episodes to evaluate the agent, the Q-Table learned by the agent, and the random seed used for evaluation. The model achieved a mean reward of 1.0 with no standard deviation."}}, {"role": "dataset", "purpose": "Environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-aleksandar-electra-srb-ner", "modules": [{"role": "model", "module": {"name": "electra-srb-ner", "description": "A model trained on the wikiann dataset for named entity recognition (NER) in Serbian language."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 32, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 20}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "electra-srb-ner is a model trained on the wikiann dataset for named entity recognition (NER) in Serbian language. The model was trained using the Electra architecture and achieved an accuracy of 0.9568 on the evaluation set. The model was trained for 20 epochs with a batch size of 32 and a learning rate of 2e-05. The model was trained using the Adam optimizer with betas=(0.9,0.999) and epsilon=1e-08. The model was evaluated using the Precision, Recall, and F1 metrics."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wikiann"}], "metrics": [{"dataset": "wikiann", "metric": 0.9568394937134688, "protocol": "Accuracy"}, {"dataset": "wikiann", "metric": 0.8934, "protocol": "Precision"}, {"dataset": "wikiann", "metric": 0.9087, "protocol": "Recall"}, {"dataset": "wikiann", "metric": 0.901, "protocol": "F1"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-sv-sk", "modules": [{"role": "model", "module": {"name": "opus-mt-sv-sk", "description": "A machine translation model that translates from Swedish (sv) to Slovak (sk) using the transformer-align architecture."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-sv-sk is a machine translation model that translates from Swedish to Slovak. It uses the transformer-align architecture and was preprocessed using normalization and SentencePiece. The model achieved a BLEU score of 30.7 and a chr-F score of 0.516 on the JW300.sv.sk test set."}}], "metrics": [{"dataset": "jw300", "metric": 30.7, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.516, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-nielsr-lilt-roberta-en-base-finetuned-funsd", "modules": [{"role": "model", "module": {"name": "lilt-roberta-en-base-finetuned-funsd", "description": "Fine-tuned version of nielsr/lilt-roberta-en-base on the funsd-layoutlmv3 dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 0.1, "training_steps": 2000}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "lilt-roberta-en-base-finetuned-funsd is a fine-tuned version of nielsr/lilt-roberta-en-base on the funsd-layoutlmv3 dataset for token classification. The model achieved a Precision of 0.8762, Recall of 0.8857, F1 of 0.8809, and Accuracy of 0.8068 on the evaluation set. The model is suitable for token classification tasks, but caution should be taken when deploying it in human-interacting systems as it reflects the biases of the systems it was trained on."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "funsd-form-understanding-in-noisy-scanned-documents"}], "metrics": [{"dataset": "funsd-form-understanding-in-noisy-scanned-documents", "metric": 0.8761670761670761, "protocol": "precision"}, {"dataset": "funsd-form-understanding-in-noisy-scanned-documents", "metric": 0.8857426726279185, "protocol": "recall"}, {"dataset": "funsd-form-understanding-in-noisy-scanned-documents", "metric": 0.8809288537549407, "protocol": "f1"}, {"dataset": "funsd-form-understanding-in-noisy-scanned-documents", "metric": 0.8068465470105789, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-dragonswing-wav2vec2-base-vietnamese", "modules": [{"role": "model", "module": {"name": "Wav2vec2 Base Vietnamese", "description": "Fine-tuned Wav2vec2 on Vietnamese Speech Recognition task using 100h labelled data from VSLP dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_name": "dragonSwing/wav2vec2-base-vietnamese", "batch_size": 1, "resample_rate": 16000}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Wav2vec2 Base Vietnamese is a speech recognition model fine-tuned on 100 hours of labelled data from the VSLP dataset. The model is based on Wav2vec2 and can be used directly without a language model. The model is best suited for speech recognition tasks in Vietnamese. The model was evaluated on the Common Voice vi dataset and achieved a WER of 31.35%."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 31.353591, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-baxterai-finetuning-sentiment-model-3000-samples", "modules": [{"role": "model", "module": {"name": "finetuning-sentiment-model-3000-samples", "description": "A fine-tuned version of distilbert-base-uncased on the amazon_polarity dataset for sentiment analysis."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 3e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 20}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of distilbert-base-uncased on the amazon_polarity dataset for sentiment analysis. It achieves an accuracy of 0.9225 and an F1 score of 0.9241 on the evaluation set. The model is suitable for text classification tasks, but its performance may vary depending on the specific use case and data distribution."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "amazon-review"}], "metrics": [{"dataset": "amazon-review", "metric": 0.9225, "protocol": "accuracy"}, {"dataset": "amazon-review", "metric": 0.9240816326530612, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-patrickvonplaten-sew-d-small-100k-ft-timit", "modules": [{"role": "model", "module": {"name": "sew-d-small-100k-ft-timit", "description": "Fine-tuned version of asapp/sew-d-small-100k on the TIMIT_ASR - NA dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0001, "train_batch_size": 32, "eval_batch_size": 1, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 1000, "num_epochs": 20.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "sew-d-small-100k-ft-timit is a fine-tuned version of asapp/sew-d-small-100k on the TIMIT_ASR - NA dataset. The model is intended for automatic speech recognition tasks. The model achieved a loss of 1.7482 and a WER of 0.7987 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 0.0001 and a batch size of 32. The model was trained for 20 epochs with a linear learning rate scheduler and mixed precision training. The model was trained using Transformers 4.12.0.dev0, Pytorch 1.8.1, Datasets 1.14.1.dev0, and Tokenizers 0.10.3."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "timit-timit-acoustic-phonetic-continuous-speech-corpus"}], "metrics": [{"dataset": "timit-timit-acoustic-phonetic-continuous-speech-corpus", "metric": 1.7482, "protocol": "loss"}, {"dataset": "timit-timit-acoustic-phonetic-continuous-speech-corpus", "metric": 0.7987, "protocol": "WER"}], "source": "huggingface"}, {"id": "huggingface-bhuang-wav2vec2-xls-r-1b-cv9-fr", "modules": [{"role": "model", "module": {"name": "Fine-tuned Wav2Vec2 XLS-R 1B model for ASR in French", "description": "A fine-tuned version of facebook/wav2vec2-xls-r-1b on the MOZILLA-FOUNDATION/COMMON_VOICE_9_0 - FR dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_id": "bhuang/wav2vec2-xls-r-1b-cv9-fr", "sampling_rate": 16000, "chunk_length_s": 5.0, "stride_length_s": 1.0}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/wav2vec2-xls-r-1b on the MOZILLA-FOUNDATION/COMMON_VOICE_9_0 - FR dataset. The model can be used for automatic speech recognition tasks in French. The model can be used with or without a language model. The model was evaluated on the Common Voice 9 and Robust Speech Event - Dev Data datasets, achieving a WER of 12.72 and 24.28, respectively, without a language model, and 10.60 and 20.85, respectively, with a language model."}}], "metrics": [{"dataset": "common-voice", "metric": 12.72, "protocol": "Test WER"}, {"dataset": "common-voice", "metric": 10.6, "protocol": "Test WER (+LM)"}], "source": "huggingface"}, {"id": "huggingface-ensaremirali-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. The model is best suited for text classification tasks. The model achieved an accuracy of 0.9265 and an F1 score of 0.9269 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.9265, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.9268984054036417, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-bhadresh-savani-roberta-base-emotion", "modules": [{"role": "model", "module": {"name": "roberta-base-emotion", "description": "A fine-tuned RoBERTa model on the Twitter-Sentiment-Analysis dataset for emotion classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "roberta-base", "learning_rate": 2e-05, "batch_size": 64, "num_train_epochs": 8}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "The roberta-base-emotion model is a fine-tuned RoBERTa model on the Twitter-Sentiment-Analysis dataset for emotion classification. The model was trained using a learning rate of 2e-5, batch size of 64, and 8 epochs. The model achieved an accuracy of 0.9395 and an F1 score of 0.9397328860104454 on the test set. The model can be used for emotion classification tasks on text data."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "twitter-sentiment-analysis-entity-level-twitter-sentiment-analysis-dataset"}], "metrics": [{"dataset": "twitter-sentiment-analysis-entity-level-twitter-sentiment-analysis-dataset", "metric": 0.9395, "protocol": "Accuracy"}, {"dataset": "twitter-sentiment-analysis-entity-level-twitter-sentiment-analysis-dataset", "metric": 0.9397328860104454, "protocol": "F1 Score"}], "source": "huggingface"}, {"id": "huggingface-keithanpai-vit-base-patch32-384-finetuned-eurosat", "modules": [{"role": "model", "module": {"name": "vit-base-patch32-384-finetuned-eurosat", "description": "A fine-tuned version of google/vit-base-patch32-384 on the imagefolder dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 32, "eval_batch_size": 32, "seed": 42, "gradient_accumulation_steps": 4, "total_train_batch_size": 128, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "num_epochs": 3}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of google/vit-base-patch32-384 on the imagefolder dataset. The model achieves an accuracy of 0.8423 on the evaluation set. The model is suitable for image classification tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "objectfolder"}], "metrics": [{"dataset": "objectfolder", "metric": 0.8423, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-liangy2-vit-base-beans", "modules": [{"role": "model", "module": {"name": "vit-base-beans", "description": "A fine-tuned version of google/vit-base-patch16-224-in21k on the beans dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "seed": 1337, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5.0}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "vit-base-beans is a fine-tuned version of google/vit-base-patch16-224-in21k on the beans dataset. It is a transformer model that can be used for image classification tasks. The model achieved an accuracy of 0.9850 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler. The model was trained for 5 epochs with a batch size of 8."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "plantvillage"}], "metrics": [{"dataset": "plantvillage", "metric": 0.9849624060150376, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-asapp-sew-tiny-100k-ft-ls100h", "modules": [{"role": "model", "module": {"name": "SEW-tiny", "description": "SEW-tiny is a pre-trained model architecture for automatic speech recognition (ASR) that improves both performance and efficiency dimensions across a variety of training setups."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"sampling_rate": 16000, "batch_size": 1, "padding": "longest"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "SEW-tiny is a pre-trained model architecture for automatic speech recognition (ASR) that improves both performance and efficiency dimensions across a variety of training setups. The model is intended to be fine-tuned on a downstream task, such as Automatic Speech Recognition, Speaker Identification, Intent Classification, Emotion Recognition, etc. The model is trained on the LibriSpeech dataset and evaluated on the clean and other test sets. The model can be used as a standalone acoustic model for transcribing audio files."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "librispeech"}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-federicopascual-finetune-sentiment-analysis-model-3000-samples", "modules": [{"role": "model", "module": {"name": "finetune-sentiment-analysis-model-3000-samples", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis. It achieves an accuracy of 0.8867 and an F1 score of 0.8944 on the evaluation set. The model is suitable for text classification tasks, but its intended uses and limitations are not specified in the model card."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.8866666666666667, "protocol": "accuracy"}, {"dataset": "imdb-movie-reviews", "metric": 0.8944099378881988, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-rajsang-pegasus-sports-titles", "modules": [{"role": "model", "module": {"name": "pegasus-sports-titles", "description": "A Pegasus model fine-tuned on generating sports article titles."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 2, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 8, "total_train_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 100, "num_epochs": 2}}}, {"role": "taskType", "module": "text-generation"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned Pegasus model on sports news articles scraped from the internet. It can generate titles for sports articles related to Tennis, Football (Soccer), Cricket, Athletics, and Rugby. The model is intended to be used for generating titles for sports articles and is not suitable for other tasks such as text summarization. The model was fine-tuned using the Pegasus model architecture and the hyperparameters used during training are provided. The model achieved good Rouge scores during training."}}, {"role": "dataset", "purpose": "Sports news articles scraped from the internet.", "module": "k-sportssum"}], "metrics": [{"dataset": "k-sportssum", "metric": 38.2315, "protocol": "Rouge1"}, {"dataset": "k-sportssum", "metric": 18.6598, "protocol": "Rouge2"}, {"dataset": "k-sportssum", "metric": 31.7393, "protocol": "RougeL"}, {"dataset": "k-sportssum", "metric": 31.7086, "protocol": "RougeLsum"}], "source": "huggingface"}, {"id": "huggingface-abdulmatinomotoso-paraphrase-detector", "modules": [{"role": "model", "module": {"name": "paraphrase_detector", "description": "A fine-tuned version of bert-base-uncased on the glue dataset for text classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "paraphrase_detector is a fine-tuned version of bert-base-uncased on the glue dataset for text classification. It achieves an accuracy of 0.8554 and an F1 score of 0.8985 on the evaluation set. The model is suitable for tasks such as paraphrase detection, but caution should be taken when deploying it in human-interacting systems as it reflects the biases of the systems it was trained on."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.8553921568627451, "protocol": "accuracy"}, {"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.8984509466437176, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-hackathon-pln-es-biomedtra-small-es-squad2-es", "modules": [{"role": "model", "module": {"name": "biomedtra-small for QA", "description": "A fine-tuned version of mrm8488/biomedtra-small-es on the squad_es (v2) training dataset for extractive Question Answering models for Biomedicine."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"num_train_epochs": 10, "learning_rate": 0.0001, "max_seq_length": 384, "doc_stride": 128}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "biomedtra-small for QA is a fine-tuned version of mrm8488/biomedtra-small-es on the squad_es (v2) training dataset for extractive Question Answering models for Biomedicine. The model was trained during the 2022 Hackathon organized by SOMOS NLP. The model is suitable for extractive QA tasks in the biomedical domain in Spanish language. The model's performance is lower than other models trained during the hackathon, but it can be improved with further fine-tuning."}}, {"role": "dataset", "purpose": "For pretraining.", "module": "squad-stanford-question-answering-dataset"}, {"role": "dataset", "purpose": "For evaluation.", "module": "bioasq-biomedical-semantic-indexing-and-question-answering"}], "metrics": [{"dataset": "bioasq-biomedical-semantic-indexing-and-question-answering", "metric": 44.3294, "protocol": "f1"}, {"dataset": "bioasq-biomedical-semantic-indexing-and-question-answering", "metric": 34.4767, "protocol": "exact"}], "source": "huggingface"}, {"id": "huggingface-jonatasgrosman-wav2vec2-large-xlsr-53-english", "modules": [{"role": "model", "module": {"name": "Fine-tuned XLSR-53 large model for speech recognition in English", "description": "Fine-tuned facebook/wav2vec2-large-xlsr-53 on English using the train and validation splits of Common Voice 6.1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_id": "jonatasgrosman/wav2vec2-large-xlsr-53-english", "sampling_rate": 16000}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned XLSR-53 large model for speech recognition in English. The model was fine-tuned on the train and validation splits of Common Voice 6.1. The model can be used directly for speech recognition without a language model. The model is suitable for tasks such as sequence classification, token classification, or question answering. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 19.06, "protocol": "WER"}, {"dataset": "common-voice", "metric": 14.81, "protocol": "WER"}, {"dataset": "common-voice", "metric": 7.69, "protocol": "CER"}, {"dataset": "common-voice", "metric": 6.84, "protocol": "CER"}], "source": "huggingface"}, {"id": "huggingface-marcel-wav2vec2-large-xlsr-german-demo", "modules": [{"role": "model", "module": {"name": "Wav2Vec2-Large-XLSR-53-German", "description": "Fine-tuned facebook/wav2vec2-large-xlsr-53 on German using 3% of the Common Voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"pretrained_model": "facebook/wav2vec2-large-xlsr-53", "batch_size": 8, "optimizer": {"name": "Adam", "learning_rate": 0.0001, "beta1": 0.9, "beta2": 0.98, "weight_decay": 0.01}, "training_data": {"name": "Common Voice", "percentage_used": "3%"}}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Wav2Vec2-Large-XLSR-53-German is a speech recognition model fine-tuned on German using 3% of the Common Voice dataset. The model is intended to be used for speech recognition tasks and can be used directly without a language model. The model was trained using the Adam optimizer with a learning rate of 1e-4 and a weight decay of 0.01. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 29.35, "protocol": "WER"}], "source": "huggingface"}, {"id": "huggingface-chris1-ppo-carracing-v0", "modules": [{"role": "model", "module": {"name": "PPO", "description": "A trained PPO agent playing CarRacing-v0 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 128, "clip_range": 0.2, "ent_coef": 0.0, "frame_stack": 2, "gae_lambda": 0.95, "gamma": 0.99, "learning_rate": "lin_1e-4", "max_grad_norm": 0.5, "n_envs": 8, "n_epochs": 10, "n_steps": 512, "n_timesteps": 4000000.0, "normalize": "{'norm_obs': False, 'norm_reward': True}", "policy": "CnnPolicy", "policy_kwargs": "dict(log_std_init=-2, ortho_init=False, activation_fn=nn.GELU, net_arch=[dict(pi=[256], vf=[256])], )", "sde_sample_freq": 4, "use_sde": true, "vf_coef": 0.5, "normalize_kwargs": {"norm_obs": false, "norm_reward": false}}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained PPO agent playing CarRacing-v0 using the stable-baselines3 library and the RL Zoo. The model was trained with a batch size of 128, a clip range of 0.2, and a gamma of 0.99. The model achieved a mean reward of 205.45 with a standard deviation of 120.65 on the CarRacing-v0 dataset. The hyperparameters used for training are provided in the model card."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 205.45, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-sebis-code-trans-t5-large-code-comment-generation-java-multitask", "modules": [{"role": "model", "module": {"name": "CodeTrans model for code comment generation java", "description": "Pretrained model on programming language java using the t5 large model architecture."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_architecture": "t5-large", "sequence_length": 512, "optimizer": {"name": "AdaFactor", "learning_rate_schedule": "inverse square root"}}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "CodeTrans is a transformer model pre-trained on a large corpus of Java code functions. It can be used to generate descriptions for Java functions or be fine-tuned on other Java code tasks. The model is best suited for tokenized Java code functions. The model was trained using the encoder-decoder architecture and multi-task training on 13 supervised tasks in the software development domain and 7 unsupervised datasets. The model achieved state-of-the-art performance on the code documentation task for Java programming language."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-romainlhardy-roberta-large-finetuned-ner", "modules": [{"role": "model", "module": {"name": "roberta-large-finetuned-ner", "description": "A fine-tuned version of roberta-large on the conll2003 dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "roberta-large-finetuned-ner is a fine-tuned version of roberta-large on the conll2003 dataset for token classification. The model achieved high precision, recall, F1 score, and accuracy on the evaluation set. The model is suitable for named entity recognition tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 0.9476811355009077, "protocol": "precision"}, {"dataset": "conll-2003", "metric": 0.9663412992258499, "protocol": "recall"}, {"dataset": "conll-2003", "metric": 0.9569202566452795, "protocol": "f1"}, {"dataset": "conll-2003", "metric": 0.990656929827253, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-squirro-distilroberta-base-squad-v2", "modules": [{"role": "model", "module": {"name": "distilroberta-base-squad_v2", "description": "Fine-tuned model on the SQuAD2.0 dataset for extractive question answering."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 64, "eval_batch_size": 8, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "distilroberta-base-squad_v2 is a fine-tuned model on the SQuAD2.0 dataset for extractive question answering. It can handle mismatched question-context pairs and is suitable for tasks that require answering questions based on a given context. The model is prepared to be used with PyTorch, TensorFlow, and ONNX frameworks. The model was trained on BookCorpus and English Wikipedia and fine-tuned with a batch size of 64, learning rate of 5e-05, and 3 epochs. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 65.2405, "protocol": "eval_exact"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 68.6265, "protocol": "eval_f1"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 67.5776, "protocol": "eval_HasAns_exact"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 74.3594, "protocol": "eval_HasAns_f1"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 62.91, "protocol": "eval_NoAns_exact"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 62.91, "protocol": "eval_NoAns_f1"}], "source": "huggingface"}, {"id": "huggingface-flood-pegasus-samsum", "modules": [{"role": "model", "module": {"name": "pegasus-samsum", "description": "A fine-tuned version of google/pegasus-cnn_dailymail on the samsum dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 1, "eval_batch_size": 1, "seed": 42, "gradient_accumulation_steps": 16, "total_train_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 1}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "pegasus-samsum is a fine-tuned version of google/pegasus-cnn_dailymail on the samsum dataset. It is a model for text summarization tasks. The model was trained with Adam optimizer with a learning rate of 5e-05 and a linear learning rate scheduler with 500 warmup steps. The model achieved a loss of 1.4814 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "samsum-corpus"}], "metrics": [{"dataset": "samsum-corpus", "metric": 1.4814, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-sun1638650145-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 environment."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "is_slippery": "whether the environment is slippery or not"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a Q-Learning agent trained to play the Taxi-v3 environment. The model achieved a mean reward of 7.54 +/- 2.73. The model can be loaded from the Hugging Face model hub and used to play the game or fine-tuned for other reinforcement learning tasks."}}, {"role": "dataset", "purpose": "OpenAI Gym environment", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.54, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-tyqiangz-indobert-lite-large-p2-smsa", "modules": [{"role": "model", "module": {"name": "IndoBERT-Lite Large Model (phase2 - uncased) Finetuned on IndoNLU SmSA dataset", "description": "A finetuned version of IndoBERT-Lite Large Model (phase2 - uncased) on IndoNLU SmSA dataset for text classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "batch_size": 16, "epochs": 5, "max_seq_length": 512, "random_seed": 42}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "IndoBERT-Lite Large Model (phase2 - uncased) is a transformer model pretrained on Indo4B dataset and finetuned on IndoNLU SmSA dataset for text classification task. The model is best suited for text classification tasks in Indonesian language. The model achieved a validation accuracy of 0.94 and F1 score of 0.91 on the SmSA validation dataset."}}, {"role": "dataset", "purpose": "Pretraining dataset.", "module": "indonlu-benchmark"}, {"role": "dataset", "purpose": "Dataset used for finetuning.", "module": "indonli"}], "metrics": [{"dataset": "indonli", "metric": 0.94, "protocol": "Validation accuracy"}, {"dataset": "indonli", "metric": 0.91, "protocol": "Validation F1"}, {"dataset": "indonli", "metric": 0.91, "protocol": "Validation Recall"}, {"dataset": "indonli", "metric": 0.93, "protocol": "Validation Precision"}], "source": "huggingface"}, {"id": "huggingface-softcatala-opennmt-deu-cat", "modules": [{"role": "model", "module": {"name": "German-Catalan Translation Model", "description": "A translation model for OpenNMT that translates German to Catalan."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"tokenizer": "pyonmttok", "model_directory": "softcatala/opennmt-deu-cat", "revision": "main", "quantization": "yes"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "This is a German-Catalan translation model for OpenNMT. The model is quantified for low latency and has been evaluated on two datasets. The model directory can be found on GitHub, along with additional information and resources."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-rmc2-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. The model is best suited for text classification tasks. The model achieved an accuracy of 0.9235 and an F1 score of 0.9237 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.9235, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.9236875354311616, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-research-backup-t5-small-tweetqa-qag-np", "modules": [{"role": "model", "module": {"name": "research-backup/t5-small-tweetqa-qag-np", "description": "Fine-tuned version of t5-small for question & answer pair generation task on the lmqg/qag_tweetqa dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "t5-small", "max_length": 256, "max_length_output": 128, "epoch": 16, "batch": 64, "lr": 0.0001, "fp16": false, "random_seed": 1, "gradient_accumulation_steps": 1, "label_smoothing": 0.15}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of t5-small for question & answer pair generation task on the lmqg/qag_tweetqa dataset. The model is best suited for generating question and answer pairs from a given paragraph. The model was trained with a batch size of 64, a learning rate of 0.0001, and a label smoothing of 0.15. The model achieved good scores on various metrics such as BLEU4, ROUGE-L, METEOR, BERTScore, and MoverScore."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "tweetqa"}], "metrics": [{"dataset": "tweetqa", "metric": 10.71, "protocol": "bleu4"}, {"dataset": "tweetqa", "metric": 27.8, "protocol": "meteor"}, {"dataset": "tweetqa", "metric": 34.77, "protocol": "rouge-l"}, {"dataset": "tweetqa", "metric": 89.48, "protocol": "bertscore"}, {"dataset": "tweetqa", "metric": 60.53, "protocol": "moverscore"}], "source": "huggingface"}, {"id": "huggingface-devetle-dqn-spaceinvadersnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "DQN Agent playing SpaceInvadersNoFrameskip-v4", "description": "A trained DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "buffer_size": 100000, "exploration_final_eps": 0.01, "exploration_fraction": 0.1, "frame_stack": 4, "gradient_steps": 1, "learning_rate": 0.0001, "learning_starts": 100000, "n_timesteps": 1800000.0, "optimize_memory_usage": true, "policy": "CnnPolicy", "target_update_interval": 1000, "train_freq": 4, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The model was trained with a batch size of 32, a buffer size of 100000, and a learning rate of 0.0001. The model achieved a mean reward of 622.00 +/- 131.55 on the SpaceInvadersNoFrameskip-v4 dataset. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 622.0, "split": "val", "protocol": "mean_reward"}, {"dataset": "atari-grand-challenge", "metric": 131.55, "split": "test", "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-husnu-bert-base-turkish-128k-cased-finetuned-lr-2e-05-epochs-3tquad2-finetuned-lr-2e-05-epochs-1", "modules": [{"role": "model", "module": {"name": "bert-base-turkish-128k-cased-finetuned_lr-2e-05_epochs-3TQUAD2-finetuned_lr-2e-05_epochs-1", "description": "Fine-tuned version of husnu/bert-base-turkish-128k-cased-finetuned_lr-2e-05_epochs-3 on the SQuAD dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of husnu/bert-base-turkish-128k-cased-finetuned_lr-2e-05_epochs-3 on the SQuAD dataset. The model is intended for question-answering tasks in Turkish. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 8. The model achieved a loss of 1.4196 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 1.4196, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-fofoforever-distilbert-base-uncased-finetuned-imdb", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-imdb", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-imdb is a fine-tuned version of distilbert-base-uncased on the imdb dataset. It can be used for text classification tasks. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64. The model was trained for 3 epochs and achieved a loss of 2.4724 on the evaluation set. The model was trained using Transformers 4.24.0, Pytorch 1.12.1+cu102, Datasets 2.3.2, and Tokenizers 0.12.1."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 2.4724, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-jozaita-q-frozenlake-v1-4x4-noslippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained model of a Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-4x4-no_slippery", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model's hyperparameters include the algorithm used, the environment, the maximum number of steps per episode, the number of episodes to evaluate the agent, the Q-table learned by the agent, and the random seed used for evaluation. The model achieved a mean reward of 1.00 with no standard deviation."}}, {"role": "dataset", "purpose": "Environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-ssarim-distilbert-base-uncased-finetuned-squad", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-squad", "description": "A fine-tuned version of distilbert-base-uncased on the squad dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-squad is a fine-tuned version of distilbert-base-uncased on the squad dataset. It is suitable for question answering tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler. The model was trained for 3 epochs with a batch size of 16. The model achieved a loss of 1.1563 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 1.1563, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-deepset-electra-base-squad2", "modules": [{"role": "model", "module": {"name": "deepset/electra-base-squad2", "description": "Pretrained model on English language using a masked language modeling (MLM) objective."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "n_epochs": 5, "base_LM_model": "google/electra-base-discriminator", "max_seq_len": 384, "learning_rate": 0.0001, "lr_schedule": "LinearWarmup", "warmup_proportion": 0.1, "doc_stride": 128, "max_query_length": 64}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "The deepset/electra-base-squad2 model is a transformer model pre-trained on a large English corpus using a masked language modeling (MLM) objective. It is fine-tuned on the SQuAD 2.0 dataset for extractive question answering. The model is suitable for tasks that require answering questions based on a given context. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 77.6074, "protocol": "exact"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 81.7181, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-ferro-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8649 on the evaluation set. The model is suitable for token classification tasks in German language. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8648740833380706, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-lijingxin-pegasus-samsum", "modules": [{"role": "model", "module": {"name": "pegasus-samsum", "description": "A fine-tuned version of google/pegasus-cnn_dailymail on the samsum dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 1, "eval_batch_size": 1, "seed": 42, "gradient_accumulation_steps": 16, "total_train_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 1}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "pegasus-samsum is a fine-tuned version of google/pegasus-cnn_dailymail on the samsum dataset. It is a model for text summarization tasks. The model was trained with Adam optimizer with a learning rate of 5e-05 and a linear learning rate scheduler with 500 warmup steps. The model achieved a loss of 1.4874 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "samsum-corpus"}], "metrics": [{"dataset": "samsum-corpus", "metric": 1.4874, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-nateraw-vit-base-beans-demo-v3", "modules": [{"role": "model", "module": {"name": "vit-base-beans-demo-v3", "description": "A fine-tuned version of google/vit-base-patch16-224-in21k on the beans dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0002, "train_batch_size": 16, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "vit-base-beans-demo-v3 is a fine-tuned version of google/vit-base-patch16-224-in21k on the beans dataset. The model achieved an accuracy of 0.9849 on the evaluation set. More information is needed to describe the model and its intended uses and limitations."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "plantvillage"}], "metrics": [{"dataset": "plantvillage", "metric": 0.9849624060150376, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-faisito-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8596 on the evaluation set. The model is suitable for token classification tasks in German language. The training was done using Adam optimizer with a learning rate of 5e-05 and a batch size of 24. The model was trained for 3 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8596481238968285, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-meshalalamr-wav2vec2-xls-r-300m-ar-7", "modules": [{"role": "model", "module": {"name": "wav2vec2-xls-r-300m-ar-7", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0003, "train_batch_size": 64, "eval_batch_size": 16, "seed": 42, "gradient_accumulation_steps": 4, "total_train_batch_size": 256, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 30, "mixed_precision_training": true}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "wav2vec2-xls-r-300m-ar-7 is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset. It is suitable for automatic speech recognition tasks. The model was trained using PyTorch and Transformers 4.17.0. The model was trained for 30 epochs with a learning rate of 0.0003 and an Adam optimizer with betas=(0.9,0.999) and epsilon=1e-08. The model achieved a WER of 0.2222 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 146.3602, "split": "val", "protocol": "loss"}, {"dataset": "common-voice", "metric": 61.6652, "split": "test", "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.2222, "protocol": "WER"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-es-vi", "modules": [{"role": "model", "module": {"name": "spa-vie", "description": "A transformer model for translating from Spanish to Vietnamese."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece (spm32k,spm32k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "spa-vie is a transformer model trained on Spanish to Vietnamese translation task. The model was trained on the Tatoeba dataset and achieved a BLEU score of 33.1 and a chrF2 score of 0.508 on the test set. The model uses normalization and SentencePiece (spm32k,spm32k) for preprocessing. The model is suitable for translating from Spanish to Vietnamese."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "tatoeba"}], "metrics": [{"dataset": "tatoeba", "metric": 33.1, "protocol": "BLEU"}, {"dataset": "tatoeba", "metric": 0.508, "protocol": "chrF2"}], "source": "huggingface"}, {"id": "huggingface-team-nave-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 512, "eval_batch_size": 512, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. It can be used for text classification tasks. The model achieved an accuracy of 0.7825 and an F1 score of 0.7271 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 512 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.7825, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.7271498598233012, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-sasha-autotrain-bertbase-imdb-1275748791", "modules": [{"role": "model", "module": {"name": "AutoTrain BERT Base model for binary classification", "description": "A BERT Base model trained using AutoTrain for binary classification on the IMDB dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_id": 1275748791, "pretrained_model": "bert-base-uncased", "problem_type": "binary classification"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a BERT Base model trained using AutoTrain for binary classification on the IMDB dataset. The model achieved an accuracy of 0.876 and an AUC of 0.953 on the validation set. The model can be accessed through cURL or Python API."}}, {"role": "dataset", "purpose": "Used for model training and validation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.283, "protocol": "loss"}, {"dataset": "imdb-movie-reviews", "metric": 0.876, "protocol": "accuracy"}, {"dataset": "imdb-movie-reviews", "metric": 0.844, "protocol": "precision"}, {"dataset": "imdb-movie-reviews", "metric": 0.923, "protocol": "recall"}, {"dataset": "imdb-movie-reviews", "metric": 0.953, "protocol": "auc"}, {"dataset": "imdb-movie-reviews", "metric": 0.882, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-vumichien-trillsson3-ft-keyword-spotting-15", "modules": [{"role": "model", "module": {"name": "trillsson3-ft-keyword-spotting-15", "description": "Fine-tuned version of vumichien/nonsemantic-speech-trillsson3 on the superb dataset for keyword spotting."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0003, "train_batch_size": 32, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "num_epochs": 10.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "audio-classification"}, {"role": "solutionSummary", "module": {"summary": "trillsson3-ft-keyword-spotting-15 is a fine-tuned version of vumichien/nonsemantic-speech-trillsson3 on the superb dataset for keyword spotting. The model achieved an accuracy of 0.9041 on the evaluation set. The model is suitable for keyword spotting tasks in audio classification. The training was done using Adam optimizer with a learning rate of 0.0003 and a linear learning rate scheduler with a warmup ratio of 0.1. The model was trained for 10 epochs with mixed precision training."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "slurp-spoken-language-understanding-resource-package"}], "metrics": [{"dataset": "slurp-spoken-language-understanding-resource-package", "metric": 0.9041, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-monaa-glue-sst-classifier-2", "modules": [{"role": "model", "module": {"name": "glue_sst_classifier_2", "description": "A fine-tuned version of bert-base-cased on the glue dataset for text classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-05, "train_batch_size": 128, "eval_batch_size": 128, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "num_epochs": 1.0}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "glue_sst_classifier_2 is a fine-tuned version of bert-base-cased on the glue dataset for text classification. The model achieved an F1 score of 0.9034 and an accuracy of 0.9014 on the evaluation set. The model is suitable for text classification tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.9033707865168539, "protocol": "f1"}, {"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.9013761467889908, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-taekyoon-komrc-train", "modules": [{"role": "model", "module": {"name": "komrc_train", "description": "Fine-tuned version of beomi/kcbert-base on the korquad dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3, "mixed_precision_training": true}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "komrc_train is a fine-tuned version of beomi/kcbert-base on the korquad dataset. It is a question-answering model that can be used to answer questions in Korean. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for 3 epochs and achieved a loss of 0.6544 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "korquad-the-korean-question-answering-dataset"}], "metrics": [{"dataset": "korquad-the-korean-question-answering-dataset", "metric": 0.6544, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-crumb-gpt2-regular-large", "modules": [{"role": "model", "module": {"name": "gpt-regular-test", "description": "A fine-tuned version of gpt2-large on the entirety of Regular Show."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-05, "train_batch_size": 1, "eval_batch_size": 1, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1}}}, {"role": "taskType", "module": "text-generation"}, {"role": "solutionSummary", "module": {"summary": "gpt-regular-test is a fine-tuned version of gpt2-large on the entirety of Regular Show. It can be used for text generation tasks. The model reflects the biases inherent to the systems they were trained on, so caution should be taken when deploying it into systems that interact with humans."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "tvseries"}], "metrics": [{"dataset": "tvseries", "metric": 2.1844, "split": "val", "protocol": "loss"}, {"dataset": "tvseries", "metric": 1.6383, "split": "test", "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-mrm8488-wav2vec2-large-xlsr-53-spanish", "modules": [{"role": "model", "module": {"name": "XLSR Wav2Vec2 Spanish Manuel Romero", "description": "Fine-tuned Wav2Vec2-Large-XLSR-53 in Spanish using the Common Voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "Wav2Vec2-Large-XLSR-53", "batch_size": 8, "optimizer": {"name": "Adam", "learning_rate": 5e-05}}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "XLSR Wav2Vec2 Spanish Manuel Romero is a fine-tuned Wav2Vec2-Large-XLSR-53 model in Spanish using the Common Voice dataset. The model can be used for automatic speech recognition tasks in Spanish. The model was trained on the Common Voice train and validation datasets and can be evaluated on the Common Voice test dataset. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-nyavol-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 environment."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 environment. The agent's Q-Table is provided, along with hyperparameters such as the maximum number of steps per episode and the number of episodes used to evaluate the agent. The model's performance is evaluated based on the mean reward achieved over multiple episodes."}}, {"role": "dataset", "purpose": "OpenAI Gym environment", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.42, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-rupe-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 96, "eval_batch_size": 96, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8503 on the evaluation set. The model is suitable for token classification tasks in German language. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8503293209175562, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-muhtasham-bert-small-finetuned-wnut17-ner", "modules": [{"role": "model", "module": {"name": "bert-small-finetuned-wnut17-ner", "description": "A fine-tuned version of google/bert_uncased_L-4_H-512_A-8 on the wnut_17 dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-small-finetuned-wnut17-ner is a fine-tuned version of google/bert_uncased_L-4_H-512_A-8 on the wnut_17 dataset for token classification. The model achieved a precision of 0.6259, recall of 0.4043, F1 score of 0.4913, and accuracy of 0.9255 on the evaluation set. The model is intended for token classification tasks and was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wnut-2017-wnut-2017-emerging-and-rare-entity-recognition"}], "metrics": [{"dataset": "wnut-2017-wnut-2017-emerging-and-rare-entity-recognition", "metric": 0.6259259259259259, "protocol": "precision"}, {"dataset": "wnut-2017-wnut-2017-emerging-and-rare-entity-recognition", "metric": 0.4043062200956938, "protocol": "recall"}, {"dataset": "wnut-2017-wnut-2017-emerging-and-rare-entity-recognition", "metric": 0.49127906976744184, "protocol": "f1"}, {"dataset": "wnut-2017-wnut-2017-emerging-and-rare-entity-recognition", "metric": 0.9255075123293955, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-sb3-a2c-pongnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "A2C", "description": "A trained model of an A2C agent playing PongNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"ent_coef": 0.01, "frame_stack": 4, "n_envs": 16, "n_timesteps": 10000000.0, "policy": "CnnPolicy", "policy_kwargs": {"optimizer_class": "RMSpropTFLike", "optimizer_kwargs": {"eps": 1e-05}}, "vf_coef": 0.25, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "A2C is a reinforcement learning algorithm used to train an agent to play PongNoFrameskip-v4. The model was trained using the stable-baselines3 library and the RL Zoo. The hyperparameters used for training include ent_coef, frame_stack, n_envs, n_timesteps, policy, policy_kwargs, vf_coef, and normalize. The model achieved a mean reward of 17.10 +/- 2.70."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 17.1, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-aubi0ne-layoutlmv3-finetuned-cord-100", "modules": [{"role": "model", "module": {"name": "layoutlmv3-finetuned-cord_100", "description": "A fine-tuned version of microsoft/layoutlmv3-base on the cord dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-05, "train_batch_size": 5, "eval_batch_size": 5, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "training_steps": 2500}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of microsoft/layoutlmv3-base on the cord dataset. It is intended for token classification tasks. The model achieved a precision of 0.9175, recall of 0.9319, F1 score of 0.9246, and accuracy of 0.9406 on the evaluation set. The model was trained with Adam optimizer with a learning rate of 1e-05 and a batch size of 5. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "cord-19"}], "metrics": [{"dataset": "cord-19", "metric": 0.9174649963154016, "protocol": "precision"}, {"dataset": "cord-19", "metric": 0.9318862275449101, "protocol": "recall"}, {"dataset": "cord-19", "metric": 0.9246193835870776, "protocol": "f1"}, {"dataset": "cord-19", "metric": 0.9405772495755518, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-ning-fish-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8591 on the evaluation set. The model is suitable for token classification tasks in German language. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8591260810195721, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-textattack-distilbert-base-uncased-ag-news", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased", "description": "A TextAttack fine-tuned model for sequence classification on the ag_news dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "learning_rate": 2e-05, "max_seq_length": 128, "loss_function": "cross-entropy"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a TextAttack fine-tuned model based on the distilbert-base-uncased architecture. It was fine-tuned on the ag_news dataset for sequence classification with a cross-entropy loss function. The model achieved an accuracy of 0.9478947368421052 on the evaluation set after 1 epoch. It can be used for text classification tasks."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "ag-news-ags-news-corpus"}], "metrics": [{"dataset": "ag-news-ags-news-corpus", "metric": 0.9478947368421052, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-wal-en", "modules": [{"role": "model", "module": {"name": "opus-mt-wal-en", "description": "A machine translation model that translates from the Wal language to English."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-wal-en is a machine translation model that translates from the Wal language to English. The model uses the transformer-align architecture and pre-processing techniques such as normalization and SentencePiece. The model has been evaluated on the JW300.wal.en test set and achieved a BLEU score of 22.5 and a chr-F score of 0.386."}}], "metrics": [{"dataset": "jw300", "metric": 22.5, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.386, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-milyiyo-minilm-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "minilm-finetuned-emotion", "description": "A MiniLM-L12-H384-uncased model fine-tuned on the emotion dataset for text classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "microsoft/MiniLM-L12-H384-uncased", "training_loss": 0.1631, "validation_loss": 0.192153}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "A MiniLM-L12-H384-uncased model fine-tuned on the emotion dataset for text classification. The model achieved an F1 score of 0.931192 on the evaluation set. The model can be used for text classification tasks related to emotions."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.931192, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-maniac-wav2vec2-xls-r-urdu", "modules": [{"role": "model", "module": {"name": "Fine-tuned facebook/wav2vec2-large-xlsr-53 on MOZILLA-FOUNDATION/COMMON_VOICE_7_0 - UR dataset", "description": "A fine-tuned version of facebook/wav2vec2-large-xlsr-53 on the MOZILLA-FOUNDATION/COMMON_VOICE_7_0 - UR dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0003, "train_batch_size": 16, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "training_steps": 1000, "mixed_precision_training": true}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/wav2vec2-large-xlsr-53 on the MOZILLA-FOUNDATION/COMMON_VOICE_7_0 - UR dataset. The model achieved a WER of 67.48% on the evaluation set. More information is needed to describe the model and its intended uses and limitations."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.6765, "protocol": "WER"}], "source": "huggingface"}, {"id": "huggingface-dvitel-h2", "modules": [{"role": "model", "module": {"name": "h2", "description": "Fine-tuned version of distilgpt2 on HearthStone dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 4, "eval_batch_size": 4, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "cosine", "num_epochs": 200, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "text-generation"}, {"role": "solutionSummary", "module": {"summary": "h2 is a fine-tuned version of distilgpt2 on HearthStone dataset. The model was trained with masked language modeling (MLM) objective and can be used for text generation. The model is suitable for tasks that use the whole sentence to make decisions, such as sequence classification, token classification, or question answering. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "hearthstone"}], "metrics": [{"dataset": "hearthstone", "metric": 0.0, "protocol": "Exact Match"}, {"dataset": "hearthstone", "metric": 0.6619, "protocol": "Bleu"}, {"dataset": "hearthstone", "metric": 0.5374, "protocol": "CodeBLEU"}, {"dataset": "hearthstone", "metric": 0.4051, "protocol": "Ngram Match Score"}, {"dataset": "hearthstone", "metric": 0.4298, "protocol": "Weighted Ngram Match Score"}, {"dataset": "hearthstone", "metric": 0.5605, "protocol": "Syntax Match Score"}, {"dataset": "hearthstone", "metric": 0.7541, "protocol": "Dataflow Match Score"}, {"dataset": "hearthstone", "metric": 73.9625, "protocol": "Chrf"}], "source": "huggingface"}, {"id": "huggingface-martinsenden-finetuning-sentiment-model-3000-samples", "modules": [{"role": "model", "module": {"name": "finetuning-sentiment-model-3000-samples", "description": "A fine-tuned version of lvwerra/distilbert-imdb on the imdb dataset for sentiment analysis."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of lvwerra/distilbert-imdb on the imdb dataset for sentiment analysis. It achieves an accuracy of 0.8933 and an F1 score of 0.8994 on the evaluation set. The model is intended for text classification tasks and has been trained using PyTorch and Transformers framework."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.8933, "protocol": "accuracy"}, {"dataset": "imdb-movie-reviews", "metric": 0.8994, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-janeel-tinyroberta-squad2-finetuned-squad", "modules": [{"role": "model", "module": {"name": "tinyroberta-squad2-finetuned-squad", "description": "Fine-tuned version of deepset/tinyroberta-squad2 on the squad_v2 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "tinyroberta-squad2-finetuned-squad is a fine-tuned version of deepset/tinyroberta-squad2 on the squad_v2 dataset. It is a question-answering model that can be used to answer questions based on a given context. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for 2 epochs and achieved a loss of 1.1592 on the validation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 1.1592, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-gchhablani-fnet-large-finetuned-cola", "modules": [{"role": "model", "module": {"name": "fnet-large-finetuned-cola", "description": "A fine-tuned version of google/fnet-large on the GLUE COLA dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-05, "train_batch_size": 4, "eval_batch_size": 8, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "fnet-large-finetuned-cola is a transformer model fine-tuned on the GLUE COLA dataset for text classification. The model achieved a Matthews Correlation score of 0.0 on the evaluation set. More information is needed about the model description, intended uses and limitations, and training and evaluation data."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "cola-corpus-of-linguistic-acceptability"}], "metrics": [{"dataset": "cola-corpus-of-linguistic-acceptability", "metric": 0.0, "protocol": "matthews_correlation"}], "source": "huggingface"}, {"id": "huggingface-fabiochiu-dqn-spaceinvadersnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "DQN Agent playing SpaceInvadersNoFrameskip-v4", "description": "A trained DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "buffer_size": 100000, "exploration_final_eps": 0.01, "exploration_fraction": 0.1, "frame_stack": 4, "gradient_steps": 1, "learning_rate": 0.0001, "learning_starts": 100000, "n_timesteps": 1000000.0, "optimize_memory_usage": true, "policy": "CnnPolicy", "target_update_interval": 1000, "train_freq": 4, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The model was trained with a batch size of 32, a buffer size of 100000, and a learning rate of 0.0001. The model achieved a mean reward of 631.50 with a standard deviation of 84.41 on the SpaceInvadersNoFrameskip-v4 dataset. The model is suitable for reinforcement learning tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-100k"}], "metrics": [{"dataset": "atari-100k", "metric": 631.5, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-hkoll2-distilbert-base-uncased-finetuned-ner", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-ner", "description": "A fine-tuned version of distilbert-base-uncased on the conll2003 dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-ner is a fine-tuned version of distilbert-base-uncased on the conll2003 dataset for token classification. The model achieved high precision, recall, F1 score, and accuracy on the evaluation set. The model is suitable for named entity recognition tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 0.9225414364640884, "protocol": "precision"}, {"dataset": "conll-2003", "metric": 0.9339970913972481, "protocol": "recall"}, {"dataset": "conll-2003", "metric": 0.9282339207293345, "protocol": "f1"}, {"dataset": "conll-2003", "metric": 0.9833828458862217, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-martin97bozic-bert-base-multilingual-uncased-finetuned-squad", "modules": [{"role": "model", "module": {"name": "bert-base-multilingual-uncased-finetuned-squad", "description": "A fine-tuned version of bert-base-multilingual-uncased on the squad dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "bert-base-multilingual-uncased-finetuned-squad is a fine-tuned version of bert-base-multilingual-uncased on the squad dataset. It can be used for question answering tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for 3 epochs and achieved a loss of 1.0109 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 1.0109, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-allermat-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. The model is best suited for text classification tasks. The model achieved an accuracy of 0.923 and an F1 score of 0.9233 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.923, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.9233300539962602, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-plim-xls-r-300m-cv-8-fr", "modules": [{"role": "model", "module": {"name": "XLS-R-300m - French", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-300m on the MOZILLA-FOUNDATION/COMMON_VOICE_8_0 - FR dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 7.5e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "gradient_accumulation_steps": 8, "total_train_batch_size": 128, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 2000, "num_epochs": 7.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "XLS-R-300m - French is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the MOZILLA-FOUNDATION/COMMON_VOICE_8_0 - FR dataset. The model is best suited for automatic speech recognition tasks. The model was trained with Adam optimizer and a linear learning rate scheduler. The model achieved a WER of 35.29% and a CER of 13.94% on the Robust Speech Event - Dev Data dataset. The model was trained using PyTorch and Transformers 4.17.0.dev0."}}, {"role": "dataset", "purpose": "For model training.", "module": "common-voice"}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-alireza1044-albert-base-v2-qnli", "modules": [{"role": "model", "module": {"name": "qnli", "description": "Fine-tuned version of albert-base-v2 on the GLUE QNLI dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-05, "train_batch_size": 32, "eval_batch_size": 8, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 4.0}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "The qnli model is a fine-tuned version of albert-base-v2 on the GLUE QNLI dataset. It is a text classification model that predicts whether a given sentence is entailed by a given context sentence or not. The model achieved an accuracy of 0.9138 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 1e-05 and a batch size of 32 for 4 epochs."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "qnli-question-answering-nli"}], "metrics": [{"dataset": "qnli-question-answering-nli", "metric": 0.9138, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-gitierrez-q-frozenlake-v1-4x4-noslippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-4x4-no_slippery", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model's hyperparameters include the algorithm used, the environment, the maximum number of steps per episode, the number of episodes to evaluate the agent, the Q-Table learned by the agent, and the random seed used for evaluation. The model achieved a mean reward of 1.0 with no standard deviation."}}, {"role": "dataset", "purpose": "Environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-selamatpagi-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "xlm-roberta-base-finetuned-panx-de is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. The model achieved an F1 score of 0.8621 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 5e-05 and a batch size of 24 for 3 epochs. The model was trained using the Transformers 4.11.3, Pytorch 1.11.0+cu113, Datasets 1.16.1, and Tokenizers 0.10.3."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8621, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-alireza1044-mobilebert-sst2", "modules": [{"role": "model", "module": {"name": "sst2", "description": "Fine-tuned version of google/mobilebert-uncased on the GLUE SST2 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-05, "train_batch_size": 32, "eval_batch_size": 8, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 10.0}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "sst2 is a fine-tuned version of google/mobilebert-uncased on the GLUE SST2 dataset. It is a text classification model that achieves an accuracy of 0.9037 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 1e-05 and a batch size of 32. The model was trained for 10 epochs using a linear learning rate scheduler. The model was trained using the Transformers 4.20.0.dev0, Pytorch 1.11.0, Datasets 2.2.2, and Tokenizers 0.12.1."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "sst-stanford-sentiment-treebank"}], "metrics": [{"dataset": "sst-stanford-sentiment-treebank", "metric": 0.9036697247706422, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-mrm8488-spanbert-finetuned-squadv2", "modules": [{"role": "model", "module": {"name": "SpanBERT (spanbert-base-cased) fine-tuned on SQuAD v2", "description": "A transformer model fine-tuned on SQuAD 2.0 dataset for Q&A downstream task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "SpanBERT (spanbert-base-cased)", "batch_size": null, "optimizer": null}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "SpanBERT is a transformer model fine-tuned on SQuAD 2.0 dataset for Q&A downstream task. The model was trained on a Tesla P100 GPU and 25GB of RAM. The model can be used for Q&A tasks and can determine when no answer is supported by the paragraph and abstain from answering. The model can be used with pipelines for fast usage. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 78.8, "protocol": "EM"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 82.22, "protocol": "F1"}], "source": "huggingface"}, {"id": "huggingface-joriscos-convtasnet-libri2mix-sepclean-16k", "modules": [{"role": "model", "module": {"name": "JorisCos/ConvTasNet_Libri2Mix_sepclean_16k", "description": "Asteroid model trained on the sep_clean task of the Libri2Mix dataset using ConvTasNet architecture."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"filterbank": {"kernel_size": 32, "n_filters": 512, "stride": 16}, "masknet": {"bn_chan": 128, "hid_chan": 512, "mask_act": "relu", "n_blocks": 8, "n_repeats": 3, "skip_chan": 128}, "optim": {"lr": 0.001, "optimizer": "adam", "weight_decay": 0.0}, "training": {"batch_size": 6, "early_stop": true, "epochs": 200, "half_lr": true, "num_workers": 4}}}}, {"role": "taskType", "module": "audio-to-audio"}, {"role": "solutionSummary", "module": {"summary": "JorisCos/ConvTasNet_Libri2Mix_sepclean_16k is an audio-to-audio model trained on the sep_clean task of the Libri2Mix dataset using ConvTasNet architecture. The model achieved good results on the Libri2Mix min test set. The model is licensed under Attribution-ShareAlike 3.0 Unported by Cosentino Joris."}}, {"role": "dataset", "purpose": "For model training.", "module": "librimix"}], "metrics": [{"dataset": "librimix", "metric": 15.243671356901526, "protocol": "si_sdr"}, {"dataset": "librimix", "metric": 15.243034178473609, "protocol": "si_sdr_imp"}, {"dataset": "librimix", "metric": 15.668108919568112, "protocol": "sdr"}, {"dataset": "librimix", "metric": 15.578229918028036, "protocol": "sdr_imp"}, {"dataset": "librimix", "metric": 25.295100756629957, "protocol": "sir"}, {"dataset": "librimix", "metric": 25.205219921301754, "protocol": "sir_imp"}, {"dataset": "librimix", "metric": 16.307682590197313, "protocol": "sar"}, {"dataset": "librimix", "metric": -51.64989963759405, "protocol": "sar_imp"}, {"dataset": "librimix", "metric": 0.9394951175291422, "protocol": "stoi"}, {"dataset": "librimix", "metric": 0.22640192740016568, "protocol": "stoi_imp"}], "source": "huggingface"}, {"id": "huggingface-hate-speech-cnerg-dehatebert-mono-indonesian", "modules": [{"role": "model", "module": {"name": "MonoBERT for Indonesian Hate Speech Detection", "description": "A model for detecting hate speech in Indonesian language, trained using only Arabic language data in a monolingual setting and fine-tuned on a multilingual BERT model."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "MonoBERT is a model for detecting hate speech in Indonesian language. It is trained using only Arabic language data in a monolingual setting and fine-tuned on a multilingual BERT model. The best validation score achieved is 0.844494 for a learning rate of 2e-5. The model is based on a paper published on hate speech detection at ECML-PKDD 2020."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-swayam01-hindi-clsril-100", "modules": [{"role": "model", "module": {"name": "Wav2Vec2 Hindi Model by Swayam Mittal", "description": "Fine-tuned Wav2Vec2 on Hindi using the Common Voice and openSLR Hindi datasets."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "Wav2Vec2ForCTC", "processor": "Wav2Vec2ProcessorWithLM", "chars_to_ignore_regex": "[\\,\\?\\.\\!\\-\\;\\:\\\"\\\u201c\\%\\\ufffd\\\u0964\\']", "resampling_rate": 16000, "batch_size": 8}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "The Wav2Vec2 Hindi Model by Swayam Mittal is a fine-tuned model on Hindi using the Common Voice and openSLR Hindi datasets. The model can be used for automatic speech recognition tasks in Hindi. The model achieved a WER of 24.17% on the Common Voice hi dataset. The model requires speech input sampled at 16kHz."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 24.17, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-madlag-bert-large-uncased-mnli", "modules": [{"role": "model", "module": {"name": "BERT-large finetuned on MNLI", "description": "BERT is a transformer model pre-trained on a large English corpus and fine-tuned on the MNLI dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_size": "large", "batch_size": "not specified", "optimizer": {"name": "not specified", "learning_rate": "not specified", "beta1": "not specified", "beta2": "not specified", "weight_decay": "not specified"}}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "BERT-large is a transformer model pre-trained on a large English corpus and fine-tuned on the MNLI dataset. The model is intended for text classification tasks. The model achieved an accuracy of 86.7% on the MNLI dataset, which is higher than the reference fine-tuned model's accuracy of 86.05%."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "multinli-multi-genre-natural-language-inference"}], "metrics": [{"dataset": "multinli-multi-genre-natural-language-inference", "metric": 0.867, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-facebook-detr-resnet-101", "modules": [{"role": "model", "module": {"name": "DETR (End-to-End Object Detection) model with ResNet-101 backbone", "description": "DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 object detection (118k annotated images)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"backbone": "ResNet-101", "object_queries": 100, "loss": {"class": "Cross-entropy", "bounding_box": "L1 and generalized IoU"}, "batch_size": 64, "optimizer": {"name": "AdamW", "learning_rate": 0.0001, "beta1": 0.9, "beta2": 0.999, "weight_decay": 0.0001}}}}, {"role": "taskType", "module": "object-detection"}, {"role": "solutionSummary", "module": {"summary": "DETR is an encoder-decoder transformer with a convolutional backbone used for object detection. The model uses object queries to detect objects in an image. The model is trained using a bipartite matching loss and cross-entropy and L1 and generalized IoU loss to optimize the parameters of the model. The model was trained on COCO 2017 object detection dataset and achieved an AP of 43.5 on COCO 2017 validation. The model can be fine-tuned for downstream tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "coco-microsoft-common-objects-in-context"}], "metrics": [{"dataset": "coco-microsoft-common-objects-in-context", "metric": 43.5, "protocol": "AP"}], "source": "huggingface"}, {"id": "huggingface-aspectcisco-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A trained Q-Learning agent playing Taxi-v3."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent playing Taxi-v3. The model includes the Q-Table learned by the agent and can be used to evaluate the agent's performance on the Taxi-v3 environment. The model was trained with the hyperparameters specified in the model card."}}, {"role": "dataset", "purpose": "The environment used for training and evaluation.", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 1.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-splend1dchan-canine-s-squad", "modules": [{"role": "model", "module": {"name": "Canine-S", "description": "A transformer-based model for question answering tasks."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_type": "canine", "batch_size": 1, "gradient_accumulation_steps": 128, "learning_rate": 3e-05, "num_train_epochs": 3, "max_seq_length": 1024, "doc_stride": 128, "max_answer_length": 240}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "Canine-S is a transformer-based model for question answering tasks. It was trained on the SQuAD dataset and achieved an exact match score of 64.70 and an F1 score of 76.58. The model uses a downsampling rate of 4 and an upsampling kernel size of 4. It has 12 hidden layers, 12 attention heads, and a hidden size of 768. The model uses a learning rate of 3e-5 and was trained for 3 epochs."}}, {"role": "dataset", "purpose": "For training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 64.7, "protocol": "exact"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 76.58, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-sb3-ppo-acrobot-v1", "modules": [{"role": "model", "module": {"name": "PPO", "description": "A reinforcement learning agent trained on Acrobot-v1 environment using the stable-baselines3 library."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"ent_coef": 0.0, "gae_lambda": 0.94, "gamma": 0.99, "n_envs": 16, "n_epochs": 4, "n_steps": 256, "n_timesteps": 1000000.0, "normalize": true, "policy": "MlpPolicy", "normalize_kwargs": {"norm_obs": true, "norm_reward": false}}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "The PPO agent was trained on the Acrobot-v1 environment using the stable-baselines3 library. The hyperparameters used for training are provided. The mean reward achieved by the agent on the Acrobot-v1 environment is -74.60 with a standard deviation of 11.48. The model can be used for further fine-tuning or for prediction on the Acrobot-v1 environment."}}, {"role": "dataset", "purpose": "Reinforcement learning environment used for training.", "module": "deepmind-control-suite"}], "metrics": [{"dataset": "deepmind-control-suite", "metric": -74.6, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-faraahahaha-fine-tune-wav2vec2-xls-r-300m-indonesia", "modules": [{"role": "model", "module": {"name": "fine-tune-Wav2Vec2-XLS-R-300M-Indonesia", "description": "A fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice_10_0 dataset for speech recognition in Indonesian."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0001, "train_batch_size": 32, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 100, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice_10_0 dataset for speech recognition in Indonesian. The model achieved a loss of 0.7924 and a WER of 0.4307 on the evaluation set. The model is intended for speech recognition tasks in Indonesian and was trained using the Transformers, PyTorch, Datasets, and Tokenizers frameworks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.7924, "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.4307, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-jcmc-wav2vec2-large-xlsr-53-ir", "modules": [{"role": "model", "module": {"name": "Fine-tuned facebook/wav2vec2-large-xlsr-53 on MOZILLA-FOUNDATION/COMMON_VOICE_7_0 - GA-IE dataset", "description": "A fine-tuned version of facebook/wav2vec2-large-xlsr-53 on the MOZILLA-FOUNDATION/COMMON_VOICE_7_0 - GA-IE dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 7.5e-05, "train_batch_size": 8, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 4, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 2000, "num_epochs": 50.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/wav2vec2-large-xlsr-53 on the MOZILLA-FOUNDATION/COMMON_VOICE_7_0 - GA-IE dataset. The model is intended for automatic speech recognition tasks. The model was trained using Adam optimizer with a learning rate of 7.5e-05, and a linear learning rate scheduler with 2000 warmup steps. The model was trained for 50 epochs with mixed precision training. The model achieved a loss of 1.0835 and a WER of 0.7490 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 1.0835, "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.749, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-mcg-nju-videomae-base-short-finetuned-kinetics", "modules": [{"role": "model", "module": {"name": "VideoMAE (base-sized model, fine-tuned on Kinetics-400)", "description": "VideoMAE is a self-supervised video pre-training model that is fine-tuned on Kinetics-400 for video classification. It is an extension of Masked Autoencoders (MAE) to video and uses a Vision Transformer (ViT) architecture with a decoder on top for predicting pixel values for masked patches."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"resolution": "16x16", "pretraining_epochs": 800, "finetuning_epochs": "Not specified", "batch_size": "Not specified"}}}, {"role": "taskType", "module": "video-classification"}, {"role": "solutionSummary", "module": {"summary": "VideoMAE is a self-supervised video pre-training model that is fine-tuned on Kinetics-400 for video classification. The model learns an inner representation of videos that can then be used to extract features useful for downstream tasks. The model is suitable for video classification tasks, but caution should be taken when deploying it in human-interacting systems as the model reflects the biases of the systems it was trained on."}}, {"role": "dataset", "purpose": "For fine-tuning and evaluation.", "module": "kinetics-400"}], "metrics": [{"dataset": "kinetics-400", "metric": 79.4, "protocol": "top-1 accuracy"}, {"dataset": "kinetics-400", "metric": 94.1, "protocol": "top-5 accuracy"}], "source": "huggingface"}, {"id": "huggingface-freeagh-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 game."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "q-Taxi-v3 is a Q-Learning agent trained to play the Taxi-v3 game. The model includes the Q-Table learned by the agent and can be used to evaluate the agent's performance. The mean reward achieved by the agent is 7.52 with a standard deviation of 2.71."}}, {"role": "dataset", "purpose": "The game environment used for training and evaluation.", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.52, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-fathyshalab-invoicevsadvertisement", "modules": [{"role": "model", "module": {"name": "invoicevsadvertisement", "description": "Fine-tuned version of microsoft/dit-base-finetuned-rvlcdip on the rvl_cdip dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 192, "eval_batch_size": 192, "seed": 42, "gradient_accumulation_steps": 4, "total_train_batch_size": 768, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "num_epochs": 5}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "invoicevsadvertisement is a fine-tuned version of microsoft/dit-base-finetuned-rvlcdip on the rvl_cdip dataset. It is an image classification model that can distinguish between invoices and advertisements. The model achieved an accuracy of 0.9892 on the evaluation set. The model was trained using the Transformers, PyTorch, Datasets, and Tokenizers frameworks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "rvl-cdip"}], "metrics": [{"dataset": "rvl-cdip", "metric": 0.9892257579553997, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-ts-fi", "modules": [{"role": "model", "module": {"name": "opus-mt-ts-fi", "description": "A machine translation model that translates from ts to fi."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-ts-fi is a machine translation model that translates from ts to fi. It uses a transformer-align model and pre-processing techniques such as normalization and SentencePiece. The model achieves a BLEU score of 27.7 and a chr-F score of 0.509 on the JW300.ts.fi test set."}}], "metrics": [{"dataset": "jw300", "metric": 27.7, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.509, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-bothrajat-dqn-breakoutnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "DQN", "description": "A trained model of a DQN agent playing BreakoutNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "buffer_size": 100000, "exploration_final_eps": 0.01, "exploration_fraction": 0.1, "frame_stack": 4, "gradient_steps": 1, "learning_rate": 0.0001, "learning_starts": 100000, "n_timesteps": 100000.0, "normalize": false, "optimize_memory_usage": true, "policy": "CnnPolicy", "target_update_interval": 1000, "train_freq": 4}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a DQN agent playing BreakoutNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The model was trained with a batch size of 32, a buffer size of 100000, and a learning rate of 0.0001. The model achieved a mean reward of 1.0 with a standard deviation of 2.0. The model is suitable for reinforcement learning tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-100k"}], "metrics": [{"dataset": "atari-100k", "metric": 1.0, "split": "val", "protocol": "mean_reward"}, {"dataset": "atari-100k", "metric": 2.0, "split": "test", "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-xc-swin-tiny-patch4-window7-224-finetuned-eurosat", "modules": [{"role": "model", "module": {"name": "swin-tiny-patch4-window7-224-finetuned-eurosat", "description": "A fine-tuned version of microsoft/swin-tiny-patch4-window7-224 on the imagefolder dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "gradient_accumulation_steps": 4, "total_train_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "num_epochs": 3}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "A fine-tuned version of microsoft/swin-tiny-patch4-window7-224 on the imagefolder dataset. Achieves an accuracy of 0.9811 on the evaluation set. The model is suitable for image classification tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "objectfolder"}], "metrics": [{"dataset": "objectfolder", "metric": 0.9811111111111112, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-adapting-comfort-congratulations-neutral-classifier", "modules": [{"role": "model", "module": {"name": "Adapting/comfort_congratulations_neutral-classifier", "description": "A classifier model trained on the empathetic_dialogues_v2 dataset to classify text into one of three labels: neutral, congratulating, or comforting."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"max_seq_length": 128, "batch_size": 32, "learning_rate": 2e-05, "num_train_epochs": 3}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "The Adapting/comfort_congratulations_neutral-classifier is a text classification model trained on the empathetic_dialogues_v2 dataset. The model classifies text into one of three labels: neutral, congratulating, or comforting. The model achieved an accuracy of 0.81 on the evaluation set. The model's hyperparameters include a maximum sequence length of 128, a batch size of 32, a learning rate of 2e-5, and three training epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "empatheticdialogues"}], "metrics": [{"dataset": "empatheticdialogues", "metric": 0.81, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-aryan4-sucidal", "modules": [{"role": "model", "module": {"name": "Suicidal", "description": "A text categorization model that predicts if a word sequence is suicidal (1) or not (0)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"epochs": 1, "batch_size": 6, "learning_rate": 1e-05}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "The Suicidal model is a text classification model that predicts if a word sequence is suicidal or not. It was trained on the Suicide and Depression Dataset obtained from Reddit. The model was fine-tuned on 1 epoch with a batch size of 6 and a learning rate of 0.00001. The model achieved high accuracy, recall, precision, and F1 score. The model can be imported from the transformers library and used for text classification tasks."}}, {"role": "dataset", "purpose": "For model training.", "module": "reddit"}], "metrics": [{"dataset": "reddit", "metric": 0.9792, "protocol": "accuracy"}, {"dataset": "reddit", "metric": 0.9788, "protocol": "recall"}, {"dataset": "reddit", "metric": 0.9677, "protocol": "precision"}, {"dataset": "reddit", "metric": 0.9732, "protocol": "F1 score"}], "source": "huggingface"}, {"id": "huggingface-tianle-bert-base-uncased-finetuned-squad", "modules": [{"role": "model", "module": {"name": "bert-base-uncased-finetuned-squad", "description": "A fine-tuned version of bert-base-uncased on the squad dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "bert-base-uncased-finetuned-squad is a fine-tuned version of bert-base-uncased on the squad dataset. It is suitable for question answering tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for 1 epoch and achieved a validation loss of 1.1006."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 1.0275, "split": "val", "protocol": "loss"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 1.1006, "split": "test", "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-dooglak-tagged-uni-500v2-ner-model-3epochs-augmented", "modules": [{"role": "model", "module": {"name": "Tagged_Uni_500v2_NER_Model_3Epochs_AUGMENTED", "description": "A fine-tuned version of bert-base-cased on the tagged_uni500v2_wikigold_split dataset for named entity recognition (NER)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of bert-base-cased on the tagged_uni500v2_wikigold_split dataset for named entity recognition (NER). It achieves an F1 score of 0.6913 and an accuracy of 0.9262 on the evaluation set. The model was trained for 3 epochs with a learning rate of 2e-05 and an Adam optimizer with betas=(0.9,0.999) and epsilon=1e-08."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wikineural"}], "metrics": [{"dataset": "wikineural", "metric": 0.7018014564967421, "protocol": "precision"}, {"dataset": "wikineural", "metric": 0.6811755952380952, "protocol": "recall"}, {"dataset": "wikineural", "metric": 0.6913347177647726, "protocol": "f1"}, {"dataset": "wikineural", "metric": 0.926232333678042, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-ase-fr", "modules": [{"role": "model", "module": {"name": "opus-mt-ase-fr", "description": "A machine translation model that translates from the ase language to French."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-ase-fr is a machine translation model that translates from the ase language to French. The model uses the transformer-align architecture and was preprocessed using normalization and SentencePiece. The model achieved a BLEU score of 37.8 and a chr-F score of 0.553 on the JW300 test set."}}], "metrics": [{"dataset": "jw300", "metric": 37.8, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.553, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-bg-en", "modules": [{"role": "model", "module": {"name": "opus-mt-bg-en", "description": "A machine translation model that translates from Bulgarian to English."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-bg-en is a machine translation model that translates from Bulgarian to English. It uses a transformer-align model and pre-processing techniques such as normalization and SentencePiece. The model achieves a BLEU score of 59.4 and a chr-F score of 0.727 on the Tatoeba.bg.en test set."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-kws-dqn-spaceinvadersnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "DQN", "description": "A trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "buffer_size": 100000, "exploration_final_eps": 0.01, "exploration_fraction": 0.1, "frame_stack": 4, "gradient_steps": 1, "learning_rate": 0.0001, "learning_starts": 100000, "n_timesteps": 10000000.0, "normalize": false, "optimize_memory_usage": false, "policy": "CnnPolicy", "target_update_interval": 1000, "train_freq": 4}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The model was trained with a batch size of 32, a buffer size of 100000, and a learning rate of 0.0001. The model achieved a mean reward of 603.00 with a standard deviation of 194.90. The model is suitable for reinforcement learning tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 603.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-speeqo-distilbert-base-uncased-finetuned-sst-2-english", "modules": [{"role": "model", "module": {"name": "DistilBERT base uncased finetuned SST-2", "description": "Fine-tuned DistilBERT-base-uncased model on SST-2 dataset for binary classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-05, "batch_size": 32, "warmup": 600, "max_seq_length": 128, "num_train_epochs": 3.0}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "DistilBERT base uncased finetuned SST-2 is a binary classification model fine-tuned on the SST-2 dataset. The model is based on the DistilBERT-base-uncased architecture and achieves an accuracy of 91.3 on the dev set. However, the model may produce biased predictions that target underrepresented populations, and users should thoroughly evaluate the risks of using this model in their use-cases. We recommend looking at bias evaluation datasets such as WinoBias, WinoGender, and Stereoset."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "sst-stanford-sentiment-treebank"}], "metrics": [{"dataset": "sst-stanford-sentiment-treebank", "metric": 91.3, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-anniepyim-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8649 on the evaluation set. The model is suitable for token classification tasks in German language. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8648740833380706, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-addy88-gptj8", "modules": [{"role": "model", "module": {"name": "8bit Version of EleutherAI/gpt-j-6B", "description": "This is an 8-bit version of the EleutherAI/gpt-j-6B model, converted by Facebook's bitsandbytes library. The model is intended to be fine-tuned on a single GPU with ~11 GB memory."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"quantization": "dynamic 8-bit", "gradient_checkpointing": true, "optimizer": {"name": "8-bit Adam"}}}}, {"role": "taskType", "module": "text-generation"}, {"role": "solutionSummary", "module": {"summary": "This is an 8-bit version of the EleutherAI/gpt-j-6B model, converted by Facebook's bitsandbytes library. The model is intended to be fine-tuned on a single GPU with ~11 GB memory. The model uses dynamic 8-bit quantization for large weight tensors and gradient checkpointing to store only one activation per layer. The model can be fine-tuned using the original hyperparameters from the LoRA paper. The model is suitable for text generation tasks, and the effect of 8-bit quantization on model quality is negligible in practice."}}, {"role": "dataset", "purpose": "For evaluation.", "module": "wikitext-2"}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-dnwalkup-stablediffusion-v1-releases", "modules": [{"role": "model", "module": {"name": "Stable Diffusion v1", "description": "A latent text-to-image diffusion model capable of generating photo-realistic images given any text input."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"resolution": "512x512", "text_encoder": "CLIP ViT-L/14", "noise_scale_schedule": "1e-5 to 1e-2", "classifier_free_guidance_scale": 1.5}}}, {"role": "taskType", "module": "text-to-image"}, {"role": "solutionSummary", "module": {"summary": "Stable Diffusion v1 is a latent text-to-image diffusion model that can generate photo-realistic images given any text input. The model uses a fixed, pretrained text encoder (CLIP ViT-L/14) and a diffusion model that is trained in the latent space of the autoencoder. The model is intended for research purposes only and should not be used to intentionally create or disseminate images that create hostile or alienating environments for people. The model was trained mainly with English captions and will not work as well in other languages. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-avioo1-roberta-base-squad2-finetuned-squad", "modules": [{"role": "model", "module": {"name": "roberta-base-squad2-finetuned-squad", "description": "A fine-tuned version of deepset/roberta-base-squad2 on an unknown dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0001, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 30}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of deepset/roberta-base-squad2 on an unknown dataset. The model is best suited for question-answering tasks. The model was trained with Adam optimizer with a learning rate of 0.0001, a batch size of 16, and a linear learning rate scheduler. The model was trained for 30 epochs. The model achieved a loss of 5.0220 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 5.022, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-ytung-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 game."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 game. The agent's Q-Table is provided, along with hyperparameters such as the maximum number of steps per episode and the number of episodes used for evaluation. The model achieved a mean reward of 7.44 with a standard deviation of 2.71."}}, {"role": "dataset", "purpose": "The game environment used for training and evaluation.", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.44, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-eleutherai-pythia-13b-deduped", "modules": [{"role": "model", "module": {"name": "Pythia-12B-deduped", "description": "A transformer-based language model trained on the Pile dataset after global deduplication."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": {"70M": "2M", "160M": "4M", "410M": "4M", "1.0B": "2M", "1.4B": "4M", "2.8B": "2M", "6.9B": "2M", "12B": "2M"}, "learning_rate": {"70M": 0.001, "160M": 0.0006, "410M": 0.0003, "1.0B": 0.0003, "1.4B": 0.0002, "2.8B": 0.00016, "6.9B": 0.00012, "12B": 0.00012}, "layers": {"70M": 6, "160M": 12, "410M": 24, "1.0B": 16, "1.4B": 24, "2.8B": 32, "6.9B": 32, "12B": 36}, "model_dim": {"70M": 512, "160M": 768, "410M": 1024, "1.0B": 2048, "1.4B": 2048, "2.8B": 2560, "6.9B": 4096, "12B": 5120}, "heads": {"70M": 8, "160M": 12, "410M": 16, "1.0B": 8, "1.4B": 16, "2.8B": 32, "6.9B": 32, "12B": 40}}}}, {"role": "taskType", "module": "text-generation"}, {"role": "solutionSummary", "module": {"summary": "Pythia-12B-deduped is a transformer-based language model trained on the Pile dataset after global deduplication. It is part of the Pythia Scaling Suite, which contains eight models of sizes ranging from 70M to 12B. The models are intended for research on the behavior, functionality, and limitations of large language models, especially interpretability research. Pythia-12B-deduped is not intended for deployment and is not suitable for generating text in other languages. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-dooglak-tagged-one-500v8-ner-model-3epochs-augmented", "modules": [{"role": "model", "module": {"name": "Tagged_One_500v8_NER_Model_3Epochs_AUGMENTED", "description": "Fine-tuned version of bert-base-cased on the tagged_one500v8_wikigold_split dataset for named entity recognition (NER)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "Tagged_One_500v8_NER_Model_3Epochs_AUGMENTED is a fine-tuned version of bert-base-cased on the tagged_one500v8_wikigold_split dataset for named entity recognition (NER). The model achieved a precision of 0.6785, recall of 0.6773, F1 score of 0.6779, and accuracy of 0.9254 on the evaluation set. The model was trained for 3 epochs with a batch size of 8 and a learning rate of 2e-05."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wikisplit"}], "metrics": [{"dataset": "wikisplit", "metric": 0.6785079928952042, "protocol": "Precision"}, {"dataset": "wikisplit", "metric": 0.6773049645390071, "protocol": "Recall"}, {"dataset": "wikisplit", "metric": 0.6779059449866904, "protocol": "F1"}, {"dataset": "wikisplit", "metric": 0.9253906002909735, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-danielev9h-hubert-base-timit-demo-google-colab-ft30ep-v5", "modules": [{"role": "model", "module": {"name": "hubert-base-timit-demo-google-colab-ft30ep_v5", "description": "Fine-tuned version of facebook/hubert-base-ls960 on the timit-asr dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0001, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 1000, "num_epochs": 30, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "hubert-base-timit-demo-google-colab-ft30ep_v5 is a fine-tuned version of facebook/hubert-base-ls960 on the timit-asr dataset. The model is suitable for automatic speech recognition tasks. The model was trained with Adam optimizer with a learning rate of 0.0001, and a batch size of 8. The model was trained for 30 epochs and achieved a loss of 0.4763 and a word error rate (WER) of 0.3322 on the evaluation set. The model was trained using PyTorch 1.11.0+cu113 and Transformers 4.17.0."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "timit-timit-acoustic-phonetic-continuous-speech-corpus"}], "metrics": [{"dataset": "timit-timit-acoustic-phonetic-continuous-speech-corpus", "metric": 0.4763, "protocol": "loss"}, {"dataset": "timit-timit-acoustic-phonetic-continuous-speech-corpus", "metric": 0.3322, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-arvkevi-nba-pbp-distilgpt2", "modules": [{"role": "model", "module": {"name": "nba_pbp_distilgpt2", "description": "A fine-tuned version of distilgpt2 on text files containing play-by-play descriptions of games played by the Boston Celtics and Golden State Warriors during the 2021-22 NBA season."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 4, "eval_batch_size": 4, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0}}}, {"role": "taskType", "module": "text-generation"}, {"role": "solutionSummary", "module": {"summary": "nba_pbp_distilgpt2 is a fine-tuned version of distilgpt2 on play-by-play descriptions of games played by the Boston Celtics and Golden State Warriors during the 2021-22 NBA season. The model generates properly formatted play-by-play descriptions of an NBA game with players from the Boston Celtics and Golden State Warriors. The model is suitable for generating play-by-play descriptions of NBA games, but caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "liveqa"}], "metrics": [{"dataset": "liveqa", "metric": 0.6324, "protocol": "loss"}, {"dataset": "liveqa", "metric": 0.8117, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-arned-pegasus-samsum", "modules": [{"role": "model", "module": {"name": "pegasus-samsum", "description": "A fine-tuned version of google/pegasus-cnn_dailymail on the samsum dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 1, "eval_batch_size": 1, "seed": 42, "gradient_accumulation_steps": 16, "total_train_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 1}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "pegasus-samsum is a fine-tuned version of google/pegasus-cnn_dailymail on the samsum dataset. It is a model for text summarization tasks. The model was trained with Adam optimizer with a learning rate of 5e-05 and a linear learning rate scheduler with 500 warmup steps. The model achieved a loss of 1.4884 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "samsum-corpus"}], "metrics": [{"dataset": "samsum-corpus", "metric": 1.4884, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-en-gil", "modules": [{"role": "model", "module": {"name": "opus-mt-en-gil", "description": "A machine translation model that translates from English to GIL (Gilbertese)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-en-gil is a machine translation model that translates from English to GIL (Gilbertese). The model uses the transformer-align architecture and pre-processing techniques such as normalization and SentencePiece. The model achieves a BLEU score of 38.8 and a chr-F score of 0.604 on the JW300.en.gil test set."}}], "metrics": [{"dataset": "jw300", "metric": 38.8, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.604, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-flair-ner-english-large", "modules": [{"role": "model", "module": {"name": "Flair NER-English-Large", "description": "A large 4-class NER model for English that uses document-level XLM-R embeddings and FLERT."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"embeddings": {"model": "xlm-roberta-large", "layers": "-1", "subtoken_pooling": "first", "fine_tune": true, "use_context": true}, "hidden_size": 256, "use_crf": false, "use_rnn": false, "optimizer": {"name": "AdamW", "learning_rate": 5e-06, "weight_decay": 0.0}, "epochs": 20, "mini_batch_size": 4, "mini_batch_chunk_size": 1}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "Flair NER-English-Large is a named entity recognition model for English that uses document-level XLM-R embeddings and FLERT. It predicts 4 tags: PER (person name), LOC (location name), ORG (organization name), and MISC (other name). The model is intended to be fine-tuned on downstream tasks, such as sequence classification, token classification, or question answering. The model was trained on the CONLL_03 dataset and achieved an F1-Score of 94.36."}}, {"role": "dataset", "purpose": "For model training.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 94.36, "protocol": "F1-Score"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-ja-it", "modules": [{"role": "model", "module": {"name": "jpn-ita transformer-align", "description": "A machine translation model that translates Japanese to Italian using a transformer-align architecture."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece (spm32k,spm32k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "This is a machine translation model that translates Japanese to Italian using a transformer-align architecture. The model was trained on the Tatoeba dataset and achieved a BLEU score of 22.8 and a chrF2 score of 0.46 on the test set. The model uses normalization and SentencePiece (spm32k,spm32k) for preprocessing."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "tatoeba-translation-challenge"}], "metrics": [{"dataset": "tatoeba-translation-challenge", "metric": 22.8, "protocol": "BLEU"}, {"dataset": "tatoeba-translation-challenge", "metric": 0.46, "protocol": "chrF2"}], "source": "huggingface"}, {"id": "huggingface-wikram-legal-key-to-text", "modules": [{"role": "model", "module": {"name": "Legal Text Generator", "description": "A model trained on the Contract Understanding Atticus Dataset (CUAD) to generate legal text based on input keywords."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_type": "GPT-2", "tokenizer": "byte-level BPE", "vocabulary_size": 50257, "token_length": 1024, "batch_size": 8, "learning_rate": 0.0001, "num_epochs": 5}}}, {"role": "taskType", "module": "text-generation"}, {"role": "solutionSummary", "module": {"summary": "The Legal Text Generator is a model trained on the Contract Understanding Atticus Dataset (CUAD) to generate legal text based on input keywords. The model is based on the GPT-2 architecture and uses a byte-level BPE tokenizer with a vocabulary size of 50,257. The model was trained for 5 epochs with a batch size of 8 and a learning rate of 1e-4. The model achieved a perplexity score of 25.3 on the CUAD dataset. The generated text should be reviewed by a legal expert before use in any legal document."}}, {"role": "dataset", "purpose": "For model training and validation.", "module": "cuad-contract-understanding-atticus-dataset"}], "metrics": [{"dataset": "cuad-contract-understanding-atticus-dataset", "metric": 25.3, "protocol": "Perplexity"}], "source": "huggingface"}, {"id": "huggingface-shunian-yelp-review-rating-reberta-base", "modules": [{"role": "model", "module": {"name": "yelp_review_rating_reberta_base", "description": "A model trained from scratch on the yelp_review_full dataset for text classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "cosine", "num_epochs": 6}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "A ReBERTa base model trained from scratch on the Yelp review dataset for text classification. The model achieved an accuracy of 0.67086 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a cosine learning rate scheduler. The model was trained for 6 epochs with a batch size of 16."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "yelp2018"}], "metrics": [{"dataset": "yelp2018", "metric": 0.67086, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-gchhablani-bert-base-cased-finetuned-mnli", "modules": [{"role": "model", "module": {"name": "bert-base-cased-finetuned-mnli", "description": "Fine-tuned version of bert-base-cased on the GLUE MNLI dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "num_epochs": 3.0}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-base-cased-finetuned-mnli is a fine-tuned version of bert-base-cased on the GLUE MNLI dataset. It is intended for text classification tasks. The model achieved an accuracy of 0.8410 on the evaluation set. The model was trained using the Transformers library with PyTorch backend."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "multinli-multi-genre-natural-language-inference"}], "metrics": [{"dataset": "multinli-multi-genre-natural-language-inference", "metric": 0.841, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-anuragshas-wav2vec2-large-xlsr-53-sah", "modules": [{"role": "model", "module": {"name": "Anurag Singh XLSR Wav2Vec2 Large 53 Sakha", "description": "Fine-tuned Wav2Vec2-Large-XLSR-53 on Sakha using the Common Voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "Wav2Vec2-Large-XLSR-53", "batch_size": 8, "optimizer": {"name": "Adam", "learning_rate": 0.0001, "beta1": 0.9, "beta2": 0.98, "weight_decay": 0.01}}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Anurag Singh XLSR Wav2Vec2 Large 53 Sakha is a fine-tuned model based on Wav2Vec2-Large-XLSR-53 on the Sakha language using the Common Voice dataset. The model can be used for automatic speech recognition tasks in Sakha. The model was trained on the Common Voice train and validation datasets and evaluated on the Common Voice test dataset. The model achieved a WER of 38.04% on the test dataset."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 38.04, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-maniac-wav2vec2-xls-r-60-urdu", "modules": [{"role": "model", "module": {"name": "Fine-tuned facebook/wav2vec2-large-xlsr-53 on MOZILLA-FOUNDATION/COMMON_VOICE_7_0 - UR dataset", "description": "A fine-tuned version of facebook/wav2vec2-large-xlsr-53 on the UR dataset of the Common Voice project."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0003, "train_batch_size": 64, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 128, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "training_steps": 2000, "mixed_precision_training": true}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/wav2vec2-large-xlsr-53 on the UR dataset of the Common Voice project. The model is intended for automatic speech recognition tasks in the Urdu language. The model achieved a loss of 3.8433 and a WER of 0.9852 on the evaluation set. The model was fine-tuned using the Transformers library with PyTorch backend and mixed precision training."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 3.8433, "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.9852, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-jiobiala24-wav2vec2-base-cv", "modules": [{"role": "model", "module": {"name": "wav2vec2-base-cv", "description": "A fine-tuned version of facebook/wav2vec2-base on the common_voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0001, "train_batch_size": 32, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 1000, "num_epochs": 30, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "wav2vec2-base-cv is a fine-tuned version of facebook/wav2vec2-base on the common_voice dataset. It is a speech recognition model that can transcribe speech to text. The model was trained using PyTorch and Transformers libraries. The model achieved a WER of 0.3804 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.0829, "split": "val", "protocol": "loss"}, {"dataset": "common-voice", "metric": 1.1562, "split": "test", "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.3804, "protocol": "WER"}], "source": "huggingface"}, {"id": "huggingface-emre-wav2vec2-xls-r-300m-ab-cv8", "modules": [{"role": "model", "module": {"name": "wav2vec2-xls-r-300m-ab-CV8", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-300m on the Common Voice dataset for Automatic Speech Recognition."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0001, "train_batch_size": 16, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 300, "num_epochs": 15, "mixed_precision_training": true}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the Common Voice dataset for Automatic Speech Recognition. The model achieved a WER of 54.74% on the evaluation set. The model is intended for ASR tasks and is not suitable for text generation. The model was trained using PyTorch and Transformers framework versions 1.10.0+cu111 and 4.11.3, respectively. The model was trained using mixed precision training and the Adam optimizer with a learning rate of 0.0001 and linear learning rate scheduling."}}, {"role": "dataset", "purpose": "For model training.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 44.9, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-ankit15nov-xlm-roberta-base-finetuned-panx-fr", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-fr", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "xlm-roberta-base-finetuned-panx-fr is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. The model achieved an F1 score of 0.8466 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 5e-05 and a linear learning rate scheduler for 3 epochs. The model was trained using Transformers 4.11.3, Pytorch 1.5.1, Datasets 1.16.1, and Tokenizers 0.10.3."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8465679676985195, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-toi-sv", "modules": [{"role": "model", "module": {"name": "opus-mt-toi-sv", "description": "A machine translation model that translates from the Toi language to Swedish."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-toi-sv is a machine translation model that translates from the Toi language to Swedish. The model uses the transformer-align architecture and was preprocessed using normalization and SentencePiece. The model achieved a BLEU score of 27.0 and a chr-F score of 0.448 on the JW300.toi.sv test set."}}], "metrics": [{"dataset": "jw300", "metric": 27.0, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.448, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-svanhvit-xlmr-enis-finetuned-ner-finetuned-conll-ner", "modules": [{"role": "model", "module": {"name": "XLMR-ENIS-finetuned-ner-finetuned-conll_ner", "description": "A fine-tuned version of vesteinn/XLMR-ENIS-finetuned-ner on the mim_gold_ner dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "XLMR-ENIS-finetuned-ner-finetuned-conll_ner is a fine-tuned version of vesteinn/XLMR-ENIS-finetuned-ner on the mim_gold_ner dataset. It is a token classification model that can be used to identify named entities in text. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler. The model achieved a precision of 0.8720, recall of 0.8430, F1 score of 0.8573, and accuracy of 0.9858 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "mimic-iii-the-medical-information-mart-for-intensive-care-iii"}], "metrics": [{"dataset": "mimic-iii-the-medical-information-mart-for-intensive-care-iii", "metric": 0.8720365189221028, "protocol": "precision"}, {"dataset": "mimic-iii-the-medical-information-mart-for-intensive-care-iii", "metric": 0.8429893238434164, "protocol": "recall"}, {"dataset": "mimic-iii-the-medical-information-mart-for-intensive-care-iii", "metric": 0.8572669368847712, "protocol": "f1"}, {"dataset": "mimic-iii-the-medical-information-mart-for-intensive-care-iii", "metric": 0.9857922913838598, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-speech-seq2seq-wav2vec2-2-roberta-large-no-adapter-frozen-enc", "modules": [{"role": "model", "module": {"name": "Unnamed ASR model", "description": "A speech recognition model trained on the librispeech_asr dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0001, "train_batch_size": 8, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 3.0, "mixed_precision_training": true}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is an unnamed speech recognition model trained on the librispeech_asr dataset. The model was trained from scratch and achieved a validation WER of 1.0008 and a validation loss of 20.5959. The model was trained using the Adam optimizer with a learning rate of 0.0001 and a linear learning rate scheduler with a warmup of 500 steps. The model was trained for 3 epochs with mixed precision training enabled."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "librispeech"}], "metrics": [{"dataset": "librispeech", "metric": 4.9792, "split": "val", "protocol": "loss"}, {"dataset": "librispeech", "metric": 20.5959, "split": "test", "protocol": "loss"}, {"dataset": "librispeech", "metric": 1.0008, "split": "val", "protocol": "wer"}, {"dataset": "librispeech", "metric": 1.0008, "split": "test", "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-lijingxin-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. The model is best suited for text classification tasks. The model achieved an accuracy of 0.9225 and an F1 score of 0.9226 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.9225, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.9226367098786769, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-fi-mos", "modules": [{"role": "model", "module": {"name": "opus-mt-fi-mos", "description": "A machine translation model that translates from Finnish (fi) to M\u00f2or\u00e9 (mos) language."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-fi-mos is a machine translation model that translates from Finnish to M\u00f2or\u00e9 language. The model uses transformer-align architecture and normalization + SentencePiece pre-processing. The model has been benchmarked on JW300.fi.mos test set and achieved a BLEU score of 21.4 and a chr-F score of 0.366."}}, {"role": "dataset", "purpose": "Test set for benchmarking.", "module": "jw300"}], "metrics": [{"dataset": "jw300", "metric": 21.4, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.366, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-edvinkxs-finetuning-sentiment-model-3000-samples", "modules": [{"role": "model", "module": {"name": "finetuning-sentiment-model-3000-samples", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 32, "eval_batch_size": 32, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 4}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis. It achieves an accuracy of 0.8867 and an F1 score of 0.8903 on the evaluation set. The model is suitable for text classification tasks, but its performance may vary depending on the specific use case and data distribution."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.8866666666666667, "protocol": "accuracy"}, {"dataset": "imdb-movie-reviews", "metric": 0.8903225806451613, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-willheld-t5-base-pointer-top-v2", "modules": [{"role": "model", "module": {"name": "t5-base-pointer-top_v2", "description": "A fine-tuned version of google/mt5-base on the top_v2 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.001, "train_batch_size": 4, "eval_batch_size": 4, "seed": 42, "gradient_accumulation_steps": 128, "total_train_batch_size": 512, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "training_steps": 3000}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "t5-base-pointer-top_v2 is a fine-tuned version of google/mt5-base on the top_v2 dataset. It is best suited for question-answering tasks. The model was trained with Adam optimizer with a learning rate of 0.001 and a batch size of 4. The model achieved a loss of 0.0256 and an exact match score of 0.8517 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "topv2-task-oriented-parsing-v2"}], "metrics": [{"dataset": "topv2-task-oriented-parsing-v2", "metric": 0.0256, "protocol": "loss"}, {"dataset": "topv2-task-oriented-parsing-v2", "metric": 0.8517, "protocol": "exact_match"}], "source": "huggingface"}, {"id": "huggingface-wpolatkan-q-frozenlake-v1-4x4-noslippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained model of a Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-4x4-no_slippery", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model's hyperparameters include the algorithm used, the environment, the maximum number of steps per episode, the number of episodes to evaluate the agent, the Q-Table learned by the agent, and the random seed used for evaluation. The model achieved a mean reward of 1.0 with no standard deviation."}}, {"role": "dataset", "purpose": "Environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-hts98-whisper-medium3-vivos", "modules": [{"role": "model", "module": {"name": "Whisper Small Vietnamese ver1.1 - Son Huynh", "description": "A fine-tuned version of openai/whisper-small on the vivos-train dataset for Vietnamese speech recognition."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-05, "train_batch_size": 2, "eval_batch_size": 8, "gradient_accumulation_steps": 8, "total_train_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 300, "training_steps": 800, "mixed_precision_training": true}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Whisper Small Vietnamese ver1.1 - Son Huynh is a fine-tuned version of openai/whisper-small on the vivos-train dataset for Vietnamese speech recognition. The model was trained using Transformers 4.26.0.dev0, Pytorch 1.11.0, Datasets 2.7.1, and Tokenizers 0.12.1. The model achieved an evaluation loss of 0.1925 and an evaluation word error rate (WER) of 15.6566. The model is intended for automatic speech recognition tasks in Vietnamese, but its limitations and intended uses are not specified."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "vivos-vivos-corpus"}], "metrics": [{"dataset": "vivos-vivos-corpus", "metric": 0.1925, "protocol": "eval_loss"}, {"dataset": "vivos-vivos-corpus", "metric": 15.6566, "protocol": "eval_wer"}, {"dataset": "vivos-vivos-corpus", "metric": 498.9405, "protocol": "eval_runtime"}, {"dataset": "vivos-vivos-corpus", "metric": 1.523, "protocol": "eval_samples_per_second"}, {"dataset": "vivos-vivos-corpus", "metric": 0.19, "protocol": "eval_steps_per_second"}, {"dataset": "vivos-vivos-corpus", "metric": 0.27, "protocol": "epoch"}, {"dataset": "vivos-vivos-corpus", "metric": 200.0, "protocol": "step"}], "source": "huggingface"}, {"id": "huggingface-keith97-bert-small2bert-small-finetuned-cnn-daily-mail-summarization-finetuned-multi-news", "modules": [{"role": "model", "module": {"name": "bert-small2bert-small-finetuned-cnn_daily_mail-summarization-finetuned-multi_news", "description": "A fine-tuned version of mrm8488/bert-small2bert-small-finetuned-cnn_daily_mail-summarization on the multi_news dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 4, "eval_batch_size": 4, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 5, "mixed_precision_training": "Native AMP", "label_smoothing_factor": 0.1}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of mrm8488/bert-small2bert-small-finetuned-cnn_daily_mail-summarization on the multi_news dataset. The model is best suited for summarization tasks. The model was trained using Adam optimizer with a learning rate of 2e-05, and a linear learning rate scheduler with warmup steps of 500. The model was trained for 5 epochs with a batch size of 4 and achieved a Rouge1 score of 38.5318 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "multi-news"}], "metrics": [{"dataset": "multi-news", "metric": 38.5318, "protocol": "Rouge1"}, {"dataset": "multi-news", "metric": 12.7285, "protocol": "Rouge2"}, {"dataset": "multi-news", "metric": 21.4358, "protocol": "Rougel"}, {"dataset": "multi-news", "metric": 33.4565, "protocol": "Rougelsum"}], "source": "huggingface"}, {"id": "huggingface-ernestumorga-sac-seals-walker2d-v0", "modules": [{"role": "model", "module": {"name": "SAC", "description": "A trained SAC agent playing seals/Walker2d-v0 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 128, "buffer_size": 100000, "gamma": 0.99, "learning_rate": 0.0005845844772048097, "learning_starts": 1000, "n_timesteps": 1000000.0, "policy": "MlpPolicy", "policy_kwargs": {"net_arch": [400, 300], "log_std_init": 0.1955317469998743}, "tau": 0.02, "train_freq": 1, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "The SAC agent is trained to play the seals/Walker2d-v0 game using the stable-baselines3 library and the RL Zoo. The model achieved a mean reward of 2271.04 with a standard deviation of 496.40. The hyperparameters used for training include batch size, buffer size, gamma, learning rate, learning starts, policy, policy kwargs, tau, train frequency, and normalization. The model is suitable for reinforcement learning tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "mujoco"}], "metrics": [{"dataset": "mujoco", "metric": 2271.04, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-graphcore-roberta-base-squad", "modules": [{"role": "model", "module": {"name": "Graphcore/roberta-base-squad", "description": "A fine-tuned version of HuggingFace/roberta-base on the SQuAD dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 6e-05, "train_batch_size": 4, "eval_batch_size": 2, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.25, "num_epochs": 2.0, "training_precision": "Mixed Precision"}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "Graphcore/roberta-base-squad is a fine-tuned version of HuggingFace/roberta-base on the SQuAD dataset. It is a transformer model that is designed to pretrain bidirectional representations from unlabelled texts. It can be used for downstream tasks such as sequence classification, named entity recognition, question answering, multiple choice, and masked language modeling. The model achieved state-of-the-art results on GLUE, RACE, and SQuAD."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 85.2696, "protocol": "exact_match"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 91.7455, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-fancyerii-bert-finetuned-ner", "modules": [{"role": "model", "module": {"name": "bert-finetuned-ner", "description": "A fine-tuned version of bert-base-cased on the conll2003 dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-finetuned-ner is a fine-tuned version of bert-base-cased on the conll2003 dataset for token classification. The model achieved high precision, recall, F1 score, and accuracy on the evaluation set. The model is suitable for named entity recognition tasks, but caution should be taken when deploying it in human-interacting systems as it may reflect the biases of the systems it was trained on."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 0.9388, "protocol": "Precision"}, {"dataset": "conll-2003", "metric": 0.9522, "protocol": "Recall"}, {"dataset": "conll-2003", "metric": 0.9454, "protocol": "F1"}, {"dataset": "conll-2003", "metric": 0.987, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-m3hrdadfi-wav2vec2-large-xlsr-turkish", "modules": [{"role": "model", "module": {"name": "XLSR Wav2Vec2 Turkish by Mehrdad Farahani", "description": "Fine-tuned Wav2Vec2-Large-XLSR-53 on Turkish using Common Voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "Wav2Vec2-Large-XLSR-53", "batch_size": 1, "optimizer": {"name": "Adam", "learning_rate": 0.0003, "beta1": 0.9, "beta2": 0.98, "weight_decay": 0.005}, "training_steps": 100000, "warmup_steps": 10000, "gradient_accumulation_steps": 16, "max_duration_in_seconds": 12, "sampling_rate": 16000, "audio_length": 16}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "XLSR Wav2Vec2 Turkish is a speech recognition model fine-tuned on Turkish using Common Voice dataset. The model is based on Wav2Vec2-Large-XLSR-53 architecture and can be used for speech recognition tasks. The model is trained on Common Voice train and validation datasets and evaluated on the test dataset. The model achieved a WER of 27.51% on the test dataset."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 27.51, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-ln-es", "modules": [{"role": "model", "module": {"name": "opus-mt-ln-es", "description": "A transformer-align model for translating from Lingala (ln) to Spanish (es)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-ln-es model is a transformer-align model that translates from Lingala to Spanish. It was trained on the OPUS dataset using normalization and SentencePiece preprocessing. The model achieved a BLEU score of 26.5 and a chr-F score of 0.444 on the JW300.ln.es test set."}}, {"role": "dataset", "purpose": "Test set for benchmarking.", "module": "jw300"}], "metrics": [{"dataset": "jw300", "metric": 26.5, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.444, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-laurentiustancioiu-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8649 on the evaluation set. The model is suitable for token classification tasks in German language. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8648740833380706, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-anton-l-xtreme-s-xlsr-300m-fleurs-asr-en-us", "modules": [{"role": "model", "module": {"name": "xtreme_s_xlsr_300m_fleurs_asr_en_us", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-300m on the GOOGLE/XTREME_S - FLEURS.EN_US dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0003, "train_batch_size": 8, "eval_batch_size": 1, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 200, "num_epochs": 30.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "xtreme_s_xlsr_300m_fleurs_asr_en_us is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the GOOGLE/XTREME_S - FLEURS.EN_US dataset. The model is best suited for automatic speech recognition tasks. The model was trained using Adam optimizer with a learning rate of 0.0003 and a linear learning rate scheduler with warmup steps of 200. The model was trained for 30 epochs with mixed precision training. The model achieved a CER of 0.1356, a loss of 0.5599, and a WER of 0.3148 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.1356, "protocol": "CER"}, {"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.5599, "protocol": "Loss"}, {"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.3148, "protocol": "WER"}], "source": "huggingface"}, {"id": "huggingface-ahmeddbahaa-mbart-large-50-finetuned-ar-wikilingua", "modules": [{"role": "model", "module": {"name": "mbart-large-50-finetuned-ar-wikilingua", "description": "A fine-tuned version of mbart-large-50 on the wiki_lingua dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-06, "train_batch_size": 4, "eval_batch_size": 4, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 250, "num_epochs": 8, "label_smoothing_factor": 0.1}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "mbart-large-50-finetuned-ar-wikilingua is a fine-tuned version of mbart-large-50 on the wiki_lingua dataset. The model is best suited for summarization tasks. The model was trained with Adam optimizer with a learning rate of 1e-06, a batch size of 4, and a linear learning rate scheduler. The model achieved a loss of 4.0001 and a Bertscore of 68.9 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wikilingua"}], "metrics": [{"dataset": "wikilingua", "metric": 4.0001, "protocol": "loss"}, {"dataset": "wikilingua", "metric": 22.11, "protocol": "rouge-1"}, {"dataset": "wikilingua", "metric": 7.33, "protocol": "rouge-2"}, {"dataset": "wikilingua", "metric": 19.75, "protocol": "rouge-l"}, {"dataset": "wikilingua", "metric": 59.4, "protocol": "gen_len"}, {"dataset": "wikilingua", "metric": 68.9, "protocol": "bertscore"}], "source": "huggingface"}, {"id": "huggingface-lezend777-t5-small-finetuned-wikisql", "modules": [{"role": "model", "module": {"name": "t5-small-finetuned-wikisql", "description": "A fine-tuned version of t5-small on the wikisql dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "table-question-answering"}, {"role": "solutionSummary", "module": {"summary": "t5-small-finetuned-wikisql is a transformer model fine-tuned on the wikisql dataset. It can be used for table question answering tasks. The model achieved a loss of 0.1271 and Rouge2 Fmeasure of 0.761 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 5e-05 and a linear learning rate scheduler for 5 epochs."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "wikisql"}], "metrics": [{"dataset": "wikisql", "metric": 0.1271, "protocol": "loss"}, {"dataset": "wikisql", "metric": 0.8165, "protocol": "rouge2_precision"}, {"dataset": "wikisql", "metric": 0.7252, "protocol": "rouge2_recall"}, {"dataset": "wikisql", "metric": 0.761, "protocol": "rouge2_fmeasure"}], "source": "huggingface"}, {"id": "huggingface-tstarshak-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 game."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 game. The agent's Q-Table is provided, along with hyperparameters such as the maximum number of steps per episode and the number of episodes used to evaluate the agent. The mean reward achieved by the agent is 7.56 with a standard deviation of 2.71."}}, {"role": "dataset", "purpose": "The game environment used for training and evaluation.", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.56, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-bengeisler-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. The model is best suited for text classification tasks. The model achieved an accuracy of 0.9285 and an F1 score of 0.9285 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.9285, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.9285214883845085, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-et-sv", "modules": [{"role": "model", "module": {"name": "opus-mt-et-sv", "description": "A transformer-align model for translating from Estonian to Swedish."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-et-sv model is a transformer-align model that translates from Estonian to Swedish. It was trained on the OPUS dataset using normalization and SentencePiece preprocessing. The model achieved a BLEU score of 28.9 and a chr-F score of 0.513 on the JW300.et.sv test set."}}], "metrics": [{"dataset": "jw300", "metric": 28.9, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.513, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-rn-fr", "modules": [{"role": "model", "module": {"name": "run-fra", "description": "A machine translation model that translates from Rundi to French."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece (spm4k,spm4k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "run-fra is a machine translation model that translates from Rundi to French. It was trained on the Tatoeba dataset using a transformer-align model with normalization and SentencePiece preprocessing. The model achieved a BLEU score of 18.2 and a chrF2 score of 0.397 on the Tatoeba-test.run.fra test set."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "tatoeba-translation-challenge"}], "metrics": [{"dataset": "tatoeba-translation-challenge", "metric": 18.2, "protocol": "BLEU"}, {"dataset": "tatoeba-translation-challenge", "metric": 0.397, "protocol": "chrF2_score"}], "source": "huggingface"}, {"id": "huggingface-vasilis-wav2vec2-large-xlsr-53-estonian", "modules": [{"role": "model", "module": {"name": "XLSR Wav2Vec2 Large 53 - Estonian by Vasilis", "description": "Fine-tuned Wav2Vec2-Large-XLSR-53 on Estonian using the Common Voice and NST Estonian ASR Database."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 8, "optimizer": {"name": "Adam", "learning_rate": 0.0005, "beta1": 0.9, "beta2": 0.98, "weight_decay": 0.01}, "num_epochs": 116}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned Wav2Vec2-Large-XLSR-53 model on Estonian using the Common Voice and NST Estonian ASR Database. The model can be used for automatic speech recognition tasks in Estonian. The model was trained for 116 epochs with a batch size of 8 and an Adam optimizer with a learning rate of 0.0005, beta1 of 0.9, beta2 of 0.98, and weight decay of 0.01. The model reflects the biases inherent to the systems they were trained on, so caution should be taken when deploying it into systems that interact with humans."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 30.65832, "protocol": "wer"}, {"dataset": "common-voice", "metric": 5.26149, "protocol": "cer"}], "source": "huggingface"}, {"id": "huggingface-sberbank-ai-rudalle-malevich", "modules": [{"role": "model", "module": {"name": "ruDALL-E Malevich (XL)", "description": "A 1.3 billion parameter model for Russian, capable of generating arbitrary images from a text prompt that describes the desired result."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"num_parameters": "1.3 B", "training_data_volume": "120 million text-image pairs"}}}, {"role": "taskType", "module": "text-to-image"}, {"role": "solutionSummary", "module": {"summary": "ruDALL-E Malevich (XL) is a text-to-image generation model that can generate arbitrary images from a text prompt that describes the desired result. The model was trained on a proprietary dataset consisting of 120 million text-image pairs. The generation pipeline includes ruDALL-E, ruCLIP for ranging results, and a superresolution model. The model is suitable for generating images in Russian language. The long term goal of this research is the creation of multimodal neural networks that can pull on concepts from a variety of mediums in order to better understand the world as a whole."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-en-niu", "modules": [{"role": "model", "module": {"name": "opus-mt-en-niu", "description": "A machine translation model that translates from English to niu."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-en-niu is a machine translation model that translates from English to niu. It uses a transformer-align model and pre-processing techniques such as normalization and SentencePiece. The model achieves a BLEU score of 53.0 and a chr-F score of 0.698 on the JW300.en.niu test set."}}], "metrics": [{"dataset": "jw300", "metric": 53.0, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.698, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-nimaboscarino-efficientformer-l1-1000", "modules": [{"role": "model", "module": {"name": "EfficientFormer-L1", "description": "EfficientFormer-L1 is a transformer model developed by Snap Research for image classification and semantic segmentation tasks on mobile devices."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"parameters": 12300000, "GMACs": 1.3, "epochs": 1000}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "EfficientFormer-L1 is a transformer model designed for image classification and semantic segmentation tasks on mobile devices. It was trained on ImageNet-1K and achieved a top-1 accuracy of 80.2%. The model is licensed under the apache-2.0 license and was developed by Snap Research."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imagenet"}], "metrics": [{"dataset": "imagenet", "metric": 0.802, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-alireza1044-mobilebert-qnli", "modules": [{"role": "model", "module": {"name": "qnli", "description": "Fine-tuned version of google/mobilebert-uncased on the GLUE QNLI dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-05, "train_batch_size": 32, "eval_batch_size": 8, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 10.0}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "The qnli model is a fine-tuned version of google/mobilebert-uncased on the GLUE QNLI dataset. It is a text classification model that predicts whether a given sentence is true or false given a corresponding question. The model achieved an accuracy of 0.9068 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 1e-05 and a linear learning rate scheduler for 10 epochs."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "qnli-question-answering-nli"}], "metrics": [{"dataset": "qnli-question-answering-nli", "metric": 0.9068277503203368, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-dooglak-article-100v6-ner-model-3epochs-augmented", "modules": [{"role": "model", "module": {"name": "Article_100v6_NER_Model_3Epochs_AUGMENTED", "description": "Fine-tuned version of bert-base-cased on the article100v6_wikigold_split dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "Article_100v6_NER_Model_3Epochs_AUGMENTED is a fine-tuned version of bert-base-cased on the article100v6_wikigold_split dataset for token classification. The model achieved a precision of 0.5109, recall of 0.5018, F1 score of 0.5063, and accuracy of 0.9052 on the evaluation set. The model was trained for 3 epochs with a batch size of 8 and a learning rate of 2e-05."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wikisplit"}], "metrics": [{"dataset": "wikisplit", "metric": 0.5108527131782946, "protocol": "Precision"}, {"dataset": "wikisplit", "metric": 0.5017766497461928, "protocol": "Recall"}, {"dataset": "wikisplit", "metric": 0.5062740076824584, "protocol": "F1"}, {"dataset": "wikisplit", "metric": 0.9052396107190628, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-avioo1-distilbert-base-uncased-finetuned-squad", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-squad", "description": "A fine-tuned version of distilbert-base-uncased on the squad dataset for question answering."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-squad is a fine-tuned version of distilbert-base-uncased on the squad dataset for question answering. The model achieved a validation loss of 1.2125. The model is suitable for question answering tasks, but its performance may vary depending on the nature of the questions and the context of the answers. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 1.2637, "split": "val", "protocol": "loss"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 1.2125, "split": "test", "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-arianpasquali-distilbert-base-uncased-finetuned-clinc", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-clinc", "description": "A fine-tuned version of distilbert-base-uncased on the clinc_oos dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 48, "eval_batch_size": 48, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-clinc is a fine-tuned version of distilbert-base-uncased on the clinc_oos dataset. It is a text classification model that can be used to classify out-of-scope queries. The model achieved an accuracy of 0.9113 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler. The model was trained for 5 epochs with a batch size of 48."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "clinc-single-domain-oos"}], "metrics": [{"dataset": "clinc-single-domain-oos", "metric": 0.9112903225806451, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-infinitejoy-wav2vec2-large-xls-r-300m-marathi-cv8", "modules": [{"role": "model", "module": {"name": "wav2vec2-large-xls-r-300m-marathi-cv8", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-300m on the MOZILLA-FOUNDATION/COMMON_VOICE_8_0 - MR dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0003, "train_batch_size": 32, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 100.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the MOZILLA-FOUNDATION/COMMON_VOICE_8_0 - MR dataset. The model is intended for automatic speech recognition tasks in Marathi. The model achieved a WER of 55.716 and a CER of 13.842 on the evaluation set. The model was trained using PyTorch and Transformers frameworks with a learning rate of 0.0003, batch size of 32, and Adam optimizer with betas=(0.9,0.999) and epsilon=1e-08."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 55.716, "protocol": "WER"}, {"dataset": "common-voice", "metric": 13.842, "protocol": "CER"}], "source": "huggingface"}, {"id": "huggingface-mbmmurad-wav2vec2-base-cvbn-37k", "modules": [{"role": "model", "module": {"name": "wav2vec2-base-cvbn-37k", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-300m on the cvbn dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 7.5e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 1000, "num_epochs": 5, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "wav2vec2-base-cvbn-37k is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the cvbn dataset. It is a speech recognition model that can transcribe speech to text. The model was trained using Adam optimizer with a learning rate of 7.5e-05 and a batch size of 16. The model was trained for 5 epochs with a linear learning rate scheduler and mixed precision training. The model achieved an evaluation loss of 0.2288 and a word error rate of 0.3332 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.2288, "protocol": "eval_loss"}, {"dataset": "common-voice", "metric": 0.3332, "protocol": "eval_wer"}, {"dataset": "common-voice", "metric": 329.8903, "protocol": "eval_runtime"}, {"dataset": "common-voice", "metric": 9.094, "protocol": "eval_samples_per_second"}, {"dataset": "common-voice", "metric": 0.57, "protocol": "eval_steps_per_second"}, {"dataset": "common-voice", "metric": 3.59, "protocol": "epoch"}, {"dataset": "common-voice", "metric": 8400.0, "protocol": "step"}], "source": "huggingface"}, {"id": "huggingface-neha2608-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8627 on the evaluation set. The model is suitable for token classification tasks in German language. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8627004891366169, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-tkazusa-lilt-en-funsd", "modules": [{"role": "model", "module": {"name": "lilt-en-funsd", "description": "A fine-tuned version of SCUT-DLVCLab/lilt-roberta-en-base on the funsd-layoutlmv3 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "training_steps": 2000, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "document-question-answering"}, {"role": "solutionSummary", "module": {"summary": "lilt-en-funsd is a fine-tuned version of SCUT-DLVCLab/lilt-roberta-en-base on the funsd-layoutlmv3 dataset. It is suitable for document question answering tasks. The model was trained with Adam optimizer with a learning rate of 5e-05, and a batch size of 8. The model achieved an overall accuracy of 0.8068 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "funsd-form-understanding-in-noisy-scanned-documents"}], "metrics": [{"dataset": "funsd-form-understanding-in-noisy-scanned-documents", "metric": 1.6459, "protocol": "Loss"}, {"dataset": "funsd-form-understanding-in-noisy-scanned-documents", "metric": 0.8789, "protocol": "Overall Precision"}, {"dataset": "funsd-form-understanding-in-noisy-scanned-documents", "metric": 0.8907, "protocol": "Overall Recall"}, {"dataset": "funsd-form-understanding-in-noisy-scanned-documents", "metric": 0.8848, "protocol": "Overall F1"}, {"dataset": "funsd-form-understanding-in-noisy-scanned-documents", "metric": 0.8068, "protocol": "Overall Accuracy"}], "source": "huggingface"}, {"id": "huggingface-chrisliu298-arxiv-ai-gpt2", "modules": [{"role": "model", "module": {"name": "ArXiv AI GPT-2", "description": "GPT-2 (774M) model capable of generating abstracts given paper titles. It was trained using all research paper titles and abstracts under artificial intelligence (AI), machine learning (LG), computation and language (CL), and computer vision and pattern recognition (CV) on arXiv."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"block_size": 512, "batch_size": 1, "gradient_accumulation": 1, "learning_rate": 1e-05, "epochs": 5}}}, {"role": "taskType", "module": "text-generation"}, {"role": "solutionSummary", "module": {"summary": "ArXiv AI GPT-2 is a transformer model pre-trained on a large corpus of research paper titles and abstracts under AI, ML, CL, and CV categories on arXiv. It can be used to generate abstracts given paper titles. The model was trained with a block size of 512, batch size of 1, gradient accumulation of 1, learning rate of 1e-5, and 5 epochs. The model's perplexity score on the test set is 14.9413."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "arxivpapers"}], "metrics": [{"dataset": "arxivpapers", "metric": 14.9413, "protocol": "perplexity"}], "source": "huggingface"}, {"id": "huggingface-valhalla-t5-base-squad", "modules": [{"role": "model", "module": {"name": "T5 for question-answering", "description": "T5-base model fine-tuned on SQuAD1.1 for QA using text-to-text approach."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "T5-base", "epochs": 4, "batch_size": "not specified"}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "T5 is a transformer model fine-tuned on SQuAD1.1 for question-answering using a text-to-text approach. The model is best suited for question-answering tasks, where it can generate an answer to a given question based on a given context. The model was trained on a TPU with 35GB RAM for 4 epochs. The model can be used through the Hugging Face Transformers library."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 81.561, "protocol": "Exact Match"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 89.9601, "protocol": "F1"}], "source": "huggingface"}, {"id": "huggingface-mpsb00-echr-test-2", "modules": [{"role": "model", "module": {"name": "ECHR_test_2", "description": "A fine-tuned version of prajjwal1/bert-tiny on the lex_glue dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.001, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1, "mixed_precision_training": true}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "ECHR_test_2 is a fine-tuned version of prajjwal1/bert-tiny on the lex_glue dataset. It is a text classification model, but more information is needed to determine its intended uses and limitations. The model was trained using Adam optimizer with a learning rate of 0.001 and a batch size of 8. It was trained for 1 epoch and achieved a validation loss of 0.2487, a macro-f1 score of 0.4052, and a micro-f1 score of 0.5660."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "lexglue"}], "metrics": [{"dataset": "lexglue", "metric": 0.2487, "protocol": "loss"}, {"dataset": "lexglue", "metric": 0.4052, "protocol": "macro-f1"}, {"dataset": "lexglue", "metric": 0.566, "protocol": "micro-f1"}], "source": "huggingface"}, {"id": "huggingface-yunocchi-swin-tiny-patch4-window7-224-finetuned-eurosat", "modules": [{"role": "model", "module": {"name": "swin-tiny-patch4-window7-224-finetuned-eurosat", "description": "A fine-tuned version of microsoft/swin-tiny-patch4-window7-224 on the imagefolder dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 32, "eval_batch_size": 32, "seed": 42, "gradient_accumulation_steps": 4, "total_train_batch_size": 128, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "num_epochs": 3}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of microsoft/swin-tiny-patch4-window7-224 on the imagefolder dataset. The model achieved an accuracy of 0.4815 on the evaluation set. More information is needed to describe the model and its intended uses and limitations."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "objectfolder"}], "metrics": [{"dataset": "objectfolder", "metric": 0.4815, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-jcastanyo-q-frozenlake-v1-4x4-noslippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained model of a Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-4x4-no_slippery", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model's hyperparameters include the algorithm used, the environment, the maximum number of steps per episode, the number of episodes to evaluate the agent, the Q-Table learned by the agent, and the random seed used for evaluation. The model achieved a mean reward of 1.0 with no standard deviation."}}, {"role": "dataset", "purpose": "Environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-antoinev17-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 10, "eval_batch_size": 10, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. The model achieved an F1 score of 0.8658 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 5e-05 and a linear learning rate scheduler. The model was trained for 3 epochs with a batch size of 10."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8658245134858313, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-ht-sv", "modules": [{"role": "model", "module": {"name": "opus-mt-ht-sv", "description": "A transformer-align model for translating from Haitian Creole (ht) to Swedish (sv)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-ht-sv model is a transformer-align model that translates from Haitian Creole to Swedish. It achieved a BLEU score of 27.9 and a chr-F score of 0.463 on the JW300.ht.sv test set. The model was preprocessed using normalization and SentencePiece. The original weights can be downloaded from the provided link."}}, {"role": "dataset", "purpose": "Test set for benchmarking.", "module": "jw300"}], "metrics": [{"dataset": "jw300", "metric": 27.9, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.463, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-fi-to", "modules": [{"role": "model", "module": {"name": "opus-mt-fi-to", "description": "A machine translation model that translates from Finnish (fi) to an unspecified target language (to)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-fi-to is a machine translation model that translates from Finnish to an unspecified target language. The model uses the transformer-align architecture and pre-processing techniques such as normalization and SentencePiece. The model has been benchmarked on the JW300.fi.to dataset and achieved a BLEU score of 38.3 and a chr-F score of 0.541."}}, {"role": "dataset", "purpose": "For benchmarking.", "module": "jw300"}], "metrics": [{"dataset": "jw300", "metric": 38.3, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.541, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-amirabbas-wav2vec2-large-xls-r-300m-turkish-demo-colab-1", "modules": [{"role": "model", "module": {"name": "wav2vec2-large-xls-r-300m-turkish-demo-colab-1", "description": "A fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0003, "train_batch_size": 16, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 20, "mixed_precision_training": true}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset. The model is intended for automatic speech recognition tasks. The model was trained with Adam optimizer with a learning rate of 0.0003 and a linear learning rate scheduler with 500 warmup steps. The model was trained for 20 epochs with mixed precision training. The model achieved a validation loss of 0.3487 and a WER of 0.3."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.0828, "split": "val", "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.3487, "split": "test", "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.3, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-davlan-bert-base-multilingual-cased-finetuned-swahili", "modules": [{"role": "model", "module": {"name": "bert-base-multilingual-cased-finetuned-swahili", "description": "A Swahili BERT model obtained by fine-tuning bert-base-multilingual-cased model on Swahili language texts."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "bert-base-multilingual-cased", "fine_tuned_language": "Swahili", "batch_size": null, "optimizer": null}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-base-multilingual-cased-finetuned-swahili is a Swahili BERT model obtained by fine-tuning bert-base-multilingual-cased model on Swahili language texts. It provides better performance than the multilingual BERT on text classification and named entity recognition datasets. The model is limited by its training dataset of entity-annotated news articles from a specific span of time. This may not generalize well for all use cases in different domains."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "cc100"}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-mrm8488-q-taxi-v3-1", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3-1", "description": "A Q-Learning agent trained to play the Taxi-v3 environment."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 environment. The agent's Q-Table is provided, along with hyperparameters such as the maximum number of steps per episode and the number of episodes used to evaluate the agent. The model's performance is evaluated based on the mean reward achieved over multiple episodes."}}, {"role": "dataset", "purpose": "OpenAI Gym environment", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.56, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-sasuke-distilbert-base-uncased-finetuned-squad", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-squad", "description": "A fine-tuned version of distilbert-base-uncased on the squad dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 32, "eval_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-squad is a fine-tuned version of distilbert-base-uncased on the squad dataset. It is suitable for question answering tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 32. The model was trained for 3 epochs and achieved a loss of 1.1458 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 1.1458, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-lurker18-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. It can be used for text classification tasks. The model achieved an accuracy of 0.9215 and an F1 score of 0.9216 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.9215, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.9215660102598912, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-iic-beto-base-spanish-sqac", "modules": [{"role": "model", "module": {"name": "beto-base-spanish_sqac", "description": "Fine-tuned version of BETO, a Spanish BERT model, on the SQAC dataset for question-answering task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_architecture": "Roberta", "tokenizer": "RobertaTokenizer", "batch_size": null, "learning_rate": null, "num_epochs": null, "optimizer": null}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of BETO, a Spanish BERT model, on the SQAC dataset for question-answering task. The model was trained following the recommendations of the authors in their paper, performing a full grid search over the hyperparameter space provided in the paper, and selecting the best model based on eval_loss. The model can be used for question-answering tasks in Spanish."}}, {"role": "dataset", "purpose": "For model training.", "module": "headqa"}], "metrics": [{"dataset": "headqa", "metric": 76.2, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-team-nave-distilbert-base-uncased-distilled-clinc", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-distilled-clinc", "description": "A fine-tuned version of distilbert-base-uncased on the clinc_oos dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 96, "eval_batch_size": 96, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 10}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-distilled-clinc is a fine-tuned version of distilbert-base-uncased on the clinc_oos dataset. The model is best suited for text classification tasks. The model achieved an accuracy of 0.9368 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler. The model was trained for 10 epochs with a batch size of 96."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "clinc150"}], "metrics": [{"dataset": "clinc150", "metric": 0.9367741935483871, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-facebook-detr-resnet-101-dc5", "modules": [{"role": "model", "module": {"name": "DETR (End-to-End Object Detection) model with ResNet-101 backbone (dilated C5 stage)", "description": "DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 object detection (118k annotated images)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"backbone": "ResNet-101", "object_queries": 100, "loss_function": "bipartite matching loss", "optimizer": "AdamW", "learning_rate": 0.0001, "batch_size": 64, "epochs": 300}}}, {"role": "taskType", "module": "object-detection"}, {"role": "solutionSummary", "module": {"summary": "DETR is an encoder-decoder transformer with a convolutional backbone used for object detection. The model uses object queries to detect objects in an image. The model is trained using a bipartite matching loss and optimized using AdamW optimizer. The model was trained on COCO 2017 object detection dataset and achieves an AP of 44.9 on COCO 2017 validation. The model can be used for object detection tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "coco-microsoft-common-objects-in-context"}], "metrics": [{"dataset": "coco-microsoft-common-objects-in-context", "metric": 44.9, "protocol": "AP"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-eo-da", "modules": [{"role": "model", "module": {"name": "epo-dan", "description": "A transformer model for translation from Esperanto to Danish."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece (spm4k,spm4k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "epo-dan is a transformer model for translation from Esperanto to Danish. It was trained on the Tatoeba dataset using normalization and SentencePiece preprocessing. The model achieved a BLEU score of 21.6 and a chrF2 score of 0.407 on the Tatoeba-test.epo.dan evaluation set."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "tatoeba"}], "metrics": [{"dataset": "tatoeba", "metric": 21.6, "protocol": "BLEU"}, {"dataset": "tatoeba", "metric": 0.407, "protocol": "chrF2"}], "source": "huggingface"}, {"id": "huggingface-graphcore-rahult-bart-base-finetuned-en-to-ro", "modules": [{"role": "model", "module": {"name": "bart-base-finetuned-en-to-ro", "description": "A fine-tuned version of facebook/bart-base on the wmt16 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 1, "eval_batch_size": 1, "seed": 42, "distributed_type": "IPU", "gradient_accumulation_steps": 128, "total_train_batch_size": 128, "total_eval_batch_size": 6, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1, "training_precision": "Mixed Precision"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "bart-base-finetuned-en-to-ro is a fine-tuned version of facebook/bart-base on the wmt16 dataset. The model is intended for translation tasks from English to Romanian. The model was trained using mixed precision and achieved a validation loss of 1.6768. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler. The model was trained for one epoch with a batch size of 128."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wmt-2016"}], "metrics": [{"dataset": "wmt-2016", "metric": 0.9521, "split": "val", "protocol": "loss"}, {"dataset": "wmt-2016", "metric": 1.6768, "split": "test", "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-zyw-test-squad-trained", "modules": [{"role": "model", "module": {"name": "test-squad-trained", "description": "This model was trained from scratch on an unknown dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "The test-squad-trained model was trained from scratch on an unknown dataset. It was trained for 3 epochs with a batch size of 16 and achieved a validation loss of 1.2026. The model is intended for question answering tasks, but more information is needed to determine its intended uses and limitations."}}, {"role": "dataset", "purpose": "For evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 0.8068, "split": "val", "protocol": "loss"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 1.2026, "split": "test", "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-philschmid-sagemaker-distilbert-emotion", "modules": [{"role": "model", "module": {"name": "sagemaker-distilbert-emotion", "description": "Fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 3e-05, "train_batch_size": 32, "eval_batch_size": 64, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 1, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "sagemaker-distilbert-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. The model achieves an accuracy of 0.9185 on the evaluation set. The model is intended for text classification tasks and reflects the biases inherent to the systems they were trained on, so caution should be taken when deploying it into systems that interact with humans."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.9185, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-jbnlry-distilbert-base-uncased-finetuned-cola", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-cola", "description": "A fine-tuned version of distilbert-base-uncased on the glue dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-cola is a fine-tuned version of distilbert-base-uncased on the glue dataset. It is suitable for text classification tasks. The model achieved a Matthews Correlation score of 0.5472 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for 5 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.5472, "protocol": "matthews_correlation"}], "source": "huggingface"}, {"id": "huggingface-crabz-fernet-cc-sk-ner", "modules": [{"role": "model", "module": {"name": "FERNET-CC_sk NER", "description": "A fine-tuned version of FERNET-CC_sk on the Slovak wikiann dataset for named entity recognition."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 10.0}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "FERNET-CC_sk NER is a fine-tuned transformer model for named entity recognition on Slovak language. It is trained on the wikiann sk dataset and achieves high precision, recall, F1 score, and accuracy. The model is suitable for recognizing entities of type LOCATION, PERSON, and ORGANIZATION. The model can be used for downstream tasks such as information extraction, text classification, and question answering."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wikiann"}], "metrics": [{"dataset": "wikiann", "metric": 0.936, "protocol": "Precision"}, {"dataset": "wikiann", "metric": 0.9472, "protocol": "Recall"}, {"dataset": "wikiann", "metric": 0.9416, "protocol": "F1"}, {"dataset": "wikiann", "metric": 0.9789, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-rerare-distilbert-base-uncased-finetuned-cola", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-cola", "description": "A fine-tuned version of distilbert-base-uncased on the glue dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-cola is a fine-tuned version of distilbert-base-uncased on the glue dataset. It is suitable for text classification tasks. The model achieved a Matthews Correlation score of 0.5291 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 16 for 5 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.5291, "protocol": "matthews_correlation"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-tw-es", "modules": [{"role": "model", "module": {"name": "opus-mt-tw-es", "description": "A machine translation model that translates from Traditional Chinese (tw) to Spanish (es) using the transformer-align architecture."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-tw-es is a machine translation model that translates from Traditional Chinese to Spanish using the transformer-align architecture. The model achieved a BLEU score of 25.9 and a chr-F score of 0.441 on the JW300.tw.es test set."}}], "metrics": [{"dataset": "jw300", "metric": 25.9, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.441, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-gary109-ai-light-dance-singing-ft-wav2vec2-large-xlsr-53-5gram-v1", "modules": [{"role": "model", "module": {"name": "ai-light-dance_singing_ft_wav2vec2-large-xlsr-53-5gram-v1", "description": "A fine-tuned version of gary109/ai-light-dance_singing_ft_wav2vec2-large-xlsr-53-5gram on the GARY109/AI_LIGHT_DANCE - ONSET-SINGING dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 3e-05, "train_batch_size": 2, "eval_batch_size": 2, "seed": 42, "gradient_accumulation_steps": 16, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "cosine", "lr_scheduler_warmup_steps": 500, "num_epochs": 10.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "ai-light-dance_singing_ft_wav2vec2-large-xlsr-53-5gram-v1 is a fine-tuned version of gary109/ai-light-dance_singing_ft_wav2vec2-large-xlsr-53-5gram on the GARY109/AI_LIGHT_DANCE - ONSET-SINGING dataset. The model is intended for automatic speech recognition tasks. The model was trained using Adam optimizer with a learning rate of 3e-05 and cosine learning rate scheduler. The model was trained for 10 epochs with a batch size of 32. The model achieved a validation loss of 0.4389 and a WER of 0.1554."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "children-s-song-dataset"}], "metrics": [{"dataset": "children-s-song-dataset", "metric": 0.1027, "split": "val", "protocol": "loss"}, {"dataset": "children-s-song-dataset", "metric": 0.4389, "split": "test", "protocol": "loss"}, {"dataset": "children-s-song-dataset", "metric": 0.1554, "protocol": "WER"}], "source": "huggingface"}, {"id": "huggingface-vicl-distilbert-base-uncased-finetuned-cola", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-cola", "description": "A fine-tuned version of distilbert-base-uncased on the glue dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-cola is a fine-tuned version of distilbert-base-uncased on the glue dataset. It is a transformer model that can be used for text classification tasks. The model achieved a Matthews Correlation score of 0.5599 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler. The model was trained for 5 epochs with a batch size of 16."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.5598704865754364, "protocol": "matthews_correlation"}], "source": "huggingface"}, {"id": "huggingface-deepset-tinyroberta-squad2", "modules": [{"role": "model", "module": {"name": "deepset/tinyroberta-squad2", "description": "Distilled version of the deepset/roberta-base-squad2 model for extractive question answering."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 96, "n_epochs": 4, "base_LM_model": "deepset/tinyroberta-squad2-step1", "max_seq_len": 384, "learning_rate": 3e-05, "lr_schedule": "LinearWarmup", "warmup_proportion": 0.2, "doc_stride": 128, "max_query_length": 64, "distillation_loss_weight": 0.75, "temperature": 1.5, "teacher": "deepset/robert-large-squad2"}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "This is a distilled version of the deepset/roberta-base-squad2 model for extractive question answering. It was distilled using the TinyBERT approach and trained on the SQuAD 2.0 dataset. The model is intended to be fine-tuned on a downstream task. The model is suitable for extractive question answering tasks, such as sequence classification, token classification, or question answering. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 78.8627, "protocol": "exact_match"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 82.0355, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-bg-uk", "modules": [{"role": "model", "module": {"name": "bul-ukr transformer-align", "description": "A machine translation model that translates from Bulgarian to Ukrainian."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece (spm32k,spm32k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "This is a machine translation model that translates from Bulgarian to Ukrainian. It was trained on the Tatoeba dataset and uses a transformer-align architecture. The model achieved a BLEU score of 49.2 and a chrF2 score of 0.683 on the Tatoeba-test.bul.ukr test set."}}, {"role": "dataset", "purpose": "Test set used for evaluation.", "module": "tatoeba-translation-challenge"}], "metrics": [{"dataset": "tatoeba-translation-challenge", "metric": 49.2, "protocol": "BLEU"}, {"dataset": "tatoeba-translation-challenge", "metric": 0.683, "protocol": "chrF2"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-es-pon", "modules": [{"role": "model", "module": {"name": "opus-mt-es-pon", "description": "A machine translation model that translates from Spanish (es) to Pohnpeian (pon) language."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-es-pon is a transformer-align model that translates from Spanish to Pohnpeian language. The model was trained on the OPUS dataset using normalization and SentencePiece pre-processing. The model achieved a BLEU score of 21.6 and a chr-F score of 0.448 on the JW300.es.pon test set."}}], "metrics": [{"dataset": "jw300", "metric": 21.6, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.448, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-rn-es", "modules": [{"role": "model", "module": {"name": "run-spa", "description": "A machine translation model that translates from Rundi to Spanish."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece (spm4k,spm4k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "run-spa is a machine translation model that translates from Rundi to Spanish. It was trained on the Tatoeba dataset using a transformer-align model with normalization and SentencePiece preprocessing. The model achieved a BLEU score of 14.4 and a chrF2 score of 0.376 on the Tatoeba-test.run.spa test set."}}, {"role": "dataset", "purpose": "Test set used for evaluation.", "module": "tatoeba"}], "metrics": [{"dataset": "tatoeba", "metric": 14.4, "protocol": "BLEU"}, {"dataset": "tatoeba", "metric": 0.376, "protocol": "chrF2_score"}], "source": "huggingface"}, {"id": "huggingface-bash1130-bert-base-finetuned-ynat", "modules": [{"role": "model", "module": {"name": "bert-base-finetuned-ynat", "description": "Fine-tuned version of klue/bert-base on the klue dataset for text classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 256, "eval_batch_size": 256, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-base-finetuned-ynat is a fine-tuned version of klue/bert-base on the klue dataset for text classification. The model achieved an F1 score of 0.8712 on the evaluation set. The model is suitable for text classification tasks, but its performance may vary depending on the specific task and dataset. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler for 5 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "klue-korean-language-understanding-evaluation"}], "metrics": [{"dataset": "klue-korean-language-understanding-evaluation", "metric": 0.8712, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-ca-it", "modules": [{"role": "model", "module": {"name": "cat-ita", "description": "A transformer model for translating from Catalan to Italian."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece (spm12k,spm12k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "A transformer model for translating from Catalan to Italian. The model was trained on the Tatoeba dataset and achieved a BLEU score of 48.6 and a chrF2 score of 0.69 on the test set. The model uses normalization and SentencePiece (spm12k,spm12k) for preprocessing."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "tatoeba"}], "metrics": [{"dataset": "tatoeba", "metric": 48.6, "protocol": "BLEU"}, {"dataset": "tatoeba", "metric": 0.69, "protocol": "chrF2"}], "source": "huggingface"}, {"id": "huggingface-rlpeter70-xlm-roberta-base-finetuned-panx-it", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-it", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8124 on the evaluation set. The model is suitable for token classification tasks in Italian language. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8124, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-flair-ner-english-ontonotes-large", "modules": [{"role": "model", "module": {"name": "Flair NER-English-Ontonotes-Large", "description": "A large 18-class NER model for English that uses document-level XLM-R embeddings and FLERT."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"embeddings": {"name": "XLM-R", "layers": "-1", "subtoken_pooling": "first", "fine_tune": true, "use_context": true}, "hidden_size": 256, "use_crf": false, "use_rnn": false, "reproject_embeddings": false, "optimizer": {"name": "AdamW", "learning_rate": 5e-06, "weight_decay": 0.0}, "epochs": 20, "mini_batch_size": 4, "mini_batch_chunk_size": 1}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "Flair NER-English-Ontonotes-Large is a large 18-class NER model for English that uses document-level XLM-R embeddings and FLERT. It can be used to predict 18 tags such as person, location, organization, date, and time. The model is fine-tuned on the Ontonotes dataset and achieves an F1-Score of 90.93. The model is intended to be fine-tuned on a downstream task, such as sequence classification, token classification, or question answering."}}, {"role": "dataset", "purpose": "For model training.", "module": "ontonotes-5-0"}], "metrics": [{"dataset": "ontonotes-5-0", "metric": 90.93, "protocol": "F1-Score"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-de-tl", "modules": [{"role": "model", "module": {"name": "deu-tgl", "description": "A transformer model for translation from German to Tagalog."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece (spm32k,spm32k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "A transformer model for translation from German to Tagalog. The model was trained on the Tatoeba dataset using normalization and SentencePiece preprocessing. The model achieved a BLEU score of 21.2 and a chrF2 score of 0.541 on the Tatoeba-test.deu.tgl test set."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "tatoeba-translation-challenge"}], "metrics": [{"dataset": "tatoeba-translation-challenge", "metric": 21.2, "protocol": "BLEU"}, {"dataset": "tatoeba-translation-challenge", "metric": 0.541, "protocol": "chrF2"}], "source": "huggingface"}, {"id": "huggingface-juierror-wav2vec2-large-xls-r-thai-test", "modules": [{"role": "model", "module": {"name": "wav2vec2-large-xls-r-thai-test", "description": "Fine-tuned version of facebook/wav2vec2-large-xlsr-53 on the common_voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0003, "train_batch_size": 8, "eval_batch_size": 8, "gradient_accumulation_steps": 2, "total_train_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 400, "num_epochs": 5, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/wav2vec2-large-xlsr-53 on the common_voice dataset. The model is suitable for automatic speech recognition tasks. The model was trained using PyTorch and Transformers 4.15.0, and evaluated using the Datasets 1.17.0 and Tokenizers 0.10.3 libraries. The model was trained for 5 epochs with a learning rate of 0.0003 and a batch size of 16. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.7728, "protocol": "eval_loss"}, {"dataset": "common-voice", "metric": 0.949, "protocol": "eval_wer"}, {"dataset": "common-voice", "metric": 678.2819, "protocol": "eval_runtime"}, {"dataset": "common-voice", "metric": 3.226, "protocol": "eval_samples_per_second"}, {"dataset": "common-voice", "metric": 0.404, "protocol": "eval_steps_per_second"}, {"dataset": "common-voice", "metric": 2.56, "protocol": "epoch"}, {"dataset": "common-voice", "metric": 600.0, "protocol": "step"}], "source": "huggingface"}, {"id": "huggingface-yaxin-xlm-roberta-base-amazon-en-es-fr-mlm", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-amazon-en-es-fr-mlm", "description": "A fine-tuned version of xlm-roberta-base on the Yaxin/amazon_reviews_multi dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 6, "eval_batch_size": 6, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5.0}}}, {"role": "taskType", "module": "fill-mask"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the Yaxin/amazon_reviews_multi dataset. It can be used for masked language modeling tasks. The model achieved an accuracy of 0.6951 on the evaluation set. More information is needed to describe the model and its intended uses and limitations."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "amazon-review"}], "metrics": [{"dataset": "amazon-review", "metric": 0.6951035447140035, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-axhyra-presentation-sentiment-31415", "modules": [{"role": "model", "module": {"name": "presentation_sentiment_31415", "description": "A fine-tuned version of distilbert-base-uncased on the tweet_eval dataset for sentiment analysis."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 7.2792011721188e-06, "train_batch_size": 4, "eval_batch_size": 4, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 4}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "presentation_sentiment_31415 is a fine-tuned version of distilbert-base-uncased on the tweet_eval dataset for sentiment analysis. The model achieved an F1 score of 0.7183 on the evaluation set. The model is suitable for text classification tasks, but its performance may vary depending on the specific use case and data distribution."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "tweeteval"}], "metrics": [{"dataset": "tweeteval", "metric": 0.71829420028644, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-sv-swc", "modules": [{"role": "model", "module": {"name": "opus-mt-sv-swc", "description": "A machine translation model that translates from Swedish (sv) to Kiswahili (swc) using a transformer-align model."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-sv-swc model is a machine translation model that translates from Swedish to Kiswahili. It uses a transformer-align model and achieves a BLEU score of 30.1 and a chr-F score of 0.536 on the JW300.sv.swc test set."}}], "metrics": [{"dataset": "jw300", "metric": 30.1, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.536, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-evelynerhuan-distilbert-base-uncased-model-2", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-model-2", "description": "A fine-tuned version of distilbert-base-uncased on the squad dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-model-2 is a fine-tuned version of distilbert-base-uncased on the squad dataset. It is suitable for question answering tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler. The model was trained for 2 epochs with a batch size of 16. The model achieved a loss of 1.7904 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 1.7904, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-jsunster-distilbert-base-uncased-finetuned-squad", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-squad", "description": "A fine-tuned version of distilbert-base-uncased on the squad dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 32, "eval_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-squad is a fine-tuned version of distilbert-base-uncased on the squad dataset. It is suitable for question answering tasks. The model was trained with Adam optimizer with a learning rate of 2e-05, betas=(0.9,0.999) and epsilon=1e-08. The model was trained for 3 epochs with a linear learning rate scheduler. The model achieved a validation loss of 1.1476."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 0.8513, "split": "val", "protocol": "loss"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 1.1476, "split": "test", "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-draventay-finetuning-sentiment-model-3000-samples", "modules": [{"role": "model", "module": {"name": "finetuning-sentiment-model-3000-samples", "description": "A fine-tuned version of Tianyi98/opt-350m-finetuned-cola on the imdb dataset for sentiment analysis."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 4, "eval_batch_size": 4, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of Tianyi98/opt-350m-finetuned-cola on the imdb dataset for sentiment analysis. It achieves an accuracy of 0.92 and an F1 score of 0.9205 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler for 2 epochs. The model is suitable for text classification tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.92, "protocol": "accuracy"}, {"dataset": "imdb-movie-reviews", "metric": 0.9205298013245033, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-wls-en", "modules": [{"role": "model", "module": {"name": "opus-mt-wls-en", "description": "A transformer-align model for translating from the WLS language to English."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-wls-en model is a transformer-align model that translates from the WLS language to English. It achieved a BLEU score of 31.8 and a chr-F score of 0.471 on the JW300.wls.en test set. The model uses normalization and SentencePiece for pre-processing. The original weights can be downloaded from the provided link."}}, {"role": "dataset", "purpose": "Test set for benchmarking.", "module": "jw300"}], "metrics": [{"dataset": "jw300", "metric": 31.8, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.471, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-jfealko-wav2vec2-large-xls-r-300m-russian-colab-beam-search-test", "modules": [{"role": "model", "module": {"name": "wav2vec2-large-xls-r-300m-russian-colab-beam_search_test", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0003, "train_batch_size": 16, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 4, "total_train_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 800, "num_epochs": 100, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset. The model is suitable for automatic speech recognition tasks. The model achieved a loss of 0.7619 and a WER of 0.4680 on the evaluation set. The model was trained using PyTorch 1.10.0+cu111 and Transformers 4.11.3."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.7619, "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.468, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-ramybaly-ner-nerd", "modules": [{"role": "model", "module": {"name": "ner_nerd", "description": "Fine-tuned version of bert-base-uncased on the nerd dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 3e-05, "train_batch_size": 16, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "num_epochs": 5}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "ner_nerd is a fine-tuned version of bert-base-uncased on the nerd dataset for token classification. The model achieved an accuracy of 0.9392 on the evaluation set. It can be used for named entity recognition tasks. The model was trained using Adam optimizer with a learning rate of 3e-05 and a batch size of 16. The model was trained for 5 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "few-nerd"}], "metrics": [{"dataset": "few-nerd", "metric": 0.9391592461061087, "protocol": "Accuracy"}, {"dataset": "few-nerd", "metric": 0.7466, "protocol": "Precision"}, {"dataset": "few-nerd", "metric": 0.7873, "protocol": "Recall"}, {"dataset": "few-nerd", "metric": 0.7664, "protocol": "F1"}], "source": "huggingface"}, {"id": "huggingface-dooglak-tagged-uni-500v0-ner-model-3epochs-augmented", "modules": [{"role": "model", "module": {"name": "Tagged_Uni_500v0_NER_Model_3Epochs_AUGMENTED", "description": "Fine-tuned version of bert-base-cased on the tagged_uni500v0_wikigold_split dataset for named entity recognition (NER)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "Tagged_Uni_500v0_NER_Model_3Epochs_AUGMENTED is a fine-tuned version of bert-base-cased on the tagged_uni500v0_wikigold_split dataset for named entity recognition (NER). The model achieved a precision of 0.6686, recall of 0.7194, F1 score of 0.6931, and accuracy of 0.9332 on the evaluation set. The model was trained for 3 epochs with a learning rate of 2e-05 and Adam optimizer with betas=(0.9,0.999) and epsilon=1e-08."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wikineural"}], "metrics": [{"dataset": "wikineural", "metric": 0.6686186703410265, "protocol": "Precision"}, {"dataset": "wikineural", "metric": 0.7194217939214232, "protocol": "Recall"}, {"dataset": "wikineural", "metric": 0.6930905195500803, "protocol": "F1"}, {"dataset": "wikineural", "metric": 0.9331875607385811, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-shahukareem-wav2vec2-large-xlsr-53-dhivehi", "modules": [{"role": "model", "module": {"name": "Shahu Kareem XLSR Wav2Vec2 Large 53 Dhivehi", "description": "Fine-tuned Wav2Vec2-Large-XLSR-53 on Dhivehi using the Common Voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 8, "optimizer": {"name": "Adam", "learning_rate": 0.0005, "beta1": 0.9, "beta2": 0.98, "weight_decay": 0.01}}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Shahu Kareem XLSR Wav2Vec2 Large 53 Dhivehi is a fine-tuned model based on Wav2Vec2-Large-XLSR-53 on Dhivehi using the Common Voice dataset. The model can be used for automatic speech recognition tasks in Dhivehi. The model was trained on the Common Voice train and validation datasets and evaluated on the Common Voice test dataset. The model achieved a WER of 32.85% on the test dataset."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 32.85, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-valhalla-distilbart-mnli-12-6", "modules": [{"role": "model", "module": {"name": "DistilBart-MNLI", "description": "Distilled version of bart-large-mnli created using the No Teacher Distillation technique."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"teacher_model_name_or_path": "facebook/bart-large-mnli", "student_encoder_layers": 12, "student_decoder_layers": 6}}}, {"role": "taskType", "module": "zero-shot-classification"}, {"role": "solutionSummary", "module": {"summary": "DistilBart-MNLI is a distilled version of bart-large-mnli created using the No Teacher Distillation technique. The model is fine-tuned on the MNLI dataset and can be used for zero-shot classification tasks. The performance drop is minimal compared to the baseline model. The logs of the trained models can be found in the wandb project."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "multinli-multi-genre-natural-language-inference"}], "metrics": [{"dataset": "multinli-multi-genre-natural-language-inference", "metric": 89.19, "protocol": "matched acc"}, {"dataset": "multinli-multi-genre-natural-language-inference", "metric": 89.01, "protocol": "mismatched acc"}], "source": "huggingface"}, {"id": "huggingface-calcworks-distilbert-base-uncased-finetuned-clinc", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-clinc", "description": "A fine-tuned version of distilbert-base-uncased on the clinc_oos dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 48, "eval_batch_size": 48, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-clinc is a fine-tuned version of distilbert-base-uncased on the clinc_oos dataset. It is suitable for text classification tasks. The model achieved an accuracy of 0.9161 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler. The model was trained for 5 epochs with a batch size of 48."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "clinc-single-domain-oos"}], "metrics": [{"dataset": "clinc-single-domain-oos", "metric": 0.9161290322580645, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-andrazp-multilingual-hate-speech-robacofi", "modules": [{"role": "model", "module": {"name": "Multilingual Hate Speech Classifier for Social Media Content", "description": "A multilingual model for hate speech classification of social media content based on pre-trained multilingual representations from the XLM-T model."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"languages": ["Arabic", "Croatian", "English", "German", "Slovenian"], "tokenizer": "XLM-T", "classes": {"0": "not-offensive", "1": "offensive"}}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "The Multilingual Hate Speech Classifier for Social Media Content is a model based on pre-trained multilingual representations from the XLM-T model. It was jointly fine-tuned on five languages, namely Arabic, Croatian, English, German, and Slovenian. The model classifies each input into one of two distinct classes: not-offensive or offensive. The model was developed with financial support from the RobaCOFI project, the AI4Media Open Call #1, and the Slovenian Research Agency."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-matthijs-mobilevit-small", "modules": [{"role": "model", "module": {"name": "MobileViT (small-sized model)", "description": "MobileViT is a light-weight, low latency convolutional neural network that combines MobileNetV2-style layers with a new block that replaces local processing in convolutions with global processing using transformers. It is pre-trained on ImageNet-1k at resolution 256x256."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 1024, "optimizer": {"name": "Adam", "learning_rate": "warmup for 3k steps, followed by cosine annealing", "weight_decay": 0.0001}}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "MobileViT is a light-weight, low latency convolutional neural network that combines MobileNetV2-style layers with a new block that replaces local processing in convolutions with global processing using transformers. It is pre-trained on ImageNet-1k at resolution 256x256. The model is suitable for image classification tasks. The model is available in different sizes, with the small-sized model having 5.6M parameters and achieving a top-1 accuracy of 78.4% and a top-5 accuracy of 94.1% on ImageNet-1k."}}, {"role": "dataset", "purpose": "For model training.", "module": "imagenet"}], "metrics": [{"dataset": "imagenet", "metric": 78.4, "protocol": "ImageNet top-1 accuracy"}, {"dataset": "imagenet", "metric": 94.1, "protocol": "ImageNet top-5 accuracy"}], "source": "huggingface"}, {"id": "huggingface-bsmith0430-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 game."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 game. The model includes the Q-Table learned by the agent and can be used to evaluate the agent's performance. The mean reward achieved by the agent is 7.54 with a standard deviation of 2.73."}}, {"role": "dataset", "purpose": "The game environment used for training and evaluation.", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.54, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-ee-de", "modules": [{"role": "model", "module": {"name": "opus-mt-ee-de", "description": "A transformer-align model for translating from Estonian (ee) to German (de)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-ee-de model is a transformer-align model that translates from Estonian to German. It achieved a BLEU score of 22.3 and a chr-F score of 0.43 on the JW300.ee.de test set. The model uses normalization and SentencePiece for pre-processing. The original weights can be downloaded from the provided link."}}], "metrics": [{"dataset": "jw300", "metric": 22.3, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.43, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-luciano-xlm-roberta-base-finetuned-lener-br-finetuned-lener-br", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-lener_br-finetuned-lener-br", "description": "A fine-tuned version of Luciano/xlm-roberta-base-finetuned-lener_br on the lener_br dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 4, "eval_batch_size": 4, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 15, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of Luciano/xlm-roberta-base-finetuned-lener_br on the lener_br dataset. The model is a transformer model pre-trained on a large corpus of English data in a self-supervised fashion. It can be used for token classification tasks. The model achieved high precision, recall, F1, and accuracy scores on the validation set. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "lener-br"}], "metrics": [{"dataset": "lener-br", "metric": 0.9206349206349206, "split": "val", "protocol": "Precision"}, {"dataset": "lener-br", "metric": 0.986258771429967, "split": "test", "protocol": "Precision"}, {"dataset": "lener-br", "metric": 0.9294391315585423, "split": "val", "protocol": "Recall"}, {"dataset": "lener-br", "metric": 0.9897717432152019, "split": "test", "protocol": "Recall"}, {"dataset": "lener-br", "metric": 0.925016077170418, "split": "val", "protocol": "F1"}, {"dataset": "lener-br", "metric": 0.9880121346555324, "split": "test", "protocol": "F1"}, {"dataset": "lener-br", "metric": 0.9832504071600401, "split": "val", "protocol": "Accuracy"}, {"dataset": "lener-br", "metric": 0.9832802904657313, "split": "test", "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-keras-io-supervised-contrastive-learning-cifar10", "modules": [{"role": "model", "module": {"name": "Keras classification model with contrastive learning", "description": "A classification model trained on cifar10 dataset using contrastive learning."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"epochs": 50, "learning_rate": "not specified", "optimizer": "not specified", "contrastive_learning": true}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a Keras classification model trained on cifar10 dataset using contrastive learning. The model achieved a test accuracy of 81.06% after 50 epochs, which is higher than the accuracy achieved without contrastive learning. The model can be used for image classification tasks with ten classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "cifar-10"}], "metrics": [{"dataset": "cifar-10", "metric": 81.06, "protocol": "test_accuracy"}], "source": "huggingface"}, {"id": "huggingface-intel-t5-base-cnn-dm-int8-dynamic", "modules": [{"role": "model", "module": {"name": "INT8 T5 base finetuned on CNN DailyMail", "description": "A PyTorch model quantized with Intel Neural Compressor using PostTrainingDynamic quantization."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"quantization_method": "PostTrainingDynamic", "model_size": {"INT8": "326M", "FP32": "892M"}}}}, {"role": "taskType", "module": "text-generation"}, {"role": "solutionSummary", "module": {"summary": "This is an INT8 PyTorch model quantized with Intel Neural Compressor using PostTrainingDynamic quantization. The original fp32 model comes from the fine-tuned model flax-community/t5-base-cnn-dm. The model is best suited for text generation tasks. The model size is smaller in INT8 than in FP32, but the accuracy is slightly lower in INT8. The model was fine-tuned on the CNN DailyMail dataset and evaluated using the rougeLsum metric."}}, {"role": "dataset", "purpose": "For fine-tuning the model.", "module": "cnn-daily-mail"}], "metrics": [{"dataset": "cnn-daily-mail", "metric": 36.5661, "split": "val", "protocol": "rougeLsum"}, {"dataset": "cnn-daily-mail", "metric": 36.5959, "split": "test", "protocol": "rougeLsum"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-en-zh", "modules": [{"role": "model", "module": {"name": "eng-zho", "description": "A transformer model pre-trained on a large corpus of English data and fine-tuned for translation from English to Chinese."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece (spm32k,spm32k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The eng-zho model is a transformer model pre-trained on a large corpus of English data and fine-tuned for translation from English to Chinese. It achieved a BLEU score of 31.4 and a chrF2 score of 0.268 on the Tatoeba-test.eng.zho test set. The model uses normalization and SentencePiece (spm32k,spm32k) for pre-processing. The model is suitable for English to Chinese translation tasks, but caution should be taken when deploying it in human-interacting systems as it may reflect the biases inherent to the systems it was trained on."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "tatoeba-translation-challenge"}], "metrics": [{"dataset": "tatoeba-translation-challenge", "metric": 31.4, "protocol": "BLEU"}, {"dataset": "tatoeba-translation-challenge", "metric": 0.268, "protocol": "chrF2"}], "source": "huggingface"}, {"id": "huggingface-meghazisofiane-opus-mt-en-ar-finetuned-en-to-ar-test2-instances", "modules": [{"role": "model", "module": {"name": "opus-mt-en-ar-finetuned-en-to-ar-test2-instances", "description": "A fine-tuned version of Helsinki-NLP/opus-mt-en-ar on the un_multi dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1, "mixed_precision_training": true}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of Helsinki-NLP/opus-mt-en-ar on the un_multi dataset. It is intended for English to Arabic translation tasks. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model achieved a BLEU score of 66.2993 on the validation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "united-nations-parallel-corpus"}], "metrics": [{"dataset": "united-nations-parallel-corpus", "metric": 66.2993, "protocol": "Bleu"}], "source": "huggingface"}, {"id": "huggingface-yuryk-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. The model is best suited for text classification tasks. The model achieved an accuracy of 0.933 and an F1 score of 0.9333 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 3 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.933, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.9332773351360893, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-neprox-stt-swedish-lr-decay-attentiondropout-model", "modules": [{"role": "model", "module": {"name": "Whisper Small - Swedish", "description": "A fine-tuned version of openai/whisper-small on the Common Voice 11.0 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 4, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 4, "total_train_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "training_steps": 3000, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Whisper Small - Swedish is a fine-tuned version of openai/whisper-small on the Common Voice 11.0 dataset. The model is intended for automatic speech recognition tasks in Swedish. The model achieved a WER of 27.5604 on the validation set. The model was trained using PyTorch 1.12.1 and Transformers 4.25.0.dev0."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.0462, "split": "val", "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.4326, "split": "test", "protocol": "loss"}, {"dataset": "common-voice", "metric": 27.5604, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-cardiffnlp-twitter-roberta-base-2021-124m-topic-single", "modules": [{"role": "model", "module": {"name": "cardiffnlp/twitter-roberta-base-2021-124m-topic-single", "description": "Fine-tuned version of cardiffnlp/twitter-roberta-base-2021-124m on the cardiffnlp/tweet_topic_single dataset for text classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"max_length": 128}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of cardiffnlp/twitter-roberta-base-2021-124m on the cardiffnlp/tweet_topic_single dataset for text classification. The model is trained to classify tweets into different topics. The achieved metrics on the test split are F1 (micro): 0.9019492025989368, F1 (macro): 0.801375264407874, and Accuracy: 0.9019492025989368. The model can be loaded in Python using the tweetnlp library."}}, {"role": "dataset", "purpose": "For model training, validation, and testing.", "module": "twitter-conversations-dataset"}], "metrics": [{"dataset": "twitter-conversations-dataset", "metric": 0.9019492025989368, "protocol": "micro_f1_cardiffnlp/tweet_topic_single"}, {"dataset": "twitter-conversations-dataset", "metric": 0.801375264407874, "protocol": "macro_f1_cardiffnlp/tweet_topic_single"}, {"dataset": "twitter-conversations-dataset", "metric": 0.9019492025989368, "protocol": "accuracy_cardiffnlp/tweet_topic_single"}], "source": "huggingface"}, {"id": "huggingface-affahrizain-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8649 on the evaluation set. The model is suitable for token classification tasks in German language. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8648740833380706, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-chk-en", "modules": [{"role": "model", "module": {"name": "opus-mt-chk-en", "description": "A transformer-align model for translating from the Chechen language to English."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-chk-en model is a transformer-align model that translates from the Chechen language to English. It achieved a BLEU score of 31.2 and a chr-F score of 0.465 on the JW300.chk.en test set. The model was preprocessed using normalization and SentencePiece."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "jw300"}], "metrics": [{"dataset": "jw300", "metric": 31.2, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.465, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-shahukareem-xls-r-300m-dv", "modules": [{"role": "model", "module": {"name": "xls-r-300m-dv", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset for Automatic Speech Recognition."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0003, "train_batch_size": 16, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 50, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "xls-r-300m-dv is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset for Automatic Speech Recognition. The model achieved a WER of 21.31% and a CER of 3.82% on the evaluation set. The model is intended for speech recognition tasks in the Dhivehi language. The training was done using Adam optimizer with a learning rate of 0.0003 and a batch size of 16. The model was trained for 50 epochs with a linear learning rate scheduler and mixed precision training. The model was trained using the Transformers 4.17.0.dev0 framework with Pytorch 1.10.2+cu102, Datasets 1.18.3, and Tokenizers 0.11.0."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 21.31, "protocol": "WER"}, {"dataset": "common-voice", "metric": 3.82, "protocol": "CER"}], "source": "huggingface"}, {"id": "huggingface-bugpie-dummy-model", "modules": [{"role": "model", "module": {"name": "CamemBERT", "description": "State-of-the-art language model for French based on the RoBERTa model."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"versions": ["base", "large", "base-wikicorpus-lem", "base-wikicorpus-lem-cased", "base-ccnet", "ccnet-large"], "pretraining_data_source": "OSCAR multilingual corpus", "pretraining_data_size": "large"}}}, {"role": "taskType", "module": "fill-mask"}, {"role": "solutionSummary", "module": {"summary": "CamemBERT is a state-of-the-art language model for French based on the RoBERTa model. It was pre-trained on a subcorpus of OSCAR multilingual corpus and evaluated on four different downstream tasks for French: part-of-speech (POS) tagging, dependency parsing, named entity recognition (NER) and natural language inference (NLI). The model can be used for various NLP tasks such as filling masks and extracting contextual embedding features from Camembert output. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For evaluation.", "module": "conll-2009"}, {"role": "dataset", "purpose": "For evaluation.", "module": "multiconer"}, {"role": "dataset", "purpose": "For evaluation.", "module": "arnli"}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-palak-xlm-roberta-large-squad", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base_squad", "description": "Fine-tuned version of xlm-roberta-large on the squad dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 3e-05, "train_batch_size": 12, "eval_batch_size": 32, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 0.67}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "xlm-roberta-base_squad is a fine-tuned version of xlm-roberta-large on the squad dataset. It is a question-answering model that can answer questions based on a given context. The model was trained with Adam optimizer and a linear learning rate scheduler. The model achieved an exact match score of 85.96% and an F1 score of 92.25% on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 85.96026490066225, "protocol": "exact_match"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 92.25000664341768, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-huodongjia-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. The model is best suited for text classification tasks. The model achieved an accuracy of 0.924 and an F1 score of 0.9240 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.924, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.924047154518693, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-alexandrainst-electra-small-offensive-text-detection-da", "modules": [{"role": "model", "module": {"name": "Danish Offensive Text Detection based on ELECTRA-small", "description": "A fine-tuned version of Maltehb/aelaectra-danish-electra-small-cased on a dataset consisting of approximately 5 million Facebook comments on DR's public Facebook pages."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 32, "eval_batch_size": 32, "gradient_accumulation_steps": 1, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "max_steps": 500000, "fp16": true, "eval_steps": 1000, "early_stopping_patience": 100}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of Maltehb/aelaectra-danish-electra-small-cased on a dataset consisting of approximately 5 million Facebook comments on DR's public Facebook pages. The model is intended to detect offensive text in Danish language. The model almost achieves SOTA results while being 20x smaller. The model can be used by running a pipeline from the transformers library."}}, {"role": "dataset", "purpose": "For model training.", "module": "facebook-page-page"}], "metrics": [{"dataset": "facebook-page-page", "metric": 74.13, "protocol": "precision"}, {"dataset": "facebook-page-page", "metric": 89.3, "protocol": "recall"}, {"dataset": "facebook-page-page", "metric": 81.01, "protocol": "f1-score"}, {"dataset": "facebook-page-page", "metric": 85.79, "protocol": "f2-score"}], "source": "huggingface"}, {"id": "huggingface-vesteinn-xlmr-enis-finetuned-ner", "modules": [{"role": "model", "module": {"name": "XLMR-ENIS-finetuned-ner", "description": "A fine-tuned version of vesteinn/XLMR-ENIS on the conll2003 dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "XLMR-ENIS-finetuned-ner is a fine-tuned version of vesteinn/XLMR-ENIS on the conll2003 dataset for token classification. The model achieved high scores in precision, recall, F1, and accuracy on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler for 3 epochs. The model was trained using Transformers 4.10.3, Pytorch 1.9.0+cu102, Datasets 1.12.1, and Tokenizers 0.10.3."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 0.9398313331170938, "protocol": "Precision"}, {"dataset": "conll-2003", "metric": 0.9517943664285128, "protocol": "Recall"}, {"dataset": "conll-2003", "metric": 0.9457750214207026, "protocol": "F1"}, {"dataset": "conll-2003", "metric": 0.9853686150987764, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-fr-swc", "modules": [{"role": "model", "module": {"name": "opus-mt-fr-swc", "description": "A machine translation model that translates from French to Swahili."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-fr-swc is a machine translation model that translates from French to Swahili. It was trained on the OPUS dataset using the transformer-align model with normalization and SentencePiece preprocessing. The model achieved a BLEU score of 28.2 and a chr-F score of 0.499 on the JW300.fr.swc test set."}}], "metrics": [{"dataset": "jw300", "metric": 28.2, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.499, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-jinghan-deberta-base-finetuned-wnli", "modules": [{"role": "model", "module": {"name": "deberta-base-finetuned-wnli", "description": "Fine-tuned version of microsoft/deberta-base on the glue dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "deberta-base-finetuned-wnli is a fine-tuned version of microsoft/deberta-base on the glue dataset. It is a transformer model that can be used for text classification tasks. The model achieved an accuracy of 0.5634 on the evaluation set. More information is needed to describe the model's intended uses and limitations, as well as the training and evaluation data."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.5633802816901409, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-apple-coreml-stable-diffusion-v1-4", "modules": [{"role": "model", "module": {"name": "Stable Diffusion v1-4", "description": "A latent text-to-image diffusion model capable of generating photo-realistic images given any text input."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"encoder": "CLIP ViT-L/14", "resolution": "512x512", "batch_size": 2048, "optimizer": {"name": "AdamW", "learning_rate": 0.0001, "gradient_accumulations": 2}}}}, {"role": "taskType", "module": "text-to-image"}, {"role": "solutionSummary", "module": {"summary": "Stable Diffusion v1-4 is a latent text-to-image diffusion model that generates photo-realistic images given any text input. The model uses a fixed, pretrained text encoder (CLIP ViT-L/14) and is trained on LAION-2B, laion-high-resolution, and laion-improved-aesthetics datasets. The model is intended for research purposes only and should not be used to intentionally create or disseminate images that create hostile or alienating environments for people. The model reflects the biases inherent to the systems they were trained on, so caution should be taken when deploying it into systems that interact with humans."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-edresson-wav2vec2-large-100k-voxpopuli-ft-common-voice-plus-tts-dataset-russian", "modules": [{"role": "model", "module": {"name": "Wav2vec2 Large 100k Voxpopuli fine-tuned with Common Voice and M-AILABS in Russian", "description": "A Wav2vec2 Large 100k Voxpopuli model fine-tuned on Russian speech data from Common Voice and M-AILABS."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_size": "Large", "fine_tuned_on": ["Common Voice", "M-AILABS"], "tokenizer": "AutoTokenizer", "batch_size": 1}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a Wav2vec2 Large 100k Voxpopuli model fine-tuned on Russian speech data from Common Voice and M-AILABS. It can be used for automatic speech recognition tasks in Russian. The model was evaluated on the Common Voice 7.0 dataset and achieved a WER of 24.80. The model was trained using PyTorch and the Apache-2.0 license applies."}}, {"role": "dataset", "purpose": "For fine-tuning.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 24.8, "protocol": "WER"}], "source": "huggingface"}, {"id": "huggingface-atsanda-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 game."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 game. The agent's Q-Table is provided, along with hyperparameters such as the maximum number of steps per episode and the number of episodes used for evaluation. The agent achieved a mean reward of 7.54 with a standard deviation of 2.73."}}, {"role": "dataset", "purpose": "The game environment used for training and evaluation.", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.54, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-asdff8fa7-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 game."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 game. The model includes the Q-Table learned by the agent and can be used to evaluate the agent's performance. The mean reward achieved by the agent is 7.48 with a standard deviation of 2.69."}}, {"role": "dataset", "purpose": "The game environment used for training and evaluation.", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.48, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-yocel1-whisper-small-fr", "modules": [{"role": "model", "module": {"name": "Whisper Small Fr - Joss", "description": "A fine-tuned version of openai/whisper-small on the Common Voice 11.0 FR dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-05, "train_batch_size": 16, "eval_batch_size": 8, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "training_steps": 4000, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Whisper Small Fr - Joss is a fine-tuned version of openai/whisper-small on the Common Voice 11.0 FR dataset. The model is intended for automatic speech recognition tasks in French. The model achieved a WER of 24.0365 on the evaluation set. The training was done using Transformers 4.25.0.dev0, Pytorch 1.12.1+cu113, Datasets 2.6.1, and Tokenizers 0.13.2."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 24.03653329331678, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-dooglak-tagged-one-100v9-ner-model-3epochs-augmented", "modules": [{"role": "model", "module": {"name": "Tagged_One_100v9_NER_Model_3Epochs_AUGMENTED", "description": "Fine-tuned version of bert-base-cased on the tagged_one100v9_wikigold_split dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "Tagged_One_100v9_NER_Model_3Epochs_AUGMENTED is a fine-tuned version of bert-base-cased on the tagged_one100v9_wikigold_split dataset for token classification. The model achieved a precision of 0.3040, recall of 0.2132, F1 score of 0.2506, and accuracy of 0.8539 on the evaluation set. The model was trained for 3 epochs with a learning rate of 2e-05 and Adam optimizer with betas=(0.9,0.999) and epsilon=1e-08."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wikisplit"}], "metrics": [{"dataset": "wikisplit", "metric": 0.3040441176470588, "protocol": "precision"}, {"dataset": "wikisplit", "metric": 0.21319927816447537, "protocol": "recall"}, {"dataset": "wikisplit", "metric": 0.2506440369752993, "protocol": "f1"}, {"dataset": "wikisplit", "metric": 0.8538912172644546, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-guruji108-xlm-roberta-base-finetuned-panx-it", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-it", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8246 on the evaluation set. The model is suitable for token classification tasks in Italian language. The training was done using Adam optimizer with a learning rate of 5e-05 and a batch size of 24 for 3 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8246, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-ceb-fi", "modules": [{"role": "model", "module": {"name": "opus-mt-ceb-fi", "description": "A machine translation model that translates from Cebuano to Finnish."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-ceb-fi is a machine translation model that translates from Cebuano to Finnish. It uses a transformer-align model and pre-processing techniques such as normalization and SentencePiece. The model achieves a BLEU score of 27.4 and a chr-F score of 0.525 on the JW300 test set."}}], "metrics": [{"dataset": "jw300", "metric": 27.4, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.525, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-it5-it5-large-wiki-summarization", "modules": [{"role": "model", "module": {"name": "IT5 Large for Wikipedia Summarization", "description": "A transformer model fine-tuned on Italian Wikipedia summarization using the WITS dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_type": "transformer", "architecture": "seq2seq", "max_length": 512, "batch_size": 8, "optimizer": {"name": "Adam", "learning_rate": 5e-05}}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "IT5 Large is a transformer model fine-tuned on Italian Wikipedia summarization using the WITS dataset. The model is a sequence-to-sequence architecture with a maximum length of 512 tokens and was optimized using the Adam optimizer with a learning rate of 5e-5. The model achieved a ROUGE-1 score of 0.335, a ROUGE-2 score of 0.191, a ROUGE-L score of 0.301, and a BERTScore of 0.508. The model is suitable for Italian text summarization tasks."}}, {"role": "dataset", "purpose": "For model training.", "module": "wit-wikipedia-based-image-text"}], "metrics": [{"dataset": "wit-wikipedia-based-image-text", "metric": 0.335, "protocol": "rouge1"}, {"dataset": "wit-wikipedia-based-image-text", "metric": 0.191, "protocol": "rouge2"}, {"dataset": "wit-wikipedia-based-image-text", "metric": 0.301, "protocol": "rougeL"}, {"dataset": "wit-wikipedia-based-image-text", "metric": 0.508, "protocol": "bertscore"}], "source": "huggingface"}, {"id": "huggingface-pks245-kd-distilbert-clinc", "modules": [{"role": "model", "module": {"name": "kd-distilBERT-clinc", "description": "Fine-tuned version of distilbert-base-uncased on the clinc_oos dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 48, "eval_batch_size": 48, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "kd-distilBERT-clinc is a fine-tuned version of distilbert-base-uncased on the clinc_oos dataset. It is a text classification model that can be used to classify out-of-scope queries. The model achieved an accuracy of 0.9158 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler for 5 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "clinc-single-domain-oos"}], "metrics": [{"dataset": "clinc-single-domain-oos", "metric": 0.9158064516129032, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-jarvisx17-japanese-sentiment-analysis", "modules": [{"role": "model", "module": {"name": "japanese-sentiment-analysis", "description": "Model trained for Japanese sentence sentiments using chABSA dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 10}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This model was trained from scratch on the chABSA dataset for Japanese sentence sentiment analysis. It achieves high accuracy and F1 score on the evaluation set. The model can be used for text classification tasks in Japanese language. The model was trained using Transformers, PyTorch, Datasets, Fugashi, and Unidic_lite."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "semeval-2014-task-4-sub-task-2"}], "metrics": [{"dataset": "semeval-2014-task-4-sub-task-2", "metric": 1.0, "protocol": "accuracy"}, {"dataset": "semeval-2014-task-4-sub-task-2", "metric": 1.0, "protocol": "f1"}, {"dataset": "semeval-2014-task-4-sub-task-2", "metric": 0.0001, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-pig4431-imdb-albert-5e", "modules": [{"role": "model", "module": {"name": "IMDB_ALBERT_5E", "description": "Fine-tuned version of albert-base-v2 on the IMDB dataset for text classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-05, "train_batch_size": 32, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "IMDB_ALBERT_5E is a fine-tuned version of albert-base-v2 on the IMDB dataset for text classification. The model achieved an accuracy of 0.9467 on the evaluation set. The model is suitable for text classification tasks, but caution should be taken when deploying it in human-interacting systems as it reflects the biases of the systems it was trained on."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.9467, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-dalvarez-q-taxi-v3-2", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3-2", "description": "A Q-Learning agent trained to play the Taxi-v3 environment."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 environment. The agent's Q-Table is provided, along with hyperparameters such as the maximum number of steps per episode and the number of episodes used to evaluate the agent. The model's performance is evaluated based on the mean reward achieved over the evaluation episodes."}}, {"role": "dataset", "purpose": "OpenAI Gym environment", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.56, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-ncduy-opus-mt-en-ro-finetuned-en-to-ro", "modules": [{"role": "model", "module": {"name": "opus-mt-en-ro-finetuned-en-to-ro", "description": "A fine-tuned version of Helsinki-NLP/opus-mt-en-ro on the wmt16 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1, "mixed_precision_training": true}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of Helsinki-NLP/opus-mt-en-ro on the wmt16 dataset. It is intended for sequence-to-sequence language modeling tasks, specifically translation from English to Romanian. The model was trained with Adam optimizer, linear learning rate scheduler, and mixed precision training. The model achieved a BLEU score of 27.6209 and a generated length of 33.5648."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wmt-2016-news-wmt-2016-news-translation-task"}], "metrics": [{"dataset": "wmt-2016-news-wmt-2016-news-translation-task", "metric": 27.6209, "protocol": "Bleu"}, {"dataset": "wmt-2016-news-wmt-2016-news-translation-task", "metric": 33.5648, "protocol": "Gen Len"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-ee-fi", "modules": [{"role": "model", "module": {"name": "opus-mt-ee-fi", "description": "A transformer-align model for translating from Estonian (ee) to Finnish (fi)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-ee-fi model is a transformer-align model that translates from Estonian to Finnish. It achieved a BLEU score of 25.0 and a chr-F score of 0.482 on the JW300.ee.fi test set. The model uses normalization and SentencePiece for pre-processing. The original weights can be downloaded from the provided link, and test set translations and scores are also available."}}], "metrics": [{"dataset": "jw300", "metric": 25.0, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.482, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-de-bi", "modules": [{"role": "model", "module": {"name": "opus-mt-de-bi", "description": "A transformer-align model for translating from German (de) to Bislama (bi)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-de-bi is a transformer-align model for translating from German to Bislama. The model was trained on the OPUS dataset using normalization and SentencePiece pre-processing. The model achieved a BLEU score of 25.7 and a chr-F score of 0.45 on the JW300.de.bi test set."}}], "metrics": [{"dataset": "jw300", "metric": 25.7, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.45, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-dooglak-article-500v0-ner-model-3epochs-unaugmented", "modules": [{"role": "model", "module": {"name": "Article_500v0_NER_Model_3Epochs_UNAUGMENTED", "description": "Fine-tuned version of bert-base-cased on the article500v0_wikigold_split dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "Article_500v0_NER_Model_3Epochs_UNAUGMENTED is a fine-tuned version of bert-base-cased on the article500v0_wikigold_split dataset for token classification. The model achieved a precision of 0.6388, recall of 0.7250, F1 score of 0.6792, and accuracy of 0.9365 on the evaluation set. The model was trained for 3 epochs with a learning rate of 2e-05 and Adam optimizer with betas=(0.9,0.999) and epsilon=1e-08."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wikisplit"}], "metrics": [{"dataset": "wikisplit", "metric": 0.6387981711299804, "protocol": "precision"}, {"dataset": "wikisplit", "metric": 0.7249814677538917, "protocol": "recall"}, {"dataset": "wikisplit", "metric": 0.6791666666666667, "protocol": "f1"}, {"dataset": "wikisplit", "metric": 0.9364674441205053, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-sh-uk", "modules": [{"role": "model", "module": {"name": "hbs-ukr", "description": "A transformer model for translating from Serbo-Croatian to Ukrainian."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece (spm32k,spm32k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "hbs-ukr is a transformer model trained on Serbo-Croatian and Ukrainian parallel data. It uses normalization and SentencePiece (spm32k,spm32k) for preprocessing. The model achieved a BLEU score of 49.6 and a chr-F score of 0.665 on the Tatoeba-test.hbs.ukr dataset. The model is intended for translating from Serbo-Croatian to Ukrainian."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "tatoeba"}], "metrics": [{"dataset": "tatoeba", "metric": 49.6, "protocol": "BLEU"}, {"dataset": "tatoeba", "metric": 0.665, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-eikoenchine-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. The model achieved an F1 score of 0.8635 on the evaluation set. The model is suitable for token classification tasks in German language. The training was done using Adam optimizer with a learning rate of 5e-05 and a batch size of 24. The model was trained for 3 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8635, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-rathodsankul-distilbert-base-uncased-finetuned-squad", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-squad", "description": "A fine-tuned version of distilbert-base-uncased on the squad dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 1, "eval_batch_size": 1, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-squad is a fine-tuned version of distilbert-base-uncased on the squad dataset. It is suitable for question answering tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler. The model was trained for one epoch and achieved a validation loss of 1.6561."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 1.1366, "split": "val", "protocol": "loss"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 1.6561, "split": "test", "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-pepa-deberta-v3-base-snli", "modules": [{"role": "model", "module": {"name": "deberta-v3-base-snli", "description": "A transformer model trained from scratch on the SNLI dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "cosine", "num_epochs": 4}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "deberta-v3-base-snli is a transformer model trained from scratch on the SNLI dataset. It can be used for text classification tasks, such as natural language inference. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for 4 epochs. The evaluation results show that the model has an F1 score of 0.9170 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "snli-stanford-natural-language-inference"}], "metrics": [{"dataset": "snli-stanford-natural-language-inference", "metric": 0.2516, "protocol": "eval_loss"}, {"dataset": "snli-stanford-natural-language-inference", "metric": 0.9171, "protocol": "eval_p"}, {"dataset": "snli-stanford-natural-language-inference", "metric": 0.917, "protocol": "eval_r"}, {"dataset": "snli-stanford-natural-language-inference", "metric": 0.917, "protocol": "eval_f1"}, {"dataset": "snli-stanford-natural-language-inference", "metric": 13.4107, "protocol": "eval_runtime"}, {"dataset": "snli-stanford-natural-language-inference", "metric": 732.551, "protocol": "eval_samples_per_second"}, {"dataset": "snli-stanford-natural-language-inference", "metric": 45.784, "protocol": "eval_steps_per_second"}, {"dataset": "snli-stanford-natural-language-inference", "metric": 0.0, "protocol": "step"}], "source": "huggingface"}, {"id": "huggingface-aykeesalazar-vc-bantai-vit-withoutambi-adunest-trial", "modules": [{"role": "model", "module": {"name": "vc-bantai-vit-withoutAMBI-adunest-trial", "description": "A fine-tuned version of google/vit-base-patch16-224-in21k on the imagefolder dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0005, "train_batch_size": 32, "eval_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "vc-bantai-vit-withoutAMBI-adunest-trial is a fine-tuned version of google/vit-base-patch16-224-in21k on the imagefolder dataset. The model achieved an accuracy of 0.7798 on the evaluation set. More information is needed to describe the model and its intended uses and limitations."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "objectfolder"}], "metrics": [{"dataset": "objectfolder", "metric": 0.7797741273100616, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-yam1ke-distilbert-base-uncased-finetuned-ner", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-ner", "description": "A fine-tuned version of distilbert-base-uncased on the conll2003 dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-ner is a fine-tuned version of distilbert-base-uncased on the conll2003 dataset for token classification. The model achieved high precision, recall, F1 score, and accuracy on the evaluation set. The model is suitable for named entity recognition tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 0.9285476533895485, "protocol": "precision"}, {"dataset": "conll-2003", "metric": 0.9362344781295447, "protocol": "recall"}, {"dataset": "conll-2003", "metric": 0.9323752228163993, "protocol": "f1"}, {"dataset": "conll-2003", "metric": 0.9838753236850049, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-en-cy", "modules": [{"role": "model", "module": {"name": "opus-mt-en-cy", "description": "A transformer-align model for translating from English to Welsh (cy)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-en-cy is a transformer-align model for translating from English to Welsh. The model was trained on the opus dataset using normalization and SentencePiece pre-processing. The model achieved a BLEU score of 25.3 and a chr-F score of 0.487 on the Tatoeba.en.cy test set."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-fi-kg", "modules": [{"role": "model", "module": {"name": "opus-mt-fi-kg", "description": "A machine translation model that translates from Finnish (fi) to Kyrgyz (kg) language."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-fi-kg is a machine translation model that translates from Finnish to Kyrgyz language. The model uses transformer-align architecture and pre-processing techniques such as normalization and SentencePiece. The model has been evaluated on JW300.fi.kg test set and achieved a BLEU score of 29.5 and a chr-F score of 0.535."}}], "metrics": [{"dataset": "jw300", "metric": 29.5, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.535, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-baffo32-gpt2-ptmap", "modules": [{"role": "model", "module": {"name": "GPT-2", "description": "Pretrained model on English language using a causal language modeling (CLM) objective."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"tokenizer": "byte-level BPE", "vocabulary_size": 50257, "token_length": 1024}}}, {"role": "taskType", "module": "text-generation"}, {"role": "solutionSummary", "module": {"summary": "GPT-2 is a transformer model pretrained on a large corpus of English data in a self-supervised fashion. It can be used for text generation or fine-tuned for downstream tasks. The model is best at generating texts from a prompt. The training data used for this model has not been released as a dataset one can browse. The model reflects the biases inherent to the systems they were trained on, so caution should be taken when deploying it into systems that interact with humans."}}, {"role": "dataset", "purpose": "For model training.", "module": "webtext"}, {"role": "dataset", "purpose": "For evaluation.", "module": "lambada"}], "metrics": [{"dataset": "lambada", "metric": 35.13, "protocol": "PPL"}, {"dataset": "lambada", "metric": 45.99, "protocol": "ACC"}], "source": "huggingface"}, {"id": "huggingface-adache-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8627 on the evaluation set. The model is suitable for token classification tasks in German language. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8627004891366169, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-et-fi", "modules": [{"role": "model", "module": {"name": "opus-mt-et-fi", "description": "A transformer-align model for translating from Estonian to Finnish."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-et-fi model is a transformer-align model that translates from Estonian to Finnish. It achieved a BLEU score of 26.6 and a chr-F score of 0.546 on the JW300.et.fi test set."}}], "metrics": [{"dataset": "jw300", "metric": 26.6, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.546, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-ndugar-v3-large-mnli", "modules": [{"role": "model", "module": {"name": "microsoft/deberta-v3-large fine-tuned on GLUE MNLI dataset", "description": "A fine-tuned version of microsoft/deberta-v3-large on the GLUE MNLI dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 6e-06, "train_batch_size": 8, "eval_batch_size": 8, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 50, "num_epochs": 2.0}}}, {"role": "taskType", "module": "zero-shot-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of microsoft/deberta-v3-large on the GLUE MNLI dataset. The model achieves an accuracy of 0.9175 and a loss of 0.4103 on the evaluation set. The model is suitable for zero-shot classification tasks. The model was trained using PyTorch 1.10.0 and Transformers 4.13.0.dev0."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "multinli-multi-genre-natural-language-inference"}], "metrics": [{"dataset": "multinli-multi-genre-natural-language-inference", "metric": 0.4103, "protocol": "Loss"}, {"dataset": "multinli-multi-genre-natural-language-inference", "metric": 0.9175, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-drishtisharma-finetuned-convnext-indian-food", "modules": [{"role": "model", "module": {"name": "finetuned-ConvNext-Indian-food", "description": "A fine-tuned version of facebook/convnext-tiny-224 on the indian_food_images dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0002, "train_batch_size": 16, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 10, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of facebook/convnext-tiny-224 on the indian_food_images dataset. It achieves an accuracy of 0.9107 on the evaluation set. The model is suitable for image classification tasks. The training hyperparameters include a learning rate of 0.0002, a batch size of 16, and an optimizer of Adam with betas=(0.9,0.999) and epsilon=1e-08. The model was trained for 10 epochs with mixed precision training."}}, {"role": "dataset", "purpose": "For model training.", "module": "foodx-251"}], "metrics": [{"dataset": "foodx-251", "metric": 0.9107332624867163, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-robinhad-data2vec-large-uk", "modules": [{"role": "model", "module": {"name": "data2vec-large-uk", "description": "A fine-tuned version of facebook/data2vec-audio-large-960h on the common_voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0001, "train_batch_size": 8, "eval_batch_size": 8, "gradient_accumulation_steps": 6, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 100, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "data2vec-large-uk is a fine-tuned version of facebook/data2vec-audio-large-960h on the common_voice dataset. It is a speech recognition model that can transcribe speech to text. The model was trained using PyTorch and Transformers with a linear learning rate scheduler and mixed precision training. The model achieved an evaluation loss of 0.3472, a word error rate of 0.3410, and a character error rate of 0.0832 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.3472, "protocol": "eval_loss"}, {"dataset": "common-voice", "metric": 0.341, "protocol": "eval_wer"}, {"dataset": "common-voice", "metric": 0.0832, "protocol": "eval_cer"}, {"dataset": "common-voice", "metric": 231.0008, "protocol": "eval_runtime"}, {"dataset": "common-voice", "metric": 25.108, "protocol": "eval_samples_per_second"}, {"dataset": "common-voice", "metric": 3.139, "protocol": "eval_steps_per_second"}, {"dataset": "common-voice", "metric": 33.06, "protocol": "epoch"}, {"dataset": "common-voice", "metric": 20400.0, "protocol": "step"}], "source": "huggingface"}, {"id": "huggingface-jellicott-bert-finetuned-ner", "modules": [{"role": "model", "module": {"name": "bert-finetuned-ner", "description": "A fine-tuned version of bert-base-cased on the conll2003 dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-finetuned-ner is a fine-tuned version of bert-base-cased on the conll2003 dataset for token classification. The model achieved high precision, recall, F1 score, and accuracy on the evaluation set. The model is suitable for named entity recognition tasks, but caution should be taken when deploying it in human-interacting systems as it may reflect the biases of the systems it was trained on."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 0.9347431025937551, "protocol": "precision"}, {"dataset": "conll-2003", "metric": 0.9522046449007069, "protocol": "recall"}, {"dataset": "conll-2003", "metric": 0.9433930804501875, "protocol": "f1"}, {"dataset": "conll-2003", "metric": 0.9868870312591982, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-nyu-mll-roberta-med-small-1m-1", "modules": [{"role": "model", "module": {"name": "RoBERTa Pretrained on Smaller Datasets", "description": "RoBERTa is a transformer model pretrained on a smaller corpus of English data in a self-supervised fashion."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0005, "warmup_steps": "6% of max steps", "dropout": 0.1, "model_sizes": {"BASE": {"L": 12, "AH": 12, "HS": 768, "FFN": 3072, "P": "125M"}, "MED-SMALL": {"L": 6, "AH": 8, "HS": 512, "FFN": 2048, "P": "45M"}}}}}, {"role": "taskType", "module": "fill-mask"}, {"role": "solutionSummary", "module": {"summary": "RoBERTa is a transformer model pretrained on a smaller corpus of English data in a self-supervised fashion. The model was pretrained on English Wikipedia and a reproduction of BookCorpus using texts from smashwords in a ratio of approximately 3:1. The model was pre-trained with two objectives: masked language modeling (MLM) and next sentence prediction (NSP). The model is intended to be fine-tuned on a downstream task. The model is suitable for tasks that use the whole sentence to make decisions, such as sequence classification, token classification, or question answering. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training.", "module": "bookcorpus"}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-sb3-qrdqn-breakoutnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "QRDQN", "description": "A reinforcement learning agent trained on BreakoutNoFrameskip-v4 using the stable-baselines3 library."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"env_wrapper": "stable_baselines3.common.atari_wrappers.AtariWrapper", "exploration_fraction": 0.025, "frame_stack": 4, "n_timesteps": 10000000.0, "optimize_memory_usage": true, "policy": "CnnPolicy", "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "QRDQN is a reinforcement learning agent trained on the BreakoutNoFrameskip-v4 environment using the stable-baselines3 library. The agent was trained for 10 million timesteps with hyperparameters including an exploration fraction of 0.025, frame stack of 4, and a CnnPolicy. The agent achieved a mean reward of 387.40 +/- 41.84 on the BreakoutNoFrameskip-v4 environment."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-100k"}], "metrics": [{"dataset": "atari-100k", "metric": 387.4, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-infinitejoy-dqn-spaceinvadersnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "DQN", "description": "A trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "buffer_size": 100000, "exploration_final_eps": 0.01, "exploration_fraction": 0.1, "frame_stack": 4, "gradient_steps": 1, "learning_rate": 0.0001, "learning_starts": 100000, "n_timesteps": 10000000.0, "optimize_memory_usage": true, "policy": "CnnPolicy", "target_update_interval": 1000, "train_freq": 4, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The model was trained with a batch size of 32, a buffer size of 100000, and a learning rate of 0.0001. The model achieved a mean reward of 688.00 with a standard deviation of 388.59. The model is suitable for reinforcement learning tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 688.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-w42-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. The model is best suited for text classification tasks. The model achieved an accuracy of 0.927 and an F1 score of 0.9271 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.927, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.9271021143652434, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-flowers-team-ta-random-sac-chimpanzee-s28", "modules": [{"role": "model", "module": {"name": "Random_SAC_chimpanzee_s28", "description": "Deep RL agent playing TeachMyAgent's parkour."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"student": "SAC", "environment": "parkour", "training_steps": 20000000, "n_evaluation_tasks": 100, "teacher": "Random", "morphology": "climbing_profile_chimpanzee"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "The Random_SAC_chimpanzee_s28 model is a deep RL agent trained to play TeachMyAgent's parkour. The model uses the SAC algorithm and was trained for 20 million steps with a teacher of Random and a morphology of climbing_profile_chimpanzee. The model achieved a mean reward of -56.56 on the BipedalWalker task, -23.6 on the Fish task, and 0.0 on the Climber task. The model reflects the biases inherent to the systems they were trained on, so caution should be taken when deploying it into systems that interact with humans."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "obstacle-tower"}], "metrics": [{"dataset": "obstacle-tower", "metric": 0.0, "split": "val", "protocol": "mean_reward"}, {"dataset": "obstacle-tower", "metric": 16.9, "split": "test", "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-course5i-sead-l-6-h-384-a-12-qnli", "modules": [{"role": "model", "module": {"name": "SEAD-L-6_H-384_A-12-qnli", "description": "A student model distilled from BERT base as teacher by using SEAD framework on qnli task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"training_args": {"learning_rate": 5e-05, "per_device_train_batch_size": 32, "per_device_eval_batch_size": 32, "num_train_epochs": 3, "weight_decay": 0.01, "push_to_hub": false}}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "SEAD-L-6_H-384_A-12-qnli is a student model distilled from BERT base as teacher by using SEAD framework on qnli task. The model is intended for text classification tasks and has achieved an evaluation accuracy of 0.9098 on the qnli dataset. The model was trained with a learning rate of 5e-5, a batch size of 32, and a weight decay of 0.01 for 3 epochs. The model was trained using the Transformers library with PyTorch backend."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-textattack-distilbert-base-uncased-rotten-tomatoes", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased", "description": "A TextAttack fine-tuned model for sequence classification on the rotten_tomatoes dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 128, "learning_rate": 1e-05, "max_seq_length": 128, "loss_function": "cross-entropy"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a TextAttack fine-tuned model based on the distilbert-base-uncased architecture. It was fine-tuned for sequence classification on the rotten_tomatoes dataset using a cross-entropy loss function. The best score achieved was an eval set accuracy of 0.8395872420262664 after 2 epochs of training."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "mr-mr-movie-reviews"}], "metrics": [{"dataset": "mr-mr-movie-reviews", "metric": 0.8395872420262664, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-sammy786-wav2vec2-xlsr-dhivehi", "modules": [{"role": "model", "module": {"name": "sammy786/wav2vec2-xlsr-dhivehi", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-1b on the MOZILLA-FOUNDATION/COMMON_VOICE_8_0 - dv dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 4.56379946629835e-05, "train_batch_size": 8, "eval_batch_size": 16, "seed": 13, "gradient_accumulation_steps": 4, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "cosine_with_restarts", "lr_scheduler_warmup_steps": 500, "num_epochs": 30, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/wav2vec2-xls-r-1b on the MOZILLA-FOUNDATION/COMMON_VOICE_8_0 - dv dataset. The model is suitable for Automatic Speech Recognition tasks. The model was trained on Common Voice Finnish train.tsv, dev.tsv, and other.tsv datasets. The model achieved a Test WER of 29.32 and Test CER of 4.02. The model was trained using Adam optimizer with a learning rate of 0.000045637994662983496, cosine_with_restarts learning rate scheduler, and Native AMP mixed precision training."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 29.32, "protocol": "WER"}, {"dataset": "common-voice", "metric": 4.02, "protocol": "CER"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-fi-ho", "modules": [{"role": "model", "module": {"name": "opus-mt-fi-ho", "description": "A transformer-align model for translating from Finnish (fi) to Hiri Motu (ho)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-fi-ho is a transformer-align model for translating from Finnish to Hiri Motu. The model was trained on the OPUS dataset using normalization and SentencePiece pre-processing. The model achieved a BLEU score of 25.7 and a chr-F score of 0.496 on the JW300.fi.ho test set."}}], "metrics": [{"dataset": "jw300", "metric": 25.7, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.496, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-akashpb13-xlsr-kurmanji-kurdish", "modules": [{"role": "model", "module": {"name": "Akashpb13/xlsr_kurmanji_kurdish", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-300m on the MOZILLA-FOUNDATION/COMMON_VOICE_7_0 - hu dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 9.6e-05, "train_batch_size": 16, "eval_batch_size": 16, "gradient_accumulation_steps": 16, "lr_scheduler_type": "cosine_with_restarts", "lr_scheduler_warmup_steps": 200, "num_epochs": 100, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Akashpb13/xlsr_kurmanji_kurdish is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the MOZILLA-FOUNDATION/COMMON_VOICE_7_0 - hu dataset. The model is intended for automatic speech recognition tasks. The model was trained on Common voice Kurmanji Kurdish train.tsv, dev.tsv, invalidated.tsv, reported.tsv, and other.tsv datasets. The model achieved a WER of 0.33073206986250464 on the Common Voice 8 dataset and a WER of 0.388585 on the Robust Speech Event - Dev Data dataset."}}, {"role": "dataset", "purpose": "For evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.33073206986250464, "protocol": "wer"}, {"dataset": "common-voice", "metric": 0.08035244447163924, "protocol": "cer"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-lt-es", "modules": [{"role": "model", "module": {"name": "lit-spa", "description": "A transformer model for translating from Lithuanian to Spanish."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece (spm32k,spm32k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "lit-spa is a transformer model trained on Lithuanian and Spanish parallel data. It uses normalization and SentencePiece (spm32k,spm32k) for preprocessing. The model achieves a BLEU score of 50.5 and a chr-F score of 0.68 on the Tatoeba-test.lit.spa dataset. The model is suitable for translating from Lithuanian to Spanish."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "tatoeba"}], "metrics": [{"dataset": "tatoeba", "metric": 50.5, "protocol": "BLEU"}, {"dataset": "tatoeba", "metric": 0.68, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-ericrosello-bert-base-uncased-finetuned-squad-frozen-v2", "modules": [{"role": "model", "module": {"name": "bert-base-uncased-finetuned-squad", "description": "A fine-tuned version of bert-base-uncased on the squad dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 2, "eval_batch_size": 2, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "bert-base-uncased-finetuned-squad is a fine-tuned version of bert-base-uncased on the squad dataset. The model is best suited for question answering tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 2. The model was trained for 3 epochs and achieved an EM score of 76.77 and an F1 score of 85.42 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 76.77388836329234, "protocol": "EM"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 85.41893520501723, "protocol": "F1"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 1.4571, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-sahajtomar-german-question-answer-electra", "modules": [{"role": "model", "module": {"name": "GELECTRAQA", "description": "QA model trained on MLQA dataset for German language using GELECTRA Large by deepset.ai."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"per_gpu_train_batch_size": 4, "per_gpu_eval_batch_size": 32, "gradient_accumulation_steps": 8, "learning_rate": 3e-05, "num_train_epochs": 1.0, "max_seq_length": 384, "doc_stride": 128}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "GELECTRAQA is a QA model trained on the MLQA dataset for the German language using GELECTRA Large by deepset.ai. The model achieved good performance on the MLQA and XQUAD TEST datasets. The model is best suited for answering questions based on a given context. The hyperparameters used for training the model are provided. The model can be used for inference using the transformers library in Python."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "mlqa-multilingual-question-answering"}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-v3rx2000-distilbert-base-uncased-finetuned-squad", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-squad", "description": "A fine-tuned version of distilbert-base-uncased on the squad dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-squad is a fine-tuned version of distilbert-base-uncased on the squad dataset. It is suitable for question answering tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for 3 epochs and achieved a loss of 1.1580 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 1.158, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-mrm8488-deberta-v3-small-finetuned-mrpc", "modules": [{"role": "model", "module": {"name": "DeBERTa v3 (small) fine-tuned on MRPC", "description": "Fine-tuned version of microsoft/deberta-v3-small on the GLUE MRPC dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 3e-05, "train_batch_size": 16, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 10.0}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "DeBERTa v3 (small) is a transformer model fine-tuned on the GLUE MRPC dataset. It can be used for text classification tasks. The model achieved an accuracy of 0.8922 and an F1 score of 0.9233 on the evaluation set. The model was fine-tuned using Adam optimizer with a learning rate of 3e-05 and a batch size of 16. The model was trained for 10 epochs."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "mrpc-microsoft-research-paraphrase-corpus"}], "metrics": [{"dataset": "mrpc-microsoft-research-paraphrase-corpus", "metric": 0.8922, "protocol": "accuracy"}, {"dataset": "mrpc-microsoft-research-paraphrase-corpus", "metric": 0.9233, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-xrverse-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8600 on the evaluation set. The model is suitable for token classification tasks in German language. The training was done using Adam optimizer with a learning rate of 5e-05 and a linear learning rate scheduler. The model was trained for 3 epochs with a batch size of 24."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8600306626540231, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-ca-fr", "modules": [{"role": "model", "module": {"name": "cat-fra", "description": "A machine translation model that translates from Catalan to French."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece (spm12k,spm12k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "cat-fra is a machine translation model that translates from Catalan to French. It was trained on the Tatoeba dataset using the transformer-align model with normalization and SentencePiece preprocessing. The model achieved a BLEU score of 52.4 and a chr-F score of 0.694 on the Tatoeba-test.cat.fra test set."}}, {"role": "dataset", "purpose": "Test set used for evaluation.", "module": "tatoeba-translation-challenge"}], "metrics": [{"dataset": "tatoeba-translation-challenge", "metric": 52.4, "protocol": "BLEU"}, {"dataset": "tatoeba-translation-challenge", "metric": 0.694, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-sun1638650145-dqn-spaceinvadersnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "DQN", "description": "A trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "buffer_size": 100000, "exploration_final_eps": 0.01, "exploration_fraction": 0.1, "frame_stack": 4, "gradient_steps": 1, "learning_rate": 0.0001, "learning_starts": 100000, "n_timesteps": 1000000.0, "optimize_memory_usage": true, "policy": "CnnPolicy", "target_update_interval": 1000, "train_freq": 4, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "The DQN model is a reinforcement learning agent trained on the SpaceInvadersNoFrameskip-v4 environment using the stable-baselines3 library and the RL Zoo. The model achieved a mean reward of 544.50 +/- 176.63. The hyperparameters used for training include batch size, buffer size, exploration fraction, learning rate, and target update interval, among others. The RL Zoo provides a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 544.5, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-dooglak-tagged-uni-500v1-ner-model-3epochs-augmented", "modules": [{"role": "model", "module": {"name": "Tagged_Uni_500v1_NER_Model_3Epochs_AUGMENTED", "description": "A fine-tuned version of bert-base-cased on the tagged_uni500v1_wikigold_split dataset for named entity recognition (NER)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of bert-base-cased on the tagged_uni500v1_wikigold_split dataset for named entity recognition (NER). It achieves an F1 score of 0.7063 and an accuracy of 0.9309 on the evaluation set. The model was trained for 3 epochs with a linear learning rate scheduler and Adam optimizer with betas=(0.9,0.999) and epsilon=1e-08."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wikineural"}], "metrics": [{"dataset": "wikineural", "metric": 0.7048748353096179, "protocol": "precision"}, {"dataset": "wikineural", "metric": 0.7076719576719577, "protocol": "recall"}, {"dataset": "wikineural", "metric": 0.7062706270627063, "protocol": "f1"}, {"dataset": "wikineural", "metric": 0.9309102015882712, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-awilli-bert-finetuned-ner", "modules": [{"role": "model", "module": {"name": "bert-finetuned-ner", "description": "A fine-tuned version of bert-base-cased on the conll2003 dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-finetuned-ner is a fine-tuned version of bert-base-cased on the conll2003 dataset for token classification. The model achieved high precision, recall, F1 score, and accuracy on the evaluation set. The model is suitable for named entity recognition tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 0.9295401918623883, "protocol": "Precision"}, {"dataset": "conll-2003", "metric": 0.9458094917536183, "protocol": "Recall"}, {"dataset": "conll-2003", "metric": 0.9376042709376042, "protocol": "F1"}, {"dataset": "conll-2003", "metric": 0.9848413492670866, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-shoaibazam-dqn-spaceinvadersnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "DQN", "description": "A trained DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "buffer_size": 100000, "exploration_final_eps": 0.01, "exploration_fraction": 0.1, "frame_stack": 4, "gradient_steps": 1, "learning_rate": 0.0001, "learning_starts": 100000, "n_timesteps": 1000000, "optimize_memory_usage": false, "policy": "CnnPolicy", "target_update_interval": 1000, "train_freq": 4, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The model was trained with a batch size of 32, a buffer size of 100000, and a learning rate of 0.0001. The model achieved a mean reward of 466.00 +/- 213.32 on the SpaceInvadersNoFrameskip-v4 dataset. The RL Zoo is a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 466.0, "split": "val", "protocol": "mean_reward"}, {"dataset": "atari-grand-challenge", "metric": 213.32, "split": "test", "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-butchland-q-frozenlake-v1-8x8-slippery-work1", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained model of a Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1", "slippery": true}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model was trained using the Q-Learning algorithm on the FrozenLake-v1-8x8 environment. The model's performance is evaluated using the mean reward metric."}}, {"role": "dataset", "purpose": "The environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 0.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-es-xh", "modules": [{"role": "model", "module": {"name": "opus-mt-es-xh", "description": "A machine translation model that translates from Spanish (es) to Xhosa (xh) using the transformer-align architecture."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-es-xh is a machine translation model that translates from Spanish to Xhosa. It uses the transformer-align architecture and was preprocessed using normalization and SentencePiece. The model achieved a BLEU score of 25.0 and a chr-F score of 0.541 on the JW300.es.xh test set."}}], "metrics": [{"dataset": "jw300", "metric": 25.0, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.541, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-willheld-byt5-small-top-v2", "modules": [{"role": "model", "module": {"name": "byt5-small-top_v2", "description": "A fine-tuned version of google/byt5-small on the top_v2 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.001, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "gradient_accumulation_steps": 32, "total_train_batch_size": 512, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "training_steps": 3000}}}, {"role": "taskType", "module": "text-generation"}, {"role": "solutionSummary", "module": {"summary": "byt5-small-top_v2 is a fine-tuned version of google/byt5-small on the top_v2 dataset. It is a transformer model that can be used for text generation tasks. The model was trained with Adam optimizer with a learning rate of 0.001 and a linear learning rate scheduler. The model achieved a loss of 0.0164 and an exact match score of 0.8596 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "topv2-task-oriented-parsing-v2"}], "metrics": [{"dataset": "topv2-task-oriented-parsing-v2", "metric": 0.0164, "protocol": "loss"}, {"dataset": "topv2-task-oriented-parsing-v2", "metric": 0.8596, "protocol": "exact_match"}], "source": "huggingface"}, {"id": "huggingface-kuro96-q-frozenlake-v1-4x4-noslippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained model of a Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-4x4-no_slippery", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model's hyperparameters include the algorithm used, the environment, the maximum number of steps per episode, the number of episodes to evaluate the agent, the Q-Table learned by the agent, and the random seed used for evaluation. The model achieved a mean reward of 1.0 with no standard deviation."}}, {"role": "dataset", "purpose": "Environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-anuragshas-whisper-small-pa", "modules": [{"role": "model", "module": {"name": "Whisper Small Punjabi", "description": "A fine-tuned version of openai/whisper-small on the common_voice_11_0 dataset for Automatic Speech Recognition."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-05, "train_batch_size": 64, "eval_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "training_steps": 400, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Whisper Small Punjabi is a fine-tuned version of openai/whisper-small on the common_voice_11_0 dataset for Automatic Speech Recognition. The model achieved a WER of 39.0469 on the evaluation set. The model was trained using PyTorch and Transformers framework with a linear learning rate scheduler and Adam optimizer. The model was trained for 400 steps with a batch size of 64 and evaluated with a batch size of 32."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-mrm8488-t5-base-finetuned-common-gen", "modules": [{"role": "model", "module": {"name": "T5-base fine-tuned on CommonGen", "description": "A T5 transformer model fine-tuned on CommonGen for generative commonsense reasoning."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "T5-base", "max_length": 32}}}, {"role": "taskType", "module": "text-generation"}, {"role": "solutionSummary", "module": {"summary": "The T5-base model was fine-tuned on CommonGen, a dataset for generative commonsense reasoning. The model generates a coherent sentence describing an everyday scenario using a set of common concepts. The model is best suited for text generation tasks and requires relational reasoning using background commonsense knowledge and compositional generalization ability to work on unseen concept combinations."}}, {"role": "dataset", "purpose": "For model training, validation, and testing.", "module": "commongen"}], "metrics": [{"dataset": "commongen", "metric": 17.1, "protocol": "ROUGE-2"}, {"dataset": "commongen", "metric": 39.47, "protocol": "ROUGE-L"}], "source": "huggingface"}, {"id": "huggingface-turkish-nlp-suite-tr-vectors-web-md", "modules": [{"role": "model", "module": {"name": "Turkish Floret word vectors for spaCy", "description": "Medium sized Turkish word vectors trained on MC4 corpus using Floret."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "cbow", "dimension": 300, "mode": "floret", "bucket": 50000, "min_n": 4, "max_n": 5, "min_count": 100, "negative": 10, "hash_count": 2, "threads": 12, "epochs": 5}}}, {"role": "taskType", "module": "feature-extraction"}, {"role": "solutionSummary", "module": {"summary": "Turkish Floret word vectors for spaCy are medium-sized word vectors trained on MC4 corpus using Floret. The vectors have 50000 keys with 300 dimensions. These vectors can be used for feature extraction tasks such as token classification. The vectors are published in Floret format and are licensed under cc-by-sa-4.0."}}, {"role": "dataset", "purpose": "For model training.", "module": "mc4"}], "metrics": [{"dataset": "mc4", "metric": 0.1112, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-t-qualizer-distilbert-base-uncased-finetuned-advers", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-advers", "description": "A fine-tuned version of distilbert-base-uncased on the adversarial_qa dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 9e-05, "train_batch_size": 2, "eval_batch_size": 2, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "training_steps": 3000}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-advers is a fine-tuned version of distilbert-base-uncased on the adversarial_qa dataset. The model is suitable for question answering tasks. However, more information is needed to understand the model's intended uses and limitations. The model was trained using Adam optimizer with a learning rate of 9e-05 and a batch size of 2. The model was trained for 3000 steps and achieved a loss of 3.6462 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "adversarialqa"}], "metrics": [{"dataset": "adversarialqa", "metric": 3.6462, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-ericntay-bert-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "bert-finetuned-emotion", "description": "A fine-tuned version of bert-base-cased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 10, "eval_batch_size": 10, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-finetuned-emotion is a fine-tuned version of bert-base-cased on the emotion dataset. The model achieved an accuracy of 0.937 on the evaluation set. More information is needed to describe the model's intended uses and limitations, as well as the training and evaluation data."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emocontext"}], "metrics": [{"dataset": "emocontext", "metric": 0.937, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-plantdoctor-swin-tiny-patch4-window7-224-plant-doctor", "modules": [{"role": "model", "module": {"name": "swin-tiny-patch4-window7-224-plant-doctor", "description": "A fine-tuned version of microsoft/swin-tiny-patch4-window7-224 on the image_folder dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 4, "eval_batch_size": 4, "seed": 42, "gradient_accumulation_steps": 4, "total_train_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "num_epochs": 3}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "A fine-tuned version of microsoft/swin-tiny-patch4-window7-224 on the image_folder dataset. The model achieved an accuracy of 0.9983 on the evaluation set. More information is needed to describe the model and its intended uses and limitations."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "objectfolder"}], "metrics": [{"dataset": "objectfolder", "metric": 0.9982930298719772, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-sk-sv", "modules": [{"role": "model", "module": {"name": "opus-mt-sk-sv", "description": "A machine translation model that translates from Slovak (sk) to Swedish (sv) using the transformer-align architecture."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-sk-sv is a machine translation model that translates from Slovak to Swedish using the transformer-align architecture. The model was trained on the OPUS dataset and achieved a BLEU score of 33.1 on the JW300.sk.sv test set."}}], "metrics": [{"dataset": "jw300", "metric": 33.1, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.544, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-clp-vit-base-patch16-224-finetuned", "modules": [{"role": "model", "module": {"name": "vit-base-patch16-224-finetuned", "description": "A fine-tuned version of google/vit-base-patch16-224 on the imagefolder dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 32, "eval_batch_size": 32, "seed": 42, "gradient_accumulation_steps": 4, "total_train_batch_size": 128, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "num_epochs": 3}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of google/vit-base-patch16-224 on the imagefolder dataset. The model achieved an accuracy of 0.3333 on the evaluation set. More information is needed to describe the model and its intended uses and limitations."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "objectfolder"}], "metrics": [{"dataset": "objectfolder", "metric": 0.3333, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-crabz-slovakbert-ner", "modules": [{"role": "model", "module": {"name": "slovakbert-ner", "description": "Fine-tuned model on Slovak language for Named Entity Recognition using a token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 32, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 15.0}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "SlovakBERT is a fine-tuned transformer model on Slovak language for Named Entity Recognition using a token classification task. The model is trained on the Slovak wikiann dataset and achieves high precision, recall, F1 score, and accuracy on the evaluation set. The model is suitable for extracting entities such as location, person, and organization from Slovak text. The model can be used with the transformers library and spaCy's displaCy for visualization."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wikiann"}], "metrics": [{"dataset": "wikiann", "metric": 0.9327115256495669, "protocol": "Precision"}, {"dataset": "wikiann", "metric": 0.9470124013528749, "protocol": "Recall"}, {"dataset": "wikiann", "metric": 0.9398075632132469, "protocol": "F1"}, {"dataset": "wikiann", "metric": 0.9785228256835333, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-meln1k-q-taxi-v3-v1", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3-v1", "description": "A Q-Learning agent trained to play the Taxi-v3 environment."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 environment. The agent's Q-Table is provided, along with hyperparameters such as the maximum number of steps per episode and the number of episodes used to evaluate the agent. The model's performance is evaluated based on the mean reward achieved over multiple episodes."}}, {"role": "dataset", "purpose": "OpenAI Gym environment", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 7.56, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-flair-ner-french", "modules": [{"role": "model", "module": {"name": "Flair French NER (default model)", "description": "A 4-class NER model for French that uses Flair embeddings and LSTM-CRF."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"hidden_size": 256, "embeddings": ["WordEmbeddings('fr')", "FlairEmbeddings('fr-forward')", "FlairEmbeddings('fr-backward')"], "tag_type": "ner", "max_epochs": 150}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a 4-class NER model for French that uses Flair embeddings and LSTM-CRF. The model predicts the following tags: person name, location name, organization name, and other name. The model is best suited for downstream tasks that require named entity recognition. The model was trained on the WikiNER dataset and achieved an F1-Score of 90.61. The Flair issue tracker is available for any issues."}}, {"role": "dataset", "purpose": "For evaluation.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 90.61, "protocol": "F1-Score"}], "source": "huggingface"}, {"id": "huggingface-sb3-trpo-reacherbulletenv-v0", "modules": [{"role": "model", "module": {"name": "TRPO", "description": "A trained TRPO agent playing ReacherBulletEnv-v0 using the stable-baselines3 library."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 128, "cg_damping": 0.1, "cg_max_steps": 25, "gae_lambda": 0.95, "gamma": 0.99, "learning_rate": 0.001, "n_critic_updates": 20, "n_envs": 2, "n_steps": 1024, "n_timesteps": 300000.0, "normalize": true, "policy": "MlpPolicy", "policy_kwargs": {"log_std_init": -1, "ortho_init": false, "activation_fn": "nn.ReLU", "net_arch": [{"pi": [256, 256], "vf": [256, 256]}]}, "sub_sampling_factor": 1, "normalize_kwargs": {"norm_obs": true, "norm_reward": false}}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained TRPO agent playing ReacherBulletEnv-v0 using the stable-baselines3 library. The model was trained using the RL Zoo training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included. The model achieved a mean reward of 16.05 +/- 9.75 on the ReacherBulletEnv-v0 dataset."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "deepmind-control-suite"}], "metrics": [{"dataset": "deepmind-control-suite", "metric": 16.05, "split": "val", "protocol": "mean_reward"}, {"dataset": "deepmind-control-suite", "metric": 9.75, "split": "test", "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-tomascufaro-wav2vec2-large-xls-r-300m-spanish-small-v3", "modules": [{"role": "model", "module": {"name": "wav2vec2-large-xls-r-300m-spanish-small-v3", "description": "Fine-tuned version of jhonparra18/wav2vec2-large-xls-r-300m-spanish-custom on the common_voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0004, "train_batch_size": 8, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 25, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of jhonparra18/wav2vec2-large-xls-r-300m-spanish-custom on the common_voice dataset. The model is suitable for automatic speech recognition tasks. The model was trained using Adam optimizer with a learning rate of 0.0004, and a linear learning rate scheduler with warmup steps of 500. The model was trained for 25 epochs with a batch size of 16. The model achieved a loss of 0.3986 and a word error rate (WER) of 0.1980 on the evaluation set. The model was trained using Transformers 4.17.0.dev0, Pytorch 1.10.2+cu102, Datasets 1.18.2.dev0, and Tokenizers 0.11.0."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.3986, "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.198, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-jas100-bert-finetuned-ner", "modules": [{"role": "model", "module": {"name": "bert-finetuned-ner", "description": "A fine-tuned version of bert-base-cased on the conll2003 dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-finetuned-ner is a fine-tuned version of bert-base-cased on the conll2003 dataset for token classification. The model achieved high precision, recall, F1 score, and accuracy on the evaluation set. The model is suitable for named entity recognition tasks, but caution should be taken when deploying it in human-interacting systems as it may reflect the biases of the systems it was trained on."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 0.9330024813895782, "protocol": "Precision"}, {"dataset": "conll-2003", "metric": 0.9491753618310333, "protocol": "Recall"}, {"dataset": "conll-2003", "metric": 0.9410194377242012, "protocol": "F1"}, {"dataset": "conll-2003", "metric": 0.9865926885265203, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-fabiochiu-t5-base-medium-title-generation", "modules": [{"role": "model", "module": {"name": "t5-base-medium-title-generation", "description": "A T5 transformer model fine-tuned on the 190k Medium Articles dataset for predicting article titles using the article textual content as input."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_type": "T5", "pretrained_model": "t5-base", "batch_size": 1, "num_beams": 8, "do_sample": true, "min_length": 10, "max_length": 64}}}, {"role": "taskType", "module": "text-generation"}, {"role": "solutionSummary", "module": {"summary": "t5-base-medium-title-generation is a T5 transformer model fine-tuned on the 190k Medium Articles dataset for predicting article titles using the article textual content as input. The model is best suited for generating short titles for articles. The model has been evaluated on a random dataset split of 1000 articles not used during training and validation. The model uses the T5 architecture and has been trained using TensorFlow 2.8.0 and Transformers 4.18.0."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "mmed"}], "metrics": [{"dataset": "mmed", "metric": 37.9, "protocol": "Rouge-1"}, {"dataset": "mmed", "metric": 24.4, "protocol": "Rouge-2"}, {"dataset": "mmed", "metric": 35.9, "protocol": "Rouge-L"}, {"dataset": "mmed", "metric": 35.9, "protocol": "Rouge-Lsum"}], "source": "huggingface"}, {"id": "huggingface-hoang-distilbert-base-uncased-finetuned-squad", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-squad", "description": "A fine-tuned version of distilbert-base-uncased on the squad dataset for question answering."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-squad is a fine-tuned version of distilbert-base-uncased on the squad dataset for question answering. The model achieved a loss of 1.1582 on the evaluation set. The model is suitable for question answering tasks, but its performance may vary depending on the nature of the questions and the context of the answers."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 1.1582, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-mrm8488-electricidad-small-finetuned-squadv1-es", "modules": [{"role": "model", "module": {"name": "Electricidad small + Spanish SQuAD v1", "description": "A fine-tuned Electra model on Spanish SQuAD v1.1 dataset for Q&A downstream task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_type": "Electra", "train_batch_size": 16, "learning_rate": 3e-05, "num_train_epochs": 10, "max_seq_length": 384, "doc_stride": 128}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "The Electricidad small + Spanish SQuAD v1 is a fine-tuned Electra model on Spanish SQuAD v1.1 dataset for Q&A downstream task. The model was trained on a Tesla P100 GPU and 25GB of RAM. The model can be used for Q&A tasks in Spanish language. The model achieved an EM score of 46.82 and an F1 score of 64.79 on the test set. The model can be used with pipelines for fast usage."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 46.82, "protocol": "EM"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 64.79, "protocol": "F1"}], "source": "huggingface"}, {"id": "huggingface-mrcoombes-distilbert-wikipedia-pokemon", "modules": [{"role": "model", "module": {"name": "DistilBERT pokemon model (uncased)", "description": "Distilled version of the BERT base model fine-tuned for sequence classification using data from the notes field of Wikipedia tables to predict the pokemon-type of a given pokedex entry."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"distillation_loss": true, "masked_language_modeling_loss": true, "cosine_embedding_loss": true}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "DistilBERT pokemon model is a smaller and faster version of the BERT base model that has been fine-tuned for sequence classification using data from the notes field of Wikipedia tables to predict the pokemon-type of a given pokedex entry. The model was pre-trained on the same corpus as BERT base model in a self-supervised fashion, using the BERT base model as a teacher. The model is suitable for text classification tasks, but it has limitations due to class imbalances in the data. The accuracy of the model could be improved by using over-sampling and under-sampling techniques."}}, {"role": "dataset", "purpose": "For model training.", "module": "wikitablet"}], "metrics": [{"dataset": "wikitablet", "metric": 0.47, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-dmiller1-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. The model is best suited for text classification tasks. The model achieved an accuracy of 0.926 and an F1 score of 0.9261 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.926, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.9261144741040841, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-ttmusic-distilbert-base-uncased-finetuned-imdb", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-imdb", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 128, "eval_batch_size": 128, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-imdb is a fine-tuned version of distilbert-base-uncased on the imdb dataset. It can be used for text classification tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 128. The model was trained for 3 epochs and achieved a loss of 2.4513 on the evaluation set. The model was trained using PyTorch 1.10.2+cu113 and Transformers 4.17.0."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 2.4513, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-sanchit-gandhi-wav2vec2-2-rnd-no-adapter", "modules": [{"role": "model", "module": {"name": "Unnamed ASR model", "description": "A speech recognition model trained on the librispeech_asr dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 3e-05, "train_batch_size": 8, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 4, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 1000, "num_epochs": 20.0, "mixed_precision_training": true}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "An ASR model trained on the librispeech_asr dataset. The model was trained from scratch and achieved a loss of 0.8384 and a WER of 0.1367 on the evaluation set. The model was trained using the Transformers library with PyTorch backend and optimized using Adam optimizer with a learning rate of 3e-05. The model was trained for 20 epochs with mixed precision training enabled."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "librispeech"}], "metrics": [{"dataset": "librispeech", "metric": 0.8678, "split": "val", "protocol": "loss"}, {"dataset": "librispeech", "metric": 0.8384, "split": "test", "protocol": "loss"}, {"dataset": "librispeech", "metric": 0.1405, "split": "val", "protocol": "wer"}, {"dataset": "librispeech", "metric": 0.1367, "split": "test", "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-linkthesinger-dialogpt-small-kannav4", "modules": [{"role": "model", "module": {"name": "Kanna Kamui DialoGPT Model", "description": "A conversational AI model based on DialoGPT architecture, fine-tuned on Kanna Kamui character from the anime series Miss Kobayashi's Dragon Maid."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"max_length": 1024, "num_attention_heads": 16, "num_layers": 6, "num_train_epochs": 3, "per_device_train_batch_size": 2, "per_device_eval_batch_size": 2, "warmup_steps": 500, "learning_rate": 5e-05}}}, {"role": "taskType", "module": "conversational"}, {"role": "solutionSummary", "module": {"summary": "Kanna Kamui DialoGPT Model is a conversational AI model based on DialoGPT architecture, fine-tuned on Kanna Kamui character from the anime series Miss Kobayashi's Dragon Maid. The model is trained on the Anime Dialogue Dataset and can generate responses to user inputs. The model's hyperparameters include max_length, num_attention_heads, num_layers, num_train_epochs, per_device_train_batch_size, per_device_eval_batch_size, warmup_steps, and learning_rate. The model achieved a perplexity score of 11.2 on the Anime Dialogue Dataset."}}, {"role": "dataset", "purpose": "For model training.", "module": "dailydialog"}], "metrics": [{"dataset": "dailydialog", "metric": 11.2, "protocol": "Perplexity"}], "source": "huggingface"}, {"id": "huggingface-tner-roberta-large-fin", "modules": [{"role": "model", "module": {"name": "tner/roberta-large-fin", "description": "A fine-tuned version of roberta-large on the tner/fin dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "roberta-large", "crf": true, "max_length": 128, "epoch": 15, "batch_size": 64, "lr": 1e-05, "gradient_accumulation_steps": 1, "lr_warmup_step_ratio": 0.1, "max_grad_norm": 10.0}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "tner/roberta-large-fin is a fine-tuned version of roberta-large on the tner/fin dataset for token classification. The model is best suited for named entity recognition tasks. It achieves an F1 score of 0.698 on the test set. The model can be used through the tner library or the transformers library, but the CRF layer is not supported in the latter. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "finer-finnish-news-corpus-for-named-entity-recognition"}], "metrics": [{"dataset": "finer-finnish-news-corpus-for-named-entity-recognition", "metric": 0.6988727858293075, "protocol": "f1"}, {"dataset": "finer-finnish-news-corpus-for-named-entity-recognition", "metric": 0.7161716171617162, "protocol": "precision"}, {"dataset": "finer-finnish-news-corpus-for-named-entity-recognition", "metric": 0.6823899371069182, "protocol": "recall"}, {"dataset": "finer-finnish-news-corpus-for-named-entity-recognition", "metric": 0.45636958249281745, "protocol": "f1_macro"}, {"dataset": "finer-finnish-news-corpus-for-named-entity-recognition", "metric": 0.4519134760270864, "protocol": "precision_macro"}, {"dataset": "finer-finnish-news-corpus-for-named-entity-recognition", "metric": 0.4705942205942206, "protocol": "recall_macro"}, {"dataset": "finer-finnish-news-corpus-for-named-entity-recognition", "metric": 0.7087378640776698, "protocol": "f1_entity_span"}, {"dataset": "finer-finnish-news-corpus-for-named-entity-recognition", "metric": 0.7227722772277227, "protocol": "precision_entity_span"}, {"dataset": "finer-finnish-news-corpus-for-named-entity-recognition", "metric": 0.6952380952380952, "protocol": "recall_entity_span"}], "source": "huggingface"}, {"id": "huggingface-lewtun-minilm-l12-h384-uncased-finetuned-imdb", "modules": [{"role": "model", "module": {"name": "MiniLM-L12-H384-uncased-finetuned-imdb", "description": "A fine-tuned version of microsoft/MiniLM-L12-H384-uncased on the imdb dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "fill-mask"}, {"role": "solutionSummary", "module": {"summary": "MiniLM-L12-H384-uncased-finetuned-imdb is a fine-tuned version of microsoft/MiniLM-L12-H384-uncased on the imdb dataset. It can be used for masked language modeling tasks such as fill-mask. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 64. The model was trained for 3 epochs and achieved a loss of 3.9328 on the evaluation set. The model was trained using PyTorch 1.9.1+cu111 and Transformers 4.10.3."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 3.9328, "protocol": "Loss"}], "source": "huggingface"}, {"id": "huggingface-kinit-slovakbert-pos", "modules": [{"role": "model", "module": {"name": "POS tagger based on SlovakBERT", "description": "A POS tagger based on SlovakBERT, fine-tuned on the Slovak part of the Universal Dependencies dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "SlovakBERT", "tagset": "Universal POS tagset (UPOS)"}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a POS tagger based on SlovakBERT, fine-tuned on the Slovak part of the Universal Dependencies dataset. The model uses the Universal POS tagset (UPOS) and achieves an accuracy of 97.84%."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "universal-dependencies"}], "metrics": [{"dataset": "universal-dependencies", "metric": 0.9784, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-alekseykorshuk-amazon-reviews-input-output-6-7b", "modules": [{"role": "model", "module": {"name": "amazon-reviews-input-output-6.7b", "description": "Fine-tuned version of facebook/opt-6.7b on the AlekseyKorshuk/amazon-reviews-input-output dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "num_epochs": 2.0}}}, {"role": "taskType", "module": "text-generation"}, {"role": "solutionSummary", "module": {"summary": "amazon-reviews-input-output-6.7b is a fine-tuned version of facebook/opt-6.7b on the AlekseyKorshuk/amazon-reviews-input-output dataset. The model is suitable for text generation tasks. The model achieved an accuracy of 0.0388 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 5e-05 for 2 epochs. The model was trained using PyTorch 1.12.1+cu113 and Transformers 4.25.0.dev0."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "amazon-product-data"}], "metrics": [{"dataset": "amazon-product-data", "metric": 0.03882113821138211, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-scottykwok-wav2vec2-large-xlsr-cantonese", "modules": [{"role": "model", "module": {"name": "Wav2vec2-large-xlsr-cantonese", "description": "A speech recognition model based on wav2vec2-large-xlsr-53, fine-tuned on Common Voice/zh-HK/6.1.0."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"training_epochs": 80, "fp16_backend": "apex"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Wav2vec2-large-xlsr-cantonese is a speech recognition model based on wav2vec2-large-xlsr-53, fine-tuned on Common Voice/zh-HK/6.1.0. The model was trained for 80 epochs using fp16_backend apex. The model achieved a CER of 15.11% when evaluated against the Common Voice/zh-HK/6.1.0 test set. The model can be used for transcribing Cantonese speech."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 15.11, "protocol": "cer"}], "source": "huggingface"}, {"id": "huggingface-meshalalamr-wav2vec2-xls-r-300m-ar-11", "modules": [{"role": "model", "module": {"name": "wav2vec2-xls-r-300m-ar-11", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0003, "train_batch_size": 64, "eval_batch_size": 16, "seed": 42, "gradient_accumulation_steps": 4, "total_train_batch_size": 256, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 30, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "wav2vec2-xls-r-300m-ar-11 is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset. It is suitable for automatic speech recognition tasks. The model was trained with Adam optimizer with a learning rate of 0.0003, and a linear learning rate scheduler with warmup steps of 500. The model was trained for 30 epochs with a batch size of 256. The model achieved a loss of 60.5659 and a word error rate (WER) of 0.2144 on the evaluation set. The model was trained using Transformers 4.17.0, Pytorch 1.11.0, Datasets 1.18.4, and Tokenizers 0.11.6."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 60.5659, "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.2144, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-thapasushil-vit-base-cifar10", "modules": [{"role": "model", "module": {"name": "vit-base-cifar10", "description": "A fine-tuned version of nateraw/vit-base-patch16-224-cifar10 on the cifar10-upside-down dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0002, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "vit-base-cifar10 is a fine-tuned version of nateraw/vit-base-patch16-224-cifar10 on the cifar10-upside-down dataset. It is a Vision Transformer model that achieved an evaluation accuracy of 0.9134. The model was trained using PyTorch and Transformers 4.18.0 with a linear learning rate scheduler and Native AMP mixed precision training for 5 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "cifar-10"}], "metrics": [{"dataset": "cifar-10", "metric": 0.2348, "protocol": "eval_loss"}, {"dataset": "cifar-10", "metric": 0.9134, "protocol": "eval_accuracy"}, {"dataset": "cifar-10", "metric": 157.4172, "protocol": "eval_runtime"}, {"dataset": "cifar-10", "metric": 127.051, "protocol": "eval_samples_per_second"}, {"dataset": "cifar-10", "metric": 1.988, "protocol": "eval_steps_per_second"}, {"dataset": "cifar-10", "metric": 0.02, "protocol": "epoch"}, {"dataset": "cifar-10", "metric": 26.0, "protocol": "step"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-es-ln", "modules": [{"role": "model", "module": {"name": "opus-mt-es-ln", "description": "A machine translation model that translates from Spanish (es) to Lingala (ln) using a transformer-align model."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-es-ln is a machine translation model that translates from Spanish to Lingala. It uses a transformer-align model and was preprocessed using normalization and SentencePiece. The model achieved a BLEU score of 27.1 and a chr-F score of 0.508 on the JW300.es.ln test set."}}], "metrics": [{"dataset": "jw300", "metric": 27.1, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.508, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-shed-e-mlm", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-imdb", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-imdb is a fine-tuned version of distilbert-base-uncased on the imdb dataset. It can be used for text classification tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 64. The model was trained for 3 epochs and achieved a loss of 2.4353 on the evaluation set. The model was trained using PyTorch and Transformers libraries."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 2.4353, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-eslamxm-mt5-base-finetuned-english", "modules": [{"role": "model", "module": {"name": "mt5-base-finetuned-english", "description": "A fine-tuned version of google/mt5-base on the xlsum dataset for abstractive summarization."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0005, "train_batch_size": 4, "eval_batch_size": 4, "seed": 42, "gradient_accumulation_steps": 8, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5, "label_smoothing_factor": 0.1}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "mt5-base-finetuned-english is a transformer model fine-tuned on the xlsum dataset for abstractive summarization. It achieves good results on the evaluation set, with a Rouge-1 score of 31.7 and a Bertscore of 74.3. The model is intended for abstractive summarization tasks, but its limitations and intended uses are not specified. The model was trained using Adam optimizer with a learning rate of 0.0005 and a linear learning rate scheduler for 5 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xl-sum"}], "metrics": [{"dataset": "xl-sum", "metric": 3.3271, "protocol": "Loss"}, {"dataset": "xl-sum", "metric": 31.7, "protocol": "Rouge-1"}, {"dataset": "xl-sum", "metric": 11.83, "protocol": "Rouge-2"}, {"dataset": "xl-sum", "metric": 26.43, "protocol": "Rouge-l"}, {"dataset": "xl-sum", "metric": 18.88, "protocol": "Gen Len"}, {"dataset": "xl-sum", "metric": 74.3, "protocol": "Bertscore"}], "source": "huggingface"}, {"id": "huggingface-sppeach-nli-distilroberta-base-finetuned-cola", "modules": [{"role": "model", "module": {"name": "nli-distilroberta-base-finetuned-cola", "description": "Fine-tuned version of cross-encoder/nli-distilroberta-base on the glue dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of cross-encoder/nli-distilroberta-base on the glue dataset. It can be used for text classification tasks. The model achieved a Matthews Correlation score of 0.4957 on the evaluation set. The model was trained with Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler. The model was trained for 5 epochs with a batch size of 16."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.49571112155193453, "protocol": "matthews_correlation"}], "source": "huggingface"}, {"id": "huggingface-jcastanyo-q-frozenlake-v1-8x8-noslippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-8x8-no_slippery", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model's hyperparameters include the algorithm used, the environment, the maximum number of steps per episode, the number of episodes to evaluate the agent, the Q-Table learned by the agent, and the random seed used for evaluation. The model achieved a mean reward of 1.0 with no standard deviation."}}, {"role": "dataset", "purpose": "Environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-muks-q-taxi-v0", "modules": [{"role": "model", "module": {"name": "q-Taxi-v0", "description": "A Q-Learning agent trained to play the Taxi-v3 environment."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "q-Taxi-v0 is a Q-Learning agent trained to play the Taxi-v3 environment. The model's hyperparameters include the maximum number of steps per episode, the number of episodes to evaluate the agent, the Q-Table learned by the agent, and the random seed used for evaluation. The model's performance is evaluated based on the mean reward achieved over multiple episodes."}}, {"role": "dataset", "purpose": "OpenAI Gym environment", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.56, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-jellevdl-bert-test-model", "modules": [{"role": "model", "module": {"name": "Bert-test-model", "description": "Fine-tuned version of bert-base-uncased on the squad dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "Bert-test-model is a fine-tuned version of bert-base-uncased on the squad dataset. It is suitable for question answering tasks. The model was trained for 3 epochs with a learning rate of 2e-05 and an Adam optimizer with betas=(0.9,0.999) and epsilon=1e-08. The model achieved a loss of 1.3708 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 1.3708, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-jackoyoungblood-qrdqn-spaceinvadersnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "QRDQN Agent playing SpaceInvadersNoFrameskip-v4", "description": "A trained model of a QRDQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"env_wrapper": "stable_baselines3.common.atari_wrappers.AtariWrapper", "exploration_fraction": 0.025, "frame_stack": 4, "n_timesteps": 10000000.0, "optimize_memory_usage": true, "policy": "CnnPolicy", "replay_buffer_kwargs": "dict(handle_timeout_termination=False)", "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a QRDQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The model was trained with hyperparameters such as exploration_fraction, frame_stack, n_timesteps, optimize_memory_usage, policy, replay_buffer_kwargs, and normalize. The model achieved a mean_reward of 2441.50 with a standard deviation of 1153.35."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 2441.5, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-ryanblak-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 environment."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 environment. The agent's Q-Table is provided, along with hyperparameters such as the maximum number of steps per episode and the number of episodes used to evaluate the agent. The model's performance is evaluated based on the mean reward achieved over multiple episodes."}}, {"role": "dataset", "purpose": "OpenAI Gym environment", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.54, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-yoshitomo-matsubara-bert-large-uncased-mnli", "modules": [{"role": "model", "module": {"name": "bert-large-uncased", "description": "Pretrained model on English language using a masked language modeling (MLM) objective."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": "not specified", "optimizer": {"name": "Adam", "learning_rate": "same as in BERT paper", "beta1": "same as in BERT paper", "beta2": "same as in BERT paper", "weight_decay": "same as in BERT paper"}}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-large-uncased is a transformer model pre-trained on a large English corpus. It was fine-tuned on the MNLI dataset using torchdistill and Google Colab. The model achieved an overall GLUE score of 80.2. The hyperparameters are the same as those in Hugging Face's example and/or the paper of BERT."}}, {"role": "dataset", "purpose": "For fine-tuning.", "module": "multinli-multi-genre-natural-language-inference"}], "metrics": [{"dataset": "multinli-multi-genre-natural-language-inference", "metric": 0.802, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-hhffxx-distilbert-base-uncased-finetuned-clinc", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-clinc", "description": "A fine-tuned version of distilbert-base-uncased on the clinc_oos dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 12, "eval_batch_size": 12, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-clinc is a fine-tuned version of distilbert-base-uncased on the clinc_oos dataset. It is a text classification model that can be used to classify out-of-scope queries. The model achieved an accuracy of 0.9503 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler for 5 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "clinc-single-domain-oos"}], "metrics": [{"dataset": "clinc-single-domain-oos", "metric": 0.9503225806451613, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-fr-ar", "modules": [{"role": "model", "module": {"name": "fra-ara", "description": "A transformer model pre-trained on French and Arabic languages for translation from French to Arabic."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece (spm32k,spm32k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "fra-ara is a transformer model pre-trained on French and Arabic languages for translation from French to Arabic. The model was trained on the Tatoeba dataset and achieved a BLEU score of 14.4 and a chrF2 score of 0.439 on the Tatoeba-test.fra.ara test set. The model uses normalization and SentencePiece (spm32k,spm32k) for pre-processing. The model is suitable for translation tasks from French to Arabic."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "tatoeba"}], "metrics": [{"dataset": "tatoeba", "metric": 14.4, "protocol": "BLEU"}, {"dataset": "tatoeba", "metric": 0.439, "protocol": "chrF2_score"}], "source": "huggingface"}, {"id": "huggingface-lewtun-test-hub-pr-1", "modules": [{"role": "model", "module": {"name": "bhadresh-savani/distilbert-base-uncased-emotion", "description": "DistilBERT model pre-trained on a large corpus of English data in a self-supervised fashion."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_type": "DistilBERT", "pretrained_weights": "distilbert-base-uncased", "batch_size": 8, "optimizer": {"name": "AdamW", "learning_rate": 5e-05, "epsilon": 1e-08, "weight_decay": 0.01}, "training_steps": 2000}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "DistilBERT is a transformer model pre-trained on a large English corpus. It can be used for text classification tasks. The model is best suited for tasks that require fast inference times and have limited computational resources. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.9298, "protocol": "Accuracy"}, {"dataset": "emotionlines", "metric": 0.9434585224927775, "protocol": "Precision"}, {"dataset": "emotionlines", "metric": 0.9144, "protocol": "Recall"}, {"dataset": "emotionlines", "metric": 0.9566112000000001, "protocol": "AUC"}, {"dataset": "emotionlines", "metric": 0.9287020109689214, "protocol": "F1"}], "source": "huggingface"}, {"id": "huggingface-prajjwal1-bert-mini-mnli", "modules": [{"role": "model", "module": {"name": "PyTorch BERT variants", "description": "Pretrained model on MNLI using PyTorch."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"epochs": 4}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "These PyTorch BERT variants are pre-trained models obtained by converting the TensorFlow checkpoint found in the official Google BERT repository. They were introduced in the paper 'Well-Read Students Learn Better: On the Importance of Pre-training Compact Models' and trained on MNLI for 4 epochs. The model is suitable for text classification tasks, and the accuracy on MNLI is 68.04% and 69.17% for MNLI-mm. If using this model, please consider citing the paper by Prajjwal Bhargava, Aleksandr Drozd, and Anna Rogers."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "multinli-multi-genre-natural-language-inference"}], "metrics": [{"dataset": "multinli-multi-genre-natural-language-inference", "metric": 68.04, "protocol": "accuracy"}, {"dataset": "multinli-multi-genre-natural-language-inference", "metric": 69.17, "protocol": "accuracy_mm"}], "source": "huggingface"}, {"id": "huggingface-danielev9h-hubert-base-timit-demo-google-colab-ft30ep-v4", "modules": [{"role": "model", "module": {"name": "hubert-base-timit-demo-google-colab-ft35ep", "description": "Fine-tuned version of facebook/hubert-base-ls960 on the timit-asr dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0001, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 1000, "num_epochs": 30, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "hubert-base-timit-demo-google-colab-ft35ep is a fine-tuned version of facebook/hubert-base-ls960 on the timit-asr dataset. The model is suitable for automatic speech recognition tasks. The model was trained with Adam optimizer with a learning rate of 0.0001, and a batch size of 8. The model was trained for 30 epochs with a linear learning rate scheduler and mixed precision training. The model achieved a loss of 0.4602 and a word error rate (WER) of 0.3466 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "timit-timit-acoustic-phonetic-continuous-speech-corpus"}], "metrics": [{"dataset": "timit-timit-acoustic-phonetic-continuous-speech-corpus", "metric": 0.4602, "protocol": "loss"}, {"dataset": "timit-timit-acoustic-phonetic-continuous-speech-corpus", "metric": 0.3466, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-alireza1044-albert-base-v2-cola", "modules": [{"role": "model", "module": {"name": "cola", "description": "Fine-tuned version of albert-base-v2 on the GLUE COLA dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-05, "train_batch_size": 16, "eval_batch_size": 8, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 4.0}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of albert-base-v2 on the GLUE COLA dataset. It can be used for text classification tasks. The model achieved a Matthews Correlation score of 0.5495 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 1e-05 and a batch size of 16. The model was trained for 4 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "cola-corpus-of-linguistic-acceptability"}], "metrics": [{"dataset": "cola-corpus-of-linguistic-acceptability", "metric": 0.5495, "protocol": "matthews_correlation"}], "source": "huggingface"}, {"id": "huggingface-jyotiyadav-eurocorpv4", "modules": [{"role": "model", "module": {"name": "eurocorpV4", "description": "A fine-tuned version of microsoft/layoutlmv3-large on the sroie dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-05, "train_batch_size": 2, "eval_batch_size": 2, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "training_steps": 1000}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "eurocorpV4 is a fine-tuned version of microsoft/layoutlmv3-large on the sroie dataset. It is a token classification model that achieves high precision, recall, F1, and accuracy scores on the test set. The model was trained using Adam optimizer with a learning rate of 1e-05, a batch size of 2, and a linear learning rate scheduler. The model was trained for 1000 steps."}}], "metrics": [{"dataset": "sroie", "metric": 0.9548022598870056, "protocol": "Precision"}, {"dataset": "sroie", "metric": 0.9602272727272727, "protocol": "Recall"}, {"dataset": "sroie", "metric": 0.9575070821529744, "protocol": "F1"}, {"dataset": "sroie", "metric": 0.9819121447028424, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-dooglak-article-250v4-ner-model-3epochs-unaugmented", "modules": [{"role": "model", "module": {"name": "Article_250v4_NER_Model_3Epochs_UNAUGMENTED", "description": "Fine-tuned version of bert-base-cased on the article250v4_wikigold_split dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of bert-base-cased on the article250v4_wikigold_split dataset for token classification. It achieved a precision of 0.4027, recall of 0.4337, F1 score of 0.4176, and accuracy of 0.8775 on the evaluation set. The model was trained for 3 epochs with a batch size of 8 and a learning rate of 2e-05 using the Adam optimizer with betas=(0.9,0.999) and epsilon=1e-08."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wikiwiki"}], "metrics": [{"dataset": "wikiwiki", "metric": 0.40273125483122907, "protocol": "precision"}, {"dataset": "wikiwiki", "metric": 0.433684794672586, "protocol": "recall"}, {"dataset": "wikiwiki", "metric": 0.4176352705410822, "protocol": "f1"}, {"dataset": "wikiwiki", "metric": 0.8774915169033556, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-guruji108-xlm-roberta-base-finetuned-panx-en", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-en", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "xlm-roberta-base-finetuned-panx-en is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification. The model achieved an F1 score of 0.7032 on the evaluation set. The model is suitable for token classification tasks, but its intended uses and limitations are not specified in the model card."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.7032474804031354, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-cardiffnlp-twitter-roberta-base-dec2021-hate", "modules": [{"role": "model", "module": {"name": "cardiffnlp/twitter-roberta-base-dec2021-hate", "description": "Fine-tuned version of cardiffnlp/twitter-roberta-base-dec2021 on the tweet_eval (hate) dataset via tweetnlp."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"max_length": 128}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "cardiffnlp/twitter-roberta-base-dec2021-hate is a fine-tuned version of cardiffnlp/twitter-roberta-base-dec2021 on the tweet_eval (hate) dataset via tweetnlp. The model is a text classification model that can predict whether a given text contains hate speech or not. The model achieved a micro F1 score of 0.5667, a macro F1 score of 0.5411, and an accuracy of 0.5667 on the test split of the tweet_eval dataset."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "tweeteval"}], "metrics": [{"dataset": "tweeteval", "metric": 0.5666666666666667, "protocol": "micro_f1_tweet_eval/hate"}, {"dataset": "tweeteval", "metric": 0.5411020518761093, "protocol": "macro_f1_tweet_eval/hate"}, {"dataset": "tweeteval", "metric": 0.5666666666666667, "protocol": "accuracy_tweet_eval/hate"}], "source": "huggingface"}, {"id": "huggingface-hrushi-q-frozenlake-v1-4x4-noslippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-4x4-no_slippery", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent playing FrozenLake-v1. The model includes the Q-Table learned by the agent and can be used to evaluate the agent's performance. The environment used for training and evaluation is FrozenLake-v1-4x4-no_slippery."}}, {"role": "dataset", "purpose": "Environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-team-nave-xlm-roberta-base-finetuned-panx-fr", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-fr", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 48, "eval_batch_size": 48, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "xlm-roberta-base-finetuned-panx-fr is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. The model achieved an F1 score of 0.8393 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 5e-05 and a batch size of 48 for 3 epochs. The model was trained using the Transformers 4.11.3, Pytorch 1.12.1, Datasets 1.16.1, and Tokenizers 0.10.3."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.839261744966443, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-histinct7002-distilbert-base-uncased-finetuned-cola", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-cola", "description": "A fine-tuned version of distilbert-base-uncased on the glue dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-cola is a fine-tuned version of distilbert-base-uncased on the glue dataset. It is suitable for text classification tasks. The model achieved a Matthews Correlation score of 0.5291 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 16 for 5 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.5290966132843783, "protocol": "matthews_correlation"}], "source": "huggingface"}, {"id": "huggingface-qianmolloy-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. The model is best suited for text classification tasks. The model achieved an accuracy of 0.9285 and an F1 score of 0.9289 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.9285, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.928851862350588, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-masakhane-m2m100-418m-fon-fr-rel-news", "modules": [{"role": "model", "module": {"name": "m2m100_418M-fon-fr-mt", "description": "Machine translation model from Fon to French based on a fine-tuned facebook/m2m100_418M model."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"fine_tuned_on": ["JW300 Fon corpus", "LAFAND"], "training_gpu": "NVIDIA V100"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "m2m100_418M-fon-fr-mt is a machine translation model from Fon to French based on a fine-tuned facebook/m2m100_418M model. The model establishes a baseline for automatically translating texts from Fon to French. However, the model is limited by its training dataset and may not generalize well for all use cases in different domains."}}, {"role": "dataset", "purpose": "For fine-tuning.", "module": "jw300"}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-sb3-qrdqn-seaquestnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "QRDQN Agent playing SeaquestNoFrameskip-v4", "description": "A trained QRDQN agent playing SeaquestNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"env_wrapper": "stable_baselines3.common.atari_wrappers.AtariWrapper", "exploration_fraction": 0.025, "frame_stack": 4, "n_timesteps": 10000000.0, "optimize_memory_usage": true, "policy": "CnnPolicy", "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained QRDQN agent playing SeaquestNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The model was trained with hyperparameters such as exploration_fraction of 0.025, frame_stack of 4, and n_timesteps of 10000000.0. The model achieved a mean_reward of 2562.00 +/- 57.58 on the SeaquestNoFrameskip-v4 dataset."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 2562.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-rajistics-layoutlmv3-finetuned-cord-300", "modules": [{"role": "model", "module": {"name": "layoutlmv3-finetuned-cord_300", "description": "A fine-tuned version of microsoft/layoutlmv3-base on the cord-layoutlmv3 dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-05, "train_batch_size": 5, "eval_batch_size": 5, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "training_steps": 4000}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of microsoft/layoutlmv3-base on the cord-layoutlmv3 dataset for token classification. It achieves high precision, recall, F1 score, and accuracy on the evaluation set. The model is suitable for tasks that require token classification, such as named entity recognition. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "cord-19"}], "metrics": [{"dataset": "cord-19", "metric": 0.9325426241660489, "protocol": "Precision"}, {"dataset": "cord-19", "metric": 0.9416167664670658, "protocol": "Recall"}, {"dataset": "cord-19", "metric": 0.9370577281191806, "protocol": "F1"}, {"dataset": "cord-19", "metric": 0.9363327674023769, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-w11wo-javanese-bert-small-imdb", "modules": [{"role": "model", "module": {"name": "Javanese BERT Small IMDB", "description": "A masked language model based on the BERT model, trained on Javanese IMDB movie reviews."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_size": "BERT Small", "batch_size": null, "optimizer": null}}}, {"role": "taskType", "module": "fill-mask"}, {"role": "solutionSummary", "module": {"summary": "Javanese BERT Small IMDB is a masked language model based on the BERT model, trained on Javanese IMDB movie reviews. It can be used for masked language modeling or feature extraction in PyTorch. The model achieved a perplexity of 19.87 on the validation dataset. However, the model reflects the biases of the IMDB reviews it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and validation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 19.87, "protocol": "perplexity"}], "source": "huggingface"}, {"id": "huggingface-tom11-xlm-roberta-base-finetuned-panx-fr", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-fr", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "xlm-roberta-base-finetuned-panx-fr is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. The model achieved an F1 score of 0.8422 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 5e-05 and a batch size of 24 for 3 epochs. The model was trained using the Transformers 4.24.0, Pytorch 1.13.0+cpu, Datasets 1.16.1, and Tokenizers 0.13.2."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8422, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-voleg44-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 game."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 game. The agent's Q-Table is provided, along with hyperparameters such as the maximum number of steps per episode and the number of episodes used for evaluation. The agent achieved a mean reward of 7.56 with a standard deviation of 2.71."}}, {"role": "dataset", "purpose": "The game environment used for training and evaluation.", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.56, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-helinivan-english-sarcasm-detector", "modules": [{"role": "model", "module": {"name": "English Sarcasm Detector", "description": "A text classification model built to detect sarcasm from news article titles."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_name": "bert-base-uncased", "tokenizer": "AutoTokenizer", "max_length": 256, "padding": true, "truncation": true}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "The English Sarcasm Detector is a text classification model fine-tuned on bert-base-uncased to detect sarcasm from news article titles. The model was trained on a ready-made dataset available on Kaggle. The model achieved an F1 score of 92.38, precision of 92.75, recall of 92.38, and accuracy of 92.42. The model can be used to classify text as sarcastic or not sarcastic."}}, {"role": "dataset", "purpose": "For model training.", "module": "headlines-dataset"}], "metrics": [{"dataset": "headlines-dataset", "metric": 92.38, "protocol": "F1"}, {"dataset": "headlines-dataset", "metric": 92.75, "protocol": "Precision"}, {"dataset": "headlines-dataset", "metric": 92.38, "protocol": "Recall"}, {"dataset": "headlines-dataset", "metric": 92.42, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-rushic24-dqn-spaceinvadersnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "DQN Agent playing SpaceInvadersNoFrameskip-v4", "description": "A trained DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "buffer_size": 100000, "exploration_final_eps": 0.01, "exploration_fraction": 0.1, "frame_stack": 4, "gradient_steps": 1, "learning_rate": 0.0001, "learning_starts": 100000, "n_timesteps": 10000000.0, "optimize_memory_usage": true, "policy": "CnnPolicy", "target_update_interval": 1000, "train_freq": 4, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The model was trained with a batch size of 32, a buffer size of 100000, and a learning rate of 0.0001. The mean reward achieved by the model is 892.00 with a standard deviation of 340.52. The model is suitable for reinforcement learning tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 892.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-phiyodr-bert-base-finetuned-squad2", "modules": [{"role": "model", "module": {"name": "bert-base-finetuned-squad2", "description": "A BERT-based model fine-tuned on SQuAD2.0 for question answering."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"base_model": "bert-base-uncased", "do_lower_case": true, "learning_rate": 3e-05, "num_train_epochs": 4, "max_seq_length": 384, "doc_stride": 128, "max_query_length": 64, "batch_size": 96}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "bert-base-finetuned-squad2 is a BERT-based model fine-tuned on SQuAD2.0 for question answering. The model is based on bert-base-uncased and was fine-tuned with a learning rate of 3e-5, 4 epochs, and a batch size of 96. The model achieved an exact match score of 70.4% and an F1 score of 73.9% on the SQuAD2.0 dev set."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 70.3950138970774, "protocol": "exact"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 73.90527661873521, "protocol": "f1"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 71.4574898785425, "protocol": "HasAns_exact"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 78.48808186475087, "protocol": "HasAns_f1"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 69.33557611438184, "protocol": "NoAns_exact"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 69.33557611438184, "protocol": "NoAns_f1"}], "source": "huggingface"}, {"id": "huggingface-umer4-urduaudio2text", "modules": [{"role": "model", "module": {"name": "UrduAudio2Text", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset for Urdu speech recognition."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0003, "train_batch_size": 16, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 30, "mixed_precision_training": true}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "UrduAudio2Text is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset for Urdu speech recognition. The model achieved a validation loss of 1.4978 and a WER of 0.8376. The model is intended for automatic speech recognition tasks in Urdu language. The model was trained using PyTorch 1.10.0+cu113 and Transformers 4.11.3."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 5.5558, "split": "val", "protocol": "loss"}, {"dataset": "common-voice", "metric": 1.4978, "split": "test", "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.8376, "protocol": "WER"}], "source": "huggingface"}, {"id": "huggingface-abyelt-whisper-models", "modules": [{"role": "model", "module": {"name": "Whisper Small Hi - Swedish", "description": "A fine-tuned version of openai/whisper-small on the Common Voice 11.0 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-05, "train_batch_size": 16, "eval_batch_size": 8, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "training_steps": 4000}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Whisper Small Hi - Swedish is a fine-tuned version of openai/whisper-small on the Common Voice 11.0 dataset. The model is intended for automatic speech recognition tasks in the Swedish language. The hyperparameters used during training include a learning rate of 1e-05, a train batch size of 16, and an eval batch size of 8. The model was trained for 4000 steps using Adam optimizer with betas=(0.9,0.999) and epsilon=1e-08. The model's performance is evaluated using the word error rate (WER) metric."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "common-voice"}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-dooglak-article-100v2-ner-model-3epochs-unaugmented", "modules": [{"role": "model", "module": {"name": "Article_100v2_NER_Model_3Epochs_UNAUGMENTED", "description": "A fine-tuned version of bert-base-cased on the article100v2_wikigold_split dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "Article_100v2_NER_Model_3Epochs_UNAUGMENTED is a fine-tuned version of bert-base-cased on the article100v2_wikigold_split dataset for token classification. The model achieved a precision of 0.0339, recall of 0.0005, f1-score of 0.0010, and accuracy of 0.7819 on the evaluation set. More information is needed to describe the model and its intended uses and limitations."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wikisplit"}], "metrics": [{"dataset": "wikisplit", "metric": 0.0339, "protocol": "precision"}, {"dataset": "wikisplit", "metric": 0.0005, "protocol": "recall"}, {"dataset": "wikisplit", "metric": 0.001, "protocol": "f1"}, {"dataset": "wikisplit", "metric": 0.7819, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-xinhui-distilbert-base-uncased-finetuned-imdb", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-imdb", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-imdb is a fine-tuned version of distilbert-base-uncased on the imdb dataset. It can be used for text classification tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 64. The model was trained for 3 epochs and achieved a loss of 2.4721 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 2.4721, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-aaraki-vit-base-patch16-224-in21k-finetuned-cifar10", "modules": [{"role": "model", "module": {"name": "vit-base-patch16-224-in21k-finetuned-cifar10", "description": "A fine-tuned version of google/vit-base-patch16-224-in21k on the cifar10 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 32, "eval_batch_size": 32, "seed": 42, "gradient_accumulation_steps": 4, "total_train_batch_size": 128, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "num_epochs": 1}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of google/vit-base-patch16-224-in21k on the cifar10 dataset. The model achieved an accuracy of 0.9788 on the evaluation set. More information is needed to describe the model and its intended uses and limitations."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "cifar-10"}], "metrics": [{"dataset": "cifar-10", "metric": 0.9788, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-rootcodes-wav2vec2-large-xls-r-300m-turkish-colab", "modules": [{"role": "model", "module": {"name": "wav2vec2-large-xls-r-300m-turkish-colab", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0003, "train_batch_size": 16, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 30, "mixed_precision_training": true}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset. The model is intended for automatic speech recognition tasks. The model achieved a validation loss of 0.4313 and a WER of 0.3336 on the evaluation set. The model was trained using PyTorch 1.10.0+cu113 and Transformers 4.11.3."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.0526, "split": "val", "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.4313, "split": "test", "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.3336, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-dvalbuena1-dqn-spaceinvadersnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "DQN", "description": "A trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "buffer_size": 100000, "exploration_final_eps": 0.01, "exploration_fraction": 0.1, "frame_stack": 4, "gradient_steps": 1, "learning_rate": 0.0001, "learning_starts": 100000, "n_timesteps": 1000000.0, "optimize_memory_usage": false, "policy": "CnnPolicy", "target_update_interval": 1000, "train_freq": 4, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "The DQN model is a reinforcement learning agent trained on the SpaceInvadersNoFrameskip-v4 environment using the stable-baselines3 library and the RL Zoo. The model achieved a mean reward of 526.00 +/- 122.47. The hyperparameters used for training include batch size, buffer size, exploration fraction, learning rate, and target update interval, among others. The RL Zoo provides a training framework for Stable Baselines3 reinforcement learning agents, with hyperparameter optimization and pre-trained agents included."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 526.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-de-fj", "modules": [{"role": "model", "module": {"name": "opus-mt-de-fj", "description": "A machine translation model that translates from German (de) to Fijian (fj)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-de-fj is a machine translation model that translates from German to Fijian. The model uses the transformer-align architecture and pre-processing techniques such as normalization and SentencePiece. The model achieved a BLEU score of 24.6 and a chr-F score of 0.47 on the JW300.de.fj test set."}}], "metrics": [{"dataset": "jw300", "metric": 24.6, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.47, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-amitjohn007-electra-finetuned-squad", "modules": [{"role": "model", "module": {"name": "amitjohn007/electra-finetuned-squad", "description": "A fine-tuned version of ahotrod/electra_large_discriminator_squad2_512 on an unknown dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"optimizer": {"name": "AdamWeightDecay", "learning_rate": {"name": "PolynomialDecay", "initial_learning_rate": 2e-05, "decay_steps": 16599, "end_learning_rate": 0.0, "power": 1.0, "cycle": false}, "decay": 0.0, "beta_1": 0.9, "beta_2": 0.999, "epsilon": 1e-08, "amsgrad": false, "weight_decay_rate": 0.01}, "training_precision": "mixed_float16"}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "amitjohn007/electra-finetuned-squad is a fine-tuned version of ahotrod/electra_large_discriminator_squad2_512 on an unknown dataset. The model is best suited for question-answering tasks. The training hyperparameters include mixed_float16 precision and AdamWeightDecay optimizer with a polynomial decay learning rate schedule. The model was trained using TensorFlow 2.9.2 and Transformers 4.24.0."}}, {"role": "dataset", "purpose": "For evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 0.3829, "split": "val", "protocol": "Train Loss"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 0.2298, "split": "test", "protocol": "Train Loss"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 2.0, "protocol": "Epoch"}], "source": "huggingface"}, {"id": "huggingface-ajrae-bert-base-uncased-finetuned-cola", "modules": [{"role": "model", "module": {"name": "bert-base-uncased-finetuned-cola", "description": "A fine-tuned version of bert-base-uncased on the glue dataset for text classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-base-uncased-finetuned-cola is a fine-tuned version of bert-base-uncased on the glue dataset for text classification. The model achieved a Matthews Correlation of 0.5865 on the evaluation set. The model is suitable for text classification tasks, but its performance may vary depending on the specific task and dataset. Caution should be taken when deploying it in human-interacting systems as the model reflects the biases of the systems it was trained on."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.5864941797290588, "protocol": "matthews_correlation"}], "source": "huggingface"}, {"id": "huggingface-w11wo-indonesian-roberta-base-posp-tagger", "modules": [{"role": "model", "module": {"name": "Indonesian RoBERTa Base POSP Tagger", "description": "Part-of-speech token-classification model based on the RoBERTa model."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"architecture": "RoBERTa Base", "training_epochs": 10, "training_batch_size": 32, "optimizer": "Adam", "learning_rate": 5e-05}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "Indonesian RoBERTa Base POSP Tagger is a part-of-speech token-classification model based on the RoBERTa model. The model was trained on the indonlu dataset and achieved an evaluation F1-macro of 95.34%. The model is suitable for token classification tasks, such as part-of-speech tagging. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "indonlu-benchmark"}], "metrics": [{"dataset": "indonlu-benchmark", "metric": 0.9399, "protocol": "Accuracy"}, {"dataset": "indonlu-benchmark", "metric": 0.8893, "protocol": "F1-macro"}], "source": "huggingface"}, {"id": "huggingface-intel-bert-base-uncased-mrpc", "modules": [{"role": "model", "module": {"name": "bert-base-uncased-mrpc", "description": "Fine-tuned version of bert-base-uncased on the GLUE MRPC dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 8, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5.0}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-base-uncased-mrpc is a fine-tuned version of bert-base-uncased on the GLUE MRPC dataset. It is a transformer model that can be used for text classification tasks. The model achieved an accuracy of 0.8603 and an F1 score of 0.9042 on the evaluation set. The model was trained with Adam optimizer with betas=(0.9,0.999) and epsilon=1e-08, and a linear learning rate scheduler. The model was trained for 5 epochs with a learning rate of 2e-05."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "mrpc-microsoft-research-paraphrase-corpus"}], "metrics": [{"dataset": "mrpc-microsoft-research-paraphrase-corpus", "metric": 0.6978, "protocol": "loss"}, {"dataset": "mrpc-microsoft-research-paraphrase-corpus", "metric": 0.8603, "protocol": "accuracy"}, {"dataset": "mrpc-microsoft-research-paraphrase-corpus", "metric": 0.9042, "protocol": "f1"}, {"dataset": "mrpc-microsoft-research-paraphrase-corpus", "metric": 0.8822, "protocol": "combined_score"}], "source": "huggingface"}, {"id": "huggingface-lewiswatson-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. It can be used for text classification tasks. The model achieved an accuracy of 0.9185 and an F1 score of 0.9182 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emocontext"}], "metrics": [{"dataset": "emocontext", "metric": 0.9185, "protocol": "accuracy"}, {"dataset": "emocontext", "metric": 0.9182094401352938, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-herooooooooo-dqn-spaceinvadersnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "DQN", "description": "A trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "buffer_size": 100000, "exploration_final_eps": 0.01, "exploration_fraction": 0.1, "frame_stack": 4, "gradient_steps": 1, "learning_rate": 0.0001, "learning_starts": 100000, "n_timesteps": 1000000, "optimize_memory_usage": true, "policy": "CnnPolicy", "target_update_interval": 1000, "train_freq": 4, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "The DQN model is a reinforcement learning agent trained on the SpaceInvadersNoFrameskip-v4 environment using the stable-baselines3 library and the RL Zoo. The model achieved a mean reward of 535.00 +/- 107.05. The hyperparameters used for training include batch size, buffer size, exploration fraction, learning rate, and target update interval, among others. The model is suitable for playing SpaceInvadersNoFrameskip-v4, but may not generalize well to other environments."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 535.0, "split": "val", "protocol": "mean_reward"}, {"dataset": "atari-grand-challenge", "metric": 107.05, "split": "test", "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-hbtemari-xlm-roberta-base-finetuned-panx-en", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-en", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "xlm-roberta-base-finetuned-panx-en is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification. The model achieved an F1 score of 0.6886 on the evaluation set. The model is suitable for token classification tasks in multilingual settings."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.6886160714285715, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-turhancan97-q-frozenlake-v1", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model achieved a mean reward of 1.00 +/- 0.00. The model can be loaded and evaluated using the provided code snippet."}}, {"role": "dataset", "purpose": "Environment for model training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-pig4431-sentiment140-albert-5e", "modules": [{"role": "model", "module": {"name": "Sentiment140_ALBERT_5E", "description": "Fine-tuned version of albert-base-v2 on the sentiment140 dataset for text classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-05, "train_batch_size": 16, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "Sentiment140_ALBERT_5E is a fine-tuned version of albert-base-v2 on the sentiment140 dataset for text classification. The model achieved an accuracy of 0.8533 on the evaluation set. The model is suitable for text classification tasks, but caution should be taken when deploying it in human-interacting systems as it may reflect the biases of the systems it was trained on."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "sentiment140"}], "metrics": [{"dataset": "sentiment140", "metric": 0.8533, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-hiiamsid-sentence-similarity-spanish-es", "modules": [{"role": "model", "module": {"name": "hiiamsid/sentence_similarity_spanish_es", "description": "A sentence-transformers model that maps sentences and paragraphs to a 768-dimensional dense vector space for clustering or semantic search."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"max_seq_length": 512, "do_lower_case": false, "batch_size": 16, "loss": "CosineSimilarityLoss", "optimizer": {"name": "AdamW", "learning_rate": 2e-05, "weight_decay": 0.01}, "epochs": 4, "warmup_steps": 144, "max_grad_norm": 1}}}, {"role": "taskType", "module": "sentence-similarity"}, {"role": "solutionSummary", "module": {"summary": "hiiamsid/sentence_similarity_spanish_es is a sentence-transformers model that maps sentences and paragraphs to a 768-dimensional dense vector space for clustering or semantic search. The model was trained on the stsb_multi_mt dataset using the CosineSimilarityLoss loss function and AdamW optimizer. The model was evaluated using Pearson and Spearman correlation coefficients for cosine, Euclidean, and Manhattan distances. The model is intended for use in semantic search and clustering tasks in Spanish language."}}, {"role": "dataset", "purpose": "For model training.", "module": "sts-benchmark"}], "metrics": [{"dataset": "sts-benchmark", "metric": 0.8280372842978689, "protocol": "cosine_pearson"}, {"dataset": "sts-benchmark", "metric": 0.8232689765056079, "protocol": "cosine_spearman"}, {"dataset": "sts-benchmark", "metric": 0.81021993884437, "protocol": "euclidean_pearson"}, {"dataset": "sts-benchmark", "metric": 0.8087904592393836, "protocol": "euclidean_spearman"}, {"dataset": "sts-benchmark", "metric": 0.809645390126291, "protocol": "manhattan_pearson"}, {"dataset": "sts-benchmark", "metric": 0.8077035464970413, "protocol": "manhattan_spearman"}, {"dataset": "sts-benchmark", "metric": 0.7803662255836028, "protocol": "dot_pearson"}, {"dataset": "sts-benchmark", "metric": 0.7699607641618339, "protocol": "dot_spearman"}], "source": "huggingface"}, {"id": "huggingface-ilyagusev-mbart-ru-sum-gazeta", "modules": [{"role": "model", "module": {"name": "MBARTRuSumGazeta", "description": "A ported version of fairseq model for automatic summarization of Russian news using MBART."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"max_source_tokens_count": 600, "no_repeat_ngram_size": 4, "num_beams": 5}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "MBARTRuSumGazeta is a ported version of fairseq model for automatic summarization of Russian news using MBART. The model is trained on Gazeta dataset and can be used to generate summaries of news articles. The model is limited to Gazeta.ru articles and may suffer from domain shift when used with other news agencies. The model reflects the biases inherent to the systems they were trained on, so caution should be taken when deploying it into systems that interact with humans."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "gazeta"}], "metrics": [{"dataset": "gazeta", "metric": 32.4, "protocol": "R-1-f"}, {"dataset": "gazeta", "metric": 14.3, "protocol": "R-2-f"}, {"dataset": "gazeta", "metric": 28.0, "protocol": "R-L-f"}, {"dataset": "gazeta", "metric": 39.7, "protocol": "chrF"}, {"dataset": "gazeta", "metric": 26.4, "protocol": "METEOR"}, {"dataset": "gazeta", "metric": 12.1, "protocol": "BLEU"}], "source": "huggingface"}, {"id": "huggingface-xrverse-pegasus-samsum", "modules": [{"role": "model", "module": {"name": "pegasus-samsum", "description": "A fine-tuned version of google/pegasus-cnn_dailymail on the samsum dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 1, "eval_batch_size": 1, "seed": 42, "gradient_accumulation_steps": 16, "total_train_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 1}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "pegasus-samsum is a fine-tuned version of google/pegasus-cnn_dailymail on the samsum dataset. It is a model for text summarization tasks. The model was trained with Adam optimizer with a learning rate of 5e-05 and a linear learning rate scheduler with 500 warmup steps. The model was trained for 1 epoch with a total train batch size of 16. The model achieved a loss of 1.4834 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "samsum-corpus"}], "metrics": [{"dataset": "samsum-corpus", "metric": 1.4834, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-muhtasham-bert-base-uncased-tajik-ner", "modules": [{"role": "model", "module": {"name": "bert-base-uncased-tajik-ner", "description": "Fine-tuned BERT model on the wikiann dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 200}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-base-uncased-tajik-ner is a fine-tuned BERT model on the wikiann dataset for token classification. The model was trained with a learning rate of 2e-05, a batch size of 8, and the Adam optimizer with betas=(0.9, 0.999) and epsilon=1e-08. The model achieved a precision of 0.5042, recall of 0.5769, F1 score of 0.5381, and accuracy of 0.8481 on the evaluation set. The model is intended for token classification tasks and reflects the biases inherent to the systems it was trained on, so caution should be taken when deploying it into systems that interact with humans."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wikiann"}], "metrics": [{"dataset": "wikiann", "metric": 0.5042016806722689, "protocol": "precision"}, {"dataset": "wikiann", "metric": 0.5769230769230769, "protocol": "recall"}, {"dataset": "wikiann", "metric": 0.5381165919282511, "protocol": "f1"}, {"dataset": "wikiann", "metric": 0.848129958443521, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-weili-swin-base-patch4-window7-224-in22k-finetuned-cifar10", "modules": [{"role": "model", "module": {"name": "swin-base-patch4-window7-224-in22k-finetuned-cifar10", "description": "A fine-tuned version of microsoft/swin-base-patch4-window7-224-in22k on the cifar10 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 32, "eval_batch_size": 32, "seed": 42, "gradient_accumulation_steps": 4, "total_train_batch_size": 128, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "num_epochs": 3}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "A fine-tuned version of microsoft/swin-base-patch4-window7-224-in22k on the cifar10 dataset. The model achieved an accuracy of 0.989 on the evaluation set. More information is needed about the model description, intended uses and limitations, and training and evaluation data."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "cifar-10"}], "metrics": [{"dataset": "cifar-10", "metric": 0.989, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-voice-wav2vec2-large-xlsr-common1000asli-demo-colab-dd", "modules": [{"role": "model", "module": {"name": "wav2vec2-large-xlsr-common1000asli-demo-colab-dd", "description": "Fine-tuned version of facebook/wav2vec2-large-xlsr-53 on the common_voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0003, "train_batch_size": 128, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 256, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 1000, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/wav2vec2-large-xlsr-53 on the common_voice dataset. The model is suitable for automatic speech recognition tasks. The model was trained with Adam optimizer and a linear learning rate scheduler. The model was trained for 1000 epochs with a batch size of 256. The model achieved a loss of 1.0671 and a word error rate (WER) of 0.5268 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 1.0671, "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.5268, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-bgstud-whisper-small-libirclean-vs-commonnative-en", "modules": [{"role": "model", "module": {"name": "whisper-small-libirClean-vs-commonNative-en", "description": "A fine-tuned version of openai/whisper-small on the librispeech_asr dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 10, "training_steps": 50, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "whisper-small-libirClean-vs-commonNative-en is a fine-tuned version of openai/whisper-small on the librispeech_asr dataset. The model is intended for automatic speech recognition tasks. The model achieved a WER of 85.5379 on the evaluation set. The training was done using Adam optimizer with a learning rate of 1e-05 and a batch size of 8. The model was trained for 50 steps with a linear learning rate scheduler and mixed precision training."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "librispeech"}], "metrics": [{"dataset": "librispeech", "metric": 85.5379, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-lgris-sew-tiny-pt", "modules": [{"role": "model", "module": {"name": "SEW-tiny-pt", "description": "Pretrained model on Brazilian Portuguese audio for downstream tasks such as Automatic Speech Recognition, Speaker Identification, Intent Classification, Emotion Recognition, etc."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"sample_rate": "16kHz"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "SEW-tiny-pt is a pre-trained model architecture for automatic speech recognition (ASR) on Brazilian Portuguese audio. It is based on wav2vec 2.0 and has significant improvements in both performance and efficiency dimensions across a variety of training setups. The model should be fine-tuned on a downstream task, such as Automatic Speech Recognition, Speaker Identification, Intent Classification, Emotion Recognition, etc. The original model can be found on the ASAPP Research GitHub page."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-lg-fi", "modules": [{"role": "model", "module": {"name": "opus-mt-lg-fi", "description": "A transformer-align model for translating from lg to fi."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-lg-fi model is a transformer-align model that translates from lg to fi. It achieved a BLEU score of 21.8 and a chr-F score of 0.424 on the JW300.lg.fi test set."}}], "metrics": [{"dataset": "jw300", "metric": 21.8, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.424, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-takehiro067-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. The model is best suited for text classification tasks. The model achieved an accuracy of 0.9255 and an F1 score of 0.9255 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.9255, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.9255179580374608, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-gcmsrc-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8620 on the evaluation set. The model is suitable for token classification tasks in German language. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8620356147237869, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-danielvelaj-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. The model is best suited for text classification tasks. The model achieved an accuracy of 0.926 and an F1 score of 0.9259 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.926, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.9258845524992532, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-wietsedv-wav2vec2-large-xlsr-53-frisian", "modules": [{"role": "model", "module": {"name": "Wav2Vec2-Large-XLSR-53-Frisian", "description": "Fine-tuned Wav2Vec2-Large-XLSR-53 on Frisian using the Common Voice dataset for speech recognition."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "facebook/wav2vec2-large-xlsr-53", "batch_size": 8, "optimizer": {"name": "Adam", "learning_rate": 5e-05}}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Wav2Vec2-Large-XLSR-53-Frisian is a fine-tuned model on Frisian using the Common Voice dataset for speech recognition. The model is intended to be used directly (without a language model) and is suitable for speech recognition tasks in Frisian. The model was trained on the Common Voice train and validation datasets and achieved a WER of 16.25% on the Common Voice test dataset for Frisian."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 16.25, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-neha2608-results", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased", "description": "Fine-tuned model on the IMDB dataset for text classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of the distilbert-base-uncased model on the IMDB dataset for text classification. The model achieved an F1 score of 0.9255 on the evaluation set. The model is suitable for text classification tasks, but caution should be taken when deploying it in human-interacting systems as it may reflect the biases of the dataset it was trained on."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.9254722461324877, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-tanbwilson-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 game."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 game. The agent's Q-Table is provided, along with hyperparameters such as the maximum number of steps per episode and the number of episodes used to evaluate the agent. The model achieved a mean reward of 7.54 with a standard deviation of 2.69."}}, {"role": "dataset", "purpose": "The game environment used for training and evaluation.", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.54, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-kaku0o0-distilbert-base-uncased-finetuned-squad", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-squad", "description": "A fine-tuned version of distilbert-base-uncased on the squad dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-05, "train_batch_size": 32, "eval_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-squad is a fine-tuned version of distilbert-base-uncased on the squad dataset. It is suitable for question answering tasks. The model was trained with Adam optimizer with a learning rate of 1e-05 and a batch size of 32. The model was trained for 3 epochs and achieved a validation loss of 1.6090."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 0.9165, "split": "val", "protocol": "loss"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 1.609, "split": "test", "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-anas-awadalla-spanbert-base-cased-few-shot-k-16-finetuned-squad-seed-42", "modules": [{"role": "model", "module": {"name": "spanbert-base-cased-few-shot-k-16-finetuned-squad-seed-42", "description": "A fine-tuned version of SpanBERT/spanbert-base-cased on the SQuAD dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 3e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "training_steps": 200}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of SpanBERT/spanbert-base-cased on the SQuAD dataset. It can be used for question answering tasks. The model was trained with Adam optimizer with a learning rate of 3e-05 and a batch size of 16. The model was trained for 200 steps and achieved an exact match score of 4.54 and an F1 score of 10.04 on the SQuAD dataset."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 4.541154210028382, "protocol": "exact_match"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 10.04181288563879, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-asnorkin-q-frozenlake-v1-4x4-noslippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained model of a Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-4x4-no_slippery", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model's hyperparameters include the algorithm used, the environment, the maximum number of steps per episode, the number of episodes to evaluate the agent, the Q-Table learned by the agent, and the random seed used for evaluation. The model achieved a mean reward of 1.00 with no standard deviation."}}, {"role": "dataset", "purpose": "Environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-aakhilv-tonystark", "modules": [{"role": "model", "module": {"name": "Tony Stark DialoGPT Model", "description": "A conversational response model based on DialoGPT architecture, fine-tuned on Tony Stark persona."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"max_length": 1024, "num_attention_heads": 16, "num_layers": 12, "num_train_epochs": 3, "learning_rate": 5e-05, "batch_size": 4}}}, {"role": "taskType", "module": "conversational"}, {"role": "solutionSummary", "module": {"summary": "Tony Stark DialoGPT Model is a conversational response model based on DialoGPT architecture, fine-tuned on Tony Stark persona. The model is trained on Persona-Chat dataset and can generate responses to user inputs. The hyperparameters include max_length, num_attention_heads, num_layers, num_train_epochs, learning_rate, and batch_size. The model achieved a perplexity score of 12.5 and an F1 score of 0.87 on the Persona-Chat dataset."}}, {"role": "dataset", "purpose": "For model training and fine-tuning.", "module": "convai2-conversational-intelligence-challenge-2"}], "metrics": [{"dataset": "convai2-conversational-intelligence-challenge-2", "metric": 12.5, "protocol": "Perplexity"}, {"dataset": "convai2-conversational-intelligence-challenge-2", "metric": 0.87, "protocol": "F1 Score"}], "source": "huggingface"}, {"id": "huggingface-joriscos-dccrnet-libri1mix-enhsingle-16k", "modules": [{"role": "model", "module": {"name": "DCCRNet_Libri1Mix_enhsignle_16k", "description": "Asteroid model for speech enhancement using DCCRNet architecture trained on the enh_single task of the Libri1Mix dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"filterbank": {"stft_kernel_size": 400, "stft_n_filters": 512, "stft_stride": 100}, "masknet": {"architecture": "DCCRN-CL", "n_src": 1}, "optim": {"lr": 0.001, "optimizer": "adam", "weight_decay": 1e-05}, "training": {"batch_size": 12, "early_stop": true, "epochs": 200, "gradient_clipping": 5, "half_lr": true, "num_workers": 4}}}}, {"role": "taskType", "module": "audio-to-audio"}, {"role": "solutionSummary", "module": {"summary": "DCCRNet_Libri1Mix_enhsignle_16k is a speech enhancement model trained on the enh_single task of the Libri1Mix dataset using the DCCRNet architecture. The model was trained with a batch size of 12, 200 epochs, and an Adam optimizer with a learning rate of 0.001. The model achieved good results on the Libri1Mix min test set with a si_sdr of 13.33 and a stoi of 0.91. The model is licensed under Attribution-ShareAlike 3.0 Unported by Joris Cosentino."}}, {"role": "dataset", "purpose": "For model training.", "module": "librimix"}], "metrics": [{"dataset": "librimix", "metric": 13.329767398333798, "protocol": "si_sdr"}, {"dataset": "librimix", "metric": 9.879986092474098, "protocol": "si_sdr_imp"}, {"dataset": "librimix", "metric": 13.87279932997016, "protocol": "sdr"}, {"dataset": "librimix", "metric": 10.370136530757103, "protocol": "sdr_imp"}, {"dataset": "librimix", "metric": 13.87279932997016, "protocol": "sar"}, {"dataset": "librimix", "metric": 10.370136530757103, "protocol": "sar_imp"}, {"dataset": "librimix", "metric": 0.9140907015623948, "protocol": "stoi"}, {"dataset": "librimix", "metric": 0.11817087802185405, "protocol": "stoi_imp"}], "source": "huggingface"}, {"id": "huggingface-samitizerxu-wav2vec2-xls-r-300m-lg", "modules": [{"role": "model", "module": {"name": "wav2vec2-xls-r-300m-lg", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-300m on the COMMON_VOICE - LG dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0003, "train_batch_size": 16, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 20.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "The wav2vec2-xls-r-300m-lg model is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the COMMON_VOICE - LG dataset. It is intended for automatic speech recognition tasks. The model achieved a WER of 0.8529 on the test set. The model was trained using PyTorch 1.10.2+cu102 and Transformers 4.17.0.dev0."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.8529, "protocol": "WER"}], "source": "huggingface"}, {"id": "huggingface-chrisjay-cos801-802-hf-workshop-mt5-small", "modules": [{"role": "model", "module": {"name": "cos801-802-hf-workshop-mt5-small", "description": "A fine-tuned version of google/mt5-small on the xlsum dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5.6e-05, "train_batch_size": 4, "eval_batch_size": 4, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "cos801-802-hf-workshop-mt5-small is a fine-tuned version of google/mt5-small on the xlsum dataset. It is a sequence-to-sequence language modeling model that can be used for text generation tasks such as summarization. The model was trained with Adam optimizer with a learning rate of 5.6e-05 and a batch size of 4. The model achieved a Rouge1 score of 20.928 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xl-sum"}], "metrics": [{"dataset": "xl-sum", "metric": 20.928, "protocol": "rouge1"}, {"dataset": "xl-sum", "metric": 6.3239, "protocol": "rouge2"}, {"dataset": "xl-sum", "metric": 17.4455, "protocol": "rougeL"}, {"dataset": "xl-sum", "metric": 17.4566, "protocol": "rougeLsum"}], "source": "huggingface"}, {"id": "huggingface-kareldo-lstm-cebab-confounding-uniform-absa-5-class-seed-42", "modules": [{"role": "model", "module": {"name": "lstm.CEBaB_confounding.uniform.absa.5-class.seed_42", "description": "A fine-tuned version of lstm on the OpenTable OPENTABLE-ABSA dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.001, "train_batch_size": 32, "eval_batch_size": 32, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5.0}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "lstm.CEBaB_confounding.uniform.absa.5-class.seed_42 is a fine-tuned version of lstm on the OpenTable OPENTABLE-ABSA dataset. The model achieved an accuracy of 0.7124 on the evaluation set. The hyperparameters used during training include a learning rate of 0.001, a train batch size of 32, an eval batch size of 32, a seed of 42, Adam optimizer with betas=(0.9,0.999) and epsilon=1e-08, a linear learning rate scheduler, and 5 epochs. The model is intended for text classification tasks, but more information is needed to determine its limitations and intended uses."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "restaurant-acos"}], "metrics": [{"dataset": "restaurant-acos", "metric": 0.7123623011015912, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-lu-fi", "modules": [{"role": "model", "module": {"name": "opus-mt-lu-fi", "description": "A machine translation model that translates from Luxembourgish to Finnish."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-lu-fi is a transformer-align model that translates from Luxembourgish to Finnish. It achieved a BLEU score of 21.4 and a chr-F score of 0.442 on the JW300.lu.fi test set."}}], "metrics": [{"dataset": "jw300", "metric": 21.4, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.442, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-netoass-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8654 on the evaluation set. The model is suitable for token classification tasks in German language. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8654425558524246, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-anas-awadalla-roberta-base-few-shot-k-16-finetuned-squad-seed-42", "modules": [{"role": "model", "module": {"name": "roberta-base-few-shot-k-16-finetuned-squad-seed-42", "description": "A fine-tuned version of roberta-base on the squad dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 3e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "training_steps": 200}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of roberta-base on the squad dataset. It can be used for question answering tasks. The model was trained with Adam optimizer with a learning rate of 3e-05, and a linear learning rate scheduler with a warmup ratio of 0.1. The model achieved an exact match score of 8.62 and an F1 score of 14.07 on the SQuAD dataset."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 8.618732261116367, "protocol": "exact_match"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 14.074017518582023, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-antoniocappiello-bert-base-italian-uncased-squad-it", "modules": [{"role": "model", "module": {"name": "Italian Bert Base Uncased on Squad-it", "description": "Pretrained model on Italian language using a question answering task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_type": "bert", "learning_rate": 3e-05, "num_train_epochs": 2, "max_seq_length": 384, "doc_stride": 128, "per_gpu_eval_batch_size": 3, "per_gpu_train_batch_size": 3, "do_lower_case": true}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "This is an Italian BERT model trained on the question answering task using SQuAD-it dataset. It is intended to be used for question answering tasks in Italian language. The model achieved an EM score of 63.8 and an F1 score of 75.30, which is better than the DrQA-it model trained on SQuAD-it. The model is based on the uncased base version of the Italian BERT."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 63.8, "protocol": "EM"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 75.3, "protocol": "F1"}], "source": "huggingface"}, {"id": "huggingface-zshang3-distilbert-base-uncased-finetuned-squad", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-squad", "description": "A fine-tuned version of distilbert-base-uncased on the squad dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-squad is a fine-tuned version of distilbert-base-uncased on the squad dataset. It is suitable for question answering tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler. The model was trained for 3 epochs with a batch size of 16. The model achieved a validation loss of 1.6083."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 1.283, "split": "val", "protocol": "loss"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 1.6083, "split": "test", "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-akashpb13-galician-xlsr", "modules": [{"role": "model", "module": {"name": "Akashpb13/Galician_xlsr", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-300m on the MOZILLA-FOUNDATION/COMMON_VOICE_7_0 - hu dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 9.6e-05, "train_batch_size": 16, "eval_batch_size": 16, "gradient_accumulation_steps": 2, "lr_scheduler_type": "cosine_with_restarts", "lr_scheduler_warmup_steps": 500, "num_epochs": 100, "mixed_precision_training": true}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Akashpb13/Galician_xlsr is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the MOZILLA-FOUNDATION/COMMON_VOICE_7_0 - hu dataset. The model is intended for automatic speech recognition tasks. The model was trained on Common voice Galician train.tsv, dev.tsv, invalidated.tsv, reported.tsv, and other.tsv. The model achieved a WER of 0.196230 on the evaluation set. The model was trained using PyTorch 1.10.0+cu102 and Transformers 4.16.0.dev0."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.19623, "protocol": "Test WER"}, {"dataset": "common-voice", "metric": 0.023982371794871796, "protocol": "Test CER"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-en-rn", "modules": [{"role": "model", "module": {"name": "transformer-align", "description": "A machine translation model trained on English to Rundi language pair using normalization and SentencePiece (spm4k,spm4k) pre-processing."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece (spm4k,spm4k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The transformer-align model is a machine translation model trained on English to Rundi language pair using normalization and SentencePiece (spm4k,spm4k) pre-processing. The model achieved a BLEU score of 10.4 and a chrF2 score of 0.436 on the Tatoeba-test.eng.run test set."}}, {"role": "dataset", "purpose": "Test set used for evaluation.", "module": "tatoeba-translation-challenge"}], "metrics": [{"dataset": "tatoeba-translation-challenge", "metric": 10.4, "protocol": "BLEU"}, {"dataset": "tatoeba-translation-challenge", "metric": 0.436, "protocol": "chrF2"}], "source": "huggingface"}, {"id": "huggingface-assamim-mt5-small-indonesian", "modules": [{"role": "model", "module": {"name": "mt5-small-indonesian-sum", "description": "A fine-tuned version of google/mt5-small on an csebuetnlp/xlsum dataset for Indonesian summarization."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"optimizer": {"learning_rate": 2e-05, "decay": 0.0, "beta_1": 0.9, "beta_2": 0.999, "epsilon": 1e-07, "amsgrad": false, "weight_decay_rate": 0.01}, "training_precision": "float32", "min_length": 20, "max_length": 200, "num_beams": 7, "repetition_penalty": 2.5, "length_penalty": 1.0, "early_stopping": true, "no_repeat_ngram_size": 2, "use_cache": true, "do_sample": true, "temperature": 0.8, "top_k": 50, "top_p": 0.95}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "mt5-small-indonesian-sum is a fine-tuned version of google/mt5-small on an csebuetnlp/xlsum dataset for Indonesian summarization. The model is intended to be used for summarization tasks and is best suited for generating summaries in Indonesian. The model was trained using masked language modeling and next sentence prediction objectives. The model was trained on BookCorpus and English Wikipedia datasets. The model achieved a Train Loss of 4.6665 and a Validation Loss of 2.6526. The model uses a set of hyperparameters for generating summaries."}}, {"role": "dataset", "purpose": "For model training.", "module": "xl-sum"}], "metrics": [{"dataset": "xl-sum", "metric": 4.6665, "protocol": "Train Loss"}, {"dataset": "xl-sum", "metric": 2.6526, "protocol": "Validation Loss"}, {"dataset": "xl-sum", "metric": 19.7876, "protocol": "Train Rouge1"}, {"dataset": "xl-sum", "metric": 6.6344, "protocol": "Train Rouge2"}, {"dataset": "xl-sum", "metric": 16.788, "protocol": "Train Rougel"}, {"dataset": "xl-sum", "metric": 16.8459, "protocol": "Train Rougelsum"}, {"dataset": "xl-sum", "metric": 18.92, "protocol": "Train Gen Len"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-sl-es", "modules": [{"role": "model", "module": {"name": "opus-mt-sl-es", "description": "A machine translation model that translates from Slovenian (sl) to Spanish (es) using a transformer-align model."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-sl-es is a machine translation model that translates from Slovenian to Spanish using a transformer-align model. The model was trained on the OPUS dataset and uses normalization and SentencePiece for pre-processing. The model achieved a BLEU score of 26.3 and a chr-F score of 0.483 on the JW300.sl.es test set."}}], "metrics": [{"dataset": "jw300", "metric": 26.3, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.483, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-apple-mobilevit-xx-small", "modules": [{"role": "model", "module": {"name": "MobileViT (extra extra small-sized model)", "description": "MobileViT is a light-weight, low latency convolutional neural network that combines MobileNetV2-style layers with a new block that replaces local processing in convolutions with global processing using transformers. It is pre-trained on ImageNet-1k at resolution 256x256."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 1024, "optimizer": {"name": "Adam", "learning_rate": "warmup for 3k steps, followed by cosine annealing", "weight_decay": 0.0001}}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "MobileViT is a light-weight, low latency convolutional neural network that combines MobileNetV2-style layers with a new block that replaces local processing in convolutions with global processing using transformers. It is pre-trained on ImageNet-1k at resolution 256x256. The model is suitable for image classification tasks. The model is pre-trained on ImageNet-1k, which is a large dataset of images with 1,000 classes. The model is best suited for mobile and embedded devices due to its small size and low latency."}}, {"role": "dataset", "purpose": "For model training.", "module": "imagenet"}], "metrics": [{"dataset": "imagenet", "metric": 69.0, "protocol": "ImageNet top-1 accuracy"}, {"dataset": "imagenet", "metric": 88.9, "protocol": "ImageNet top-5 accuracy"}], "source": "huggingface"}, {"id": "huggingface-leisa-distilbert-base-uncased-finetuned-imdb", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-imdb", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-imdb is a fine-tuned version of distilbert-base-uncased on the imdb dataset. It can be used for text classification tasks. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64. The model was trained for 3 epochs and achieved a loss of 2.3114 on the evaluation set. The model was trained using PyTorch 1.10.0 and Transformers 4.12.5."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 2.3114, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-ghofrani-common7", "modules": [{"role": "model", "module": {"name": "common7", "description": "A fine-tuned version of common7/checkpoint-18500 on the MOZILLA-FOUNDATION/COMMON_VOICE_7_0 - FA dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 6e-05, "train_batch_size": 32, "eval_batch_size": 16, "seed": 42, "gradient_accumulation_steps": 4, "total_train_batch_size": 128, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 100, "num_epochs": 150.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "common7 is a fine-tuned version of common7/checkpoint-18500 on the MOZILLA-FOUNDATION/COMMON_VOICE_7_0 - FA dataset. It is a speech recognition model that achieves a WER of 0.3478 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 6e-05 and a linear learning rate scheduler. The model was trained for 150 epochs with a batch size of 128 and mixed precision training. The model was trained using the Transformers 4.17.0.dev0 framework with PyTorch 1.10.2, Datasets 1.18.3.dev0, and Tokenizers 0.10.3."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.3448, "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.3478, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-utkarshbelkhede-distilbert-sec-10k", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-sst-2-english", "description": "A fine-tuned DistilBERT model on the SST-2 dataset for sentiment analysis."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-05, "train_batch_size": 16, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-sst-2-english is a fine-tuned DistilBERT model on the SST-2 dataset for sentiment analysis. The model was trained for 3 epochs with a learning rate of 1e-05 and an Adam optimizer. The model achieved an accuracy of 0.9323 and an F1 score of 0.8258 on the validation set. The model is suitable for text classification tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "sst-stanford-sentiment-treebank"}], "metrics": [{"dataset": "sst-stanford-sentiment-treebank", "metric": 0.2091, "split": "val", "protocol": "loss"}, {"dataset": "sst-stanford-sentiment-treebank", "metric": 0.2092, "split": "test", "protocol": "loss"}, {"dataset": "sst-stanford-sentiment-treebank", "metric": 0.9323, "split": "val", "protocol": "accuracy"}, {"dataset": "sst-stanford-sentiment-treebank", "metric": 0.9323, "split": "test", "protocol": "accuracy"}, {"dataset": "sst-stanford-sentiment-treebank", "metric": 0.8258, "split": "val", "protocol": "f1"}, {"dataset": "sst-stanford-sentiment-treebank", "metric": 0.8258, "split": "test", "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-jdang-bert-finetuned-ner", "modules": [{"role": "model", "module": {"name": "bert-finetuned-ner", "description": "A fine-tuned version of bert-base-cased on the conll2003 dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-finetuned-ner is a fine-tuned version of bert-base-cased on the conll2003 dataset for token classification. The model achieved high precision, recall, F1 score, and accuracy on the evaluation set. The model is suitable for named entity recognition tasks, but caution should be taken when deploying it in human-interacting systems as it may reflect the biases of the systems it was trained on."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 0.9357509521443947, "protocol": "Precision"}, {"dataset": "conll-2003", "metric": 0.9510265903736116, "protocol": "Recall"}, {"dataset": "conll-2003", "metric": 0.9433269343126617, "protocol": "F1"}, {"dataset": "conll-2003", "metric": 0.9864160828869135, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-nl-es", "modules": [{"role": "model", "module": {"name": "opus-mt-nl-es", "description": "A machine translation model that translates from Dutch to Spanish."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-nl-es is a machine translation model that translates from Dutch to Spanish. It was trained on the OPUS dataset using a transformer-align model with normalization and SentencePiece preprocessing. The model achieved a BLEU score of 51.6 and a chr-F score of 0.698 on the Tatoeba.nl.es test set."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-haritzpuerto-tinybert-general-4l-312d-squad", "modules": [{"role": "model", "module": {"name": "TinyBERT_General_4L_312D-squad", "description": "Fine-tuned version of huawei-noah/TinyBERT_General_4L_312D on the squad dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-05, "train_batch_size": 20, "eval_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "TinyBERT_General_4L_312D-squad is a fine-tuned version of huawei-noah/TinyBERT_General_4L_312D on the squad dataset. It is a question-answering model that achieves an exact match of 33.30% and an F1 score of 45.04% on the evaluation set. The model was trained with Adam optimizer and a linear learning rate scheduler for one epoch."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 33.301797540208135, "protocol": "exact_match"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 45.03886349847048, "protocol": "f1"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 2.5477, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-jeremiahz-roberta-base-mnli", "modules": [{"role": "model", "module": {"name": "roberta-base-mnli", "description": "A fine-tuned version of roberta-base on the GLUE MNLI dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 8, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.06, "num_epochs": 10.0}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "roberta-base-mnli is a fine-tuned version of roberta-base on the GLUE MNLI dataset. It can be used for text classification tasks. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler with a warmup ratio of 0.06. The model achieved an evaluation accuracy of 0.8697."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "multinli-multi-genre-natural-language-inference"}], "metrics": [{"dataset": "multinli-multi-genre-natural-language-inference", "metric": 0.7539, "protocol": "eval_loss"}, {"dataset": "multinli-multi-genre-natural-language-inference", "metric": 0.8697, "protocol": "eval_accuracy"}, {"dataset": "multinli-multi-genre-natural-language-inference", "metric": 25.5655, "protocol": "eval_runtime"}, {"dataset": "multinli-multi-genre-natural-language-inference", "metric": 384.581, "protocol": "eval_samples_per_second"}, {"dataset": "multinli-multi-genre-natural-language-inference", "metric": 48.073, "protocol": "eval_steps_per_second"}, {"dataset": "multinli-multi-genre-natural-language-inference", "metric": 0.0, "protocol": "step"}], "source": "huggingface"}, {"id": "huggingface-sarahliu186-distilbert-base-uncased-finetuned-cola", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-cola", "description": "A fine-tuned version of distilbert-base-uncased on the glue dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-cola is a fine-tuned version of distilbert-base-uncased on the glue dataset. It is suitable for text classification tasks. The model achieved a Matthews Correlation score of 0.5488 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for 5 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.5488, "protocol": "matthews_correlation"}], "source": "huggingface"}, {"id": "huggingface-saattrupdan-xlmr-base-texas-squad-da", "modules": [{"role": "model", "module": {"name": "xlmr-base-texas-squad-da", "description": "Fine-tuned version of xlm-roberta-base on the TExAS-SQuAD-da dataset for Danish language."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 4, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "xlmr-base-texas-squad-da is a fine-tuned version of xlm-roberta-base on the TExAS-SQuAD-da dataset for Danish language. It is best suited for question-answering tasks in Danish language. The model achieved an exact match of 63.96% and an F1-score of 68.40% on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler for 3 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 63.96, "protocol": "exact match"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 68.4, "protocol": "f1-score"}], "source": "huggingface"}, {"id": "huggingface-dmitry-np-q-frozenlake-v1-4x4-non-slippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained model of a Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-4x4-no_slippery", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model's hyperparameters include the algorithm used, the environment, the maximum number of steps per episode, the number of episodes to evaluate the agent, the Q-Table learned by the agent, and the random seed used for evaluation. The model achieved a mean reward of 1.0 with no standard deviation."}}, {"role": "dataset", "purpose": "Environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-emre-wav2vec2-xls-r-300m-turkish-tr-med", "modules": [{"role": "model", "module": {"name": "wav2vec2-xls-r-300m-Turkish-Tr-med", "description": "A fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0003, "train_batch_size": 16, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 60, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "wav2vec2-xls-r-300m-Turkish-Tr-med is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset. It is intended for automatic speech recognition tasks. The model was trained with Adam optimizer with a learning rate of 0.0003 and a linear learning rate scheduler with 500 warmup steps. The model achieved a loss of 0.4727 and a WER of 0.4677 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.4727, "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.4677, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-facebook-detr-resnet-101-panoptic", "modules": [{"role": "model", "module": {"name": "DETR (End-to-End Object Detection) model with ResNet-101 backbone", "description": "DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 panoptic (118k annotated images)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"backbone": "ResNet-101", "object_queries": 100, "loss_function": "bipartite matching loss", "class_loss": "cross-entropy", "bounding_box_loss": "linear combination of L1 and generalized IoU loss"}}}, {"role": "taskType", "module": "image-segmentation"}, {"role": "solutionSummary", "module": {"summary": "DETR is an encoder-decoder transformer with a convolutional backbone used for object detection and panoptic segmentation. The model uses object queries to detect objects in an image. The model is trained using a bipartite matching loss and can be extended to perform panoptic segmentation. The model was trained on COCO 2017 panoptic and achieves good results on this dataset. The model can be used for panoptic segmentation."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "coco-microsoft-common-objects-in-context"}], "metrics": [{"dataset": "coco-microsoft-common-objects-in-context", "metric": 40.1, "protocol": "box AP"}, {"dataset": "coco-microsoft-common-objects-in-context", "metric": 33.0, "protocol": "segmentation AP"}, {"dataset": "coco-microsoft-common-objects-in-context", "metric": 45.1, "protocol": "PQ"}], "source": "huggingface"}, {"id": "huggingface-ambiwlans-ppo-1m-spaceinvadersnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "PPO Agent playing SpaceInvadersNoFrameskip-v4", "description": "A trained PPO agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 256, "clip_range": "lin_0.1", "ent_coef": 0.01, "frame_stack": 4, "learning_rate": "lin_2.5e-4", "n_envs": 8, "n_epochs": 4, "n_steps": 128, "n_timesteps": 1000000.0, "policy": "CnnPolicy", "vf_coef": 0.5, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained PPO agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The model was trained with hyperparameters such as batch size, learning rate, and number of epochs. The mean reward achieved by the model is 273.00 with a standard deviation of 82.29. The model is intended for reinforcement learning tasks and was trained on the SpaceInvadersNoFrameskip-v4 dataset."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 273.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-alexanderpeter-bert-finetuned-ner", "modules": [{"role": "model", "module": {"name": "bert-finetuned-ner", "description": "Fine-tuned version of bert-base-cased on the conll2003 dataset for named entity recognition."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-finetuned-ner is a fine-tuned version of bert-base-cased on the conll2003 dataset for named entity recognition. The model achieved high precision, recall, and F1 score on the evaluation set. It is suitable for token classification tasks, such as named entity recognition. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler for 3 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 0.0593, "protocol": "eval_loss"}, {"dataset": "conll-2003", "metric": 0.9293, "protocol": "eval_precision"}, {"dataset": "conll-2003", "metric": 0.9485, "protocol": "eval_recall"}, {"dataset": "conll-2003", "metric": 0.9388, "protocol": "eval_f1"}, {"dataset": "conll-2003", "metric": 0.9858, "protocol": "eval_accuracy"}, {"dataset": "conll-2003", "metric": 120.5431, "protocol": "eval_runtime"}, {"dataset": "conll-2003", "metric": 26.97, "protocol": "eval_samples_per_second"}, {"dataset": "conll-2003", "metric": 3.376, "protocol": "eval_steps_per_second"}, {"dataset": "conll-2003", "metric": 2.0, "protocol": "epoch"}, {"dataset": "conll-2003", "metric": 3512.0, "protocol": "step"}], "source": "huggingface"}, {"id": "huggingface-sammy786-wav2vec2-xlsr-kyrgyz", "modules": [{"role": "model", "module": {"name": "sammy786/wav2vec2-xlsr-kyrgyz", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-1b on the MOZILLA-FOUNDATION/COMMON_VOICE_8_0 - ky dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 4.56379946629835e-05, "train_batch_size": 8, "eval_batch_size": 16, "seed": 13, "gradient_accumulation_steps": 2, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "cosine_with_restarts", "lr_scheduler_warmup_steps": 500, "num_epochs": 30, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "sammy786/wav2vec2-xlsr-kyrgyz is a fine-tuned version of facebook/wav2vec2-xls-r-1b on the MOZILLA-FOUNDATION/COMMON_VOICE_8_0 - ky dataset. The model is intended for automatic speech recognition tasks. The model was trained on Common voice Finnish train.tsv, dev.tsv and other.tsv datasets. The model achieved a Test WER of 39.19 and Test CER of 6.25. The model was trained using PyTorch 1.10.0+cu102 and Transformers 4.16.0.dev0."}}, {"role": "dataset", "purpose": "For model training.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 39.19, "protocol": "WER"}, {"dataset": "common-voice", "metric": 6.25, "protocol": "CER"}], "source": "huggingface"}, {"id": "huggingface-alexrfelicio-t5-small-finetuned8-en-to-de", "modules": [{"role": "model", "module": {"name": "t5-small-finetuned8-en-to-de", "description": "A fine-tuned version of t5-small on the wmt16 dataset for English-to-German translation."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1, "mixed_precision_training": true}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "t5-small-finetuned8-en-to-de is a transformer model fine-tuned on the wmt16 dataset for English-to-German translation. The model uses a sequence-to-sequence architecture and is best suited for translation tasks. The model was trained with Adam optimizer and a linear learning rate scheduler. The model was trained for one epoch with a batch size of 16 and mixed precision training. The BLEU score for the model is 3.9127 and the generated length is 4.0207."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wmt-2016"}], "metrics": [{"dataset": "wmt-2016", "metric": 3.9127, "protocol": "BLEU"}, {"dataset": "wmt-2016", "metric": 4.0207, "protocol": "Gen Len"}], "source": "huggingface"}, {"id": "huggingface-sujit27-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 game."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 game. The model includes the Q-Table learned by the agent and can be used to evaluate the agent's performance. The mean reward achieved by the agent is 7.52 with a standard deviation of 2.76."}}, {"role": "dataset", "purpose": "The game environment used for training and evaluation.", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.52, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-shed-e-thucnews", "modules": [{"role": "model", "module": {"name": "thucnews", "description": "A fine-tuned version of hfl/rbt6 on the load_train dataset for text classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0001, "train_batch_size": 256, "eval_batch_size": 256, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 8, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "thucnews is a fine-tuned transformer model on the load_train dataset for text classification. It achieves an accuracy of 0.9433 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 0.0001 and a batch size of 256. The model was trained for 8 epochs with mixed precision training. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-lindeberg-distilbert-base-uncased-finetuned-cola", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-cola", "description": "A fine-tuned version of distilbert-base-uncased on the glue dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-cola is a fine-tuned version of distilbert-base-uncased on the glue dataset. It is a transformer model that can be used for text classification tasks. The model achieved a Matthews Correlation score of 0.4497 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 16."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.4496664370323995, "protocol": "matthews_correlation"}], "source": "huggingface"}, {"id": "huggingface-ajitjadhav-t5-small-finetuned-t5-summarization", "modules": [{"role": "model", "module": {"name": "t5-small-finetuned-t5-summarization", "description": "A fine-tuned version of t5-small on the cnn_dailymail dataset for summarization."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 6e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 6, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "t5-small-finetuned-t5-summarization is a transformer model fine-tuned on the cnn_dailymail dataset for summarization. It uses a linear learning rate scheduler and mixed precision training. The model achieved a Rouge1 score of 24.5755 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "cnn-daily-mail"}], "metrics": [{"dataset": "cnn-daily-mail", "metric": 24.5755, "protocol": "Rouge1"}, {"dataset": "cnn-daily-mail", "metric": 11.8424, "protocol": "Rouge2"}, {"dataset": "cnn-daily-mail", "metric": 20.3031, "protocol": "Rougel"}, {"dataset": "cnn-daily-mail", "metric": 23.1867, "protocol": "Rougelsum"}], "source": "huggingface"}, {"id": "huggingface-histinct7002-distilbert-base-uncased-finetuned-ner", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-ner", "description": "A fine-tuned version of distilbert-base-uncased on the conll2003 dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-ner is a fine-tuned version of distilbert-base-uncased on the conll2003 dataset for token classification. The model achieved high scores on the evaluation set, with a precision of 0.9334, recall of 0.9398, F1 of 0.9366, and accuracy of 0.9845. The model is suitable for named entity recognition tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 0.9334444444444444, "protocol": "Precision"}, {"dataset": "conll-2003", "metric": 0.9398142969012194, "protocol": "Recall"}, {"dataset": "conll-2003", "metric": 0.9366185406098445, "protocol": "F1"}, {"dataset": "conll-2003", "metric": 0.9845425516704529, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-kingabzpro-wav2vec2-large-xlsr-53-wolof", "modules": [{"role": "model", "module": {"name": "Wav2Vec2ForCTC", "description": "Pretrained model on Wolof language using a Wav2Vec2ForCTC architecture for automatic speech recognition."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_name": "kingabzpro/wav2vec2-large-xlsr-53-wolof", "device": "cuda", "padding": true, "sampling_rate": 16000, "batch_size": 8, "num_proc": 4}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Wav2Vec2ForCTC is a pretrained model on Wolof language using a Wav2Vec2ForCTC architecture for automatic speech recognition. The model was trained on the AI4D Baamtu Datamation dataset. The model achieved a WER of 7.88% on the Wolof test set. The model is intended to be fine-tuned on other speech recognition tasks in Wolof language."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "mediaspeech"}], "metrics": [{"dataset": "mediaspeech", "metric": 7.88, "protocol": "WER"}], "source": "huggingface"}, {"id": "huggingface-ysharma-distilbert-base-uncased-finetuned-emotions", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotions", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotions is a fine-tuned version of distilbert-base-uncased on the emotion dataset. It can be used for text classification tasks related to emotions. The model achieved an F1 score of 0.9331 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler. The model was trained for 2 epochs with a batch size of 64."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emocontext"}], "metrics": [{"dataset": "emocontext", "metric": 0.9331148494056558, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-clevrly-xlnet-base-mnli-orgs-finetuned1", "modules": [{"role": "model", "module": {"name": "xlnet-base-mnli-orgs-finetuned1", "description": "Fine-tuned version of clevrly/xlnet-base-mnli-finetuned on the None dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 1, "eval_batch_size": 1, "seed": 42, "gradient_accumulation_steps": 4, "total_train_batch_size": 4, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "xlnet-base-mnli-orgs-finetuned1 is a fine-tuned version of clevrly/xlnet-base-mnli-finetuned on the None dataset. It is a transformer model that can be used for text classification tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler. The model achieved an F1 score of 0.6957 on the validation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "multinli-multi-genre-natural-language-inference"}], "metrics": [{"dataset": "multinli-multi-genre-natural-language-inference", "metric": 0.6957, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-fi-ru", "modules": [{"role": "model", "module": {"name": "opus-mt-fi-ru", "description": "A machine translation model that translates from Finnish to Russian."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-fi-ru is a machine translation model that translates from Finnish to Russian. It uses a transformer-align model and pre-processing techniques such as normalization and SentencePiece. The model achieves a BLEU score of 46.3 and a chr-F score of 0.67 on the Tatoeba.fi.ru test set."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-sam999-distilbert-base-uncased-finetuned-squad", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-squad", "description": "A fine-tuned version of distilbert-base-uncased on the squad dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 0.2}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-squad is a fine-tuned version of distilbert-base-uncased on the squad dataset. It is suitable for question answering tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler. The model was trained for 0.2 epochs with a batch size of 16. The model achieved a validation loss of 1.6908."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 1.8853, "split": "val", "protocol": "loss"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 1.6908, "split": "test", "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-abhinav-kumar-thakur-distilbert-base-uncased-finetuned-mrpc", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-mrpc", "description": "A fine-tuned version of distilbert-base-uncased on the MRPC dataset from the GLUE benchmark."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-mrpc is a fine-tuned version of distilbert-base-uncased on the MRPC dataset from the GLUE benchmark. It is suitable for text classification tasks. The model achieved an accuracy of 0.8578 and an F1 score of 0.9007 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 16 for 5 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.8578431372549019, "protocol": "accuracy"}, {"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.9006849315068494, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-voleg44-q-frozenlake-v1-4x4-noslippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained model of a Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-4x4-no_slippery", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model's hyperparameters include the algorithm used, the environment, the maximum number of steps per episode, the number of episodes to evaluate the agent, the Q-table learned by the agent, and the random seed used for evaluation. The model achieved a mean reward of 1.00 with no standard deviation."}}, {"role": "dataset", "purpose": "Environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-ueb1-icebert-finetuned-ner", "modules": [{"role": "model", "module": {"name": "IceBERT-finetuned-ner", "description": "A fine-tuned version of IceBERT on the mim_gold_ner dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "IceBERT-finetuned-ner is a fine-tuned version of IceBERT on the mim_gold_ner dataset for token classification. The model achieved high precision, recall, F1 score, and accuracy on the evaluation set. The model is suitable for named entity recognition tasks in Icelandic language. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "mimic-iii-the-medical-information-mart-for-intensive-care-iii"}], "metrics": [{"dataset": "mimic-iii-the-medical-information-mart-for-intensive-care-iii", "metric": 0.8926985693142575, "protocol": "precision"}, {"dataset": "mimic-iii-the-medical-information-mart-for-intensive-care-iii", "metric": 0.8648584060222249, "protocol": "recall"}, {"dataset": "mimic-iii-the-medical-information-mart-for-intensive-care-iii", "metric": 0.8785579899253504, "protocol": "f1"}, {"dataset": "mimic-iii-the-medical-information-mart-for-intensive-care-iii", "metric": 0.985303647287535, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-fznmhmmd-distilbert-base-uncased-finetuned-cola", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-cola", "description": "A fine-tuned version of distilbert-base-uncased on the glue dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-cola is a fine-tuned version of distilbert-base-uncased on the glue dataset. It is suitable for text classification tasks. The model achieved a Matthews Correlation score of 0.5544 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler. The model was trained for 5 epochs with a batch size of 16."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.5543972545286807, "protocol": "matthews_correlation"}], "source": "huggingface"}, {"id": "huggingface-miyagawaorj-distilbert-base-uncased-finetuned-clinc", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-clinc", "description": "A fine-tuned version of distilbert-base-uncased on the clinc_oos dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-clinc is a fine-tuned version of distilbert-base-uncased on the clinc_oos dataset. It is a text classification model that can be used to classify out-of-scope queries. The model achieved an accuracy of 0.9474 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler for 5 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "clinc-single-domain-oos"}], "metrics": [{"dataset": "clinc-single-domain-oos", "metric": 0.9474193548387096, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-nyk-en", "modules": [{"role": "model", "module": {"name": "opus-mt-nyk-en", "description": "A transformer-align model for translating from the Nyk language to English."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-nyk-en model is a transformer-align model that translates from the Nyk language to English. It achieved a BLEU score of 27.3 and a chr-F score of 0.423 on the JW300.nyk.en test set. The model uses normalization and SentencePiece for pre-processing. Note that the quality of the translations may depend on the quality and size of the training data, and the model may not perform well on out-of-domain or rare language pairs."}}], "metrics": [{"dataset": "jw300", "metric": 27.3, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.423, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-pig4431-imdb-roberta-5e", "modules": [{"role": "model", "module": {"name": "IMDB_roBERTa_5E", "description": "A fine-tuned version of roberta-base on the IMDB dataset for text classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-05, "train_batch_size": 32, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "IMDB_roBERTa_5E is a fine-tuned version of roberta-base on the IMDB dataset for text classification. The model achieved an accuracy of 0.9467 on the evaluation set. The model is suitable for text classification tasks, but caution should be taken when deploying it in human-interacting systems as it reflects the biases of the systems it was trained on."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.9467, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-heranm-finetuning-sentiment-model-3000-samples", "modules": [{"role": "model", "module": {"name": "finetuning-sentiment-model-3000-samples", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "finetuning-sentiment-model-3000-samples is a fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis. The model achieved an accuracy of 0.8733 and an F1 score of 0.8766 on the evaluation set. The model is suitable for text classification tasks, but its performance may vary depending on the specific use case and data distribution."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.8733, "protocol": "accuracy"}, {"dataset": "imdb-movie-reviews", "metric": 0.8766, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-bem-fi", "modules": [{"role": "model", "module": {"name": "opus-mt-bem-fi", "description": "A machine translation model that translates from Bemba to Finnish."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-bem-fi is a machine translation model that translates from Bemba to Finnish. The model uses the transformer-align architecture and pre-processing techniques such as normalization and SentencePiece. The model achieves a BLEU score of 22.8 and a chr-F score of 0.439 on the JW300.bem.fi test set."}}], "metrics": [{"dataset": "jw300", "metric": 22.8, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.439, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-mofe-xls-r-hausa-40", "modules": [{"role": "model", "module": {"name": "facebook/wav2vec2-xls-r-300m", "description": "Fine-tuned model on the Common Voice 8.0 - HA dataset for Automatic Speech Recognition."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 9.6e-05, "train_batch_size": 8, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 4, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 2000, "num_epochs": 80.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the Common Voice 8.0 - HA dataset for Automatic Speech Recognition. The model achieved a WER of 51.31% on the evaluation set. The model was trained using Adam optimizer with a learning rate of 9.6e-05, and a linear learning rate scheduler with warmup steps of 2000. The model was trained for 80 epochs with mixed precision training. The model was trained using the Transformers 4.17.0.dev0, Pytorch 1.10.2+cu113, Datasets 1.18.4.dev0, and Tokenizers 0.11.0."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 51.31, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-saiharsha-vit-base-beans", "modules": [{"role": "model", "module": {"name": "vit-base-beans", "description": "A fine-tuned version of google/vit-base-patch16-224-in21k on the beans dataset for image classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5.0}}}, {"role": "taskType", "module": "image-classification"}, {"role": "solutionSummary", "module": {"summary": "vit-base-beans is a fine-tuned version of google/vit-base-patch16-224-in21k on the beans dataset for image classification. The model achieved an accuracy of 0.9699 on the evaluation set. The model is suitable for image classification tasks, but its performance may vary depending on the specific use case. The model was trained using PyTorch and Transformers frameworks with a linear learning rate scheduler and Adam optimizer."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "plantvillage"}], "metrics": [{"dataset": "plantvillage", "metric": 0.9699248120300752, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-brjezierski-bert-finetuned-ner", "modules": [{"role": "model", "module": {"name": "bert-finetuned-ner", "description": "A fine-tuned version of bert-base-cased on the conll2003 dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-finetuned-ner is a fine-tuned version of bert-base-cased on the conll2003 dataset for token classification. The model achieved high precision, recall, F1 score, and accuracy on the evaluation set. The model is suitable for named entity recognition tasks, but caution should be taken when deploying it in human-interacting systems as it may reflect the biases of the systems it was trained on."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 0.9340841338191455, "protocol": "Precision"}, {"dataset": "conll-2003", "metric": 0.9491753618310333, "protocol": "Recall"}, {"dataset": "conll-2003", "metric": 0.9415692821368947, "protocol": "F1"}, {"dataset": "conll-2003", "metric": 0.9853858833225407, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-dspg-distilbert-base-uncased-finetuned-squad", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-squad", "description": "A fine-tuned version of distilbert-base-uncased on the squad dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-squad is a fine-tuned version of distilbert-base-uncased on the squad dataset. It is suitable for question answering tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for 3 epochs and achieved a loss of 1.1596 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 1.1596, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-constanter-q-frozenlake-v1-4x4-noslippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-4x4-no_slippery", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model's hyperparameters include the algorithm used, the environment, the maximum number of steps per episode, the number of episodes to evaluate the agent, the Q-Table learned by the agent, and the random seed used for evaluation. The model achieved a mean reward of 1.0 with no standard deviation."}}, {"role": "dataset", "purpose": "Environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-et-es", "modules": [{"role": "model", "module": {"name": "opus-mt-et-es", "description": "A machine translation model that translates from Estonian to Spanish."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-et-es is a machine translation model that translates from Estonian to Spanish. It uses a transformer-align model and pre-processing techniques such as normalization and SentencePiece. The model achieves a BLEU score of 27.2 and a chr-F score of 0.49 on the JW300.et.es test set."}}], "metrics": [{"dataset": "jw300", "metric": 27.2, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.49, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-pietrotrope-hate-trained", "modules": [{"role": "model", "module": {"name": "hate_trained", "description": "Fine-tuned version of distilbert-base-uncased on the tweet_eval dataset for text classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 9.303025140957233e-06, "train_batch_size": 4, "eval_batch_size": 4, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 4}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "hate_trained is a fine-tuned version of distilbert-base-uncased on the tweet_eval dataset for text classification. The model achieved an F1 score of 0.7730 on the evaluation set. The model is suitable for text classification tasks, but its performance may vary depending on the specific use case and data distribution."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "tweeteval"}], "metrics": [{"dataset": "tweeteval", "metric": 0.7730369969869401, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-dooglak-article-250v2-ner-model-3epochs-augmented", "modules": [{"role": "model", "module": {"name": "Article_250v2_NER_Model_3Epochs_AUGMENTED", "description": "Fine-tuned version of bert-base-cased on the article250v2_wikigold_split dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of bert-base-cased on the article250v2_wikigold_split dataset for token classification. It achieved a precision of 0.6846, recall of 0.6809, F1 score of 0.6827, and accuracy of 0.9284 on the evaluation set. The model was trained for 3 epochs with a batch size of 8 and a learning rate of 2e-05 using the Adam optimizer with betas=(0.9,0.999) and epsilon=1e-08."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wikisplit"}], "metrics": [{"dataset": "wikisplit", "metric": 0.6846043165467626, "protocol": "precision"}, {"dataset": "wikisplit", "metric": 0.680881511161992, "protocol": "recall"}, {"dataset": "wikisplit", "metric": 0.6827378390012915, "protocol": "f1"}, {"dataset": "wikisplit", "metric": 0.928421690702902, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-motmono-diy-ppo-cartpole-v1", "modules": [{"role": "model", "module": {"name": "PPO Agent Playing CartPole-v1", "description": "A trained PPO agent playing CartPole-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"seed": 1, "total_timesteps": 500000, "learning_rate": 0.00025, "num_envs": 4, "num_steps": 128, "anneal_lr": true, "gae": true, "gamma": 0.99, "gae_lambda": 0.95, "num_minibatches": 4, "update_epochs": 4, "norm_adv": true, "clip_coef": 0.2, "clip_vloss": true, "ent_coef": 0.01, "vf_coef": 0.5, "max_grad_norm": 0.5, "batch_size": 512, "minibatch_size": 128}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained PPO agent playing CartPole-v1. The model was trained with a total of 500,000 timesteps and achieved a mean reward of 490.60 +/- 28.20. The hyperparameters used for training include a learning rate of 0.00025, 4 environments, 128 steps per environment, and 4 minibatches. The model was trained with the goal of maximizing the reward in the CartPole-v1 environment."}}, {"role": "dataset", "purpose": "Environment for model training.", "module": "safe-control-gym"}], "metrics": [{"dataset": "safe-control-gym", "metric": 490.6, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-manishkalra-finetuning-movie-sentiment-model-9000-samples", "modules": [{"role": "model", "module": {"name": "finetuning-movie-sentiment-model-9000-samples", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis. It achieves an accuracy of 0.9178 and an F1 score of 0.9155 on the evaluation set. The model is suitable for text classification tasks, particularly for sentiment analysis on movie reviews. However, the model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.9177777777777778, "protocol": "accuracy"}, {"dataset": "imdb-movie-reviews", "metric": 0.9155251141552511, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-jfrojanoj-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. The model is best suited for text classification tasks. The model achieved an accuracy of 0.926 and an F1 score of 0.9258 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.926, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.9257579044598276, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-sukhendrasingh-finetuning-sentiment-model-3000-samples", "modules": [{"role": "model", "module": {"name": "finetuning-sentiment-model-3000-samples", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis. It achieves an accuracy of 0.8733 and an F1 score of 0.8797 on the evaluation set. The model was trained for 2 epochs with a batch size of 16 and a learning rate of 2e-05 using the Adam optimizer with betas=(0.9,0.999) and epsilon=1e-08. The model was trained using the Transformers 4.16.2, Pytorch 1.10.0+cu111, Datasets 1.18.3, and Tokenizers 0.11.0."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.8733333333333333, "protocol": "accuracy"}, {"dataset": "imdb-movie-reviews", "metric": 0.879746835443038, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-masakhane-m2m100-418m-fr-fon-rel-news", "modules": [{"role": "model", "module": {"name": "m2m100_418M-fr-fon-mt", "description": "Machine translation model from French to Fon based on a fine-tuned facebook/m2m100_418M model."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"fine_tuned_on": ["JW300 Fon corpus", "LAFAND"], "training_gpu": "NVIDIA V100"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "m2m100_418M-fr-fon-mt is a machine translation model from French to Fon based on a fine-tuned facebook/m2m100_418M model. The model establishes a baseline for automatically translating texts from French to Fon. However, the model is limited by its training dataset and may not generalize well for all use cases in different domains."}}, {"role": "dataset", "purpose": "For fine-tuning.", "module": "jw300"}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-sidhanttholenlp-distilbert-finetuned-imdb", "modules": [{"role": "model", "module": {"name": "distilbert-finetuned-imdb", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-finetuned-imdb is a fine-tuned version of distilbert-base-uncased on the imdb dataset. It is a transformer model that can be used for text classification tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 64. The model was trained for 3 epochs and achieved a loss of 2.4667 on the evaluation set. The model was trained using PyTorch 1.12.0+cu113 and Transformers 4.20.1."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 2.4667, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-tatoeba-af-ru", "modules": [{"role": "model", "module": {"name": "af-ru transformer-align", "description": "A machine translation model that translates from Afrikaans to Russian using a transformer-align architecture."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece (spm32k,spm32k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "This is a machine translation model that translates from Afrikaans to Russian using a transformer-align architecture. The model was trained on the Tatoeba dataset and achieved a BLEU score of 38.2 and a chrF2 score of 0.58 on the test set. The model uses normalization and SentencePiece (spm32k,spm32k) for pre-processing."}}, {"role": "dataset", "purpose": "Test set used for evaluation.", "module": "tatoeba-translation-challenge"}], "metrics": [{"dataset": "tatoeba-translation-challenge", "metric": 38.2, "protocol": "BLEU"}, {"dataset": "tatoeba-translation-challenge", "metric": 0.58, "protocol": "chrF2"}], "source": "huggingface"}, {"id": "huggingface-sepidmnorozy-parsbert-finetuned-pos", "modules": [{"role": "model", "module": {"name": "parsbert-finetuned-pos", "description": "A fine-tuned version of HooshvareLab/bert-base-parsbert-uncased on the udpos28 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "parsbert-finetuned-pos is a fine-tuned version of HooshvareLab/bert-base-parsbert-uncased on the udpos28 dataset. It is a token classification model that can be used for part-of-speech tagging in Persian language. The model achieved high precision, recall, F1 score, and accuracy on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler for 3 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "universal-dependencies"}], "metrics": [{"dataset": "universal-dependencies", "metric": 0.9447937270415372, "protocol": "precision"}, {"dataset": "universal-dependencies", "metric": 0.9486470191864382, "protocol": "recall"}, {"dataset": "universal-dependencies", "metric": 0.9467164522465448, "protocol": "f1"}, {"dataset": "universal-dependencies", "metric": 0.9598951738759165, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-flair-ner-dutch", "modules": [{"role": "model", "module": {"name": "Dutch NER in Flair (default model)", "description": "A 4-class NER model for Dutch that uses Transformer embeddings and LSTM-CRF."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"embeddings": {"name": "TransformerWordEmbeddings", "pretrained_model": "wietsedv/bert-base-dutch-cased"}, "hidden_size": 256, "tag_type": "ner", "max_epochs": 150}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a 4-class NER model for Dutch that uses Transformer embeddings and LSTM-CRF. It can predict person names, location names, organization names, and other names. The model is trained on the CoNLL-03 dataset and achieves an F1-Score of 92.58. The model is intended to be fine-tuned on downstream tasks and can be used with Flair's SequenceTagger class. The model is based on the paper 'FLAIR: An Easy-to-Use Framework for State-of-the-Art NLP'."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 92.58, "protocol": "F1-Score"}], "source": "huggingface"}, {"id": "huggingface-ernestumorga-sac-seals-ant-v0", "modules": [{"role": "model", "module": {"name": "SAC", "description": "A trained SAC agent playing seals/Ant-v0 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 512, "buffer_size": 1000000, "gamma": 0.98, "learning_rate": 0.0018514039303149058, "learning_starts": 1000, "n_timesteps": 1000000.0, "policy": "MlpPolicy", "policy_kwargs": {"net_arch": [256, 256], "log_std_init": -2.2692589009754176}, "tau": 0.05, "train_freq": 64, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "The model is a trained SAC agent playing seals/Ant-v0 using the stable-baselines3 library and the RL Zoo. The hyperparameters used for training are provided, along with the mean reward achieved on the seals/Ant-v0 dataset. The model can be downloaded and used for further training or evaluation."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 966.1, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-sb3-a2c-antbulletenv-v0", "modules": [{"role": "model", "module": {"name": "A2C", "description": "A reinforcement learning agent trained on AntBulletEnv-v0 using the stable-baselines3 library."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"ent_coef": 0.0, "gae_lambda": 0.9, "gamma": 0.99, "learning_rate": "lin_0.00096", "max_grad_norm": 0.5, "n_envs": 4, "n_steps": 8, "n_timesteps": 2000000.0, "normalize": true, "normalize_advantage": false, "policy": "MlpPolicy", "policy_kwargs": {"log_std_init": -2, "ortho_init": false}, "use_rms_prop": true, "use_sde": true, "vf_coef": 0.4, "normalize_kwargs": {"norm_obs": true, "norm_reward": false}}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "A2C is a reinforcement learning agent trained on AntBulletEnv-v0 using the stable-baselines3 library. The agent was trained using the A2C algorithm with hyperparameters such as gamma, learning rate, and number of steps. The model achieved a mean reward of 2519.30 with a standard deviation of 10.68. The model can be used for tasks such as robotic control and navigation."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 2519.3, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-dimboump-glue-sst-classifier", "modules": [{"role": "model", "module": {"name": "glue_sst_classifier", "description": "A fine-tuned version of bert-base-cased on the glue dataset for text classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 1e-05, "train_batch_size": 128, "eval_batch_size": 128, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.1, "num_epochs": 1.0}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "glue_sst_classifier is a fine-tuned version of bert-base-cased on the glue dataset for text classification. The model achieved an F1 score of 0.9034 and an accuracy of 0.9014 on the evaluation set. The model is suitable for text classification tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.9033707865168539, "protocol": "f1"}, {"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.9013761467889908, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-w11wo-javanese-bert-small-imdb-classifier", "modules": [{"role": "model", "module": {"name": "Javanese BERT Small IMDB Classifier", "description": "A movie-classification model based on the BERT model, trained on Javanese IMDB movie reviews."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"architecture": "BERT Small", "training_epochs": 5, "training_data_size": "47.5 MB of text"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "Javanese BERT Small IMDB Classifier is a movie-classification model based on the BERT model, trained on Javanese IMDB movie reviews. The model achieved an accuracy of 76.37% on the validation dataset. It can be used as a text classifier. However, the model reflects the biases of the IMDB reviews it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and validation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.131, "protocol": "train_loss"}, {"dataset": "imdb-movie-reviews", "metric": 1.113, "protocol": "valid_loss"}, {"dataset": "imdb-movie-reviews", "metric": 0.763, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-edresson-wav2vec2-large-100k-voxpopuli-ft-tts-dataset-portuguese", "modules": [{"role": "model", "module": {"name": "Wav2vec2 Large 100k Voxpopuli fine-tuned with a single-speaker dataset in Portuguese", "description": "Wav2vec2 Large 100k Voxpopuli fine-tuned in Portuguese using a single-speaker dataset (TTS-Portuguese Corpus)."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_name": "Edresson/wav2vec2-large-100k-voxpopuli-ft-TTS-Dataset-portuguese", "tokenizer_name": "Edresson/wav2vec2-large-100k-voxpopuli-ft-TTS-Dataset-portuguese", "resample": {"orig_freq": 48000, "new_freq": 16000}}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Wav2vec2 Large 100k Voxpopuli fine-tuned with a single-speaker dataset in Portuguese is a speech recognition model that was fine-tuned on a single-speaker dataset (TTS-Portuguese Corpus) and Common Voice dataset. The model uses Wav2vec2 architecture and was trained using CTC loss. The model is suitable for speech recognition tasks in Portuguese. The model's performance is evaluated using the Word Error Rate (WER) metric."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-arashasg-wikibert2wikibert", "modules": [{"role": "model", "module": {"name": "WikiBert2WikiBert", "description": "An encoder-decoder transformer model for summarization tasks, initialized using the Persian WikiBert Model weights."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"tokenizer": "BertTokenizerFast", "max_length": 512, "epochs": 5}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "WikiBert2WikiBert is an encoder-decoder transformer model for summarization tasks, initialized using the Persian WikiBert Model weights. The model is fine-tuned on PN-summary and Persian BBC datasets. The model achieved a Rouge-1 score of 38.97%, Rouge-2 score of 18.42%, and Rouge-l score of 34.50% on the evaluation set. The model can be used to generate summaries for Persian text."}}, {"role": "dataset", "purpose": "For training.", "module": "perkey"}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-lgris-wavlm-large-coraa-pt-cv7", "modules": [{"role": "model", "module": {"name": "wavlm-large-CORAA-pt-cv7", "description": "A fine-tuned version of lgris/WavLM-large-CORAA-pt on the common_voice dataset for automatic speech recognition."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0001, "train_batch_size": 8, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 2, "total_train_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 100, "training_steps": 5000}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of lgris/WavLM-large-CORAA-pt on the common_voice dataset for automatic speech recognition. The model achieved a loss of 0.2546 and a WER of 0.2261 on the evaluation set. The model is intended for automatic speech recognition tasks and reflects the biases inherent to the systems they were trained on, so caution should be taken when deploying it into systems that interact with humans."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.2546, "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.2261, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-shri3-q-frozenlake-v1-4x4-noslippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained model of a Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-4x4-no_slippery"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model was trained using the Q-Learning algorithm and evaluated on the FrozenLake-v1-4x4-no_slippery environment. The model achieved a mean reward of 1.00 +/- 0.00, but the verification status is unknown."}}, {"role": "dataset", "purpose": "The environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "extra": "1.00 +/- 0.00", "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-it5-mt5-small-wiki-summarization", "modules": [{"role": "model", "module": {"name": "mT5 Small for Wikipedia Summarization", "description": "A multilingual T5 model fine-tuned on Italian Wikipedia summarization."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_type": "mt5", "model_size": "small", "batch_size": 32, "optimizer": {"name": "Adam", "learning_rate": 0.0001}}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "The mT5 Small model is a multilingual T5 model fine-tuned on Italian Wikipedia summarization. It was trained on the WITS dataset and achieved good scores on the Rouge and BERTScore metrics. The model is suitable for summarizing Italian Wikipedia articles."}}, {"role": "dataset", "purpose": "For model training.", "module": "wits-why-is-this-sarcastic"}], "metrics": [{"dataset": "wits-why-is-this-sarcastic", "metric": 0.347, "protocol": "rouge1"}, {"dataset": "wits-why-is-this-sarcastic", "metric": 0.2, "protocol": "rouge2"}, {"dataset": "wits-why-is-this-sarcastic", "metric": 0.316, "protocol": "rougeL"}, {"dataset": "wits-why-is-this-sarcastic", "metric": 0.517, "protocol": "bertscore"}], "source": "huggingface"}, {"id": "huggingface-alefarasin-ppo-cartpole-v1", "modules": [{"role": "model", "module": {"name": "PPO Agent Playing CartPole-v1", "description": "A trained PPO agent playing CartPole-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"seed": 1, "total_timesteps": 50000, "learning_rate": 0.00025, "num_envs": 4, "num_steps": 128, "anneal_lr": true, "gae": true, "gamma": 0.99, "gae_lambda": 0.95, "num_minibatches": 4, "update_epochs": 4, "norm_adv": true, "clip_coef": 0.2, "clip_vloss": true, "ent_coef": 0.01, "vf_coef": 0.5, "max_grad_norm": 0.5, "batch_size": 512, "minibatch_size": 128}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained PPO agent playing CartPole-v1. The model was trained with PPO algorithm with hyperparameters such as learning rate, gamma, and number of steps. The model achieved a mean reward of 155.80 with a standard deviation of 45.55. The model can be used as a starting point for custom implementation of PPO agent for other environments."}}, {"role": "dataset", "purpose": "Environment for model training.", "module": "safe-control-gym"}], "metrics": [{"dataset": "safe-control-gym", "metric": 155.8, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-gary109-ai-light-dance-singing-ft-wav2vec2-large-xlsr-53", "modules": [{"role": "model", "module": {"name": "ai-light-dance_singing_ft_wav2vec2-large-xlsr-53", "description": "Fine-tuned version of facebook/wav2vec2-large-xlsr-53 on the GARY109/AI_LIGHT_DANCE - ONSET-SINGING dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 2, "eval_batch_size": 2, "seed": 42, "gradient_accumulation_steps": 16, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "cosine", "lr_scheduler_warmup_steps": 500, "num_epochs": 10.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "ai-light-dance_singing_ft_wav2vec2-large-xlsr-53 is a fine-tuned version of facebook/wav2vec2-large-xlsr-53 on the GARY109/AI_LIGHT_DANCE - ONSET-SINGING dataset. It is intended for automatic speech recognition tasks. The model was trained using Adam optimizer with a learning rate of 5e-05 and cosine learning rate scheduler. The model achieved a WER of 0.2043 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "vocalset-vocalset-a-singing-voice-dataset"}], "metrics": [{"dataset": "vocalset-vocalset-a-singing-voice-dataset", "metric": 0.4327, "protocol": "loss"}, {"dataset": "vocalset-vocalset-a-singing-voice-dataset", "metric": 0.2043, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-arnold-wav2vec2-large-xlsr-hausa2-demo-colab", "modules": [{"role": "model", "module": {"name": "wav2vec2-large-xlsr-hausa2-demo-colab", "description": "Fine-tuned version of facebook/wav2vec2-large-xlsr-53 on the common_voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 9.6e-05, "train_batch_size": 12, "eval_batch_size": 8, "seed": 13, "gradient_accumulation_steps": 3, "total_train_batch_size": 36, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 400, "num_epochs": 50, "mixed_precision_training": true}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of facebook/wav2vec2-large-xlsr-53 on the common_voice dataset. The model is intended for automatic speech recognition tasks. The model was trained using Adam optimizer with a learning rate of 9.6e-05 and a linear learning rate scheduler. The model was trained for 50 epochs with mixed precision training. The model achieved a validation loss of 0.2993 and a WER of 0.4826."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.2991, "split": "val", "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.2993, "split": "test", "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.4826, "protocol": "WER"}], "source": "huggingface"}, {"id": "huggingface-othmanej-distil-wav2vec2", "modules": [{"role": "model", "module": {"name": "Distil-wav2vec2", "description": "Distilled version of the wav2vec2 model for automatic speech recognition."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_size": "197.9 Mb"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Distil-wav2vec2 is a distilled version of the wav2vec2 model for automatic speech recognition. It is 45% smaller and twice as fast as the original wav2vec2 base model. The model was evaluated on the Librispeech dataset and achieved a word error rate of 0.0983 on test-clean and 0.2266 on test-other. The model can be used for speech recognition tasks and a notebook is available on GitHub for usage."}}, {"role": "dataset", "purpose": "For evaluation.", "module": "librispeech"}], "metrics": [{"dataset": "librispeech", "metric": 0.0983, "split": "val", "protocol": "WER"}, {"dataset": "librispeech", "metric": 0.2266, "split": "test", "protocol": "WER"}], "source": "huggingface"}, {"id": "huggingface-lewtun-minilmv2-l12-h384-distilled-finetuned-clinc", "modules": [{"role": "model", "module": {"name": "MiniLMv2-L12-H384-distilled-finetuned-clinc", "description": "A fine-tuned version of MiniLMv2-L12-H384-distilled-from-RoBERTa-Large on the clinc_oos dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0001, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 10, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "MiniLMv2-L12-H384-distilled-finetuned-clinc is a fine-tuned version of MiniLMv2-L12-H384-distilled-from-RoBERTa-Large on the clinc_oos dataset. It is a transformer model that can be used for text classification tasks. The model achieved an accuracy of 0.9529 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 0.0001 and a batch size of 64. The model was trained for 10 epochs with mixed precision training."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "clinc-single-domain-oos"}], "metrics": [{"dataset": "clinc-single-domain-oos", "metric": 0.9529032258064516, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-dumitrescustefan-bert-base-romanian-ner", "modules": [{"role": "model", "module": {"name": "bert-base-romanian-ner", "description": "Fine-tuned BERT model for Named Entity Recognition (NER) on Romanian language."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_type": "bert", "architecture": "BERT", "tokenizer": "bert-base-romanian-cased-v1", "batch_size": 32, "max_seq_length": 128, "learning_rate": 5e-05, "num_train_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-base-romanian-ner is a fine-tuned BERT model for Named Entity Recognition (NER) on Romanian language. It recognizes 15 types of entities and achieves state-of-the-art performance for the NER task. The model is fine-tuned on RONEC version 2.0, which is a BIO2 annotated corpus. The model can be used directly in Transformers or through the roner Python package. The corpus has 12330 sentences with over 0.5M tokens, to a total of 80.283 distinctly annotated entities."}}, {"role": "dataset", "purpose": "For model fine-tuning.", "module": "ronec-romanian-named-entity-corpus"}], "metrics": [{"dataset": "ronec-romanian-named-entity-corpus", "metric": 0.9276865720748901, "protocol": "test/ent_type"}, {"dataset": "ronec-romanian-named-entity-corpus", "metric": 0.9118986129760742, "protocol": "test/exact"}, {"dataset": "ronec-romanian-named-entity-corpus", "metric": 0.9356381297111511, "protocol": "test/partial"}, {"dataset": "ronec-romanian-named-entity-corpus", "metric": 0.8921924233436584, "protocol": "test/strict"}], "source": "huggingface"}, {"id": "huggingface-csalamea-roberta-base-bne-finetuned-amazon-reviews-multi", "modules": [{"role": "model", "module": {"name": "roberta-base-bne-finetuned-amazon_reviews_multi", "description": "A fine-tuned version of BSC-TeMU/roberta-base-bne on the amazon_reviews_multi dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of BSC-TeMU/roberta-base-bne on the amazon_reviews_multi dataset. The model achieved an accuracy of 0.9325 on the evaluation set. The model is suitable for text classification tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "amazon-review"}], "metrics": [{"dataset": "amazon-review", "metric": 0.9325, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-flair-upos-english", "modules": [{"role": "model", "module": {"name": "Flair English Universal Part-of-Speech Tagging", "description": "A sequence tagger model for English that predicts universal POS tags."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"embedding_types": ["FlairEmbeddings('news-forward')", "FlairEmbeddings('news-backward')"], "hidden_size": 256, "tag_type": "upos", "max_epochs": 150}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a sequence tagger model for English that predicts universal POS tags. It is based on Flair embeddings and LSTM-CRF. The model is trained on the Ontonotes dataset and achieves an F1-Score of 98.6. The model is intended to be fine-tuned on downstream tasks such as sequence classification, token classification, or question answering. The model is suitable for tasks that use the whole sentence to make decisions."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "ontonotes-5-0"}], "metrics": [{"dataset": "ontonotes-5-0", "metric": 98.6, "protocol": "F1-Score"}], "source": "huggingface"}, {"id": "huggingface-yayab-q-taxi-v3", "modules": [{"role": "model", "module": {"name": "q-Taxi-v3", "description": "A Q-Learning agent trained to play the Taxi-v3 environment."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "is_slippery": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent that can play the Taxi-v3 environment. The model achieved a mean reward of 7.56 with a standard deviation of 2.71 over a number of evaluation episodes. The model can be loaded and used to evaluate the agent in the environment."}}, {"role": "dataset", "purpose": "OpenAI Gym environment", "module": "nyctaxi"}], "metrics": [{"dataset": "nyctaxi", "metric": 7.56, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-minyoung-distilbert-base-uncased-finetuned-cola", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-cola", "description": "A fine-tuned version of distilbert-base-uncased on the glue dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-cola is a fine-tuned version of distilbert-base-uncased on the glue dataset. It is suitable for text classification tasks. The model achieved a Matthews Correlation score of 0.5495 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler. The model was trained for 5 epochs with a batch size of 16."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "glue-general-language-understanding-evaluation-benchmark"}], "metrics": [{"dataset": "glue-general-language-understanding-evaluation-benchmark", "metric": 0.5495, "protocol": "matthews_correlation"}], "source": "huggingface"}, {"id": "huggingface-dooglak-article-500v3-ner-model-3epochs-unaugmented", "modules": [{"role": "model", "module": {"name": "Article_500v3_NER_Model_3Epochs_UNAUGMENTED", "description": "Fine-tuned version of bert-base-cased on the article500v3_wikigold_split dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of bert-base-cased on the article500v3_wikigold_split dataset for token classification. It achieved a precision of 0.6713, recall of 0.6822, F1 score of 0.6767, and accuracy of 0.9298 on the evaluation set. The model was trained for 3 epochs with a learning rate of 2e-05 and Adam optimizer with betas=(0.9,0.999) and epsilon=1e-08."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wikisplit"}], "metrics": [{"dataset": "wikisplit", "metric": 0.6712553261225828, "protocol": "precision"}, {"dataset": "wikisplit", "metric": 0.6822118587608261, "protocol": "recall"}, {"dataset": "wikisplit", "metric": 0.6766892450024782, "protocol": "f1"}, {"dataset": "wikisplit", "metric": 0.9297837351453659, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-kerkathy-distilbert-base-uncased-finetuned-imdb", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-imdb", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-imdb is a fine-tuned version of distilbert-base-uncased on the imdb dataset. It can be used for text classification tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 64. The model was trained for 3 epochs and achieved a loss of 2.4721 on the evaluation set. The model was trained using PyTorch and Transformers 4.22.1."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 2.4721, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-juanmarmol-distilbert-base-uncased-finetuned-squad", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-squad", "description": "A fine-tuned version of distilbert-base-uncased on the squad dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-squad is a fine-tuned version of distilbert-base-uncased on the squad dataset. It is suitable for question answering tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for 3 epochs and achieved a loss of 1.1524 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 1.1524, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-kevinbram-testarenz", "modules": [{"role": "model", "module": {"name": "testarenz", "description": "A fine-tuned version of distilbert-base-uncased on the squad dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "testarenz is a fine-tuned version of distilbert-base-uncased on the squad dataset. It is a question-answering model that can be used to answer questions based on a given context. The model was trained for one epoch with a linear learning rate scheduler and achieved a validation loss of 1.2153. The model was trained using the Transformers, PyTorch, Datasets, and Tokenizers libraries."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 1.2153, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-cs-fr", "modules": [{"role": "model", "module": {"name": "opus-mt-cs-fr", "description": "A machine translation model that translates from Czech (cs) to French (fr) using the transformer-align architecture."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-cs-fr model is a machine translation model that translates from Czech to French using the transformer-align architecture. The model was trained on the OPUS dataset and uses normalization and SentencePiece for pre-processing. The model achieved a BLEU score of 21.0 and a chr-F score of 0.488 on the GlobalVoices.cs.fr test set."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-chuvn-longformer-base-4096-finetuned-squad2-length-1024-128window", "modules": [{"role": "model", "module": {"name": "longformer-base-4096-finetuned-squad2-length-1024-128window", "description": "A fine-tuned version of allenai/longformer-base-4096 on the squad_v2 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 4, "eval_batch_size": 4, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of allenai/longformer-base-4096 on the squad_v2 dataset. It can be used for question answering tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 4. The model was trained for 1 epoch and achieved a validation loss of 0.9057."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 0.8641, "split": "val", "protocol": "loss"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 0.9057, "split": "test", "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-vuiseng9-wav2vec2-base-100h", "modules": [{"role": "model", "module": {"name": "Wav2Vec2-Base-100h", "description": "A fork of facebook/wav2vec2-base-100h, a model for automatic speech recognition (ASR) trained on LibriSpeech dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 1}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Wav2Vec2-Base-100h is a fork of facebook/wav2vec2-base-100h, a model for automatic speech recognition (ASR) trained on LibriSpeech dataset. The model is evaluated on LibriSpeech's 'clean' and 'other' test data and achieves a word error rate (WER) of 6.1 and 13.5, respectively. The model is intended to be fine-tuned on downstream ASR tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "librispeech"}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-sg-sv", "modules": [{"role": "model", "module": {"name": "opus-mt-sg-sv", "description": "A machine translation model that translates from sg to sv."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-sg-sv is a machine translation model that translates from sg to sv. It uses the transformer-align model and pre-processing techniques such as normalization and SentencePiece. The model achieves a BLEU score of 25.3 and a chr-F score of 0.428 on the JW300.sg.sv test set."}}], "metrics": [{"dataset": "jw300", "metric": 25.3, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.428, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-ln-de", "modules": [{"role": "model", "module": {"name": "opus-mt-ln-de", "description": "A machine translation model that translates from Lingala (ln) to German (de) using a transformer-align model."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-ln-de is a machine translation model that translates from Lingala to German using a transformer-align model. The model was trained on the OPUS dataset and uses normalization and SentencePiece for pre-processing. The model achieved a BLEU score of 23.3 and a chr-F score of 0.428 on the JW300.ln.de test set."}}], "metrics": [{"dataset": "jw300", "metric": 23.3, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.428, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-artifact-ai-en-spacy-wnut-xlm-roberta-base-ner", "modules": [{"role": "model", "module": {"name": "en_spacy_wnut_xlm_roberta_base_ner", "description": "A spaCy model for named entity recognition (NER) using the XLM-RoBERTa transformer and trained on the WNUT-2017 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"spaCy_version": ">=3.4.1,<3.5.0", "pipeline": ["transformer", "ner"], "transformer": "XLM-RoBERTa", "labels": ["corporation", "creative-work", "group", "location", "person", "product"]}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "en_spacy_wnut_xlm_roberta_base_ner is a spaCy model for named entity recognition (NER) using the XLM-RoBERTa transformer and trained on the WNUT-2017 dataset. The model achieved an F1 score of 62.12% on the evaluation set. The model is suitable for identifying named entities in text, with labels including corporation, creative-work, group, location, person, and product."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wnut-2017-wnut-2017-emerging-and-rare-entity-recognition"}], "metrics": [{"dataset": "wnut-2017-wnut-2017-emerging-and-rare-entity-recognition", "metric": 65.78, "protocol": "NER Precision"}, {"dataset": "wnut-2017-wnut-2017-emerging-and-rare-entity-recognition", "metric": 58.85, "protocol": "NER Recall"}, {"dataset": "wnut-2017-wnut-2017-emerging-and-rare-entity-recognition", "metric": 62.12, "protocol": "NER F Score"}], "source": "huggingface"}, {"id": "huggingface-albertdestajo-distilbert-base-uncased-finetuned-mrpc", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-mrpc", "description": "A fine-tuned version of distilbert-base-uncased on the GLUE dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-mrpc is a fine-tuned version of distilbert-base-uncased on the GLUE dataset. It is suitable for text classification tasks. The model achieved an accuracy of 0.7917 and an F1 score of 0.8609 on the evaluation set. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 16."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-pszemraj-distilgpt2-magicprompt-sd", "modules": [{"role": "model", "module": {"name": "distilgpt2-magicprompt-SD", "description": "A fine-tuned version of distilgpt2 on the Gustavosta/Stable-Diffusion-Prompts dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.001, "train_batch_size": 16, "eval_batch_size": 2, "seed": 42, "distributed_type": "multi-GPU", "num_devices": 2, "gradient_accumulation_steps": 8, "total_train_batch_size": 256, "total_eval_batch_size": 4, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "cosine", "lr_scheduler_warmup_ratio": 0.05, "num_epochs": 10.0}}}, {"role": "taskType", "module": "text-to-image"}, {"role": "solutionSummary", "module": {"summary": "distilgpt2-magicprompt-SD is a fine-tuned version of distilgpt2 on the Gustavosta/Stable-Diffusion-Prompts dataset. It can be used for text generation or prompt augmentation. The model is suitable for generating short texts from a prompt. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "diffusiondb"}], "metrics": [{"dataset": "diffusiondb", "metric": 1.3089, "protocol": "Loss"}, {"dataset": "diffusiondb", "metric": 3.7022, "protocol": "Perplexity"}], "source": "huggingface"}, {"id": "huggingface-sebis-code-trans-t5-large-code-documentation-generation-php-multitask-finetune", "modules": [{"role": "model", "module": {"name": "CodeTrans model for code documentation generation php", "description": "Pretrained model on programming language php using the t5 large model architecture."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"pretraining": {"batch_size": 4096, "optimizer": {"name": "AdaFactor", "learning_rate_schedule": "inverse square root"}, "sequence_length": 512}, "fine_tuning": {"batch_size": 256, "sequence_length": 512}}}}, {"role": "taskType", "module": "summarization"}, {"role": "solutionSummary", "module": {"summary": "CodeTrans is a T5-based model pre-trained on a large corpus of PHP code. It can be used to generate documentation for PHP functions or fine-tuned on other PHP code tasks. The model is best suited for tokenized PHP code. The model was trained using multi-task training on 13 supervised tasks in the software development domain and 7 unsupervised datasets. The model was then fine-tuned on the code documentation generation task for the PHP function/method. The model achieved an F1 score of 23.05 on the PHP dataset."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-kwy-sv", "modules": [{"role": "model", "module": {"name": "opus-mt-kwy-sv", "description": "A machine translation model that translates from the Kwy language to Swedish using a transformer-align model."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-kwy-sv model is a machine translation model that translates from the Kwy language to Swedish using a transformer-align model. The model was trained on the OPUS dataset and achieved a BLEU score of 20.2 and a chr-F score of 0.373 on the JW300.kwy.sv test set."}}], "metrics": [{"dataset": "jw300", "metric": 20.2, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.373, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-jaimin-wav2vec2-base-gujarati-demo", "modules": [{"role": "model", "module": {"name": "XLSR Wav2Vec2 Guj by Jaimin", "description": "Fine-tuned Wav2Vec2 model on Gujarati speech data for automatic speech recognition."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "facebook/wav2vec2-large-xlsr-53", "batch_size": 8, "optimizer": {"name": "Adam", "learning_rate": 5e-05}}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned Wav2Vec2 model on Gujarati speech data for automatic speech recognition. The model was trained on Google datasets and achieved a test WER of 28.92%. The model can be used directly without a language model and is suitable for speech recognition tasks in Gujarati language."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "gigaspeech"}], "metrics": [{"dataset": "gigaspeech", "metric": 28.92, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-activationai-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. It can be used for text classification tasks. The model achieved an accuracy of 0.928 and an F1 score of 0.9280 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.928, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.9280065074208208, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-plim-xls-r-1b-fr", "modules": [{"role": "model", "module": {"name": "Fine-tuned facebook/wav2vec2-xls-r-1b on MOZILLA-FOUNDATION/COMMON_VOICE_7_0 - FR dataset", "description": "This model is a fine-tuned version of facebook/wav2vec2-xls-r-1b on the MOZILLA-FOUNDATION/COMMON_VOICE_7_0 - FR dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 7.5e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "gradient_accumulation_steps": 8, "total_train_batch_size": 128, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 2000, "num_epochs": 5.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of facebook/wav2vec2-xls-r-1b on the MOZILLA-FOUNDATION/COMMON_VOICE_7_0 - FR dataset. It can be used for automatic speech recognition tasks in French. The model was trained using Adam optimizer with a learning rate of 7.5e-05 and a linear learning rate scheduler. The model was trained for 5 epochs with a batch size of 128 and mixed precision training. The model achieved a loss of 0.2464 and a word error rate (WER) of 0.2220 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.2464, "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.222, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-dooglak-tagged-one-250v7-ner-model-3epochs-augmented", "modules": [{"role": "model", "module": {"name": "Tagged_One_250v7_NER_Model_3Epochs_AUGMENTED", "description": "Fine-tuned version of bert-base-cased on the tagged_one250v7_wikigold_split dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "Tagged_One_250v7_NER_Model_3Epochs_AUGMENTED is a fine-tuned version of bert-base-cased on the tagged_one250v7_wikigold_split dataset for token classification. The model achieved a Precision of 0.5509, Recall of 0.4676, F1 of 0.5058, and Accuracy of 0.8894 on the evaluation set. The model is intended for token classification tasks, but more information is needed to determine its limitations and intended uses."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wikisplit"}], "metrics": [{"dataset": "wikisplit", "metric": 0.5509259259259259, "protocol": "precision"}, {"dataset": "wikisplit", "metric": 0.4675834970530452, "protocol": "recall"}, {"dataset": "wikisplit", "metric": 0.5058448459086079, "protocol": "f1"}, {"dataset": "wikisplit", "metric": 0.8893517705222476, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-user-leanring-hi-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. The model achieved an accuracy of 0.928 and an F1 score of 0.9279536670242958 on the evaluation set. The model is suitable for text classification tasks, but its intended uses and limitations are not specified in the model card."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.928, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.9279536670242958, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-skang-distilbert-base-uncased-finetuned-imdb", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-imdb", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-imdb is a fine-tuned version of distilbert-base-uncased on the imdb dataset. It can be used for text classification tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 64. The model was trained for 3 epochs and achieved a loss of 0.6627 on the evaluation set. The model was trained using PyTorch and Transformers 4.23.1."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.6627, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-corianas-qrdqn-3frame-spaceinvadersnoframeskip-1-best", "modules": [{"role": "model", "module": {"name": "QRDQN Agent playing SpaceInvadersNoFrameskip-v4", "description": "A trained model of a QRDQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"env_wrapper": "stable_baselines3.common.atari_wrappers.AtariWrapper", "exploration_fraction": 0.025, "frame_stack": 3, "n_timesteps": 10000000.0, "optimize_memory_usage": true, "policy": "CnnPolicy", "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained QRDQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The model was trained for 10 million timesteps with hyperparameters including an exploration fraction of 0.025, frame stack of 3, and a CnnPolicy. The mean reward achieved by the model is 1855.50 with a standard deviation of 869.41."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 1855.5, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-artifact-ai-en-spacy-wnut-roberta-base-ner", "modules": [{"role": "model", "module": {"name": "en_spacy_wnut_roberta_base_ner", "description": "A spaCy model for named entity recognition (NER) using the RoBERTa transformer and trained on the WNUT-2017 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"spaCy_version": ">=3.4.1,<3.5.0", "pipeline": ["transformer", "ner"], "transformer": "RoBERTa", "labels": ["corporation", "creative-work", "group", "location", "person", "product"]}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "en_spacy_wnut_roberta_base_ner is a spaCy model for named entity recognition (NER) using the RoBERTa transformer and trained on the WNUT-2017 dataset. The model has 6 labels for the NER component: corporation, creative-work, group, location, person, and product. The model achieved an F-score of 57.65% on the evaluation set. The model can be used for NER tasks in English text, but its performance may vary depending on the domain and context of the text."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wnut-2017-wnut-2017-emerging-and-rare-entity-recognition"}], "metrics": [{"dataset": "wnut-2017-wnut-2017-emerging-and-rare-entity-recognition", "metric": 0.5875776398, "protocol": "precision"}, {"dataset": "wnut-2017-wnut-2017-emerging-and-rare-entity-recognition", "metric": 0.5657894737, "protocol": "recall"}, {"dataset": "wnut-2017-wnut-2017-emerging-and-rare-entity-recognition", "metric": 0.5764777575, "protocol": "f_score"}, {"dataset": "wnut-2017-wnut-2017-emerging-and-rare-entity-recognition", "metric": 57.65, "protocol": "ENTS_F"}, {"dataset": "wnut-2017-wnut-2017-emerging-and-rare-entity-recognition", "metric": 58.76, "protocol": "ENTS_P"}, {"dataset": "wnut-2017-wnut-2017-emerging-and-rare-entity-recognition", "metric": 56.58, "protocol": "ENTS_R"}, {"dataset": "wnut-2017-wnut-2017-emerging-and-rare-entity-recognition", "metric": 67607.5, "protocol": "TRANSFORMER_LOSS"}, {"dataset": "wnut-2017-wnut-2017-emerging-and-rare-entity-recognition", "metric": 89310.0, "protocol": "NER_LOSS"}], "source": "huggingface"}, {"id": "huggingface-rjzauner-distilbert-rotten-tomatoes-sentiment-classifier", "modules": [{"role": "model", "module": {"name": "distilbert_rotten_tomatoes_sentiment_classifier", "description": "Fine-tuned version of distilbert-base-uncased on the rotten_tomatoes dataset for text classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert_rotten_tomatoes_sentiment_classifier is a fine-tuned version of distilbert-base-uncased on the rotten_tomatoes dataset for text classification. The model was trained using a learning rate of 2e-05, a batch size of 64, and the Adam optimizer with betas=(0.9,0.999) and epsilon=1e-08. The model achieved an accuracy of 0.8386 on the evaluation set. The model is intended to be used as part of a blog post to help others engineers better understand what natural language processing is and how to perform a text classification."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.8386491557223265, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-asalics-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. The model is best suited for text classification tasks. The model achieved an accuracy of 0.924 and an F1 score of 0.9244 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.924, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.9244145121183605, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-dooglak-article-50v6-ner-model-3epochs-unaugmented", "modules": [{"role": "model", "module": {"name": "Article_50v6_NER_Model_3Epochs_UNAUGMENTED", "description": "A fine-tuned version of bert-base-cased on the article50v6_wikigold_split dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "Article_50v6_NER_Model_3Epochs_UNAUGMENTED is a fine-tuned version of bert-base-cased on the article50v6_wikigold_split dataset for token classification. The model achieved an accuracy of 0.7773 on the evaluation set. More information is needed to describe the model and its intended uses and limitations."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wikisplit"}], "metrics": [{"dataset": "wikisplit", "metric": 0.0, "protocol": "Precision"}, {"dataset": "wikisplit", "metric": 0.0, "protocol": "Recall"}, {"dataset": "wikisplit", "metric": 0.0, "protocol": "F1"}, {"dataset": "wikisplit", "metric": 0.7773, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-bothrajat-q-frozenlake-v1-4x4-noslippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained model of a Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-4x4-no_slippery", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model's hyperparameters include the algorithm used, the environment, the maximum number of steps per episode, the number of episodes to evaluate the agent, the Q-Table learned by the agent, and the random seed used for evaluation. The model achieved a mean reward of 1.00 +/- 0.00 on the FrozenLake-v1-4x4-no_slippery environment."}}, {"role": "dataset", "purpose": "Environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "extra": "1.00 +/- 0.00", "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-anuragshas-wav2vec2-large-xls-r-300m-pa-in", "modules": [{"role": "model", "module": {"name": "XLS-R-300M - Punjabi", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset for speech recognition."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0003, "train_batch_size": 16, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_ratio": 0.12, "num_epochs": 120, "mixed_precision_training": "Native AMP"}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "XLS-R-300M is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice dataset for speech recognition in Punjabi. The model was trained using masked language modeling and next sentence prediction objectives. The model achieved a WER of 45.611 on the Common Voice 7 dataset. The model is intended to be fine-tuned on downstream tasks and reflects the biases inherent to the systems they were trained on, so caution should be taken when deploying it into systems that interact with humans."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 45.611, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-maxhilsdorf-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. The model can be used for text classification tasks, such as sentiment analysis or emotion detection. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 2 epochs. The model achieved an evaluation accuracy of 0.91 and an F1 score of 0.9083."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.2991, "protocol": "eval_loss"}, {"dataset": "emotionlines", "metric": 0.91, "protocol": "eval_accuracy"}, {"dataset": "emotionlines", "metric": 0.9083, "protocol": "eval_f1"}, {"dataset": "emotionlines", "metric": 3.258, "protocol": "eval_runtime"}, {"dataset": "emotionlines", "metric": 613.873, "protocol": "eval_samples_per_second"}, {"dataset": "emotionlines", "metric": 9.822, "protocol": "eval_steps_per_second"}, {"dataset": "emotionlines", "metric": 1.0, "protocol": "epoch"}, {"dataset": "emotionlines", "metric": 250.0, "protocol": "step"}], "source": "huggingface"}, {"id": "huggingface-andi611-distilbert-base-uncased-qa-boolq", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-boolq", "description": "A fine-tuned version of distilbert-base-uncased on the boolq dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 16, "eval_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 1000, "num_epochs": 5}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-boolq is a fine-tuned version of distilbert-base-uncased on the boolq dataset. It is a question-answering model that predicts whether a given sentence contains the answer to a yes/no question. The model achieved an accuracy of 0.7315 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 5e-05 and a linear learning rate scheduler with 1000 warmup steps for 5 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "boolq-boolean-questions"}], "metrics": [{"dataset": "boolq-boolean-questions", "metric": 0.7314984709480122, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-sayby-dqn-spaceinvadersnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "DQN", "description": "A trained DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "buffer_size": 100000, "exploration_final_eps": 0.01, "exploration_fraction": 0.1, "frame_stack": 4, "gradient_steps": 1, "learning_rate": 0.0001, "learning_starts": 100000, "n_timesteps": 1000000.0, "optimize_memory_usage": false, "policy": "CnnPolicy", "target_update_interval": 1000, "train_freq": 4, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The model was trained with a batch size of 32, a buffer size of 100000, and a learning rate of 0.0001. The model achieved a mean reward of 653.50 with a standard deviation of 137.33 on the SpaceInvadersNoFrameskip-v4 dataset. The model is suitable for reinforcement learning tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 653.5, "split": "val", "protocol": "mean_reward"}, {"dataset": "atari-grand-challenge", "metric": 137.33, "split": "test", "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-sahilrajpal121-train5a1e8w7-label-classification", "modules": [{"role": "model", "module": {"name": "Baseline Model trained on train5a1e8w7 to apply classification on label", "description": "A baseline model trained on tabular data using logistic regression with balanced class weights."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "LogisticRegression", "C": 0.1, "class_weight": "balanced", "max_iter": 1000}}}, {"role": "taskType", "module": "tabular-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a baseline model trained on tabular data using logistic regression with balanced class weights. The model was trained on the train5a1e8w7 dataset and achieved an accuracy of 0.693101. The model was trained using the dabl library and logs of the training process can be found in logs.txt. Note that this model is intended as a baseline and for better results, it is recommended to use AutoTrain."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-rajistics-imdb", "modules": [{"role": "model", "module": {"name": "imdb", "description": "A fine-tuned version of bert-base-cased on the imdb dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 8, "eval_batch_size": 8, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "The imdb model is a fine-tuned version of bert-base-cased on the imdb dataset. It was trained for one epoch with a learning rate of 5e-05 and achieved an accuracy of 0.876. The model is suitable for text classification tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.876, "protocol": "Accuracy"}], "source": "huggingface"}, {"id": "huggingface-stplgg-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. It can be used for text classification tasks. The model achieved an accuracy of 0.923 and an F1 score of 0.9230 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.923, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.9230160877762784, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-cardiffnlp-roberta-base-topic-single", "modules": [{"role": "model", "module": {"name": "cardiffnlp/roberta-base-topic-single", "description": "Fine-tuned version of roberta-base on the cardiffnlp/tweet_topic_single dataset using tweetnlp."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"max_length": 128}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "cardiffnlp/roberta-base-topic-single is a fine-tuned version of roberta-base on the cardiffnlp/tweet_topic_single dataset using tweetnlp. The model is best suited for text classification tasks on social media data. The model achieved an F1 score of 0.8819 and an accuracy of 0.8819 on the test split of the dataset."}}, {"role": "dataset", "purpose": "For model training, validation, and testing.", "module": "twitter-conversations-dataset"}], "metrics": [{"dataset": "twitter-conversations-dataset", "metric": 0.8818665091553456, "protocol": "micro_f1_cardiffnlp/tweet_topic_single"}, {"dataset": "twitter-conversations-dataset", "metric": 0.7359303318518903, "protocol": "macro_f1_cardiffnlp/tweet_topic_single"}, {"dataset": "twitter-conversations-dataset", "metric": 0.8818665091553456, "protocol": "accuracy_cardiffnlp/tweet_topic_single"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-es-tl", "modules": [{"role": "model", "module": {"name": "spa-tgl", "description": "A transformer-align model for translating from Spanish to Tagalog."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece (spm32k,spm32k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "spa-tgl is a transformer-align model trained on Spanish to Tagalog translations. It uses normalization and SentencePiece for preprocessing. The model achieves a BLEU score of 24.7 on the Tatoeba-test.spa.tgl dataset."}}, {"role": "dataset", "purpose": "Test set for evaluation.", "module": "tatoeba-translation-challenge"}], "metrics": [{"dataset": "tatoeba-translation-challenge", "metric": 24.7, "protocol": "BLEU"}, {"dataset": "tatoeba-translation-challenge", "metric": 0.538, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-ty-fr", "modules": [{"role": "model", "module": {"name": "opus-mt-ty-fr", "description": "A transformer-align model for translating from the Ty language to French."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "The opus-mt-ty-fr model is a transformer-align model that translates from the Ty language to French. It achieved a BLEU score of 30.2 and a chr-F score of 0.48 on the JW300.ty.fr test set. The model uses normalization and SentencePiece for pre-processing."}}], "metrics": [{"dataset": "jw300", "metric": 30.2, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.48, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-simonosgoode-bloom-560m-finetuned-cdn-law", "modules": [{"role": "model", "module": {"name": "Canadian Appellate Judgement Model", "description": "A fine-tuned version of bigscience/bloom-560m on Canadian appellate decisions (Ontario Court of Appeal and the British Columbia Court of Appeal) found in the Pile of Law dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3.0}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "The Canadian Appellate Judgement Model is a fine-tuned version of bigscience/bloom-560m on Canadian appellate decisions. It is intended to facilitate research into large language models and legal reasoning. The model is not intended for use in any legal domain or to support legal work. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 8. The model achieved a loss of 2.0135 on the evaluation set."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-dooglak-article-100v1-ner-model-3epochs-unaugmented", "modules": [{"role": "model", "module": {"name": "Article_100v1_NER_Model_3Epochs_UNAUGMENTED", "description": "A fine-tuned version of bert-base-cased on the article100v1_wikigold_split dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "Article_100v1_NER_Model_3Epochs_UNAUGMENTED is a fine-tuned version of bert-base-cased on the article100v1_wikigold_split dataset for token classification. The model achieved a precision of 0.06, recall of 0.0016, F1 score of 0.0030, and accuracy of 0.7832 on the evaluation set. More information is needed to describe the model, its intended uses and limitations, and the training and evaluation data."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wikisplit"}], "metrics": [{"dataset": "wikisplit", "metric": 0.06, "protocol": "precision"}, {"dataset": "wikisplit", "metric": 0.0015592515592515593, "protocol": "recall"}, {"dataset": "wikisplit", "metric": 0.00303951367781155, "protocol": "f1"}, {"dataset": "wikisplit", "metric": 0.7832046377355834, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-stevemobs-deberta-base-finetuned-squad1-aqa", "modules": [{"role": "model", "module": {"name": "deberta-base-finetuned-squad1-aqa", "description": "Fine-tuned version of deberta-base-finetuned-squad1 on the adversarial_qa dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 12, "eval_batch_size": 12, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "deberta-base-finetuned-squad1-aqa is a fine-tuned version of deberta-base-finetuned-squad1 on the adversarial_qa dataset. It is a question-answering model that can be used to answer questions based on a given context. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 12. The model was trained for 2 epochs and achieved a loss of 1.5912 on the evaluation set."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "adversarialqa"}], "metrics": [{"dataset": "adversarialqa", "metric": 1.5912, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-linker81-q-learning-frozenlake-v1-4x4-no-slippery", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1-4x4-no-slippery", "description": "A trained Q-Learning agent playing FrozenLake-v1-4x4-no-slippery."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "eval_seed": "random seed for evaluation", "is_slippery": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent playing FrozenLake-v1-4x4-no-slippery. The model achieved a mean reward of 1.00 +/- 0.00 over the evaluation episodes. The model was trained with the Q-Learning algorithm and evaluated with a maximum number of steps per episode, a number of episodes to evaluate the agent, and a random seed for evaluation. The environment used for training and evaluation was FrozenLake-v1-4x4-no_slippery."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-arnaudmkonan-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "xlm-roberta-base-finetuned-panx-de is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. The model achieved an F1 score of 0.8637 on the evaluation set. The model is suitable for token classification tasks in German language."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.863677639046538, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-ceb-en", "modules": [{"role": "model", "module": {"name": "transformer-align", "description": "A machine translation model trained on Cebuano to English language pairs using the transformer-align architecture."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece (spm32k,spm32k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "A transformer-align model trained on Cebuano to English language pairs. The model was trained on the Tatoeba dataset and achieved a BLEU score of 21.5 and a chrF2 score of 0.387 on the test set. The model uses normalization and SentencePiece (spm32k,spm32k) for preprocessing."}}, {"role": "dataset", "purpose": "Test set used for evaluation.", "module": "tatoeba-translation-challenge"}], "metrics": [{"dataset": "tatoeba-translation-challenge", "metric": 21.5, "protocol": "BLEU"}, {"dataset": "tatoeba-translation-challenge", "metric": 0.387, "protocol": "chrF2_score"}], "source": "huggingface"}, {"id": "huggingface-k3lana-xlm-roberta-base-finetuned-panx-fr", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-fr", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.8346 on the evaluation set. The model is suitable for token classification tasks in French language. The training was done using Adam optimizer with a learning rate of 5e-05 and a linear learning rate scheduler for 3 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8346456692913387, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-kalmufti-dqn-spaceinvadersnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "DQN", "description": "A trained model of a DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "buffer_size": 100000, "exploration_final_eps": 0.01, "exploration_fraction": 0.1, "frame_stack": 4, "gradient_steps": 1, "learning_rate": 0.0001, "learning_starts": 100000, "n_timesteps": 1000000.0, "optimize_memory_usage": true, "policy": "CnnPolicy", "target_update_interval": 1000, "train_freq": 4, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "The DQN model is a reinforcement learning agent trained on the SpaceInvadersNoFrameskip-v4 environment using the stable-baselines3 library and the RL Zoo. The model achieved a mean reward of 663.50 +/- 171.13. The hyperparameters used for training include batch size, buffer size, exploration fraction, learning rate, and target update interval. The model is suitable for tasks that require decision-making based on sequential data, such as game playing or robotics control."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 663.5, "split": "val", "protocol": "mean_reward"}, {"dataset": "atari-grand-challenge", "metric": 171.13, "split": "test", "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-lolaibrin-distilbert-base-uncased-finetuned-squad", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-squad", "description": "A fine-tuned version of distilbert-base-uncased on the squad dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-squad is a fine-tuned version of distilbert-base-uncased on the squad dataset. It can be used for question answering tasks. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for 3 epochs and achieved a loss of 1.2108 on the evaluation set."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 1.2108, "protocol": "loss"}], "source": "huggingface"}, {"id": "huggingface-hackathon-pln-es-roberta-base-bne-squad2-es", "modules": [{"role": "model", "module": {"name": "roberta-base es for QA", "description": "A fine-tuned version of PlanTL-GOB-ES/roberta-base-bne on the squad_es(v2) training dataset for Question Answering tasks in Spanish."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"num_train_epochs": 2, "learning_rate": 3e-05, "max_seq_length": 386, "doc_stride": 128}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of PlanTL-GOB-ES/roberta-base-bne on the squad_es(v2) training dataset for Question Answering tasks in Spanish. The model achieved an F1 score of 69.39 and an exact match score of 62.14 on the dev set. The hyperparameters were chosen based on those used in deepset/roberta-base-squad2, an English-based model trained for similar purposes."}}, {"role": "dataset", "purpose": "For model fine-tuning and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 62.13526733007252, "protocol": "exact_match"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 69.38515019522332, "protocol": "f1_score"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 53.07017543859649, "protocol": "HasAns_exact_match"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 67.57238714827123, "protocol": "HasAns_f1_score"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 5928.0, "protocol": "HasAns_total"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 71.19730185497471, "protocol": "NoAns_exact_match"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 71.19730185497471, "protocol": "NoAns_f1_score"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 5930.0, "protocol": "NoAns_total"}], "source": "huggingface"}, {"id": "huggingface-xkang-bert-finetuned-ner", "modules": [{"role": "model", "module": {"name": "bert-finetuned-ner", "description": "A fine-tuned version of bert-base-cased on the conll2003 dataset for token classification."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 8, "eval_batch_size": 8, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "bert-finetuned-ner is a fine-tuned version of bert-base-cased on the conll2003 dataset for token classification. The model achieved high precision, recall, F1 score, and accuracy on the evaluation set. The model is suitable for named entity recognition tasks, but caution should be taken when deploying it in human-interacting systems as it may reflect the biases of the systems it was trained on."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "conll-2003"}], "metrics": [{"dataset": "conll-2003", "metric": 0.9392329403951519, "protocol": "precision"}, {"dataset": "conll-2003", "metric": 0.9520363513968361, "protocol": "recall"}, {"dataset": "conll-2003", "metric": 0.9455913079816131, "protocol": "f1"}, {"dataset": "conll-2003", "metric": 0.9864308000235474, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-idea-ccnl-erlangshen-macbert-325m-textmatch-chinese", "modules": [{"role": "model", "module": {"name": "Erlangshen-MacBERT-325M-TextMatch-Chinese", "description": "Pretrained model on Chinese language using a text-matching task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model_size": "325M", "learning_rate": 2e-05, "max_length": 512, "max_epochs": 3, "batch_size": 8}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "Erlangshen-MacBERT-325M-TextMatch-Chinese is a transformer model pre-trained on a large Chinese corpus for text-matching tasks. The model is intended to be fine-tuned on downstream tasks such as text classification. The model is trained using the UniMC framework and achieves state-of-the-art performance on the BUSTM task from FewCLUE. The model is suitable for text-matching tasks in Chinese language, but caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "fewclue"}], "metrics": [{"dataset": "fewclue", "metric": 81.6, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-olpa-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. The model achieved an F1 score of 0.8627 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 5e-05 and a linear learning rate scheduler. The model was trained for 3 epochs with a batch size of 24."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8627004891366169, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-hiranhsw-q-frozenlake-v1-4x4", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-4x4", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained Q-Learning agent playing FrozenLake-v1. The model is intended to be used to evaluate the agent's performance in the FrozenLake-v1 environment. The model includes the Q-Table learned by the agent, as well as hyperparameters such as the maximum number of steps per episode and the number of episodes used for evaluation. The model's performance is measured in terms of mean reward, with a standard deviation provided."}}, {"role": "dataset", "purpose": "Environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 0.75, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-eligabel-finetuning-sentiment-model-3000-samples", "modules": [{"role": "model", "module": {"name": "finetuning-sentiment-model-3000-samples", "description": "A fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "seed": 42, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "finetuning-sentiment-model-3000-samples is a fine-tuned version of distilbert-base-uncased on the imdb dataset for sentiment analysis. The model achieved an accuracy of 0.8167 and an F1 score of 0.8308 on the evaluation set. The model is suitable for text classification tasks, but its performance may vary depending on the specific use case and data distribution."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "imdb-movie-reviews"}], "metrics": [{"dataset": "imdb-movie-reviews", "metric": 0.8167, "protocol": "accuracy"}, {"dataset": "imdb-movie-reviews", "metric": 0.8308, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-harrier-dqn-spaceinvadersnoframeskip-v4", "modules": [{"role": "model", "module": {"name": "DQN Agent playing SpaceInvadersNoFrameskip-v4", "description": "A trained DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"batch_size": 32, "buffer_size": 100000, "exploration_final_eps": 0.01, "exploration_fraction": 0.1, "frame_stack": 4, "gradient_steps": 1, "learning_rate": 0.0001, "learning_starts": 100000, "n_timesteps": 1000000.0, "optimize_memory_usage": false, "policy": "CnnPolicy", "target_update_interval": 1000, "train_freq": 4, "normalize": false}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained DQN agent playing SpaceInvadersNoFrameskip-v4 using the stable-baselines3 library and the RL Zoo. The model was trained with a batch size of 32, a buffer size of 100000, and a learning rate of 0.0001. The model achieved a mean reward of 615.50 with a standard deviation of 186.61 on the SpaceInvadersNoFrameskip-v4 dataset. The model is suitable for reinforcement learning tasks."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "atari-grand-challenge"}], "metrics": [{"dataset": "atari-grand-challenge", "metric": 615.5, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-infinitejoy-wav2vec2-large-xlsr-53-odia", "modules": [{"role": "model", "module": {"name": "Joydeep Bhattacharjee XLSR Wav2Vec2 Large 53 Odia", "description": "Fine-tuned Wav2Vec2-Large-XLSR-53 on Odia using the Common Voice dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "Wav2Vec2-Large-XLSR-53", "batch_size": 8, "optimizer": {"name": "Adam", "learning_rate": 0.0001, "beta1": 0.9, "beta2": 0.98, "weight_decay": 0.01}}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Joydeep Bhattacharjee XLSR Wav2Vec2 Large 53 Odia is a fine-tuned model based on Wav2Vec2-Large-XLSR-53 architecture, trained on the Common Voice dataset for Odia language. The model can be used for automatic speech recognition tasks in Odia language. The model can be used directly without a language model and is suitable for tasks such as sequence classification, token classification, or question answering. The model achieved a WER score of 55.07% on the Odia test data of Common Voice."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 55.07, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-lv-sv", "modules": [{"role": "model", "module": {"name": "opus-mt-lv-sv", "description": "A machine translation model that translates from Latvian (lv) to Swedish (sv) using the transformer-align architecture."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-lv-sv is a machine translation model that translates from Latvian to Swedish using the transformer-align architecture. The model was trained on the OPUS dataset and achieved a BLEU score of 22.0 and a chr-F score of 0.444 on the JW300.lv.sv test set."}}], "metrics": [{"dataset": "jw300", "metric": 22.0, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.444, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-en-pag", "modules": [{"role": "model", "module": {"name": "opus-mt-en-pag", "description": "A transformer-align model for translating from English to pag."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-en-pag is a transformer-align model that translates from English to pag. The model was trained on the OPUS dataset using normalization and SentencePiece pre-processing. The model achieved a BLEU score of 37.9 and a chr-F score of 0.598 on the JW300.en.pag test set."}}], "metrics": [{"dataset": "jw300", "metric": 37.9, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.598, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-jgriffi-xlm-roberta-base-finetuned-panx-de", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-de", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 12, "eval_batch_size": 12, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "xlm-roberta-base-finetuned-panx-de is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. The model achieved an F1 score of 0.8646 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 5e-05 and a batch size of 12 for 3 epochs. The model was trained using the Transformers 4.11.3, Pytorch 1.11.0+cu113, Datasets 1.16.1, and Tokenizers 0.10.3."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.8646, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-qunaieer-distilbert-base-uncased-finetuned-emotion", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-emotion", "description": "A fine-tuned version of distilbert-base-uncased on the emotion dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 64, "eval_batch_size": 64, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 2}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-emotion is a fine-tuned version of distilbert-base-uncased on the emotion dataset. The model is best suited for text classification tasks. The model achieved an accuracy of 0.926 and an F1 score of 0.9259893400415584 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a batch size of 64 for 2 epochs."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "emotionlines"}], "metrics": [{"dataset": "emotionlines", "metric": 0.926, "protocol": "accuracy"}, {"dataset": "emotionlines", "metric": 0.9259893400415584, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-vbertret-q-frozenlake-v1-4x4", "modules": [{"role": "model", "module": {"name": "Q-Learning Agent playing FrozenLake-v1", "description": "A trained model of a Q-Learning agent playing FrozenLake-v1."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"algorithm": "Q-Learning", "environment": "FrozenLake-v1-4x4-no_slippery", "max_steps": "maximum number of steps per episode", "n_eval_episodes": "number of episodes to evaluate the agent", "qtable": "Q-Table learned by the agent", "eval_seed": "random seed used for evaluation"}}}, {"role": "taskType", "module": "reinforcement-learning"}, {"role": "solutionSummary", "module": {"summary": "This is a trained model of a Q-Learning agent playing FrozenLake-v1. The model's hyperparameters include the algorithm used, the environment, the maximum number of steps per episode, the number of episodes to evaluate the agent, the Q-Table learned by the agent, and the random seed used for evaluation. The model achieved a mean reward of 1.0 with no standard deviation."}}, {"role": "dataset", "purpose": "Environment used for training and evaluation.", "module": "openai-gym"}], "metrics": [{"dataset": "openai-gym", "metric": 1.0, "protocol": "mean_reward"}], "source": "huggingface"}, {"id": "huggingface-uer-roberta-base-finetuned-cluener2020-chinese", "modules": [{"role": "model", "module": {"name": "Chinese RoBERTa-Base Model for NER", "description": "A RoBERTa-based model fine-tuned on the CLUENER2020 dataset for named entity recognition in Chinese."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"pretrained_model": "chinese_roberta_L-12_H-768", "sequence_length": 512, "batch_size": 32, "learning_rate": 3e-05, "epochs": 5}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This is a RoBERTa-based model fine-tuned on the CLUENER2020 dataset for named entity recognition in Chinese. The model can be used for token classification tasks. The model was fine-tuned for five epochs with a sequence length of 512 and a batch size of 32. The model reflects the biases inherent to the systems they were trained on, so caution should be taken when deploying it into systems that interact with humans."}}], "metrics": [], "source": "huggingface"}, {"id": "huggingface-premalmatalia-electra-base-best-squad2", "modules": [{"role": "model", "module": {"name": "ELECTRA-base for QA", "description": "Pretrained model on English language using ELECTRA-base for extractive question answering task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"max_seq_len": 386, "doc_stride": 128, "n_best_size": 20, "max_answer_length": 30, "min_null_score": 7.0, "batch_size": 8, "n_epochs": 2, "base_LM_model": "google/electra-base-discriminator", "learning_rate": 1.5e-05, "adam_epsilon": 1e-05, "adam_beta1": 0.95, "adam_beta2": 0.999, "warmup_steps": 100, "weight_decay": 0.01, "optimizer": "AdamW", "lr_scheduler": "polynomial"}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "ELECTRA-base is a transformer model pre-trained on a large English corpus for extractive question answering task. The model is fine-tuned on SQuAD 2.0 dataset. The model can be used to answer questions based on a given context. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 79.331256, "protocol": "exact"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 83.232347, "protocol": "f1"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 76.50135, "protocol": "HasAns_exact"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 84.314719, "protocol": "HasAns_f1"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 82.15307, "protocol": "NoAns_exact"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 82.15307, "protocol": "NoAns_f1"}], "source": "huggingface"}, {"id": "huggingface-gcmsrc-xlm-roberta-base-finetuned-panx-en", "modules": [{"role": "model", "module": {"name": "xlm-roberta-base-finetuned-panx-en", "description": "A fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 5e-05, "train_batch_size": 24, "eval_batch_size": 24, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 3}}}, {"role": "taskType", "module": "token-classification"}, {"role": "solutionSummary", "module": {"summary": "This model is a fine-tuned version of xlm-roberta-base on the xtreme dataset for token classification task. It achieves an F1 score of 0.6931 on the evaluation set. The model is suitable for token classification tasks in multilingual settings."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders"}], "metrics": [{"dataset": "xtreme-cross-lingual-transfer-evaluation-of-multilingual-encoders", "metric": 0.6931246506428173, "protocol": "f1"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-ar-el", "modules": [{"role": "model", "module": {"name": "ara-ell transformer-align", "description": "A machine translation model that translates from Arabic to Modern Greek (1453-) using a transformer-align architecture."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"preprocessing": "normalization + SentencePiece (spm32k,spm32k)"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "ara-ell transformer-align is a machine translation model that translates from Arabic to Modern Greek (1453-) using a transformer-align architecture. The model was trained on a normalization and SentencePiece preprocessed dataset. It achieved a BLEU score of 43.9 and a chr-F score of 0.636 on the Tatoeba-test.ara.ell test set."}}, {"role": "dataset", "purpose": "Test set used for evaluation.", "module": "tatoeba-translation-challenge"}], "metrics": [{"dataset": "tatoeba-translation-challenge", "metric": 43.9, "protocol": "BLEU"}, {"dataset": "tatoeba-translation-challenge", "metric": 0.636, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-rossanez-t5-small-finetuned-de-en-256-nofp16", "modules": [{"role": "model", "module": {"name": "t5-small-finetuned-de-en-256-nofp16", "description": "A fine-tuned version of t5-small on the wmt14 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 16, "eval_batch_size": 16, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 1}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "t5-small-finetuned-de-en-256-nofp16 is a fine-tuned version of t5-small on the wmt14 dataset. It is intended for translation tasks from German to English. The model was trained with Adam optimizer with a learning rate of 2e-05 and a batch size of 16. The model was trained for one epoch and achieved a validation loss of 2.1234, a Bleu score of 7.7305, and a generated length of 17.4033."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "wmt-2014"}], "metrics": [{"dataset": "wmt-2014", "metric": 2.1234, "protocol": "Validation Loss"}, {"dataset": "wmt-2014", "metric": 7.7305, "protocol": "Bleu"}, {"dataset": "wmt-2014", "metric": 17.4033, "protocol": "Gen Len"}], "source": "huggingface"}, {"id": "huggingface-rhr99-wav2vec2-large-xls-r-300m-bn-colab", "modules": [{"role": "model", "module": {"name": "wav2vec2-large-xls-r-300m-bn-colab", "description": "Fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice_9_0 dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 0.0003, "train_batch_size": 4, "eval_batch_size": 8, "seed": 42, "gradient_accumulation_steps": 8, "total_train_batch_size": 32, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "lr_scheduler_warmup_steps": 500, "num_epochs": 2, "mixed_precision_training": true}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "wav2vec2-large-xls-r-300m-bn-colab is a fine-tuned version of facebook/wav2vec2-xls-r-300m on the common_voice_9_0 dataset. The model is intended for automatic speech recognition tasks. The model was trained using Adam optimizer with a learning rate of 0.0003, and a linear learning rate scheduler with 500 warmup steps. The model was trained for 2 epochs with mixed precision training. The model achieved a validation loss of 0.4662 and a WER of 0.9861."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 0.8479, "split": "val", "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.4662, "split": "test", "protocol": "loss"}, {"dataset": "common-voice", "metric": 0.9861, "protocol": "WER"}], "source": "huggingface"}, {"id": "huggingface-helsinki-nlp-opus-mt-ase-de", "modules": [{"role": "model", "module": {"name": "opus-mt-ase-de", "description": "A machine translation model that translates from the Ase language to German."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"model": "transformer-align", "preprocessing": "normalization + SentencePiece"}}}, {"role": "taskType", "module": "translation"}, {"role": "solutionSummary", "module": {"summary": "opus-mt-ase-de is a machine translation model that translates from the Ase language to German. The model was trained on the OPUS dataset using the transformer-align architecture and pre-processing techniques such as normalization and SentencePiece. The model achieved a BLEU score of 27.2 and a chr-F score of 0.478 on the JW300 test set."}}], "metrics": [{"dataset": "jw300", "metric": 27.2, "protocol": "BLEU"}, {"dataset": "jw300", "metric": 0.478, "protocol": "chr-F"}], "source": "huggingface"}, {"id": "huggingface-sakares-wav2vec2-large-xlsr-thai-demo", "modules": [{"role": "model", "module": {"name": "Wav2Vec2-Large-XLSR-53-Thai", "description": "Fine-tuned Wav2Vec2-Large-XLSR-53 on Common Voice Thai dataset for automatic speech recognition."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"pretrained_model": "facebook/wav2vec2-large-xlsr-53", "batch_size": 8, "optimizer": {"name": "Adam", "learning_rate": 0.0003, "beta1": 0.9, "beta2": 0.98, "weight_decay": 0.005}, "num_training_steps": 100000, "num_warmup_steps": 5000}}}, {"role": "taskType", "module": "automatic-speech-recognition"}, {"role": "solutionSummary", "module": {"summary": "Wav2Vec2-Large-XLSR-53-Thai is a fine-tuned model on Common Voice Thai dataset for automatic speech recognition. The model is based on Wav2Vec2-Large-XLSR-53 and was fine-tuned using masked language modeling (MLM) objective. The model can be used directly for speech recognition or fine-tuned on a downstream task. The model is best suited for speech recognition tasks in Thai language. The model reflects the biases of the systems it was trained on, so caution should be taken when deploying it in human-interacting systems."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "common-voice"}], "metrics": [{"dataset": "common-voice", "metric": 44.46, "protocol": "wer"}], "source": "huggingface"}, {"id": "huggingface-transformersbook-distilbert-base-uncased-finetuned-clinc", "modules": [{"role": "model", "module": {"name": "distilbert-base-uncased-finetuned-clinc", "description": "A fine-tuned version of distilbert-base-uncased on the clinc_oos dataset."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"learning_rate": 2e-05, "train_batch_size": 48, "eval_batch_size": 48, "optimizer": {"name": "Adam", "betas": [0.9, 0.999], "epsilon": 1e-08}, "lr_scheduler_type": "linear", "num_epochs": 5}}}, {"role": "taskType", "module": "text-classification"}, {"role": "solutionSummary", "module": {"summary": "distilbert-base-uncased-finetuned-clinc is a fine-tuned version of distilbert-base-uncased on the clinc_oos dataset. The model is used for text classification tasks. The model achieved an accuracy of 0.9174 on the evaluation set. The model was trained using Adam optimizer with a learning rate of 2e-05 and a linear learning rate scheduler. The model was trained for 5 epochs with a batch size of 48."}}, {"role": "dataset", "purpose": "For model training and evaluation.", "module": "clinc-single-domain-oos"}], "metrics": [{"dataset": "clinc-single-domain-oos", "metric": 0.9174193548387096, "protocol": "accuracy"}], "source": "huggingface"}, {"id": "huggingface-bioformers-bioformer-cased-v1-0-squad1", "modules": [{"role": "model", "module": {"name": "Bioformer-8L", "description": "A question-answering model fine-tuned on the SQuAD1 dataset for 3 epochs."}}, {"role": "algorithm", "purpose": "Model training hyper-parameters.", "module": {"config": {"max_seq_length": 512, "per_device_train_batch_size": 16, "gradient_accumulation_steps": 1, "total_train_batch_size": 16, "learning_rate": 3e-05, "num_train_epochs": 3}}}, {"role": "taskType", "module": "question-answering"}, {"role": "solutionSummary", "module": {"summary": "Bioformer-8L is a question-answering model fine-tuned on the SQuAD1 dataset for 3 epochs. It was trained on biomedical texts and performs on par with DistilBERT on the SQuAD1 dataset. Inference speed of Bioformer is 3x as fast as BERT-base/BioBERT/PubMedBERT, and is 40% faster than DistilBERT."}}, {"role": "dataset", "purpose": "For fine-tuning.", "module": "squad-stanford-question-answering-dataset"}], "metrics": [{"dataset": "squad-stanford-question-answering-dataset", "metric": 78.55250709555345, "protocol": "EM"}, {"dataset": "squad-stanford-question-answering-dataset", "metric": 85.91482799690257, "protocol": "F1"}], "source": "huggingface"}, {"id": "soupmonsrer-simple-lgbm-baseline-opnuna-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-stratifiedkfold"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_splits": 10, "shuffle": "True", "random_state": 42}}}, {"role": "solutionSummary", "module": {"summary": "The task is to predict credit card fraud using GBDT and LightGBM with a combination of synthetic and original data. After loading, preprocessing, and feature engineering, the API call is used to create a StratifiedKFold object with 10 folds, which ensures that each fold maintains the same class proportion as the entire dataset. This object is then used in a loop to train and validate the LightGBM model on different subsets of the data. The performance of individual folds is assessed using ROC AUC score, and test predictions are ensembled together for the final submission."}}], "source": "kaggle"}, {"id": "soupmonsrer-simple-lgbm-baseline-opnuna-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "lightgbm-lgbmmodel"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"objective": "binary", "metric": "auc", "lambda_l1": 1.0050418664783429e-08, "lambda_l2": 9.938606206413121, "scale_pos_weight": 1, "num_leaves": 44, "feature_fraction": 0.8247273276668771, "bagging_fraction": 0.5842711778104961, "bagging_freq": 6, "min_data_in_leaf": 134, "min_child_samples": 70, "max_depth": 8, "num_iterations": 300, "learning_rate": 0.05}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet addresses a credit card fraud detection competition using LightGBM to create a classification model. After combining the data, preprocessing, handling imbalanced classes, and creating time-based features, the API call is made to create an LGBM classifier model. Stratified K-Fold cross-validation is performed, and the model is trained with the specified parameters using early stopping. The model's performance is measured using the ROC AUC score for each fold, and an ensemble of test predictions is created. Finally, feature importances are displayed, and submission is prepared."}}], "source": "kaggle"}, {"id": "shivamb-semi-supervised-classification-usinf-autoe-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-manifold-tsne"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_components": 2, "random_state": 0}}}, {"role": "solutionSummary", "module": {"summary": "In this code snippet, the author aims to perform semi-supervised classification for fraud detection on the Credit Card Fraud dataset and then applies the same technique on the Titanic dataset. Before the API call, the dataset is preprocessed and feature engineered. The API is used to create a t-SNE plot, which helps visualize the fraud and non-fraud transactions in a lower-dimensional space. This visualization is then used for comparison with the latent representations obtained from an autoencoder. After the API call, the autoencoder is built, trained, and a simple logistic regression classifier is applied on the obtained latent representations to make predictions."}}], "source": "kaggle"}, {"id": "tynmer-inai-3-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-minmaxscaler"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is focused on analyzing the Marvel Wikia dataset, aiming to predict a character's survival status based on their gender, sexual orientation, appearances, and the year they were introduced. After loading and preprocessing the data, the API is called to create a MinMaxScaler object, which is then utilized to scale several features in the dataset. By scaling the features, the data is transformed to fit within a specific range, ensuring that the model does not overemphasize certain features with larger values during training. Subsequently, several classifiers (DecisionTreeClassifier, LogisticRegressionCV, RandomForestClassifier, KNeighborsClassifier, and MLPClassifier) are trained and evaluated on the preprocessed dataset."}}], "source": "kaggle"}, {"id": "tynmer-inai-3-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-minmaxscaler"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {}}}, {"role": "solutionSummary", "module": {"summary": "The task is to predict whether a Marvel character is alive or deceased using various features. The dataset is first preprocessed by removing irrelevant columns and encoding categorical variables as numerical values. The API is called to scale the feature columns (GSM, SEX, APPEARANCES, and Year) of the dataset using MinMaxScaler, which linearly scales the data to a range of 0 to 1. This is done to ensure that the different features are on the same scale, which can improve the performance of the machine learning algorithms used later. After the scaling, the data is split into training and testing sets, and several machine learning models are trained and evaluated on their accuracy."}}], "source": "kaggle"}, {"id": "tynmer-inai-3-003", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-minmaxscaler"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict whether a Marvel character is alive or deceased based on various features. After loading the dataset and preprocessing it, including dropping some columns and normalizing the values, the API is called to create a MinMaxScaler for scaling the data. This scaler is then utilized to transform several columns in the dataset. Following the scaling, the cleaned and transformed dataset is split into training and testing sets, and multiple classifiers are trained and tested for their accuracy in predicting the target variable (alive or deceased)."}}], "source": "kaggle"}, {"id": "tynmer-inai-3-004", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-minmaxscaler"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"[0]": "dataframe(shape=(16376, 4))", "[1]": "series(shape=(16376,))", "test_size": 0.30000000000000004}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict the aliveness of comic book characters using various classifiers. A dataset containing character attributes is cleaned, preprocessed, and scaled before using the API call to split it into training and testing sets. Following the split, several classifiers, including DecisionTreeClassifier, LogisticRegressionCV, RandomForestClassifier, KNeighborsClassifier, and MLPClassifier, are trained using the training set and their performance is evaluated with the test set by calculating their accuracy scores."}}], "source": "kaggle"}, {"id": "tynmer-inai-3-005", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-tree-decisiontreeclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict whether a comic character is alive or deceased using various attributes. After loading and preprocessing the data, several features are selected, and the dataset is split into training and testing sets. The API is called to create a logistic regression model, which is fitted with the training data and evaluated using the testing data. Alongside logistic regression, other classifiers such as decision trees, random forests, K-nearest neighbors, and MLP classifiers are also used for comparison, and their respective accuracy scores are printed."}}], "source": "kaggle"}, {"id": "tynmer-inai-3-006", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-ensemble-randomforestclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is about predicting the \"ALIVE\" status of comic book characters based on various features such as gender, sexuality, appearances, and year. After cleaning and pre-processing the dataset, the data is split into training and testing sets. The API call is used to create a KNeighborsClassifier model. This model, along with other classifiers such as DecisionTreeClassifier, LogisticRegressionCV, RandomForestClassifier, and MLPClassifier, are trained on the training set and their accuracy scores are evaluated on the testing set to compare their performance."}}], "source": "kaggle"}, {"id": "haplophyrne-week-4-ensemble-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-labelencoder"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict COVID-19 confirmed cases and fatalities using multiple models and merging their predictions into a final submission. After loading and preprocessing the data, including feature engineering and filling missing values, the API is called to create a MinMaxScaler object. This scaler is then used to normalize the training data, ensuring that all features are on a similar scale. This is crucial since the models used, such as DecisionTreeClassifier, are sensitive to the scale of input features. After scaling the training data, the same scaler is used to transform the testing data, maintaining the same scaling parameters applied to the training data. This allows for consistent and meaningful comparisons between the training and testing datasets, ultimately improving the model's performance on unseen data."}}], "source": "kaggle"}, {"id": "haplophyrne-week-4-ensemble-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "xgboost-xgbregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 1500, "max_depth": 10, "learning_rate": 0.1}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to perform COVID-19 forecasting using multiple machine learning models to predict confirmed cases and fatalities. The given dataset is preprocessed, and features are extracted and transformed. The XGBRegressor model is instantiated with specific parameters and then fitted using the training data. After fitting the model, predictions are made on the test data. The results of several models are then combined to create an ensemble forecast, which is saved to a submission file."}}], "source": "kaggle"}, {"id": "haplophyrne-week-4-ensemble-003", "modules": [{"role": "algorithm", "purpose": "API", "module": "xgboost-xgbregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 1500, "max_depth": 10, "learning_rate": 0.1}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to forecast the number of confirmed COVID-19 cases and fatalities using various machine learning models. The input data is preprocessed and various features are extracted, such as day of the week, month, day of the year, and week of the year. The API call is made to create an XGBRegressor model with specific hyperparameters, which is then used to fit the training data. The model is subsequently used to make predictions on the testing data for both confirmed cases and fatalities, and these predictions are combined with those from other models to form the final forecast."}}], "source": "kaggle"}, {"id": "haplophyrne-week-4-ensemble-004", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-onehotencoder"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"sparse": "False"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to forecast COVID-19 Confirmed Cases and Fatalities using various machine learning models and techniques. The OneHotEncoder API is called to encode the 'Country_Region' and 'Province_State' categorical features into a numerical format that can be used by machine learning models. The sparse argument is set to False to ensure dense arrays are returned. The encoded features are then used as input for several prediction models, including Decision Trees, Ridge Regression, and Neural Networks. The results from these models are combined to generate the final submission.csv file containing the predicted Confirmed Cases and Fatalities."}}], "source": "kaggle"}, {"id": "haplophyrne-week-4-ensemble-005", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-onehotencoder"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"sparse": "False"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict the number of COVID-19 ConfirmedCases and Fatalities using various models and combining their predictions. The OneHotEncoder API is called to encode the 'geo_ids_base' array, which contains unique geographic identifiers. Before the API call, the 'geo_ids_base' array is created by assigning a unique index to each geographic region. After the API call, the encoded 'geo_ids_base' array is used as a part of the input features for training and prediction in the given models. The results from different models are combined with certain weights to produce the final submission predictions."}}], "source": "kaggle"}, {"id": "haplophyrne-week-4-ensemble-006", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-linear-model-ridge"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"alpha": 2, "fit_intercept": "False"}}}, {"role": "solutionSummary", "module": {"summary": "This code snippet aims to predict the number of COVID-19 confirmed cases and fatalities using various machine learning models. The dataset is preprocessed, including handling missing values and extracting date-related features. The Ridge regression model with alpha set to 2 and fit_intercept to False is then created and used as a part of the ensemble model. After training the model on the training data, it is used to make predictions on the testing data. The final predictions are combined with the results from other models in the ensemble to create a submission file for the forecasting competition."}}], "source": "kaggle"}, {"id": "haplophyrne-week-4-ensemble-007", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-linear-model-ridge"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"alpha": 2, "fit_intercept": "True"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict the number of confirmed COVID-19 cases and fatalities using multiple machine learning models. The Ridge regression model is utilized as one of the models, and its alpha parameter is set to 2 for regularization, while fit_intercept is set to True to include the intercept term in the linear model. The Ridge model is trained on features such as location, date, and previous confirmed cases and fatalities. After training, the model is used to make predictions for the test data, and the final predictions are combined with predictions from other models to create an ensemble submission."}}], "source": "kaggle"}, {"id": "andreshg-eda-beginner-to-expert-plotly-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-multilabelbinarizer"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to perform an exploratory data analysis (EDA) on Netflix shows and movies dataset. After cleaning and preprocessing the dataset, the focus shifts to the analysis of genres. To analyze genres, the API is called to create a MultiLabelBinarizer object to transform the 'genre' column, which contains lists of genres, into a binary matrix indicating the presence of each genre. This binary matrix is then used to generate various visualizations, including bar charts, heatmaps, and a word cloud, providing insights into genre distributions, correlations, and popularity in the dataset."}}], "source": "kaggle"}, {"id": "andreshg-eda-beginner-to-expert-plotly-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-multilabelbinarizer"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {}}}, {"role": "solutionSummary", "module": {"summary": "In the given code snippet, the primary goal is to analyze and visualize Netflix movie and TV show data. The API call is used within the `calculate_mlb` function to transform the 'genre' feature of the dataset into a binary matrix representation. The MultiLabelBinarizer is applied to both movie and TV show data separately, creating two dataframes that are used later in the analysis to explore genre correlations and create visualizations such as heatmaps. By transforming the genre feature using the API, the dataset is prepared for further exploration and visualization of relationships between genres in both movies and TV shows."}}], "source": "kaggle"}, {"id": "magnussesodia-ps-s3e4-subsampling-ensewble-modelli-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-robustscaler"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet focuses on detecting credit card fraud using machine learning techniques. After an extensive exploratory data analysis (EDA), preprocessing is performed on the dataset. In this context, the API is called to create an instance of the OrdinalEncoder for transforming the 'Time_bucket' feature. This feature is derived from the 'Time' column and categorized into early morning, morning, afternoon, and evening periods. The OrdinalEncoder will convert these categorical values into numerical form, which is suitable for the machine learning models used later in the notebook. After the transformation, the data is used to train and evaluate XGBClassifier, CatBoostClassifier, and LGBMClassifier models, and the results are combined for the final submission."}}], "source": "kaggle"}, {"id": "magnussesodia-ps-s3e4-subsampling-ensewble-modelli-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-compose-columntransformer"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"transformers": "[('robust_scaler', RobustScaler(), ['Amount']), ('ord_enc', OrdinalEncoder(), ['Time_bucket'])]", "verbose_feature_names_out": "True", "remainder": "passthrough"}}}, {"role": "solutionSummary", "module": {"summary": "The task is credit card fraud detection using an ensemble of three models. After loading data, preprocessing steps are performed including scaling the 'Amount' column using RobustScaler, and encoding the 'Time_bucket' column with OrdinalEncoder. The API is called to create a ColumnTransformer that applies these transformations, leaving the remaining columns (PCA-scaled features) untouched. The transformer is then fit to the combined dataset and used to transform both the combined dataset and the test dataset. This preprocessed data is then used to train three different models: XGBClassifier, CatBoostClassifier, and LGBMClassifier. The predictions from these models are combined and output as a submission."}}], "source": "kaggle"}, {"id": "magnussesodia-ps-s3e4-subsampling-ensewble-modelli-003", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-stratifiedkfold"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_splits": 5, "shuffle": "True", "random_state": 0}}}, {"role": "solutionSummary", "module": {"summary": "The purpose of this code snippet is to detect credit card fraud using an ensemble of machine learning models. After performing EDA and preprocessing, the API is called to create a StratifiedKFold cross-validator that aims to maintain the class distribution across the training and validation sets. This is particularly important in this context due to the imbalanced nature of the dataset. The ensemble consists of three models - XGBClassifier, CatBoostClassifier, and LGBMClassifier - which are trained using undersampling and StratifiedKFold cross-validation to improve their performance on the imbalanced data. The final test predictions are generated by averaging the predictions from all three models, and the results are saved in a submission file."}}], "source": "kaggle"}, {"id": "magnussesodia-ps-s3e4-subsampling-ensewble-modelli-004", "modules": [{"role": "algorithm", "purpose": "API", "module": "xgboost-xgbclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 2000, "min_child_weight": 96, "max_depth": 7, "learning_rate": 0.18, "subsample": 0.9500000000000001, "colsample_bytree": 0.9500000000000001, "reg_lambda": 1.5, "reg_alpha": 1.5, "gamma": 1.5, "max_bin": 512, "random_state": 0, "objective": "binary:logistic", "tree_method": "gpu_hist", "eval_metric": "auc"}}}, {"role": "solutionSummary", "module": {"summary": "The goal is to predict whether a credit card transaction is fraudulent or legitimate. After performing EDA, preprocessing, and feature engineering, the API is called to create an XGBoost classifier model. The model's parameters are set to optimize performance on the given problem. The model is then fit and used to make predictions on the test data. This XGBoost model is part of an ensemble, along with a CatBoost and LightGBM model, which are also trained and used for predictions. The final submission is created by averaging the predictions from all three models."}}], "source": "kaggle"}, {"id": "magnussesodia-ps-s3e4-subsampling-ensewble-modelli-005", "modules": [{"role": "algorithm", "purpose": "API", "module": "catboost-catboostclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 500, "learning_rate": 0.03, "one_hot_max_size": 12, "depth": 4, "l2_leaf_reg": 0.014, "colsample_bylevel": 0.06, "min_data_in_leaf": 12, "boosting_type": "Plain", "bootstrap_type": "Bernoulli", "verbose": "False"}}}, {"role": "solutionSummary", "module": {"summary": "The goal of this code snippet is to detect credit card fraud using an ensemble of three models: XGBClassifier, CatBoostClassifier, and LGBMClassifier. After loading the data, preprocessing, and performing exploratory data analysis, the API is called to instantiate the CatBoostClassifier with specific hyperparameters. Undersampling is employed to deal with class imbalance, and StratifiedKFold is used to train the classifier on different portions of the sampled data. The classifier's predictions on the test set are combined with predictions from the other two models to form the final ensemble output."}}], "source": "kaggle"}, {"id": "magnussesodia-ps-s3e4-subsampling-ensewble-modelli-006", "modules": [{"role": "algorithm", "purpose": "API", "module": "lightgbm-lgbmmodel"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 500, "num_rounds": 274, "learning_rate": 0.1, "num_leaves": 195, "max_depth": 9, "min_data_in_leaf": 46, "lambda_l1": 0.01, "lambda_l2": 0.6000000000000001, "min_gain_to_split": 1.42, "bagging_fraction": 0.45, "feature_fraction": 0.30000000000000004, "verbose": -1}}}, {"role": "solutionSummary", "module": {"summary": "The task is to detect credit card fraud using an ensemble of three models: XGBClassifier, CatBoostClassifier, and LGBMClassifier. After preprocessing the data, which includes scaling the Amount column and transforming the Time column into time buckets, the data is split using StratifiedKFold cross-validation. The API is called to create an LGBMClassifier with specific parameters. This LGBMClassifier, along with the previously created XGBClassifier and CatBoostClassifier, is trained on different portions of the sampled data to deal with class imbalance. The predictions from each model are then combined to create the final test submission file."}}], "source": "kaggle"}, {"id": "viktortaran-ps-s-3-e-f-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-repeatedstratifiedkfold"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_splits": 5, "n_repeats": 2, "random_state": 2023}}}, {"role": "solutionSummary", "module": {"summary": "This code snippet is designed to solve a binary classification problem using multiple machine learning models, such as LGBM, XGBoost, CatBoost, and others. The API call is made to create a RepeatedStratifiedKFold cross-validator object, which is used to split the dataset into training and validation sets. With this cross-validation technique, the dataset is split into n_splits (5) equal parts (folds), and the model is trained and tested n_repeats (2) times. This approach ensures better evaluation of the model's performance as it reduces the variance associated with a single train-test split. The cross-validation results are then used to optimize model hyperparameters with Optuna, and different ensembling techniques like weighted ensembling, stacking, and blending are applied to improve the final prediction performance."}}], "source": "kaggle"}, {"id": "viktortaran-ps-s-3-e-f-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-impute-simpleimputer"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"strategy": "mean"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet focuses on a machine learning competition with the goal of predicting fraud, using various classification techniques. After loading the data, preprocessing steps are carried out, such as dropping duplicates, analyzing distributions, and handling missing values. The API call is used to create an imputer object for imputing missing numerical values with the mean strategy. Subsequently, the data is transformed and encoded using this imputer, followed by various classification models being trained, including LightGBM, XGBoost, CatBoost, Random Forest, LassoCV, Logistic Regression, and Keras-based models. Finally, ensemble techniques such as weighted averaging, stacking, and blending are implemented to improve the overall performance of the predictions."}}], "source": "kaggle"}, {"id": "viktortaran-ps-s-3-e-f-003", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-impute-simpleimputer"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"strategy": "most_frequent"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is a part of a larger machine learning pipeline that processes various datasets for classification tasks. Prior to the API call, several libraries, datasets, and tools are imported, and data preprocessing steps are performed. The purpose of this specific API call is to handle missing categorical data as a part of the data preprocessing phase. It creates a SimpleImputer object with a strategy of 'most_frequent' to fill missing values with the most frequent value in the respective column. After creating the SimpleImputer object, it is used to impute the missing values in the categorical columns of the training and test datasets, making the data ready for further processing, including feature engineering, modeling, and ensembling."}}], "source": "kaggle"}, {"id": "viktortaran-ps-s-3-e-f-004", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-onehotencoder"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"handle_unknown": "ignore", "sparse": "False", "drop": "first"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is for a classification problem using various machine learning algorithms. The dataset is preprocessed, including handling missing values, encoding categorical variables, scaling, and feature engineering. The API call creates an instance of OneHotEncoder for encoding categorical variables. After encoding, the data is further processed using various techniques such as adversarial validation, normalization, and outlier removal. Finally, several machine learning models are trained, and their predictions are combined using different ensemble techniques like weighted averaging, stacking, and blending."}}], "source": "kaggle"}, {"id": "viktortaran-ps-s-3-e-f-005", "modules": [{"role": "algorithm", "purpose": "API", "module": "xgboost-xgbclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"lambda": 4.4462110371108015, "alpha": 0.594619882364806, "colsample_bytree": 0.453731749454566, "subsample": 0.543157492076168, "learning_rate": 0.010560944921536001, "n_estimators": 3370, "max_depth": 8, "min_child_weight": 3, "num_parallel_tree": 1, "early_stopping_rounds": 200, "tree_method": "gpu_hist", "scale_pos_weight": 0.50094813442976}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is designed to preprocess the dataset and create ensemble models for a classification task. The XGBoost Classifier is set up with specific tuned parameters using Optuna. Preprocessing steps include handling missing values, dropping duplicates, encoding, and feature scaling. The dataset is then split into training and testing sets for model evaluation. After setting up the XGBoost Classifier, it is trained on the training set, and the model's performance is assessed using the AUC score. The predictions on the test set are then generated, and multiple ensemble methods (i.e., simply weighted, stacking, and blending) are applied to combine the predictions. The final predictions are saved to CSV files for each ensemble method."}}], "source": "kaggle"}, {"id": "anubhavgoyal11-students-exam-performance-eda-rando-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-standardscaler"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict students' math scores based on features like gender, race/ethnicity, parental level of education, and test preparation course. An extensive exploratory data analysis is performed to understand the relationships between variables and visualize the data. A custom transformation pipeline is created, which includes StandardScaler for numeric columns, a custom ordinal encoder for ordinal columns, and the API call is used for one-hot encoding categorical columns. After preprocessing the data using the pipeline, a RandomForestRegressor is trained and optimized using GridSearchCV, RandomizedSearchCV, and Optuna. Finally, the model is evaluated on the test set, and residuals are plotted to analyze prediction errors."}}], "source": "kaggle"}, {"id": "anubhavgoyal11-students-exam-performance-eda-rando-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-compose-columntransformer"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"transformers": "[('std_scaler', StandardScaler(), ['reading score', 'writing score', 'Percentage']), ('ord_encode', CustomOrdinalEncoder(), ['Grade', 'race/ethnicity', 'parental level of education']), ('label_encode', OneHotEncoder(), ['gender', 'lunch', 'test preparation course'])]", "remainder": "passthrough"}}}, {"role": "solutionSummary", "module": {"summary": "The goal of this code snippet is to predict a student's math score based on different factors such as gender, ethnicity, parental level of education, and test preparation course status. After importing the data and performing exploratory data analysis, the API is called to create a transformation pipeline that scales numerical columns, encodes ordinal categorical columns using a custom ordinal encoder, and one-hot encodes nominal categorical columns. The dataset is then split into training and testing sets, and the transformation pipeline is fit on the training set and applied to both training and testing sets. Subsequently, a RandomForestRegressor model is trained, and hyperparameters are optimized using GridSearchCV, RandomizedSearchCV, and Optuna. Finally, predictions are made on the test set, and the model's performance is evaluated using RMSE and R-square metrics."}}], "source": "kaggle"}, {"id": "anubhavgoyal11-students-exam-performance-eda-rando-003", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-train-test-split"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"[0]": "dataframe(shape=(1000, 9))", "[1]": "series(shape=(1000,))", "test_size": 0.2, "random_state": 42}}}, {"role": "solutionSummary", "module": {"summary": "The goal of the code is to predict students' math scores based on their performance in reading and writing exams and various demographic factors. The dataset is preprocessed and exploratory data analysis is performed to understand the relationships between the features. Prior to the API call, the data is divided into features (X) and target (y). The API call splits the dataset into training and testing sets, with 80% of the data used for training and 20% for testing. After the split, a transformation pipeline is created to preprocess the data, and several models, including RandomForestRegressor, are fitted and evaluated for their performance in predicting students' math scores. Hyperparameter optimization is also performed to improve the model's performance."}}], "source": "kaggle"}, {"id": "anubhavgoyal11-students-exam-performance-eda-rando-004", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-ensemble-randomforestregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"random_state": 42}}}, {"role": "solutionSummary", "module": {"summary": "The goal is to predict math scores of students based on their performance in exams and other factors. The dataset is first explored and visualized, and new features are engineered. Then, a transformation pipeline is created to preprocess the data. The API call is made to build the RandomForestRegressor model with a fixed random state for reproducibility. After fitting the model to the prepared training data, a k-fold cross-validation is performed to evaluate the model's performance. Subsequently, hyperparameter optimization techniques like GridSearchCV, RandomizedSearchCV, and Optuna are used to improve the model's performance. Finally, the model is retrained with the best parameters and predictions are made on the test set, which are visualized and assessed based on the residuals."}}], "source": "kaggle"}, {"id": "anubhavgoyal11-students-exam-performance-eda-rando-005", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-kfold"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_splits": 5}}}, {"role": "solutionSummary", "module": {"summary": "In this code snippet, the goal is to predict a student's math score based on various attributes such as reading and writing scores, gender, race/ethnicity, etc. After preprocessing the data and creating features, the API call is made to set up a 5-fold cross-validation scheme. This is used to evaluate the performance of a Random Forest Regressor model by calculating the mean squared error for each fold. The model's performance is further optimized using GridSearchCV, RandomizedSearchCV, and Optuna for hyperparameter tuning, and the final predictions are made using the best parameters found. The predictions are then visually inspected using plots of actual vs. predicted values and residual analysis."}}], "source": "kaggle"}, {"id": "anubhavgoyal11-students-exam-performance-eda-rando-006", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-cross-val-score"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "RandomForestRegressor(random_state=42)", "X": "array(shape=(800, 12))", "y": "series(shape=(800,))", "scoring": "neg_mean_squared_error", "cv": "KFold(n_splits=5, random_state=None, shuffle=False)"}}}, {"role": "solutionSummary", "module": {"summary": "The goal of this code snippet is to predict students' math scores based on features such as reading and writing scores, gender, race/ethnicity, parental level of education, lunch and test preparation course. After initial data exploration and preprocessing, a transformation pipeline is created to process the data. The API call is used to evaluate the performance of a RandomForestRegressor using 5-fold cross-validation. After computing the cross-validation scores, the root mean squared error (RMSE) is calculated to assess the performance of the model. Further, different hyperparameter optimization techniques are applied, and the final model is evaluated, showing the distribution of residuals and a plot of standardized residuals against predicted math scores."}}], "source": "kaggle"}, {"id": "anubhavgoyal11-students-exam-performance-eda-rando-007", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-ensemble-randomforestregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"random_state": 42}}}, {"role": "solutionSummary", "module": {"summary": "The objective is to predict students' math scores using their reading and writing scores along with other demographic information. After loading the dataset, exploratory data analysis is performed to gain insights into the relationships between the variables. A transformation pipeline is created to preprocess the data, including scaling numeric columns and encoding categorical columns. Then, the API call is made to create a RandomForestRegressor model. The model is fit to the training data, and its performance is assessed using cross-validation. Subsequently, hyperparameter optimization techniques such as GridSearchCV, RandomizedSearchCV, and Optuna are employed to find the best parameters for the model. Finally, predictions are made using the optimized model, and the model's performance is evaluated through visualizations and error metrics."}}], "source": "kaggle"}, {"id": "anubhavgoyal11-students-exam-performance-eda-rando-008", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-gridsearchcv"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "RandomForestRegressor(random_state=42)", "param_grid": "[{n_estimators: [100, 250, 400], max_features: [8, 16, 24]}, {bootstrap: [False], n_estimators: [200, 400], max_features: [15, 30]}]", "cv": "KFold(n_splits=5, random_state=None, shuffle=False)", "scoring": "neg_mean_squared_error", "return_train_score": "True"}}}, {"role": "solutionSummary", "module": {"summary": "The task is to predict students' math scores based on various features such as reading and writing scores, gender, race/ethnicity, and other factors. After performing exploratory data analysis and creating a transformation pipeline to preprocess the data, a RandomForestRegressor model is built. The API call is used to perform a grid search to find the best hyperparameters for the model using a predefined set of parameters and KFold cross-validation. After using GridSearchCV, the best hyperparameters are found, and the model's performance is evaluated using the root mean squared error (RMSE) metric."}}], "source": "kaggle"}, {"id": "anubhavgoyal11-students-exam-performance-eda-rando-009", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-ensemble-randomforestregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"random_state": 42}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict students' math scores using a RandomForestRegressor algorithm. The dataset consists of student performance in exams with features like gender, race/ethnicity, parental level of education, lunch status, and test preparation course status. After conducting exploratory data analysis and feature engineering, the data is preprocessed using a transformation pipeline. The API is called to create a RandomForestRegressor model with a fixed random state to ensure reproducibility. The model is then fitted with training data and evaluated using cross-validation and various hyperparameter optimization techniques, such as GridSearchCV, RandomizedSearchCV, and Optuna, before making final predictions. The performance of the model is assessed using RMSE and R-square metrics."}}], "source": "kaggle"}, {"id": "anubhavgoyal11-students-exam-performance-eda-rando-010", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-randomizedsearchcv"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "RandomForestRegressor(random_state=42)", "param_distributions": "{n_estimators: <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7b761a1369e0>, max_features: <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7b761863c820>}", "n_iter": 10, "cv": "KFold(n_splits=5, random_state=None, shuffle=False)", "scoring": "neg_mean_squared_error", "random_state": 42}}}, {"role": "solutionSummary", "module": {"summary": "The goal is to predict a student's math score based on their reading and writing scores, gender, race, parental level of education, lunch, and test preparation course. The dataset is preprocessed, including feature engineering and transformation pipeline. The API is called to perform hyperparameter optimization for a RandomForestRegressor model using RandomizedSearchCV. After the optimization, the best parameters are used to fit the final model, and predictions are made on the test dataset. The performance of the model is evaluated using RMSE and R-square metrics, and a residual plot is created to visualize the distribution of errors."}}], "source": "kaggle"}, {"id": "posew7-studentsgherformance-in-exam-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-train-test-split"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"[0]": "array(shape=(1000, 1))", "[1]": "array(shape=(1000, 1))", "test_size": 0.30000000000000004}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to analyze the relationship between various features of students' performance in exams. After loading the dataset and performing some initial analysis, the API is called to split the dataset into training and testing sets, focusing on the relationship between reading and writing scores. Subsequently, a Linear Regression model is built, fitted with the training data, and then used to make predictions. The model's performance is assessed using the train and test scores, and the relationship between reading and writing scores is visualized with a scatter plot."}}], "source": "kaggle"}, {"id": "posew7-studentsgherformance-in-exam-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-linear-model-linearregression"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"[0]": "dataframe(shape=(1000, 3))", "[1]": "array(shape=(1000,))", "test_size": 0.30000000000000004, "random_state": 1}}}, {"role": "solutionSummary", "module": {"summary": "This code snippet aims to predict students' gender based on their math, reading, and writing scores using the K-Nearest Neighbors (KNN) algorithm. Preprocessing involves dropping unnecessary columns and encoding the gender column as binary values. The dataset is then normalized, and the API call is used to split the dataset into training and testing sets. Afterward, the KNN model is trained and evaluated using different values for the number of neighbors, and eventually, a GridSearchCV is employed to find the optimal value. The model's performance is analyzed using confusion matrices and classification reports."}}], "source": "kaggle"}, {"id": "posew7-studentsgherformance-in-exam-003", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-neighbors-kneighborsclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_neighbors": 11}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is focused on predicting students' gender based on their performance in exams. After preprocessing the data, the KNeighborsClassifier is instantiated with varying 'n_neighbors' values in a loop to find the optimal number of neighbors. The model is then trained and its score on the training data is appended to a list. The purpose of this loop is to determine the best 'n_neighbors' value that results in the highest score. After finding the optimal number of neighbors, further evaluation and cross-validation of the KNN model is carried out."}}], "source": "kaggle"}, {"id": "posew7-studentsgherformance-in-exam-004", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-neighbors-kneighborsclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_neighbors": 15}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet focuses on predicting student gender based on their exam scores. After loading the dataset, cleaning, and processing the data, the API is called to create a K-Nearest Neighbors (KNN) classifier with 15 neighbors. The classifier is then trained on the training set and used to make predictions on the test set. The performance of the model is evaluated using the score, confusion matrix, and classification report. Further, the optimal number of neighbors is determined using cross-validation and GridSearchCV, and the model is refitted with the best parameters for improved performance."}}], "source": "kaggle"}, {"id": "posew7-studentsgherformance-in-exam-005", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-decomposition-pca"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_components": 2, "whiten": "True"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet focuses on analyzing students' performance in exams and predicting their gender based on their scores. After cleaning and preprocessing the data, the API is called to perform Principal Component Analysis (PCA) to reduce the dimensionality of the dataset. The transformed data is then used to visualize the distribution of male and female students in the reduced feature space. Following the PCA, a K-Nearest Neighbors (KNN) classifier is trained and evaluated using both cross-validation and GridSearchCV for hyperparameter tuning. The classifier's performance is assessed through confusion matrices and classification reports."}}], "source": "kaggle"}, {"id": "posew7-studentsgherformance-in-exam-006", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-train-test-split"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"[0]": "dataframe(shape=(1000, 3))", "[1]": "array(shape=(1000,))", "test_size": 0.30000000000000004}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict the gender of students based on test scores using a K-Nearest Neighbors Classifier. After data preprocessing, the dataset is split into features (test scores) and target (gender). The API call is used to split the dataset into training and testing sets, with 30% of the data reserved for testing. Multiple models with different numbers of neighbors are evaluated, and the best parameters are identified using GridSearchCV. The performance of the final model is analyzed using confusion matrices and classification reports, followed by PCA for dimensionality reduction and visualization."}}], "source": "kaggle"}, {"id": "posew7-studentsgherformance-in-exam-007", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-neighbors-kneighborsclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_neighbors": 15}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to analyze student performance in exams, with a focus on predicting student gender based on their scores. After importing the dataset and performing preprocessing, a KNeighborsClassifier model is created with n_neighbors=15. The model is then evaluated using cross-validation and fitted on the training data. Subsequently, the accuracy scores for the training and testing sets are calculated, and the model performance is assessed using confusion matrices and classification reports. Other methods, such as PCA and GridSearchCV, are also used to explore the dataset further and optimize the model's hyperparameters."}}], "source": "kaggle"}, {"id": "posew7-studentsgherformance-in-exam-008", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-cross-val-score"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "KNeighborsClassifier(n_neighbors=15)", "X": "dataframe(shape=(1000, 3))", "y": "array(shape=(1000,))", "cv": 10}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet analyzes student performance data to predict the student's gender based on their exam scores. After preprocessing the data, the K-Nearest Neighbors (KNN) algorithm is chosen as the classifier. The API call is used to perform a 10-fold cross-validation on the data to estimate the model's accuracy. This helps provide an unbiased assessment of the model's performance by iteratively training and validating the model on different subsets of the data. The mean and standard deviation of the obtained accuracies are then printed, offering insights into the model's generalization ability and stability."}}], "source": "kaggle"}, {"id": "posew7-studentsgherformance-in-exam-009", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-neighbors-kneighborsclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "KNeighborsClassifier()", "param_grid": "{n_neighbors: array(shape=(49,))}", "cv": 10}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet analyzes student performance data to predict gender based on test scores. After preprocessing the data, the K-Nearest Neighbors (KNN) classifier is used to fit the model. The API call performs a GridSearchCV to find the optimal number of neighbors (k) for the KNN classifier. This technique helps in finding the best hyperparameter by performing an exhaustive search over specified parameter values while using cross-validation to estimate the model's performance. After obtaining the best value for k, the model is evaluated using various performance metrics such as confusion matrix and classification report."}}], "source": "kaggle"}, {"id": "kacperkubara-who-pcores-wxlw-in-exams-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-onehotencoder"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet explores the Students Performance in Exams dataset to investigate the factors that affect exam scores. After analyzing the dataset based on gender, parental level of education, lunch type, and test preparation course, the next step is to preprocess the data for K-Means clustering. The exam scores are converted into categorical labels, and then the API is called to create a LabelEncoder object, which is later used to transform the categorical labels into numerical values. This transformation is necessary for applying the K-Means algorithm and visualizing the resulting clusters in a 3D plot."}}], "source": "kaggle"}, {"id": "kacperkubara-who-pcores-wxlw-in-exams-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-cluster-kmeans"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_clusters": 5, "init": "k-means++"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet analyzes the Students Performance in Exams dataset to understand factors affecting exam scores. After exploring various features and their impact on scores, the author decides to cluster the dataset using K-Means algorithm to find similarities between groups of students based on their exam scores. The data preprocessing involves transforming exam scores into categorical features and encoding them. The API call is made to fit the K-Means algorithm with an optimal number of clusters, determined using the Elbow Method. Finally, the clusters are visualized in a 3D plot to observe the relationship between scores in different subjects."}}], "source": "kaggle"}, {"id": "sierram-cosine-similarity-wide-descristions-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-feature-extraction-text-tfidfvectorizer"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"stop_words": "english", "binary": "False", "max_df": 0.9500000000000001, "min_df": 0.15, "ngram_range": "(1, 2)", "use_idf": "False", "norm": "None"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to find similarities between wine descriptions using the cosine similarity method. The dataset containing wine descriptions is loaded, and the API is called to create a TfidfVectorizer object, which is then used to transform the wine descriptions into a document-term matrix. The choice of arguments helps to preprocess the text and filter the features, considering only unigrams and bigrams. After transforming the data, a custom function `comp_description` is defined to compare a given description with the dataset's descriptions using cosine similarity and return the most similar description. The function is then called with sample wine descriptions to demonstrate its functionality."}}], "source": "kaggle"}, {"id": "sharvalkszindf-ptwsepisvbor-ynesypdknkfaeibhten-av-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-stratifiedkfold"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_splits": 10, "random_state": 42, "shuffle": "True"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is for credit card fraud detection, using a combination of the original dataset and a synthetic dataset. The API call creates a Stratified K-Fold cross-validator with 10 splits, in order to maintain the proportion of the target class across all folds during the model training and evaluation phases. Before the API call, the data is loaded, combined, preprocessed, and several new features are created. Following the API call, two separate models, LightGBM and XGBoost, are trained using the generated folds, and their feature importances are visualized. Finally, the predictions from both models are combined with a weighted average, and the results are saved for submission."}}], "source": "kaggle"}, {"id": "sharvalkszindf-ptwsepisvbor-ynesypdknkfaeibhten-av-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "lightgbm-lgbmmodel"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"objective": "binary", "metric": "auc", "n_jobs": -1, "random_state": 42, "n_estimators": 7604, "learning_rate": 0.0050609676874, "num_leaves": 72, "subsample": 0.146140309581375, "colsample_bytree": 0.648904250776283, "min_child_weight": 5, "reg_alpha": 0.060187613753000004, "reg_lambda": 0.654011754206945, "device": "gpu"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict credit card fraud using LightGBM and XGBoost models. The dataset is preprocessed, including the addition of new features such as 'Time group' and 'Day'. The purpose of the API call is to create an instance of the LightGBM classifier with the best parameters found through hyperparameter tuning using Optuna. The classifier is then fit on the training data and used for making predictions in a k-fold cross-validation setting. Model performance is evaluated using AUC scores, and feature importance plots are generated for both LightGBM and XGBoost models. A weighted average of the predictions from both models is calculated and used to create the final submission file."}}], "source": "kaggle"}, {"id": "sharvalkszindf-ptwsepisvbor-ynesypdknkfaeibhten-av-003", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-stratifiedkfold"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_splits": 10, "random_state": 42, "shuffle": "True"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to detect fraudulent transactions in a dataset by using both LightGBM and XGBoost models. After loading the dataset, preprocessing, and feature engineering, the API is called to create a Stratified K-Fold cross-validator with 10 folds. The purpose is to maintain the proportion of fraud cases in each fold to ensure a balanced evaluation. The dataset is then split into training and validation sets, and both LightGBM and XGBoost models are trained and evaluated on these sets. The performance of both models is assessed using AUC scores, and a weighted average of their predictions is calculated for the final submission."}}], "source": "kaggle"}, {"id": "sharvalkszindf-ptwsepisvbor-ynesypdknkfaeibhten-av-004", "modules": [{"role": "algorithm", "purpose": "API", "module": "xgboost-xgbclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"max_depth": 3, "eta": 0.15958379295041802, "subsample": 0.8765751361651161, "colsample_bytree": 0.8911874956298851, "lambda": 0.18054051550265401, "alpha": 0.506406058776367, "scale_pos_weight": 7.022083833341036, "min_child_weight": 1, "gamma": 0.276844367484328, "reg_lambda": 0.9718401826200601, "reg_alpha": 0.7219240918291031, "n_estimators": 1237, "learning_rate": 0.014094528559679001, "objective": "binary:logistic", "tree_method": "gpu_hist"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to build a credit card fraud detection model using the given dataset. The dataset is preprocessed and feature engineering is performed by categorizing the 'Time' feature and adding a 'Day' feature. The API is called to create an XGBoost classifier using the best parameters obtained from hyperparameter tuning using Optuna. The model is then trained using a 10-fold StratifiedKFold cross-validator. After training, feature importances are visualized, and the predictions are combined with those from an LGBM classifier using a weighted average approach. Finally, the submission file with the predicted fraud probabilities is generated."}}], "source": "kaggle"}, {"id": "tomatenbiss-machine-learning-or-studeats-performan-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-onehotencoder"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"handle_unknown": "ignore"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet analyzes the relationship between students' demographic and personal attributes and their performance in exams. The dataset is extended to include pass or fail status for each subject and overall. Various visualizations are created to explore the relationships between the different attributes and the pass/fail rates. The API is then called to perform OneHotEncoding on the categorical features, transforming them into a format suitable for machine learning algorithms. Next, the dataset is split into training and testing sets, and multiple classification models are trained and evaluated to predict students' overall pass/fail status. The script concludes with a discussion on the ethical implications of using the data for predictions and potential discriminatory outcomes."}}], "source": "kaggle"}, {"id": "tomatenbiss-machine-learning-or-studeats-performan-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-train-test-split"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"[0]": "dataframe(shape=(1000, 11))", "[1]": "series(shape=(1000,))", "test_size": 0.15, "random_state": 0}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet analyzes the performance of students in exams based on their gender, race/ethnicity, lunch fees, and attendance in a test preparation course. After loading the data, extending it with pass/fail flags, and visualizing the relationships between features and the passing rate, the API is called to split the dataset into training and testing sets. Subsequently, the data is encoded using one-hot encoding, and various machine learning models such as k-Nearest Neighbors, Decision Tree, and Support Vector Machine are trained and evaluated for predicting if a student passes all exams or not. Finally, the implications of using such data for predictions and the ethical considerations are briefly discussed."}}], "source": "kaggle"}, {"id": "tomatenbiss-machine-learning-or-studeats-performan-003", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-neighbors-kneighborsclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_neighbors": 51}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet's goal is to predict whether students pass their exams based on demographic information and the completion of a test preparation course. After visualizing the data and identifying potential trends, the dataset is prepared for machine learning by one-hot encoding categorical variables. The API is called within a loop to create a K-Nearest Neighbors classifier with varying numbers of neighbors. The classifiers are fitted with the training data, and their performance is evaluated on the test data to find the optimal value for the number of neighbors. Further, two additional classifiers, DecisionTree and SVC, are explored to compare their performance with the KNN model."}}], "source": "kaggle"}, {"id": "tomatenbiss-machine-learning-or-studeats-performan-004", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-tree-decisiontreeclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"kernel": "poly", "gamma": "scale"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet analyzes the performance of students in exams. After loading the data, several visualizations are created to explore the relationships between student attributes and their exam results. OneHotEncoder is used to preprocess the categorical data, and then the dataset is split into training and testing sets. The API is called to create a Support Vector Machine (SVM) classifier with a polynomial kernel. The SVM classifier is then fitted using the training data and evaluated on the testing data. The performance of other classification methods is also examined, and the script concludes with a discussion of the ethical considerations of using the given data for predictions."}}], "source": "kaggle"}, {"id": "joshbeau-cnn-pneimonia-prediction-with-x-ray-image-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-train-test-split"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"[0]": "array(shape=(5840, 64, 64, 3))", "[1]": "array(shape=(5840, 2))", "test_size": 0.33, "random_state": 42}}}, {"role": "solutionSummary", "module": {"summary": "The purpose of this code snippet is to build a convolutional neural network (CNN) model to predict pneumonia from chest X-ray images. The X-ray images are preprocessed, resized, and normalized before being combined into a single dataset. The API call is made to split the dataset into training and testing sets, with 33% of the data reserved for testing. The CNN model is then built, trained, and evaluated using the created training and testing sets. Finally, the model's performance is assessed through accuracy metrics and visualizations."}}], "source": "kaggle"}, {"id": "residentmario-undersampling-and-oversampling-imbal-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-datasets-make-classification"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_samples": 1000, "n_features": 2, "n_informative": 2, "n_redundant": 0, "n_repeated": 0, "n_classes": 3, "n_clusters_per_class": 1, "weights": "[0.2, 0.1, 0.7]", "class_sep": 0.8, "random_state": 0}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet demonstrates an approach to handle imbalanced datasets using under-sampling and over-sampling techniques. The API call is used to create synthetic datasets with different class weights to visualize the effect of class imbalance on the classifier's decision boundaries. The datasets are then used to train a Linear Support Vector Machine (SVM) classifier, and the decision boundaries are plotted to show the impact of class weights on the classifier's performance. The main focus of this code snippet is to emphasize the importance of dealing with class imbalance in machine learning problems and to present various techniques for handling such imbalanced datasets."}}], "source": "kaggle"}, {"id": "residentmario-undersampling-and-oversampling-imbal-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-svm-linearsvc"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_samples": 5000, "n_features": 2, "n_informative": 2, "n_redundant": 0, "n_repeated": 0, "n_classes": 3, "n_clusters_per_class": 1, "weights": "[0.01, 0.05, 0.94]", "class_sep": 0.8, "random_state": 0}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is focused on dealing with imbalanced datasets, specifically demonstrating the importance of under- and over-sampling techniques. The API call creates a synthetic dataset with 5000 samples, 2 informative features, and 3 classes with varying class proportions, simulating an imbalanced dataset. The dataset is then used to illustrate different sampling techniques, such as `RandomOverSampler` and `RandomUnderSampler`, and their impact on the performance of a Support Vector Machine (SVM) classifier. The notebook also covers ensemble samplers, learning curves, and a practical application using a credit card fraud dataset."}}], "source": "kaggle"}, {"id": "ahmedmohamedmahrous-google-play-store-eda-rating-p-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-train-test-split"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"[0]": "dataframe(shape=(10531, 8))", "[1]": "series(shape=(10531,))", "train_size": 0.75, "random_state": 0}}}, {"role": "solutionSummary", "module": {"summary": "The goal of this code snippet is to analyze Google Play Store Apps data to understand the relationship between various features and app ratings. After data preprocessing and exploratory data analysis, the dataset is split into training and testing sets using the API call. The train_size parameter is set to 0.75, meaning 75% of the data is used for training, and the remaining 25% is used for testing. The random_state parameter is set to 0 to ensure reproducibility of the results. After the dataset split, the features are standardized, and a Gradient Boosting Regressor model is used to predict app ratings. Model performance is evaluated through various metrics, including R2 score, Mean Absolute Error (MAE), Mean Squared Error (MSE), and Root Mean Squared Error (RMSE)."}}], "source": "kaggle"}, {"id": "ahmedmohamedmahrous-google-play-store-eda-rating-p-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-standardscaler"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet analyzes Google Play Store app data. After loading the data, it is preprocessed and cleaned, which includes handling missing values, duplicates, and outliers. The data is then visualized and explored to understand the relationships between various features, such as app ratings, category, type, content rating, genres, and more. The dataset is then split into training and testing sets, and a Gradient Boosting Regressor model is trained to predict app ratings based on the selected features. The performance of the model is evaluated using metrics, such as R2 score, mean absolute error (MAE), mean squared error (MSE), and root mean squared error (RMSE)."}}], "source": "kaggle"}, {"id": "nilanml-eda-lasso-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-train-test-split"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"[0]": "dataframe(shape=(169, 9))", "[1]": "series(shape=(169,))", "test_size": 0.1, "shuffle": "False"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to analyze avocado prices across different regions and types (organic and conventional) using time series plots, bar plots, and correlation heatmaps. After preprocessing, the dataset is prepared for machine learning by concatenating the features and target variable and grouping by date. The API call is used to split the dataset into training and testing sets without shuffling. Afterwards, various regression algorithms are applied to the training set to predict avocado prices, and their performances are compared using the root mean squared error metric. Finally, the predictions of the best-performing model (Lasso) are visualized along with actual test data points."}}], "source": "kaggle"}, {"id": "nilanml-eda-lasso-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-tree-decisiontreeregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is about analyzing avocado prices and sales volume across different regions and time periods. After data preprocessing and visualization, a machine learning model is built to predict average prices based on multiple input features. The API call is a part of an ensemble of regression models that are trained and evaluated. After training the RandomForestRegressor model along with the other models, the performance is measured using the root mean squared error (RMSE) and compared against the actual test points."}}], "source": "kaggle"}, {"id": "nilanml-eda-lasso-003", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-neighbors-kneighborsregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_neighbors": 2}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet involves analyzing avocado prices and sales volumes over time and across different regions. After performing data cleaning, preprocessing, and visualization, the script moves on to use multiple regression models to predict avocado prices. The API call is used to create a K-Nearest Neighbors Regressor model with 2 neighbors. This model is part of a list of regressor models the script iterates through, training and testing each, and then calculating and printing the root mean squared errors for comparison. The goal is to identify the best model for predicting avocado prices based on various input features."}}], "source": "kaggle"}, {"id": "nilanml-eda-lasso-004", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-svm-svr"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {}}}, {"role": "solutionSummary", "module": {"summary": "In this code snippet, the task is to analyze avocado prices using various visualizations and build a price prediction model. After visualizing the data and preprocessing it, the dataset is grouped by date and split into training and testing sets. The API call is part of a set of machine learning models being tested for their performance in predicting avocado prices. The models are fit to the training data and evaluated using the mean squared error metric on the test data. Finally, the best-performing model is used to predict and visualize the prices for the test data."}}], "source": "kaggle"}, {"id": "nilanml-eda-lasso-005", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-ensemble-gradientboostingregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet analyzes avocado prices in various regions over time. After data cleaning, processing, and visualization, the dataset is prepared for machine learning. The goal is to predict average prices based on the given features. The API call is used to create an XGBoost regression model, which is included as one of the various models tested for prediction performance. After fitting each model with the training data, the root mean squared error is calculated to compare their performance, and the Lasso regression model is ultimately chosen to visualize the predictions against the actual test points."}}], "source": "kaggle"}, {"id": "nilanml-eda-lasso-006", "modules": [{"role": "algorithm", "purpose": "API", "module": "catboost-catboostregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"logging_level": "Silent"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet focuses on analyzing and predicting avocado prices. After data preprocessing, several visualizations are created to understand the trends in prices and sales volumes. The dataset is then prepared for machine learning by grouping it by date and extracting relevant features. A variety of regression models are trained and tested on this data to predict average prices, and the API is called to include the CatBoostRegressor in this group of models. The performance of each model is evaluated using the root mean squared error metric, and the results are displayed for comparison."}}], "source": "kaggle"}, {"id": "nilanml-eda-lasso-007", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-linear-model-lasso"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet's goal is to predict avocado prices using a variety of regression models, including Ridge regression. The dataset is preprocessed, visualized, and aggregated before being split into training and testing sets. The API is called to create an instance of the Ridge regression model with default parameters. Along with other models, the Ridge regression model is then fit to the training data, and predictions are made on the test set. The performance of each model is evaluated by calculating the root mean squared error (RMSE) between the predicted and actual avocado prices. The Lasso regression model is ultimately selected for visualizing the comparison between predictions and actual test points."}}], "source": "kaggle"}, {"id": "nilanml-eda-lasso-008", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-linear-model-bayesianridge"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to analyze and predict avocado prices using various regression models. After loading and preprocessing the data, the snippet visualizes various aspects of the data. Then, it proceeds to split the dataset into training and testing sets and tests multiple regression models, including ElasticNet. The API call is used to create an ElasticNet regression model, which is then fitted on the training data and used to make predictions on the test data. The performance of each model is evaluated using the root mean squared error. Finally, the predictions of the Lasso regression model are visualized in comparison to the actual test data points."}}], "source": "kaggle"}, {"id": "nilanml-eda-lasso-009", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-linear-model-huberregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet analyzes avocado prices using various visualizations and machine learning models. After preprocessing the data, a Lasso regression model is created using the API call. The model is then fitted with the training data, and predictions are made using the test data. The performance of the Lasso model, along with several other regression models, is evaluated using the root mean squared error metric. Finally, a plot is generated to display the actual vs. predicted values of the test data for the Lasso model."}}], "source": "kaggle"}, {"id": "codebreaker619-movie-recommender-system-content-ba-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-feature-extraction-text-tfidfvectorizer"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"min_df": 3, "max_features": "None", "strip_accents": "unicode", "analyzer": "word", "token_pattern": "\\w{1,}", "ngram_range": "(1, 3)", "stop_words": "english"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to create a movie recommendation system based on movie plot summaries. The tmdb_5000_credits and tmdb_5000_movies datasets are loaded, merged, and cleaned. The API call is used to create a TfidfVectorizer, which is responsible for converting the text data in the 'overview' column into numerical vectors. These vectors are then used to compute the pairwise similarity scores between movies using the sigmoid_kernel function. A recommendation function is defined that takes a movie title as input and returns the top 10 most similar movies based on the pairwise similarity scores computed earlier."}}], "source": "kaggle"}, {"id": "niteshyadav3103-diabetes-prediction-stacking-boost-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-ensemble-gradientboostingclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"ccp_alpha": 0.0, "criterion": "friedman_mse", "init": "None", "learning_rate": 0.1, "loss": "log_loss", "max_depth": 3, "max_features": "None", "max_leaf_nodes": "None", "min_impurity_decrease": 0.0, "min_samples_leaf": 1, "min_samples_split": 2, "min_weight_fraction_leaf": 0.0, "n_estimators": 100, "n_iter_no_change": "None", "random_state": "None", "subsample": 1.0, "tol": 0.0001, "validation_fraction": 0.1, "verbose": 0, "warm_start": "False"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is focused on building a predictive model for diabetes diagnosis using the Pima Indians Diabetes dataset. After loading, preprocessing, and visualizing the data, the API is called to create a Gradient Boosting Classifier. The model is then trained and used to make predictions on the test set. The performance of this model is compared with other classifiers such as Logistic Regression, KNN, SVM, Decision Tree, Random Forest, Ada Boost, Stochastic Gradient Boosting, XGBoost, Stacking, and Cat Boost. The best performing classifiers are identified based on their accuracy scores."}}], "source": "kaggle"}, {"id": "niteshyadav3103-diabetes-prediction-stacking-boost-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-ensemble-gradientboostingclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"learning_rate": 0.1, "subsample": 0.9, "max_features": 0.75, "loss": "deviance", "n_estimators": 100}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to classify the presence of diabetes in the Pima Indians dataset using various machine learning models. After cleaning the data, handling outliers, and visualizing the distribution and correlations, the API is called to create a Stochastic Gradient Boosting (SGB) model with specific parameters. The model is then trained on the preprocessed data and used to make predictions. The performance of the SGB model is compared with other models like Logistic Regression, K Neighbors Classifier, Support Vector Classifier, Decision Tree Classifier, Random Forest Classifier, Ada Boost Classifier, Gradient Boosting Classifier, Cat Boost Classifier, XGBoost, and Stacking to identify the best-performing model."}}], "source": "kaggle"}, {"id": "niteshyadav3103-diabetes-prediction-stacking-boost-003", "modules": [{"role": "algorithm", "purpose": "API", "module": "catboost-catboostclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"iterations": 30, "learning_rate": 0.1}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict diabetes diagnosis using various machine learning models. After cleaning, processing, and visualizing the data, the API is called to create a CatBoostClassifier model with specified iterations and learning rate. The model is then fitted with the training data, and its performance is evaluated on the test data. The results are compared with other machine learning models to determine which one provides the best accuracy. CatBoostClassifier and Stacking are found to give the best results among the tested models."}}], "source": "kaggle"}, {"id": "niteshyadav3103-diabetes-prediction-stacking-boost-004", "modules": [{"role": "algorithm", "purpose": "API", "module": "xgboost-xgbclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"booster": "gblinear", "learning_rate": 1, "max_depth": 3, "n_estimators": 10}}}, {"role": "solutionSummary", "module": {"summary": "The goal of this code snippet is to predict diabetes in patients using various machine learning models, including Cat Boost and Stacking. After loading and preprocessing the data, several models are trained and tested to evaluate their performance. The API is called to implement the Extreme Gradient Boosting (XGBoost) classifier, which is one of the models used in this comparison. The model is fitted with the training data, and predictions are made on the test data. The accuracy scores of XGBoost and other models are calculated, visualized, and compared to identify the models with the best performance."}}], "source": "kaggle"}, {"id": "niteshyadav3103-diabetes-prediction-stacking-boost-005", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-train-test-split"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"[0]": "dataframe(shape=(674, 8))", "[1]": "series(shape=(674,))", "test_size": 0.5, "random_state": 355}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict the presence of diabetes using various machine learning algorithms and stacking for improved accuracy. The Pima Indians Diabetes Dataset is loaded, preprocessed, and visualized for better understanding. The API call is used to divide the dataset into two parts: the training set and a holdout set, each containing 50% of the data. The training set is then further split into training and testing sets for base models, and the holdout set is used to train the meta-model. The base models are Logistic Regression and SVM, and the meta-model is a Random Forest Classifier. After training, the models' accuracies are compared to determine the best-performing model."}}], "source": "kaggle"}, {"id": "niteshyadav3103-diabetes-prediction-stacking-boost-006", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-train-test-split"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"[0]": "dataframe(shape=(337, 8))", "[1]": "series(shape=(337,))", "test_size": 0.2, "random_state": 355}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict the presence of diabetes using various machine learning algorithms on the Pima Indians Diabetes dataset. After preprocessing the data (handling zero values, outliers, and data distribution), the dataset is split into a training set and holdout set (50% each) using the API call. Then, the training set is further split into a training and test dataset (80% and 20%, respectively). Multiple classifiers, including Logistic Regression, SVM, Decision Tree, and ensemble methods, are trained and evaluated on these datasets. Finally, the models are compared based on their accuracy scores."}}], "source": "kaggle"}, {"id": "niteshyadav3103-diabetes-prediction-stacking-boost-007", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-linear-model-logisticregression"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict diabetes outcomes using various machine learning algorithms. After loading and preprocessing the dataset, including handling missing values, outliers, and data distribution, the API is called to create an SVC (Support Vector Classifier) model. The model is fitted with the training data and used to make predictions on the test data. The model's performance is evaluated using accuracy scores, confusion matrices, and classification reports. This process is done for multiple classifiers to compare their performance and identify the best-performing models."}}], "source": "kaggle"}, {"id": "vipulgandhi-how-to-choose-right-metric-for-evaauat-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-train-test-split"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"[0]": "dataframe(shape=(768, 8))", "[1]": "series(shape=(768,))", "stratify": "series(shape=(768,))", "random_state": 56}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is focused on evaluating different classification and regression metrics on various machine learning models. The API call is used to split the input dataset into training and testing sets, ensuring a representative ratio of each class in both sets by using stratified sampling. After the split, multiple machine learning models are trained, including Logistic Regression, SGDClassifier, and RandomForestClassifier. Following this, an array of evaluation metrics are calculated and compared, such as accuracy, log loss, ROC-AUC, confusion matrix, and classification report, to assess the performance of the models and help identify the best-fitting model for the given dataset."}}], "source": "kaggle"}, {"id": "docxian-cord-19-metadata-evaluation-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-feature-extraction-text-countvectorizer"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"ngram_range": "(3, 3)", "analyzer": "word"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is an analysis of the CORD-19 dataset, mainly focusing on the titles and abstracts of the research papers. The goal is to find the most common words, bigrams, and trigrams that appear in the titles and abstracts. The API call is used within a function to create a word vectorizer with a specific n-gram range. By calling the function with different n-gram ranges, the code subsequently generates word frequency tables for bigrams and trigrams. These frequency tables are then visualized using bar graphs and word clouds for better understanding of the most common terms in the dataset."}}], "source": "kaggle"}, {"id": "ammon1-statistics-distributions-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-minmaxscaler"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"random_state": 42}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is aimed at analyzing student performance in exams based on gender, race, and other factors. After loading the dataset and performing exploratory data analysis, including visualizations, the dataset is preprocessed with one-hot encoding and scaled using MinMaxScaler. The API call is made to create a RandomForestRegressor model with a fixed random state. Subsequently, GridSearchCV is used to find the best hyperparameters for the RandomForestRegressor model, and the model is fit and scored using the transformed input data. The low score suggests that the given parameters might not predict the math exam scores effectively."}}], "source": "kaggle"}, {"id": "ammon1-statistics-distributions-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-gridsearchcv"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "RandomForestRegressor(random_state=42)", "param_grid": "{n_estimators: [200, 500], max_features: [\"auto\", \"sqrt\", \"log2\"], max_depth: [4, 5, 6, 7, 8], criterion: [\"mse\", \"mae\"]}", "cv": 5}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to analyze students' performance in exams based on several factors, such as gender, race, and parental level of education. Visualizations are created to explore the distribution of variables. The dataset is then preprocessed, including one-hot encoding of categorical variables and scaling of numerical variables. The API call is used to perform hyperparameter tuning on a RandomForestRegressor model using GridSearchCV with 5-fold cross-validation. The model is fit on the transformed data, and the best parameters are identified. The model's score is evaluated, and an alternative Lasso model is also tested."}}], "source": "kaggle"}, {"id": "codebreaker619-movie-recommender-system-collaborat-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-minmaxscaler"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"metric": "cosine", "algorithm": "brute"}}}, {"role": "solutionSummary", "module": {"summary": "The goal of this code snippet is to build a movie recommender system using the K Nearest Neighbors based Collaborative Filtering on the Movielens dataset. After loading the dataset, preprocessing, and filtering based on popularity threshold, a pivot table is created to represent the movie ratings. This table is then converted into a sparse matrix, and the API is called to instantiate the NearestNeighbors model using cosine similarity and the brute-force algorithm. The model is then fitted on the sparse matrix. After randomly selecting a movie, the model finds the top five similar movies based on cosine similarity, and these movies are then recommended as similar to the original movie."}}], "source": "kaggle"}, {"id": "vikasukani-video-game-sales-epa-visualizations-ml-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-labelencoder"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"[0]": "array(shape=(16598, 6))", "[1]": "array(shape=(16598,))", "test_size": 0.2, "random_state": 45}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is an analysis of video game sales data using various visualizations and machine learning models. Before the API call, categorical features are encoded using LabelEncoder, and the dataset is prepared for model training by creating the features matrix X and the target array y. The API call is made to split the dataset into training and test sets, preserving 20% of the data for testing. Afterward, several machine learning models such as Linear Regression, K-Nearest Neighbors, Decision Tree, Random Forest, and Support Vector Machines are trained and evaluated to compare their performance on the dataset."}}], "source": "kaggle"}, {"id": "vikasukani-video-game-sales-epa-visualizations-ml-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-linear-model-linearregression"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_neighbors": 8}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is an analysis of video game sales data and aims to predict global sales using different machine learning regression models. After data preprocessing, the API is called within a loop to create KNeighborsRegressor models with varying n_neighbors values. The models are then fitted with the training data and used to make predictions on the test data. The r2_score is calculated for each KNeighborsRegressor model, and the results are plotted to visualize the performance of different n_neighbors values. This helps in selecting the optimal n_neighbors value for the KNeighborsRegressor model in this particular problem."}}], "source": "kaggle"}, {"id": "vikasukani-video-game-sales-epa-visualizations-ml-003", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-neighbors-kneighborsregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_neighbors": 3}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is about analyzing video game sales data and building a regression model to predict global sales. The dataset is preprocessed, categorical features are label-encoded, and the data is split into training and testing sets. The API call is used to create a K-Nearest Neighbors Regressor with 3 neighbors. The model is then trained on the training set and used to make predictions on the test set. The performance of the KNN model is evaluated using the R2 score along with other regression models such as Linear Regression, Decision Tree, Random Forest, SVM, and XGBoost for comparison."}}], "source": "kaggle"}, {"id": "vikasukani-video-game-sales-epa-visualizations-ml-004", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-tree-decisiontreeregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"random_state": 32}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is an analysis and visualization of video game sales data. After data cleaning and preprocessing, various machine learning models are employed to predict global sales based on the features. The API call creates a DecisionTreeRegressor model with a specified random state for reproducibility. The model is then fit on the training data and used to make predictions on the test data. The performance of the DecisionTreeRegressor is evaluated using the r2_score, and the results are compared to other models like KNeighborsRegressor, RandomForestRegressor, Support Vector Machines, and XGBoost."}}], "source": "kaggle"}, {"id": "vikasukani-video-game-sales-epa-visualizations-ml-005", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-ensemble-randomforestregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"random_state": 10}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is focused on analyzing and visualizing video game sales data. After loading the dataset, preprocessing, and exploration, the objective is to predict global sales using various machine learning models. The API call is made to create a RandomForestRegressor model with a specified random state to ensure consistent results. This model is then trained on the training set and its performance is evaluated on the test set using R2 score. The snippet also explores other machine learning models such as Linear Regression, KNeighborsRegressor, DecisionTreeRegressor, Support Vector Regression, and XGBoostRegressor for comparison."}}], "source": "kaggle"}, {"id": "vikasukani-video-game-sales-epa-visualizations-ml-006", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-svm-svr"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"kernel": "linear"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is focused on analyzing the video game sales dataset using various data visualization techniques and prediction models. After the data is loaded, cleaned, and preprocessed, different regression models are employed to predict global sales of video games. The API call initializes a Support Vector Regression (SVR) model with a linear kernel. It is then fitted to the training data and used to make predictions on the test data. The performance of this model is compared with other models, including K-Nearest Neighbors, Decision Tree, Random Forest, and XGBoost, to determine the most suitable model for predicting global sales."}}], "source": "kaggle"}, {"id": "vikasukani-video-game-sales-epa-visualizations-ml-007", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-svm-svr"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"kernel": "rbf"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is an analysis of video game sales with various visualizations and machine learning models. After performing exploratory data analysis, cleaning, and preprocessing, the API call is made to create a Support Vector Regression (SVR) model with the Radial Basis Function (RBF) kernel. The model is then fitted to the training data and used to make predictions on the test data. The performance of this model is compared with other regression models, such as Linear Regression, K-Nearest Neighbors, Decision Tree, Random Forest, and XGBoost, using the R2 score to evaluate their performance."}}], "source": "kaggle"}, {"id": "ibtesama-getting-started-with-a-movie-recommendati-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-feature-extraction-text-tfidfvectorizer"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"stop_words": "english"}}}, {"role": "solutionSummary", "module": {"summary": "The goal of this code snippet is to build a movie recommendation system using different approaches, including demographic filtering, content-based filtering, and collaborative filtering. In the content-based filtering part, the API call is used to create a TF-IDF Vectorizer object to process the movie plot descriptions (overviews) and convert them into numerical representations. The \"stop_words\" argument is set to \"english\" to remove common English words, such as \"the\" and \"a\", which do not provide much information for the recommendation system. After fitting and transforming the data using the TF-IDF Vectorizer object, a similarity matrix is calculated using cosine similarity to find the most similar movies based on their plot descriptions."}}], "source": "kaggle"}, {"id": "ibtesama-getting-started-with-a-movie-recommendati-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-feature-extraction-text-countvectorizer"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"stop_words": "english"}}}, {"role": "solutionSummary", "module": {"summary": "In this code snippet, the goal is to build a movie recommender system using demographic filtering, content-based filtering, and collaborative filtering approaches. The API call is made to create a count matrix for the 'soup' feature, which is a metadata feature combining keywords, cast, director, and genres. The CountVectorizer is used instead of the TF-IDF vectorizer because we don't want to down-weight the presence of an actor or director if they have acted or directed more movies. The matrix is then used to compute cosine similarity scores, and the recommender function is applied to suggest similar movies. The code also explores a collaborative filtering approach using the Surprise library, implementing the Single Value Decomposition (SVD) method."}}], "source": "kaggle"}, {"id": "ahmedfn-predicting-avocado-s-average-price-through-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-train-test-split"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"[0]": "dataframe(shape=(18249, 12))", "[1]": "series(shape=(18249,))", "test_size": 0.2, "random_state": 42}}}, {"role": "solutionSummary", "module": {"summary": "The goal is to predict the average price of avocados based on various features. Initially, the data is preprocessed, including dropping unnecessary columns, transforming categorical columns, and extracting day and month from the date column. The API call is used to split the dataset into training and testing sets. After the split, various regression models such as Linear Regression, Decision Tree Regressor, and Random Forest Regressor are trained, and their performance is evaluated using metrics like MAE, MSE, and RMSE. The best model is selected based on the lowest RMSE, and the residual distribution is visualized to assess the model's suitability for the data."}}], "source": "kaggle"}, {"id": "ahmedfn-predicting-avocado-s-average-price-through-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-linear-model-linearregression"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict avocado prices based on several features. After preprocessing the data and creating dummy variables, the dataset is split into training and testing sets. The API is called to create a Decision Tree Regressor model, which is then fitted with the training data and used to make predictions on the testing data. The performance of the model is assessed through scatter plots and error metrics. Furthermore, the performance of the Decision Tree Regressor is compared to that of Linear Regression and RandomForestRegressor models to choose the best model for the data."}}], "source": "kaggle"}, {"id": "amolbhivarkar-knn-for-classification-using-scikit-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-train-test-split"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"[0]": "array(shape=(768, 8))", "[1]": "array(shape=(768,))", "test_size": 0.4, "random_state": 42, "stratify": "array(shape=(768,))"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict diabetes in patients using the k-Nearest Neighbors algorithm on the Pima Indians Diabetes Dataset. The dataset is loaded, and features and target values are stored in variables X and y, respectively. The API call is used to split the dataset into training and testing sets, ensuring that the labels' distribution in these sets is similar to the original dataset by using the stratify argument. After the split, a k-NN classifier is built, and the optimal number of neighbors is found using GridSearchCV with 5-fold cross-validation. Finally, the best score and the best parameters are displayed."}}], "source": "kaggle"}, {"id": "amolbhivarkar-knn-for-classification-using-scikit-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-neighbors-kneighborsclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_neighbors": 5}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet focuses on predicting diabetes in patients using the k-Nearest Neighbors algorithm. The Pima Indians Diabetes Dataset is loaded and split into features and target variables. After splitting the data into train and test sets, the API is called iteratively with different values of k (number of neighbors) to find the best performing model. The model's performance is then visualized by plotting the testing and training accuracies for different values of k. After identifying the optimal value for k, the model is further fine-tuned using GridSearchCV, which performs cross-validation and hyperparameter tuning to find the best number of neighbors for the final model."}}], "source": "kaggle"}, {"id": "amolbhivarkar-knn-for-classification-using-scikit-003", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-neighbors-kneighborsclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_neighbors": 7}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet's goal is to predict whether the patients in the \"Pima Indians Diabetes Dataset\" have diabetes or not, using the k-Nearest Neighbors algorithm. After loading the dataset, splitting it into training and testing sets, and exploring the relationship between the number of neighbors and the accuracy, the API is called to create a k-Nearest Neighbors classifier with 7 neighbors. The classifier is then fit using the training data, and the model's accuracy is evaluated on the testing data. Later, additional techniques such as cross-validation, hyperparameter tuning, and GridSearchCV are applied to further improve the model's performance."}}], "source": "kaggle"}, {"id": "amolbhivarkar-knn-for-classification-using-scikit-004", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-neighbors-kneighborsclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "KNeighborsClassifier()", "param_grid": "{n_neighbors: array(shape=(49,))}", "cv": 5}}}, {"role": "solutionSummary", "module": {"summary": "The goal of the code snippet is to predict diabetes outcomes using the k-Nearest Neighbors (kNN) algorithm on the Pima Indians Diabetes dataset. After loading the dataset and splitting it into training and testing sets, a kNN classifier is trained and tested for different values of k (number of neighbors). To find the optimal value of k, the API call is used for hyperparameter tuning through GridSearchCV. It performs a search over a range of k values using 5-fold cross-validation. After fitting the model, the best score and optimal value of k are determined, which can be used to create a kNN classifier with improved accuracy."}}], "source": "kaggle"}, {"id": "dataraj-learning-plotly-while-analysing-happiness-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "lightgbm-lgbmmodel"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 5000}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet explores the factors that impact happiness scores of different countries and regions. The dataset is visualized through various scatter plots to understand the relationship between happiness scores and other variables, such as GDP per capita, life expectancy, and freedom of choice. The API is called to fit a LightGBM regression model using the selected independent variables to predict happiness scores. The number of estimators is set to 5000. After fitting the model, Permutation Importance is used to determine the importance of each independent variable in predicting happiness scores, providing insight into which factors have the highest and lowest impact on happiness."}}], "source": "kaggle"}, {"id": "mohaiminul101-hvvgatmcqrece-ptedqctgon-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-train-test-split"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"[0]": "dataframe(shape=(18249, 13))", "[1]": "series(shape=(18249,))", "train_size": 0.7000000000000001, "test_size": 0.30000000000000004, "random_state": 0}}}, {"role": "solutionSummary", "module": {"summary": "The goal is to predict avocado prices using a dataset containing various features. The dataset is loaded and the target variable (average price) is separated from the rest of the data. The API call is then used to split the dataset into training and testing sets with a 70-30 ratio. After the split, categorical columns are transformed using One Hot Encoding, and numerical features are scaled using MinMaxScaler. Finally, two machine learning models, Random Forest Regressor and Linear Regression, are trained and their performance is evaluated using mean absolute percentage error."}}], "source": "kaggle"}, {"id": "mohaiminul101-hvvgatmcqrece-ptedqctgon-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-onehotencoder"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"handle_unknown": "ignore", "sparse": "False"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict average avocado prices using a dataset of various related features. The dataset is loaded, and the target variable (average price) is separated from the other features. The dataset is then split into training and testing sets. The API call is used to handle categorical columns by creating a one-hot encoded representation of the data. The transformed data replaces the original categorical columns in the dataset, and the numerical values are scaled using MinMaxScaler. Finally, two regression models, RandomForestRegressor and LinearRegression, are fitted on the training data, and their performance is evaluated on the test data using Mean Absolute Percentage Error."}}], "source": "kaggle"}, {"id": "mohaiminul101-hvvgatmcqrece-ptedqctgon-003", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-minmaxscaler"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 100, "random_state": 0, "verbose": 1}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict avocado prices using two different models: RandomForestRegressor and LinearRegression. After loading the dataset, preprocessing steps are taken, including train-test split, one-hot encoding for categorical columns, and scaling the values using MinMaxScaler. The API is called to create a RandomForestRegressor model with specified parameters. The model is fitted with the training data, and predictions are made using the test data. The accuracy is then measured using a custom function to calculate the Mean Absolute Percentage Error. The same process is repeated for LinearRegression to compare the performance of the two models."}}], "source": "kaggle"}, {"id": "zdeutsch-axocados-predictions-with-ml-models-keras-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-labelencoder"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict avocado prices using various machine learning models and a neural network. The dataset is first loaded, preprocessed, and visualizations are created. The API is called to encode categorical variables in the dataset, transforming them to numerical format suitable for machine learning algorithms. After encoding, the data is standardized and split into training and testing sets. Multiple machine learning models, including logistic regression, KNN, SVM, and decision tree, are trained and evaluated. Finally, a Keras neural network is implemented and its performance is compared with the other models."}}], "source": "kaggle"}, {"id": "zdeutsch-axocados-predictions-with-ml-models-keras-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-labelencoder"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict avocado prices using machine learning models and deep learning with a Keras ANN. After preprocessing the data, the API is called to standardize the features by removing the mean and scaling to unit variance. This is done to ensure that the features are on the same scale, which is essential for machine learning models that are sensitive to feature scaling. The standardized features are then used to train several machine learning models, including KNN, logistic regression, SVM, decision tree, and a Keras ANN. The performance of these models is compared using confusion matrices and joint plots."}}], "source": "kaggle"}, {"id": "zdeutsch-axocados-predictions-with-ml-models-keras-003", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-train-test-split"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"[0]": "array(shape=(18249, 11))", "[1]": "array(shape=(18249,))", "test_size": 0.2, "random_state": 0}}}, {"role": "solutionSummary", "module": {"summary": "The task is to predict avocado prices using machine learning models. The dataset is loaded and preprocessed, which includes dropping unnecessary columns, encoding categorical variables, and standardizing the remaining features. The API call is used to split the dataset into training and testing sets. Afterwards, multiple classifiers like Logistic Regression, KNN, SVM, and Decision Tree are trained and their predictions are evaluated using joint plots. Additionally, a Keras neural network model is trained and its performance is visualized."}}], "source": "kaggle"}, {"id": "zdeutsch-axocados-predictions-with-ml-models-keras-004", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-standardscaler"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet focuses on analyzing avocado prices using various machine learning models and visualizations. After preprocessing the data, which includes dropping irrelevant columns and encoding categorical variables, the dataset is split into training and testing sets. The API call is used to encode the target variable, 'AveragePrice,' into integer values for both training and test sets to make it compatible with classifiers. Then, multiple machine learning models, including logistic regression, K-Nearest Neighbors (KNN), Support Vector Machines (SVM), and Decision Trees, are implemented to predict avocado prices, followed by a Keras neural network model. The performance of these models is evaluated using joint plots of actual and predicted values."}}], "source": "kaggle"}, {"id": "zdeutsch-axocados-predictions-with-ml-models-keras-005", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-linear-model-logisticregression"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "LogisticRegression()", "n_jobs": 1}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet analyzes avocado prices using machine learning models. After data preprocessing and standardization, the API is called to create an instance of the OneVsRestClassifier, which is a strategy for handling multi-class classification problems. The estimator used is LogisticRegression, and the classifier is fitted on the training dataset. Following this, K-Nearest Neighbors, Support Vector Machines, and Decision Tree classifiers are also fitted with the same strategy, and their predictions are compared using confusion matrices and joint plots. Finally, a Keras neural network model is implemented as an alternative approach for the classification task."}}], "source": "kaggle"}, {"id": "zdeutsch-axocados-predictions-with-ml-models-keras-006", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-neighbors-kneighborsclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_neighbors": 1}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict the average price of avocados using a dataset containing various features. After preprocessing, visualizations are created to explore correlations between features, and the dataset is split into training and testing sets. The API is used to create a K-Nearest Neighbors (KNN) classifier with n_neighbors set to 1. The model is then trained and predictions are made on the test set. Additional models like Logistic Regression, SVM, and Decision Tree are also trained, and their results are compared using confusion matrices. The KNN model's performance is further analyzed by tuning the k value."}}], "source": "kaggle"}, {"id": "zdeutsch-axocados-predictions-with-ml-models-keras-007", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-multiclass-onevsrestclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "KNeighborsClassifier(n_neighbors=1)", "n_jobs": 1}}}, {"role": "solutionSummary", "module": {"summary": "This code snippet is focused on predicting avocado prices using multiple machine learning models, including logistic regression, k-nearest neighbors (KNN), support vector machines (SVM), and decision trees. After loading and preprocessing the dataset, the API is called to use the OneVsRestClassifier with KNN as the base estimator. This classifier is chosen to handle the multi-class classification problem by fitting one classifier per class. The API is subsequently called for other algorithms as well, and the performance of each model is visually compared using joint plots. The code also explores the optimal value for the k parameter in KNN and implements a neural network using Keras."}}], "source": "kaggle"}, {"id": "zdeutsch-axocados-predictions-with-ml-models-keras-008", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-svm-svc"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "SVC()", "n_jobs": 1}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is an analysis of avocado prices. After data preprocessing, encoding categorical variables, and scaling features, various machine learning models are implemented to predict the average price, including logistic regression, K-nearest neighbors, and support vector machines (SVM). The API call employs the OneVsRestClassifier to handle multiclass problems for the SVM model. After fitting the models, including the SVM model created using the API, predictions are made, and the performance of each model is assessed visually through joint plots. The K-nearest neighbors model is further tuned for optimal performance."}}], "source": "kaggle"}, {"id": "zdeutsch-axocados-predictions-with-ml-models-keras-009", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-tree-decisiontreeclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "DecisionTreeClassifier()", "n_jobs": 1}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict avocado prices using various machine learning models. After pre-processing the dataset, categorical variables are encoded, and the data is standardized and split into training and testing sets. The API is called to construct a DecisionTreeClassifier in a OneVsRest setting. The process is repeated for other classifiers, such as Logistic Regression, K-Nearest Neighbors, and Support Vector Machines. After fitting the models to the training data, predictions are made on the test set, and the performance of each model is visualized through joint plots. The best performing model is then identified and used for further analysis."}}], "source": "kaggle"}, {"id": "zdeutsch-axocados-predictions-with-ml-models-keras-010", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-neighbors-kneighborsclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_neighbors": 20}}}, {"role": "solutionSummary", "module": {"summary": "This code snippet is focused on predicting the average price of avocados using machine learning models, including K-Nearest Neighbors (KNN). The dataset is preprocessed, encoded, and standardized before being split into training and testing sets. The API is called within a loop to find the optimal value of 'k' (number of neighbors) for the KNN model. The error rates for different 'k' values are plotted to visualize the best choice. Once the optimal 'k' value is identified (k=3), the KNN model is trained and tested, and the results are visualized using a joint plot."}}], "source": "kaggle"}, {"id": "zdeutsch-axocados-predictions-with-ml-models-keras-011", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-neighbors-kneighborsclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_neighbors": 3}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet analyzes the avocado prices dataset, focusing on visualizations and implementing machine learning models. After preprocessing and encoding categorical variables, the data is split into training and testing sets. The API is called to create a K-Nearest Neighbors (KNN) model with 3 neighbors. The model is then trained using the training data and predictions are made on the test data. Various visualizations are generated, and the KNN model's performance is compared to other models such as Logistic Regression, SVM, and Decision Trees. The optimal value of K is determined by minimizing the error rate."}}], "source": "kaggle"}, {"id": "zdeutsch-axocados-predictions-with-ml-models-keras-012", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-multiclass-onevsrestclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "KNeighborsClassifier(n_neighbors=3)", "n_jobs": 1}}}, {"role": "solutionSummary", "module": {"summary": "In the code snippet, the goal is to predict avocado prices using various machine learning models. After preprocessing the data and encoding categorical variables, the dataset is split into training and testing sets. The API call is used to create a one-vs-rest classifier using K-Nearest Neighbors algorithm with 3 neighbors, and the model is trained on the training set. The model's performance is evaluated by visualizing the joint plot of predicted values and actual values. Additionally, other models such as logistic regression, SVC, and decision tree are also used for comparison, and a neural network is implemented using Keras."}}], "source": "kaggle"}, {"id": "edgarbc-playgrgund-s3e4-lgbm-baseline-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-stratifiedkfold"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_splits": 10, "shuffle": "True", "random_state": 555}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict fraudulent transactions using the LightGBM model. The dataset is combined with the original training set and preprocessed. The Optuna library is used to perform hyperparameter optimization. After that, time features are engineered and added to the dataset. The API call creates a StratifiedKFold cross-validator with 10 splits, which ensures that each fold maintains the same proportion of the target class as the complete dataset. The cross-validation loop trains the LightGBM model on each split, evaluates the ROC AUC score, and predicts the test set's target values. Finally, the test set predictions are averaged, and a submission file is created."}}], "source": "kaggle"}, {"id": "edgarbc-playgrgund-s3e4-lgbm-baseline-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "lightgbm-lgbmmodel"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"objective": "binary", "metric": "auc", "scale_pos_weight": 1, "lambda_l1": 0.0307402598809, "lambda_l2": 13.546583557430239, "num_leaves": 44, "feature_fraction": 0.814366931574891, "bagging_fraction": 0.5961770170888631, "bagging_freq": 4, "min_child_samples": 81, "min_data_in_leaf": 142, "max_depth": 11, "num_iterations": 300, "learning_rate": 0.1}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to detect credit card fraud using LightGBM classifier. After loading and preprocessing the data, including feature engineering, the dataset is split into training and testing sets using stratified K-Fold cross-validation. Optuna is utilized for hyperparameter tuning, and the best parameters are then used to create a LightGBM model. The model is fitted, and its performance is evaluated using ROC AUC score. Finally, predictions are made on the test dataset and an ensemble of test predictions is generated, which is then used to create a submission file."}}], "source": "kaggle"}, {"id": "kdmitrie-pgs34-basic-thst-of-models-blending-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-standardscaler"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {}}}, {"role": "solutionSummary", "module": {"summary": "The goal of this code snippet is to detect fraud using various machine learning models. The dataset is first loaded, and then a function is defined to preprocess the data by standardizing the features using the StandardScaler. This is important to ensure that all features have the same scale, which can improve the performance of certain machine learning models. After defining this function, it is called to preprocess the data for both the train and test sets. The preprocessed data is then split into training and validation sets, and various machine learning models are evaluated, with their predictions combined in a final submission file."}}], "source": "kaggle"}, {"id": "kdmitrie-pgs34-basic-thst-of-models-blending-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-train-test-split"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"[0]": "array(shape=(503936, 39))", "[1]": "array(shape=(503936,))", "test_size": 0.2, "random_state": 2}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to build a model to predict credit card fraud. After pre-processing and preparing the data, the API call is used to split the dataset into training and validation sets. Following the split, various machine learning models such as linear models, XGBoost, CatBoost, RandomForest, and LightGBM are trained and evaluated using cross-validation. The models are then blended, and their performance is measured. Finally, the predictions are made on the test set, and multiple submission files are created for different model combinations."}}], "source": "kaggle"}, {"id": "kdmitrie-pgs34-basic-thst-of-models-blending-003", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-stratifiedkfold"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_splits": 5, "shuffle": "True", "random_state": 0}}}, {"role": "solutionSummary", "module": {"summary": "The code aims to build a binary classification model for a given dataset using various machine learning algorithms. The dataset is preprocessed, features are engineered, and then it is split into training and test sets. The API call is used to create a StratifiedKFold cross-validator, which ensures that the proportion of target class labels in each fold is approximately the same as in the entire dataset. This is particularly useful when dealing with imbalanced datasets. After the cross-validator is created, various classifiers, such as Logistic Regression, XGBoost, CatBoost, RandomForest, and LightGBM, are trained using the cross-validator. The performance of each classifier is evaluated and ultimately, an ensemble prediction is made using the best-performing classifiers. The final prediction is then saved to a CSV file for submission."}}], "source": "kaggle"}, {"id": "kdmitrie-pgs34-basic-thst-of-models-blending-004", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-linear-model-lasso"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"alpha": 1e-05}}}, {"role": "solutionSummary", "module": {"summary": "In this notebook, the goal is to predict credit card fraud using a combination of datasets and different models. After loading and preparing the data, the Lasso regression model is applied, which is a linear model that includes an L1 regularization term to help prevent overfitting. The model is then examined using a helper function examine_clf_print, which fits the model and prints the average cross-validation score using the given splitter (StratifiedKFold). The output of this API call is a list of trained Lasso models that are later used for ensembling and making predictions on the test data. The notebook continues to test other models and analyze their performance to create a blended solution."}}], "source": "kaggle"}, {"id": "kdmitrie-pgs34-basic-thst-of-models-blending-005", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-linear-model-ridge"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"alpha": 1}}}, {"role": "solutionSummary", "module": {"summary": "The goal is to create a model for predicting credit card fraud using a combination of datasets and multiple classifiers. The dataset is preprocessed, and the prepared data is split into training and testing sets. The API call is used to create a Ridge classifier with a specific alpha parameter. The Ridge classifier is then evaluated using a helper function, examine_clf_print, along with other classifiers such as Lasso and Logistic Regression. The performance of all classifiers is analyzed, blended, and the final prediction is made using an ensemble of the best-performing classifiers. The results are then submitted in various CSV files."}}], "source": "kaggle"}, {"id": "kdmitrie-pgs34-basic-thst-of-models-blending-006", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-linear-model-logisticregression"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"max_iter": 1000, "C": 1.6}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to solve a binary classification problem using various machine learning models. A series of data preprocessing steps are performed, including feature engineering, data concatenation, and handling missing values. The API call is used to create a logistic regression model with specific parameters, which is then examined using a custom function that trains and validates the model using cross-validation. The performance of this logistic regression model is compared with several other models, such as linear regression, random forest, and gradient boosting, in order to select the best performing model for making predictions on the test dataset."}}], "source": "kaggle"}, {"id": "kdmitrie-pgs34-basic-thst-of-models-blending-007", "modules": [{"role": "algorithm", "purpose": "API", "module": "xgboost-xgbclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 90, "max_depth": 2, "tree_method": "hist"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is focused on detecting fraudulent activities in credit card transactions. The dataset is combined from generated data and the external original dataset. After preprocessing, the data is split into training and validation sets. The API call is utilized to create an XGBoost classifier with specific parameters. The classifier is then trained and its performance is evaluated using cross-validation. Various other models (such as linear models, random forests, and LightGBM) are also tested and their performance is compared. Finally, predictions are made and submitted for evaluation."}}], "source": "kaggle"}, {"id": "kdmitrie-pgs34-basic-thst-of-models-blending-008", "modules": [{"role": "algorithm", "purpose": "API", "module": "catboost-catboostregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"iterations": 200, "depth": 2, "learning_rate": 0.1, "loss_function": "RMSE"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is designed to predict and submit results for a binary classification problem using a variety of machine learning models. The CatBoostRegressor, with specified parameters, is one of the models being tested. After setting up the necessary data and splitting it into training/validation sets, the API is called to initialize the CatBoostRegressor model. Subsequently, the model is trained and examined using cross-validation, and its performance is evaluated. Finally, predictions from multiple models are combined, and the resulting ensemble predictions are submitted as the final output."}}], "source": "kaggle"}, {"id": "kdmitrie-pgs34-basic-thst-of-models-blending-009", "modules": [{"role": "algorithm", "purpose": "API", "module": "catboost-catboostclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"iterations": 1000, "depth": 2, "learning_rate": 0.15, "loss_function": "Logloss"}}}, {"role": "solutionSummary", "module": {"summary": "This code snippet aims to detect fraudulent transactions by blending multiple models, including CatBoostClassifier. After merging and preprocessing the data, the dataset is split into training and testing sets. Then, a series of different models, including linear models, XGBoost, RandomForest, LightGBM, and CatBoost, are trained and their performance is evaluated. The API call creates a CatBoostClassifier instance with specific parameters and trains it on the training data. The performance of the individual models, as well as the blended model, is evaluated using ROC AUC score. Finally, predictions from the models are combined and used for submission."}}], "source": "kaggle"}, {"id": "kdmitrie-pgs34-basic-thst-of-models-blending-010", "modules": [{"role": "algorithm", "purpose": "API", "module": "lightgbm-lgbmmodel"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 1000, "max_depth": 2, "learning_rate": 0.01, "num_leaves": 10, "lambda_l1": 3, "lambda_l2": 3, "bagging_fraction": 0.8, "feature_fraction": 0.8}}}, {"role": "solutionSummary", "module": {"summary": "In this code snippet, the aim is to create a model for identifying credit card fraud using various machine learning models and blending their results to improve the performance. The data is initially prepared, and several models, such as Lasso, Ridge, XGBoost, CatBoost, RandomForest, and LightGBM, are trained on the dataset. The API call creates an instance of the LightGBM model with specific parameters. The model is then trained and validated using k-fold cross-validation. The predictions from all the models are then combined, and their performance is evaluated. Finally, a submission file is generated containing the blended predictions for a test dataset."}}], "source": "kaggle"}, {"id": "kdmitrie-pgs34-basic-thst-of-models-blending-011", "modules": [{"role": "algorithm", "purpose": "API", "module": "lightgbm-lgbmmodel"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 1000, "max_depth": 2, "learning_rate": 0.01, "num_leaves": 10, "lambda_l1": 3, "lambda_l2": 3, "bagging_fraction": 0.8, "feature_fraction": 0.8}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to detect credit card fraud by training various models and blending their predictions. The dataset consists of train, test, and external data, which is preprocessed and combined. Multiple models are tested, including linear models, Random Forest, XGBoost, CatBoost, LightGBM, and Neural Networks. The API call is made to create an LGBMClassifier model with specific hyperparameters. The model is then trained and evaluated using cross-validation. After identifying the performance of each model, the predictions of the best models are blended to create the final predictions, which are used for submission."}}], "source": "kaggle"}, {"id": "kdmitrie-pgs34-basic-thst-of-models-blending-012", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-standardscaler"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_splits": 5, "shuffle": "True", "random_state": 0}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to create a binary classification model for a fraud detection problem using a combination of different models. The dataset is concatenated with an external dataset to improve the model's performance. Before the API call, the data is preprocessed, and new features are created. The API call is used to create a stratified k-fold cross-validation object, which helps maintain the same class distribution in each fold as in the whole dataset. After the API call, various models such as logistic regression, XGBoost, CatBoost, Random Forest, and LightGBM are trained and evaluated using this cross-validation strategy. Finally, the predictions of these models are combined and submitted."}}], "source": "kaggle"}, {"id": "kdmitrie-pgs34-basic-thst-of-models-blending-013", "modules": [{"role": "algorithm", "purpose": "API", "module": "xgboost-xgbclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 90, "max_depth": 2, "tree_method": "hist"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to detect fraud in a dataset using an ensemble of machine learning models. Adversarial validation is employed to check whether the train and test datasets are similar. An XGBoost classifier is created with specific parameters and is used to predict the test data. The classifier is trained and validated using cross-validation to obtain the model's performance. The context surrounding the API call includes loading and preprocessing the data, splitting it into training and testing sets, examining different models for performance, and ultimately blending all well-performing models to make predictions and generate the submission files."}}], "source": "kaggle"}, {"id": "kdmitrie-pgs34-basic-thst-of-models-blending-014", "modules": [{"role": "algorithm", "purpose": "API", "module": "catboost-catboostclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"iterations": 1000, "depth": 2, "learning_rate": 0.15, "loss_function": "Logloss"}}}, {"role": "solutionSummary", "module": {"summary": "In this code snippet, the goal is to build a model to predict fraud using various machine learning algorithms. After loading, preprocessing, and feature engineering, the CatBoostClassifier is used to build a model. The specified parameters are set to optimize the model performance, and the dataset is then split into training and validation sets. Multiple models are tested, including linear models, XGBoost, RandomForest, and LightGBM. The models are blended, and their combined predictions are evaluated to ensure a robust model. Finally, the predictions are submitted."}}], "source": "kaggle"}, {"id": "kdmitrie-pgs34-basic-thst-of-models-blending-015", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-standardscaler"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to build and evaluate various machine learning models for a fraud detection problem using a combination of training, test, and external datasets. The API is used to standardize the features in the dataset for better model performance. Prior to the API call, the data is loaded, preprocessed, and prepared for model training. After the standardization, various models such as Lasso, Ridge, Logistic Regression, XGBoost, CatBoost, RandomForest, and LightGBM are trained and tested using cross-validation. Finally, the best models are blended, and their predictions are used for submission."}}], "source": "kaggle"}, {"id": "kdmitrie-pgs34-basic-thst-of-models-blending-016", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-train-test-split"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"[0]": "array(shape=(211355, 37))", "[1]": "array(shape=(211355,))", "test_size": 0.2, "random_state": 10}}}, {"role": "solutionSummary", "module": {"summary": "In this code snippet, the aim is to build a machine learning model to predict fraud in a dataset containing both synthetic and real-world data. After preparing and processing the data, including adversarial validation, the API call is used to split the dataset into training and validation sets. The train-validation split is crucial to help estimate the model's performance on unseen data and prevent overfitting. Following this, various classification models such as logistic regression, XGBoost, CatBoost, RandomForest, and LightGBM are trained and evaluated using cross-validation. The models are then combined using an ensemble approach and their performance is assessed on the validation set. Finally, predictions are made on the test set and saved to a submission file."}}], "source": "kaggle"}, {"id": "kdmitrie-pgs34-basic-thst-of-models-blending-017", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-stratifiedkfold"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_splits": 5, "shuffle": "True", "random_state": 0}}}, {"role": "solutionSummary", "module": {"summary": "In this code snippet, the goal is to create a model that predicts whether a transaction is fraudulent or not. The API call is used to create a StratifiedKFold cross-validation object that will be utilized for validating various machine learning models on the dataset. StratifiedKFold is chosen to ensure that each fold maintains the same class distribution as the original dataset, which is essential in a highly imbalanced dataset, such as fraudulent transactions. Before the API call, the data is prepared, concatenated, and new features are created. After the API call, several machine learning models, such as Logistic Regression, XGBoost, CatBoost, RandomForest, and LightGBM, are trained and evaluated using the StratifiedKFold cross-validation scheme. The models' results are blended, and a submission file is created for each model and their combination."}}], "source": "kaggle"}, {"id": "kdmitrie-pgs34-basic-thst-of-models-blending-018", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-linear-model-lasso"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"alpha": 1e-05}}}, {"role": "solutionSummary", "module": {"summary": "The goal is to build a fraud detection model based on different datasets and various machine learning algorithms. After consolidating datasets and preprocessing the data, the code snippet focuses on evaluating several models. The API call is used to fit a Lasso model on training data for the purpose of regularization and feature selection. The model is then examined using the custom `examine_clf_print` function, which trains the model using cross-validation, prints the model's information, and calculates the average ROC AUC score. This Lasso model is part of several other models tested, including Ridge, Logistic Regression, XGBoost, CatBoost, RandomForest, and LightGBM, which are later combined to form an ensemble model for making predictions."}}], "source": "kaggle"}, {"id": "kdmitrie-pgs34-basic-thst-of-models-blending-019", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-linear-model-ridge"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"alpha": 1}}}, {"role": "solutionSummary", "module": {"summary": "The task involves detecting fraudulent transactions from a combination of datasets. After preprocessing the data and creating new features, several models are tested for their performance. The API call initializes a Ridge regression model with a regularization parameter alpha set to 1. The model is then used within the custom `examine_clf_print` function to train, validate, and print performance metrics. This process is carried out for various other models as well, and the best-performing models are blended together to make the final prediction."}}], "source": "kaggle"}, {"id": "kdmitrie-pgs34-basic-thst-of-models-blending-020", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-linear-model-logisticregression"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"max_iter": 1000, "C": 1.6}}}, {"role": "solutionSummary", "module": {"summary": "In this code snippet, the goal is to predict credit card fraud using various machine learning models. The dataset is combined from multiple sources, including the original dataset and additional data from Kaggle competitions. The API call is used to train a logistic regression model on the processed training data, with a specified maximum number of iterations and regularization parameter C. The trained model is then evaluated using cross-validation, and the results are printed. The logistic regression model is one of the models used in the ensemble, along with other models like Ridge regression, XGBoost, CatBoost, RandomForest, and LightGBM. The final predictions are obtained by blending the predictions from all the models in the ensemble."}}], "source": "kaggle"}, {"id": "kdmitrie-pgs34-basic-thst-of-models-blending-021", "modules": [{"role": "algorithm", "purpose": "API", "module": "xgboost-xgbclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 40, "max_depth": 2, "tree_method": "hist"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to detect fraud in a credit card dataset, using various machine learning models. Before the API call, the data is processed, including concatenation of different datasets, feature engineering, and data splitting. The API is called to create an XGBoost classifier with specific parameters. The model is then trained and evaluated using cross-validation, and results are printed. Finally, multiple models are blended to make predictions on the test set, and the submission file is generated."}}], "source": "kaggle"}, {"id": "kdmitrie-pgs34-basic-thst-of-models-blending-022", "modules": [{"role": "algorithm", "purpose": "API", "module": "catboost-catboostclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"iterations": 220, "depth": 2, "learning_rate": 1.0, "loss_function": "Logloss"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict if a given transaction is fraudulent or not, using the CatBoostClassifier. The data is preprocessed, combined, and features are engineered. After splitting the data into training and validation sets, multiple models are tested, including linear models, XGBoost, RandomForest, and LightGBM. The API is called to create a CatBoostClassifier with specific parameters. The model is then fitted on the training data, and its performance is evaluated using cross-validation. Finally, the predictions from different classifiers are blended, and a submission file is created for submission in a competition."}}], "source": "kaggle"}, {"id": "kdmitrie-pgs34-basic-thst-of-models-blending-023", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-ensemble-randomforestclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 150, "max_depth": 2, "n_jobs": -1, "random_state": 0}}}, {"role": "solutionSummary", "module": {"summary": "The goal is to create a machine learning model to predict the target variable using a combination of datasets. The data is preprocessed, feature engineering is performed, and new features are added. The API call fits a RandomForestClassifier to the training data using cross-validation. The classifier is then examined to check its performance and combined with other classifiers to create an ensemble model. The ensemble model's performance is evaluated, and finally, predictions are made on the test dataset for submission."}}], "source": "kaggle"}, {"id": "kdmitrie-pgs34-basic-thst-of-models-blending-024", "modules": [{"role": "algorithm", "purpose": "API", "module": "lightgbm-lgbmmodel"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 1000, "max_depth": 2, "learning_rate": 0.1, "num_leaves": 10, "lambda_l1": 3, "lambda_l2": 2, "bagging_fraction": 0.8, "feature_fraction": 0.8}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to participate in a Kaggle competition by predicting the target variable using various machine learning models. After preprocessing the data, splitting it into training and testing sets, and performing feature engineering, the LightGBM Classifier is instantiated with specific parameters. The classifier is then fit and evaluated using cross-validation. Multiple classifiers, including logistic regression, XGBoost, and LightGBM models, are combined in an ensemble and the final predictions are obtained. The submission files are then created for each individual model and the ensemble model."}}], "source": "kaggle"}, {"id": "satoshiss-frauk-predictions-s3e4-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-stratifiedkfold"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_splits": 10, "random_state": 10, "shuffle": "True"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict credit card fraud using an imbalanced dataset. An additional dataset, 'original', is used to supplement the competition dataset, and features are extracted from the transaction data. The API call creates a StratifiedKFold cross-validator to split the dataset into 10 folds, which helps to maintain the same class distribution in each fold as in the full dataset. This is crucial for imbalanced datasets to avoid overfitting. The dataset is then used to train and validate multiple machine learning models, including XGBoost, CatBoost, and LightGBM. The predictions from the best models are combined to create the final submission file."}}], "source": "kaggle"}, {"id": "satoshiss-frauk-predictions-s3e4-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "xgboost-xgbclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 10000, "max_depth": 5, "eval_metric": "auc", "early_stopping_rounds": 100, "random_state": 55, "tree_method": "gpu_hist"}}}, {"role": "solutionSummary", "module": {"summary": "The goal of the code snippet is to predict fraudulent credit card transactions using various classification models on an imbalanced dataset. After loading, preprocessing, and feature engineering, the data is split into training and testing sets using stratified k-fold cross-validation. The API call creates an XGBoost classifier with specified parameters, which is then trained on each fold of the cross-validation. The performance of the model is evaluated using the ROC AUC score, and the importance of the features is also analyzed. Additionally, predictions are made on the test data, and the process is repeated for CatBoost and LightGBM classifiers. The results are compared and combined to create an ensemble model for the final submission."}}], "source": "kaggle"}, {"id": "satoshiss-frauk-predictions-s3e4-003", "modules": [{"role": "algorithm", "purpose": "API", "module": "catboost-catboostclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"objective": "Logloss", "n_estimators": 10000, "max_depth": 5, "eval_metric": "AUC", "early_stopping_rounds": 100, "random_state": 55}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet focuses on predicting credit card fraud using both the competition dataset and the original dataset, with the goal of improving the model's performance. To achieve this, various features such as hour of the day and transaction amount are extracted from the data. After creating the training and test sets, the API call is made to create a CatBoostClassifier model with specified parameters. This model is trained on the combined dataset in a 5-fold cross-validation setup, and its performance is evaluated using Area Under the Curve (AUC) score. Finally, the trained model is used to make predictions on the test dataset, and the results are combined with other models' predictions for final submission."}}], "source": "kaggle"}, {"id": "satoshiss-frauk-predictions-s3e4-004", "modules": [{"role": "algorithm", "purpose": "API", "module": "lightgbm-lgbmmodel"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"objective": "binary", "n_estimators": 10000, "max_depth": 5, "metric": "auc", "random_state": 55, "device": "GPU", "verbose": -1}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is focused on classifying anonymized credit card transactions as fraudulent or genuine. The dataset is combined with original transaction data to improve the model's performance. Several models, including XGBoost, CatBoost, and LightGBM, are trained and evaluated using stratified K-fold cross-validation. For the LightGBM model, the API is called with specific parameters to classify binary targets, using AUC as the evaluation metric, and setting the device to GPU for faster training. The performance of the models is compared, and the final submission is created using an ensemble of the XGBoost and CatBoost models."}}], "source": "kaggle"}, {"id": "satoshiss-frauk-predictions-s3e4-005", "modules": [{"role": "algorithm", "purpose": "API", "module": "catboost-catboostclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"objective": "Logloss", "n_estimators": 10000, "max_depth": 5, "eval_metric": "AUC", "early_stopping_rounds": 100, "random_state": 55}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet focuses on analyzing credit card transactions to detect fraudulent activities using machine learning algorithms. The dataset is enhanced by concatenating with the original dataset and adding relevant features. Different classifiers, including XGBoost, CatBoost, and LightGBM, are used to predict the probability of a transaction being fraudulent. In the given API call, a CatBoost classifier is created with specified parameters and is trained on the data in a cross-validation loop. The classifier's performance is evaluated using the ROC-AUC score, and the model's predictions are combined with those of other classifiers for the final submission. The code also includes visualizations to understand the predictions and feature importances."}}], "source": "kaggle"}, {"id": "satoshiss-frauk-predictions-s3e4-006", "modules": [{"role": "algorithm", "purpose": "API", "module": "xgboost-xgbclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 10000, "max_depth": 5, "eval_metric": "auc", "early_stopping_rounds": 100, "random_state": 55, "tree_method": "gpu_hist"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict credit card fraud using various features from the dataset, which is a combination of competition data and original data. After preprocessing and feature engineering, the API is called to create an XGBoost classifier with specified parameters. The model is then trained using stratified k-fold cross-validation. In each fold, the model is fitted on the training data and evaluated on the test data. The performance of the model is assessed using the ROC AUC score. Additionally, other models like CatBoost and LightGBM are trained, and their predictions are combined to improve the overall model performance."}}], "source": "kaggle"}, {"id": "belgrader-covid-19-week-4-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-labelencoder"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to forecast the number of COVID-19 confirmed cases and fatalities using various datasets, including temperature data and country-level statistics. After preprocessing and merging the datasets, LabelEncoder is applied to transform the 'Country_Region' column into numerical values. The API is called to create a MinMaxScaler object, which is then used to scale the training and testing data, ensuring that all features are within a similar range. Subsequently, the XGBoost Regressor model is trained and used to make predictions for confirmed cases and fatalities. The results are then rounded off, negative values are set to zero, and the final predictions are saved in a submission file."}}], "source": "kaggle"}, {"id": "belgrader-covid-19-week-4-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "xgboost-xgbregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 1500, "max_depth": 15, "learning_rate": 0.1}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is focused on predicting the spread of COVID-19 using various datasets. After preprocessing the data, including handling missing values, encoding categorical variables, and normalizing the features, the XGBoost Regressor API is called to create a model with specific parameters. The model is then fit on training data for both confirmed cases and fatalities. After fitting the models, predictions are made on the testing data, and negative predictions are rounded off to zero. Finally, the predictions are added to the submission dataset, which is then saved as a CSV file for submission."}}], "source": "kaggle"}, {"id": "belgrader-covid-19-week-4-003", "modules": [{"role": "algorithm", "purpose": "API", "module": "xgboost-xgbregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 1500, "max_depth": 15, "learning_rate": 0.1}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to forecast COVID-19 confirmed cases and fatalities using the XGBoost Regressor model. Prior to the API call, the training and testing data are preprocessed, including filling missing values, splitting dates, label encoding, and scaling the feature values. The XGBoost Regressor is then instantiated with specific hyperparameters, such as n_estimators, max_depth, and learning_rate. The model is trained separately for confirmed cases and fatalities using the preprocessed training data and used to predict the corresponding values for the testing data. The predictions are then rounded off and any negative values are set to zero before adding them to the submission dataset."}}], "source": "kaggle"}, {"id": "kabure-tine-review-s-eda-recommend-systems-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-feature-extraction-text-tfidfvectorizer"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"ngram_range": "(2, 3)", "min_df": 5, "stop_words": "english", "max_df": 0.5}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is part of an exploratory analysis of a wine dataset, aiming to extract meaningful information about wine quality and characteristics based on sommelier reviews. The API call is used to apply the TF-IDF (Term Frequency-Inverse Document Frequency) vectorizer to the wine descriptions for the top 10 countries in the dataset, with the aim of identifying significant n-grams (combinations of words) that are specific to each country. The vectorizer is configured to consider 2-grams and 3-grams, with a minimum document frequency of 5, and a maximum document frequency of 0.5. This helps in identifying important and meaningful n-grams while filtering out common or unimportant ones. The resulting n-grams are then displayed in a series of bar plots for each country."}}], "source": "kaggle"}, {"id": "badugib-animal-crossing-recommender-cosine-similia-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-labelencoder"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {}}}, {"role": "solutionSummary", "module": {"summary": "This code snippet aims to create a recommender system for Animal Crossing: New Horizons players, predicting which items villagers are likely to want based on their current possessions. The data is cleaned and transformed, and LabelEncoder is used to convert the categorical customer and item names into numerical values. These values are then used to create a sparse matrix representing the villagers and their purchased items. Cosine similarity is applied to calculate the similarity between items, and the recommender system is built using collaborative filtering. Finally, the top 10 recommended items for each villager are displayed in a table."}}], "source": "kaggle"}, {"id": "paultimothymooney-most-common-words-in-the-cold-19-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-feature-extraction-text-countvectorizer"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"ngram_range": "(3, 3)", "analyzer": "word"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet analyzes the CORD-19 dataset, which consists of scholarly articles related to COVID-19. The goal is to explore the most common words in the titles of these papers. The API is called within a custom function to create a CountVectorizer with a specific n-gram range, focusing on 3-grams. The function processes the titles in the dataset, extracts the n-grams, calculates their frequencies, and returns a sorted DataFrame with the most common n-grams. Subsequently, the main script generates bar graphs, word clouds, and other visualizations to help explore the dataset further."}}], "source": "kaggle"}, {"id": "aestheteaman01-covtan-covid-19-timeseries-analysis-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-labelencoder"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {}}}, {"role": "solutionSummary", "module": {"summary": "The task is to analyze factors influencing the spread of COVID-19 and forecast confirmed cases and fatalities. After data preprocessing, which involves label encoding and dropping unnecessary columns, the API is called to create a MinMaxScaler object for scaling the training and testing datasets. This scaling helps in adjusting the feature values to a specific range, improving the performance of the machine learning model. Once the data is scaled, an XGBRegressor is applied to predict confirmed cases and fatalities, and the predictions are added to the final submission dataset."}}], "source": "kaggle"}, {"id": "aestheteaman01-covtan-covid-19-timeseries-analysis-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "xgboost-xgbregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 1500, "max_depth": 15, "learning_rate": 0.1}}}, {"role": "solutionSummary", "module": {"summary": "The goal is to forecast the COVID-19 confirmed cases and fatalities using a dataset that contains information about demographic factors, temperature, and other relevant features. The dataset is preprocessed, and non-essential columns are removed, while categorical columns are encoded using a LabelEncoder. The data is then scaled using MinMaxScaler. The API is called to create an XGBoost Regressor model with specific parameters. The model is fitted separately for confirmed cases and fatalities using the prepared training data. The predictions for confirmed cases and fatalities are made on the testing data, rounded off, and stored in the submission dataset."}}], "source": "kaggle"}, {"id": "aestheteaman01-covtan-covid-19-timeseries-analysis-003", "modules": [{"role": "algorithm", "purpose": "API", "module": "xgboost-xgbregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 1500, "max_depth": 15, "learning_rate": 0.1}}}, {"role": "solutionSummary", "module": {"summary": "The purpose of the code snippet is to analyze the spread of COVID-19 and build a time series model to predict confirmed cases and fatalities. After data preprocessing and exploration, the XGBRegressor from the XGBoost library is used to create two separate models for predicting confirmed cases and fatalities. The models are fitted with the scaled training dataset, and predictions are made on the testing dataset. These predictions are then rounded and negative values are set to zero. Finally, the predictions are added to the submission dataset and saved as a CSV file for submission."}}], "source": "kaggle"}, {"id": "nkitgupta-advance-data-preprocessing-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-impute-knnimputer"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_neighbors": 3}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is focused on preprocessing a dataset for machine learning. It covers various methods for handling missing values, encoding categorical attributes, and visualizing missing data. In the specific part where the API call is made, the KNNImputer is used to impute missing values in the dataset based on the k-nearest neighbors method. Prior to the API call, the dataset is loaded and prepared. After initializing the KNNImputer with 3 nearest neighbors, the imputer is fit on the dataset, and then used to transform the dataset, filling in the missing values based on their k-nearest neighbors. This imputed dataset can then be used for further analysis or modeling."}}], "source": "kaggle"}, {"id": "nkitgupta-advance-data-preprocessing-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-tree-decisiontreeregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet addresses data preprocessing techniques, specifically focusing on encoding categorical attributes. The dataset is loaded and various methods to handle missing values are explored. Then, the API call is used to create a LabelEncoder object for temporarily converting categorical variables into numerical representations before applying other encoding techniques. After the API call, the LabelEncoder object is employed to transform the categorical columns, and different encoding methods are demonstrated, such as likelihood encoding and target encoding."}}], "source": "kaggle"}, {"id": "nkitgupta-advance-data-preprocessing-003", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-tree-decisiontreeregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet explores advanced data preprocessing techniques, focusing on handling missing values and encoding categorical attributes. Prior to the API call, various encoding methods, such as likelihood encoding and target encoding, are implemented, and their results are displayed. The LabelEncoder API is then utilized to temporarily encode the categorical variables before applying a target encoding method. After the encoding, the dataset is modified accordingly, and the different encoding methods are compared and analyzed. The code aims to demonstrate the advantages and disadvantages of various encoding techniques and their impact on the resulting dataset."}}], "source": "kaggle"}, {"id": "nkitgupta-advance-data-preprocessing-004", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-linear-model-logisticregression"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {}}}, {"role": "solutionSummary", "module": {"summary": "In this code snippet, the focus is on encoding categorical attributes for a dataset. A temporary encoding of categorical variables is performed using the LabelEncoder from scikit-learn. This is done in order to explore supervised encoding methods, such as likelihood encoding and target encoding, to handle categorical variables in a more meaningful way. After encoding the categorical variables using the LabelEncoder, the dataset is further processed using the likelihood encoding and target encoding approaches, and the results are compared. Once the encoding is completed, the temporary encoding is reversed to obtain the original categorical variables."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-ensemble-randomforestclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"random_state": 2023}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to recognize fraudulent credit card transactions. After loading and preprocessing the data, including the creation of additional features, a range of classifiers and regressors are evaluated using the AUC (Area Under the ROC Curve) metric. The API call is performed to create a RandomForestClassifier model, which is then evaluated using the custom cross_val_auc function. Following the evaluation of multiple models, an ensemble of the best-performing models is created, and the final predictions are submitted."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-cross-val-predict"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "RandomForestClassifier(random_state=2023)", "X": "array(shape=(50961, 44))", "y": "series(shape=(50961,))", "cv": "[(array([    0,     1,     2, ..., 50957, 50958, 50960]), array([   18,    24,    28, ..., 50904, 509..., (array([    0,     1,     2, ..., 50956, 50958, 50959]), array([    3,    13,    15, ..., 50951, 509..., (array([    1,     3,     4, ..., 50958, 50959, 50960]), array([    0,     2,     8, ..., 50932, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    6,    10,    12, ..., 50942, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    9,    16,    22, ..., 50939, 509..., (array([    0,     1,     2, ..., 50957, 50959, 50960]), array([    7,    30,    44, ..., 50952, 509..., (array([    0,     2,     3, ..., 50958, 50959, 50960]), array([    1,    23,    36, ..., 50935, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    4,     5,    25, ..., 50938, 509...]", "n_jobs": -1, "method": "predict_proba", "verbose": "False"}}}, {"role": "solutionSummary", "module": {"summary": "The task is to detect fraudulent credit card transactions using various machine learning models. In the code snippet, the dataset is preprocessed, including feature engineering and scaling. The API call is used to perform cross-validated predictions for a RandomForestClassifier model. This is part of a series of tests for different classifiers and regressors to evaluate their performance in terms of AUC score, which are logged and visualized in a bar plot. The goal is to identify the best-performing models, which are then combined in an ensemble to make the final predictions on the test dataset."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-003", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-ensemble-extratreesclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"random_state": 2023}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to recognize fraudulent credit card transactions using various machine learning models. The dataset is preprocessed, visualized, and feature-engineered, and then the API is called to create an ExtraTreesClassifier model. The performance of this model, along with several other classifiers and regressors, is evaluated using cross-validation and ROC AUC scores. These models are then compared and combined in an ensemble to create a final submission of predicted probabilities for a Kaggle competition."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-004", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-cross-val-predict"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "ExtraTreesClassifier(random_state=2023)", "X": "array(shape=(50961, 44))", "y": "series(shape=(50961,))", "cv": "[(array([    0,     1,     2, ..., 50957, 50958, 50960]), array([   18,    24,    28, ..., 50904, 509..., (array([    0,     1,     2, ..., 50956, 50958, 50959]), array([    3,    13,    15, ..., 50951, 509..., (array([    1,     3,     4, ..., 50958, 50959, 50960]), array([    0,     2,     8, ..., 50932, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    6,    10,    12, ..., 50942, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    9,    16,    22, ..., 50939, 509..., (array([    0,     1,     2, ..., 50957, 50959, 50960]), array([    7,    30,    44, ..., 50952, 509..., (array([    0,     2,     3, ..., 50958, 50959, 50960]), array([    1,    23,    36, ..., 50935, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    4,     5,    25, ..., 50938, 509...]", "n_jobs": -1, "method": "predict_proba", "verbose": "False"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to recognize fraudulent credit card transactions using various machine learning models. After loading the dataset, conducting feature engineering, and preparing the data, the API is called to perform cross-validated predictions for each model using the training data. The area under the ROC curve (AUC) score is calculated, and the performance of each model is compared. The selected models are then used in an ensemble to make predictions on the test data, and the final predictions are saved for submission."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-005", "modules": [{"role": "algorithm", "purpose": "API", "module": "xgboost-xgbclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"random_state": 2023}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet's objective is to detect fraudulent credit card transactions. After loading the dataset, preprocessing steps, feature engineering, and data visualization are performed. The API call is made in the context of model testing, where multiple models are evaluated using cross-validation. The XGBClassifier, a gradient boosting model, is tested and its performance is measured based on the AUC score. Following this, feature importance and ensemble learning are conducted to improve the final predictions. The results are then saved in a submission file."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-006", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-cross-val-predict"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, c...", "X": "array(shape=(50961, 44))", "y": "series(shape=(50961,))", "cv": "[(array([    0,     1,     2, ..., 50957, 50958, 50960]), array([   18,    24,    28, ..., 50904, 509..., (array([    0,     1,     2, ..., 50956, 50958, 50959]), array([    3,    13,    15, ..., 50951, 509..., (array([    1,     3,     4, ..., 50958, 50959, 50960]), array([    0,     2,     8, ..., 50932, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    6,    10,    12, ..., 50942, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    9,    16,    22, ..., 50939, 509..., (array([    0,     1,     2, ..., 50957, 50959, 50960]), array([    7,    30,    44, ..., 50952, 509..., (array([    0,     2,     3, ..., 50958, 50959, 50960]), array([    1,    23,    36, ..., 50935, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    4,     5,    25, ..., 50938, 509...]", "n_jobs": -1, "method": "predict_proba", "verbose": "False"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is focused on detecting fraudulent credit card transactions by training and evaluating various machine learning models. After loading and preprocessing the data, several models are trained to compare their performance. The API is called to perform cross-validated predictions for the XGBClassifier model. The predictions are then used to compute the ROC AUC score, which is a performance metric for classification problems. This process is repeated for other models, and their scores are stored in a dictionary and visualized in a bar plot to compare their performance."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-007", "modules": [{"role": "algorithm", "purpose": "API", "module": "catboost-catboostclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"verbose": "False", "random_state": 2023}}}, {"role": "solutionSummary", "module": {"summary": "The purpose of this code snippet is to recognize fraudulent credit card transactions using various machine learning models. After loading the dataset and performing exploratory data analysis, the dataset is balanced and preprocessed. The API call is made to create a CatBoostClassifier model to be evaluated using a custom cross_val_auc function. The model is tested against other classifiers and regressors, and an ensemble approach is used to generate the final predictions. Finally, the predictions are saved to a CSV file for submission."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-008", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-cross-val-predict"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "<catboost.core.CatBoostClassifier object at 0x7c7496ef0d60>", "X": "array(shape=(50961, 44))", "y": "series(shape=(50961,))", "cv": "[(array([    0,     1,     2, ..., 50957, 50958, 50960]), array([   18,    24,    28, ..., 50904, 509..., (array([    0,     1,     2, ..., 50956, 50958, 50959]), array([    3,    13,    15, ..., 50951, 509..., (array([    1,     3,     4, ..., 50958, 50959, 50960]), array([    0,     2,     8, ..., 50932, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    6,    10,    12, ..., 50942, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    9,    16,    22, ..., 50939, 509..., (array([    0,     1,     2, ..., 50957, 50959, 50960]), array([    7,    30,    44, ..., 50952, 509..., (array([    0,     2,     3, ..., 50958, 50959, 50960]), array([    1,    23,    36, ..., 50935, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    4,     5,    25, ..., 50938, 509...]", "n_jobs": -1, "method": "predict_proba", "verbose": "False"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to recognize fraudulent credit card transactions. After performing exploratory data analysis, feature engineering, and data preprocessing, the API is called to evaluate the performance of various classification models using cross-validation. The function cross_val_auc is defined to calculate the AUC score using cross_val_predict, which generates out-of-fold predictions for each model. The models are iteratively tested, and their AUC scores are logged and visualized in a bar plot. The best-performing models are then combined in an ensemble to make final predictions."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-009", "modules": [{"role": "algorithm", "purpose": "API", "module": "lightgbm-lgbmmodel"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"random_state": 2023}}}, {"role": "solutionSummary", "module": {"summary": "The task is to recognize fraudulent credit card transactions using various machine learning models. After loading the dataset, performing feature engineering, and preparing the data, the API is called to create an LGBMClassifier model. This model is then tested using cross-validation, and its performance is compared with other models, such as logistic regression, decision trees, and ensemble methods like XGBoost and CatBoost. After evaluating the models, an ensemble of the best-performing models is created and used to make predictions on the test set, which are then combined and submitted."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-010", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-cross-val-predict"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "LGBMClassifier(random_state=2023)", "X": "array(shape=(50961, 44))", "y": "series(shape=(50961,))", "cv": "[(array([    0,     1,     2, ..., 50957, 50958, 50960]), array([   18,    24,    28, ..., 50904, 509..., (array([    0,     1,     2, ..., 50956, 50958, 50959]), array([    3,    13,    15, ..., 50951, 509..., (array([    1,     3,     4, ..., 50958, 50959, 50960]), array([    0,     2,     8, ..., 50932, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    6,    10,    12, ..., 50942, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    9,    16,    22, ..., 50939, 509..., (array([    0,     1,     2, ..., 50957, 50959, 50960]), array([    7,    30,    44, ..., 50952, 509..., (array([    0,     2,     3, ..., 50958, 50959, 50960]), array([    1,    23,    36, ..., 50935, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    4,     5,    25, ..., 50938, 509...]", "n_jobs": -1, "method": "predict_proba", "verbose": "False"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to recognize fraudulent credit card transactions using various machine learning models. After loading and preprocessing the data, the API call is used to estimate the LGBMClassifier model's performance by making cross-validated predictions. The `cross_val_auc` function calculates the AUC score for each model, which is then stored in a dictionary. The same function is applied to various other classifiers and regressors to compare their performance. After identifying the best models, an ensemble method is used to combine the predictions, and the final predictions are submitted."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-011", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-tree-decisiontreeregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"random_state": 2023}}}, {"role": "solutionSummary", "module": {"summary": "The goal of this code snippet is to recognize fraudulent credit card transactions. The dataset is loaded, preprocessed, and analyzed using dimensionality reduction techniques. A variety of machine learning models, including classifiers and regressors, are tested to find the best model for the task. The API call in question involves using a DecisionTreeRegressor with a fixed random state for reproducibility. This model is evaluated using the custom function `cross_val_auc`, which calculates the AUC score for regression models by considering them as classifiers. After testing different models, the best performing ones are combined into an ensemble to make the final predictions, which are then submitted in a CSV file."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-012", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-cross-val-predict"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "DecisionTreeRegressor(random_state=2023)", "X": "array(shape=(50961, 44))", "y": "series(shape=(50961,))", "cv": "[(array([    0,     1,     2, ..., 50957, 50958, 50960]), array([   18,    24,    28, ..., 50904, 509..., (array([    0,     1,     2, ..., 50956, 50958, 50959]), array([    3,    13,    15, ..., 50951, 509..., (array([    1,     3,     4, ..., 50958, 50959, 50960]), array([    0,     2,     8, ..., 50932, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    6,    10,    12, ..., 50942, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    9,    16,    22, ..., 50939, 509..., (array([    0,     1,     2, ..., 50957, 50959, 50960]), array([    7,    30,    44, ..., 50952, 509..., (array([    0,     2,     3, ..., 50958, 50959, 50960]), array([    1,    23,    36, ..., 50935, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    4,     5,    25, ..., 50938, 509...]", "n_jobs": -1, "verbose": "False"}}}, {"role": "solutionSummary", "module": {"summary": "The goal is to recognize fraudulent credit card transactions using the given dataset. The code snippet first performs exploratory data analysis, including visualizations of feature distributions and correlations, as well as dimensionality reduction for clustering. Then, the data is prepared by sampling and scaling. A variety of machine learning models are evaluated using cross-validation, including linear models, classifiers, regressors, and hyperparameter-tuned models. The API call is used to perform cross-validation and make predictions for a DecisionTreeRegressor model as part of the model evaluation process. Finally, an ensemble of four models is created, and the final predictions are submitted."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-013", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-ensemble-randomforestregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"random_state": 2023}}}, {"role": "solutionSummary", "module": {"summary": "The task is to recognize fraudulent credit card transactions using a variety of models. After loading the dataset, performing feature engineering, and visualizing the data, the API call is made within the cross_val_auc function to test the RandomForestRegressor model. This is done alongside other models, including classifiers and regressors, as part of a comparative analysis to determine which model performs best in terms of AUC score. Following the evaluation of all models, an ensemble is created using a weighted combination of XGBoost, CatBoost, and their regression variants to make final predictions for the test set and generate a submission file."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-014", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-cross-val-predict"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "RandomForestRegressor(random_state=2023)", "X": "array(shape=(50961, 44))", "y": "series(shape=(50961,))", "cv": "[(array([    0,     1,     2, ..., 50957, 50958, 50960]), array([   18,    24,    28, ..., 50904, 509..., (array([    0,     1,     2, ..., 50956, 50958, 50959]), array([    3,    13,    15, ..., 50951, 509..., (array([    1,     3,     4, ..., 50958, 50959, 50960]), array([    0,     2,     8, ..., 50932, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    6,    10,    12, ..., 50942, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    9,    16,    22, ..., 50939, 509..., (array([    0,     1,     2, ..., 50957, 50959, 50960]), array([    7,    30,    44, ..., 50952, 509..., (array([    0,     2,     3, ..., 50958, 50959, 50960]), array([    1,    23,    36, ..., 50935, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    4,     5,    25, ..., 50938, 509...]", "n_jobs": -1, "verbose": "False"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is aimed at detecting fraudulent credit card transactions using various classifiers and regressors. After preparing the data and performing feature engineering, the API call is made to obtain predictions from the RandomForestRegressor model using cross-validation with the preprocessed training data. The purpose of this call is to evaluate the RandomForestRegressor model's performance using ROC AUC score in the defined function `cross_val_auc`. Similar cross-validation predictions and evaluations are made for other classifiers and regressors. The results are then visualized in a bar plot to compare the performance of all models, and an ensemble model is created for the final submission."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-015", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-ensemble-extratreesregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"random_state": 2023}}}, {"role": "solutionSummary", "module": {"summary": "This code snippet aims to recognize fraudulent credit card transactions. After loading the dataset, performing feature engineering, and visualizing the data, the API is called to create an ExtraTreesRegressor model as part of the model evaluation process. Various classifiers and regressors are tested, including ExtraTreesRegressor, to find the best model for the task. After testing all models, an ensemble of the best models is created, and predictions are made on the test dataset. Finally, the results are saved in a submission file for evaluation."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-016", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-cross-val-predict"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "ExtraTreesRegressor(random_state=2023)", "X": "array(shape=(50961, 44))", "y": "series(shape=(50961,))", "cv": "[(array([    0,     1,     2, ..., 50957, 50958, 50960]), array([   18,    24,    28, ..., 50904, 509..., (array([    0,     1,     2, ..., 50956, 50958, 50959]), array([    3,    13,    15, ..., 50951, 509..., (array([    1,     3,     4, ..., 50958, 50959, 50960]), array([    0,     2,     8, ..., 50932, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    6,    10,    12, ..., 50942, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    9,    16,    22, ..., 50939, 509..., (array([    0,     1,     2, ..., 50957, 50959, 50960]), array([    7,    30,    44, ..., 50952, 509..., (array([    0,     2,     3, ..., 50958, 50959, 50960]), array([    1,    23,    36, ..., 50935, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    4,     5,    25, ..., 50938, 509...]", "n_jobs": -1, "verbose": "False"}}}, {"role": "solutionSummary", "module": {"summary": "The objective is to recognize fraudulent credit card transactions. The dataset is loaded, preprocessed, and features are engineered. Then, a variety of machine learning models are evaluated using cross-validation with stratified K-Fold splits. The API call is made to obtain predictions for the ExtraTreesRegressor model using cross_val_predict. The predictions are then used to compute the ROC-AUC score for each model. Based on the scores, an ensemble of the best-performing models is built, and the final predictions are generated and submitted."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-017", "modules": [{"role": "algorithm", "purpose": "API", "module": "xgboost-xgbregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"random_state": 2023}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to recognize fraudulent credit card transactions. After loading and preprocessing the data, several models are evaluated using cross-validation to determine their performance. The API call is made to include an XGBoost Regressor model in this evaluation process. The purpose of this model is to leverage the gradient boosting capabilities of XGBoost in a regression setting, which can still be used in this classification problem due to the AUC metric. Once all models are evaluated, an ensemble of the best performers is created, and their predictions are combined to form the final submission."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-018", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-cross-val-predict"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, col...", "X": "array(shape=(50961, 44))", "y": "series(shape=(50961,))", "cv": "[(array([    0,     1,     2, ..., 50957, 50958, 50960]), array([   18,    24,    28, ..., 50904, 509..., (array([    0,     1,     2, ..., 50956, 50958, 50959]), array([    3,    13,    15, ..., 50951, 509..., (array([    1,     3,     4, ..., 50958, 50959, 50960]), array([    0,     2,     8, ..., 50932, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    6,    10,    12, ..., 50942, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    9,    16,    22, ..., 50939, 509..., (array([    0,     1,     2, ..., 50957, 50959, 50960]), array([    7,    30,    44, ..., 50952, 509..., (array([    0,     2,     3, ..., 50958, 50959, 50960]), array([    1,    23,    36, ..., 50935, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    4,     5,    25, ..., 50938, 509...]", "n_jobs": -1, "verbose": "False"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to recognize fraudulent credit card transactions using various machine learning models. After loading and preprocessing the dataset, a range of classifiers and regressors are evaluated using cross-validation to measure their AUC-ROC scores. The API call is used for an XGBRegressor model to generate predictions during cross-validation. The obtained AUC scores are then plotted in a bar chart to compare the performance of different models. Following the evaluation, an ensemble of models is created to make final predictions, and the results are saved for submission."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-019", "modules": [{"role": "algorithm", "purpose": "API", "module": "catboost-catboostregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"verbose": "False", "random_state": 2023}}}, {"role": "solutionSummary", "module": {"summary": "The goal of this code snippet is to recognize fraudulent credit card transactions. After loading and preprocessing the dataset, various machine learning models are tested for their performance. Among them, the CatBoostRegressor is called with specified arguments to evaluate its performance in a regression setting. The performance of the CatBoostRegressor and other models are compared using the AUC metric. The best-performing models are then used in an ensemble to make predictions on the test dataset, which are combined and submitted as the final predictions for the task."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-020", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-cross-val-predict"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "<catboost.core.CatBoostRegressor object at 0x7c7496ef0d60>", "X": "array(shape=(50961, 44))", "y": "series(shape=(50961,))", "cv": "[(array([    0,     1,     2, ..., 50957, 50958, 50960]), array([   18,    24,    28, ..., 50904, 509..., (array([    0,     1,     2, ..., 50956, 50958, 50959]), array([    3,    13,    15, ..., 50951, 509..., (array([    1,     3,     4, ..., 50958, 50959, 50960]), array([    0,     2,     8, ..., 50932, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    6,    10,    12, ..., 50942, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    9,    16,    22, ..., 50939, 509..., (array([    0,     1,     2, ..., 50957, 50959, 50960]), array([    7,    30,    44, ..., 50952, 509..., (array([    0,     2,     3, ..., 50958, 50959, 50960]), array([    1,    23,    36, ..., 50935, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    4,     5,    25, ..., 50938, 509...]", "n_jobs": -1, "verbose": "False"}}}, {"role": "solutionSummary", "module": {"summary": "The goal is to recognize fraudulent credit card transactions using various machine learning models. The dataset is loaded, preprocessed, and feature engineered. The API call is used to perform cross-validated predictions, which are then evaluated using the ROC AUC score for each model, including regressors and classifiers. Finally, an ensemble model is created by combining the predictions of the best-performing models, and a submission is generated for the Kaggle competition."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-021", "modules": [{"role": "algorithm", "purpose": "API", "module": "lightgbm-lgbmmodel"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"random_state": 2023}}}, {"role": "solutionSummary", "module": {"summary": "The goal is to recognize fraudulent credit card transactions. After loading the dataset, preprocessing, and feature engineering, multiple models are tested, including classifiers and regressors. The API is called to create a LightGBMRegressor model, which is then evaluated using cross-validation. Following the evaluation, several models are selected, tuned, and their feature importances are plotted. An ensemble of the best-performing models is created, and predictions are made on the test set. The final submission is prepared by combining the predictions of the ensemble models and saving them to a CSV file."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-022", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-cross-val-predict"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "LGBMRegressor(random_state=2023)", "X": "array(shape=(50961, 44))", "y": "series(shape=(50961,))", "cv": "[(array([    0,     1,     2, ..., 50957, 50958, 50960]), array([   18,    24,    28, ..., 50904, 509..., (array([    0,     1,     2, ..., 50956, 50958, 50959]), array([    3,    13,    15, ..., 50951, 509..., (array([    1,     3,     4, ..., 50958, 50959, 50960]), array([    0,     2,     8, ..., 50932, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    6,    10,    12, ..., 50942, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    9,    16,    22, ..., 50939, 509..., (array([    0,     1,     2, ..., 50957, 50959, 50960]), array([    7,    30,    44, ..., 50952, 509..., (array([    0,     2,     3, ..., 50958, 50959, 50960]), array([    1,    23,    36, ..., 50935, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    4,     5,    25, ..., 50938, 509...]", "n_jobs": -1, "verbose": "False"}}}, {"role": "solutionSummary", "module": {"summary": "The goal is to detect fraudulent credit card transactions using machine learning models. After loading and processing the data, several models are tested, including LGBMRegressor. The API call is used to predict values using cross-validation, which helps evaluate the model's performance on the dataset. The resulting predictions are then used to compute the ROC AUC score, which is stored in a dictionary along with the model name. The scores are compared to determine the best performing model, and ensembles are created to improve prediction accuracy. Finally, the selected model is used to generate predictions on the test dataset for submission."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-023", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-tree-decisiontreeclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"random_state": 2023, "min_samples_split": 19, "min_samples_leaf": 106, "max_leaf_nodes": 80, "max_features": 21, "max_depth": 19}}}, {"role": "solutionSummary", "module": {"summary": "The goal is to recognize fraudulent credit card transactions. The dataset is preprocessed with feature engineering and scaling, followed by evaluating various machine learning models using cross-validation. In the API call, a DecisionTreeClassifier is created with specific hyperparameters, optimized through a previous search process. The classifier is then evaluated using cross_val_auc function, which computes the ROC-AUC score. This process is conducted for various classifiers and regressors to identify the best model, and the final ensemble model is created and used to generate predictions for submission."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-024", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-cross-val-predict"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "DecisionTreeClassifier(max_depth=19, max_features=21, max_leaf_nodes=80,\n                       min_...", "X": "array(shape=(50961, 44))", "y": "series(shape=(50961,))", "cv": "[(array([    0,     1,     2, ..., 50957, 50958, 50960]), array([   18,    24,    28, ..., 50904, 509..., (array([    0,     1,     2, ..., 50956, 50958, 50959]), array([    3,    13,    15, ..., 50951, 509..., (array([    1,     3,     4, ..., 50958, 50959, 50960]), array([    0,     2,     8, ..., 50932, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    6,    10,    12, ..., 50942, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    9,    16,    22, ..., 50939, 509..., (array([    0,     1,     2, ..., 50957, 50959, 50960]), array([    7,    30,    44, ..., 50952, 509..., (array([    0,     2,     3, ..., 50958, 50959, 50960]), array([    1,    23,    36, ..., 50935, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    4,     5,    25, ..., 50938, 509...]", "n_jobs": -1, "method": "predict_proba", "verbose": "False"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to recognize fraudulent credit card transactions from a dataset. After loading, preprocessing, and feature engineering, the dataset is prepared for use. The API is called within a function named `cross_val_auc` to evaluate the performance of various classifier and regressor models using cross-validation. The function takes an estimator and performs cross-validated predictions, calculating the AUC score for each model. These scores are then stored in a dictionary and later used to visualize the performance of each model and choose the best one for the ensemble."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-025", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-tree-decisiontreeregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"random_state": 2023, "min_samples_split": 19, "min_samples_leaf": 106, "max_leaf_nodes": 80, "max_features": 21, "max_depth": 19}}}, {"role": "solutionSummary", "module": {"summary": "The goal of the code snippet is to recognize fraudulent credit card transactions. After loading, preprocessing, and feature engineering, several machine learning models are tested, including the API call to create a DecisionTreeRegressor. The chosen hyperparameters for the DecisionTreeRegressor are the result of a prior search. The created model is fitted and its performance is evaluated using the cross_val_auc function. The snippet continues to explore various other models to compare their performance, and ultimately creates an ensemble model using the best-performing models for the final submission."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-026", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-cross-val-predict"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "DecisionTreeRegressor(max_depth=19, max_features=21, max_leaf_nodes=80,\n                      min_sa...", "X": "array(shape=(50961, 44))", "y": "series(shape=(50961,))", "cv": "[(array([    0,     1,     2, ..., 50957, 50958, 50960]), array([   18,    24,    28, ..., 50904, 509..., (array([    0,     1,     2, ..., 50956, 50958, 50959]), array([    3,    13,    15, ..., 50951, 509..., (array([    1,     3,     4, ..., 50958, 50959, 50960]), array([    0,     2,     8, ..., 50932, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    6,    10,    12, ..., 50942, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    9,    16,    22, ..., 50939, 509..., (array([    0,     1,     2, ..., 50957, 50959, 50960]), array([    7,    30,    44, ..., 50952, 509..., (array([    0,     2,     3, ..., 50958, 50959, 50960]), array([    1,    23,    36, ..., 50935, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    4,     5,    25, ..., 50938, 509...]", "n_jobs": -1, "verbose": "False"}}}, {"role": "solutionSummary", "module": {"summary": "This code snippet focuses on recognizing fraudulent credit card transactions. After loading the dataset and performing feature engineering, a variety of models are tested for their performance using cross-validation. The API call is used to obtain predicted values from the DecisionTreeRegressor model with the specified hyperparameters. The performance of this model, along with other models, is assessed using the AUC-ROC score. Further, the best performing models are combined into an ensemble for the final prediction."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-027", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-ensemble-randomforestclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"random_state": 2023, "min_samples_split": 12, "min_samples_leaf": 27, "max_leaf_nodes": 45, "max_features": 16, "max_depth": 39}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to build a credit card fraud detection model using various machine learning algorithms. The data is preprocessed and cleaned, with additional features created. The API is called to create a RandomForestClassifier model with specific hyperparameters, which are then used to evaluate the model's performance using cross-validation. Multiple models, including linear models, classifiers, and regressors, are tested and compared to select the best-performing models. Finally, an ensemble of the top models is created to make predictions on the test set and generate a submission file."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-028", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-cross-val-predict"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "RandomForestClassifier(max_depth=39, max_features=16, max_leaf_nodes=45,\n                       min_...", "X": "array(shape=(50961, 44))", "y": "series(shape=(50961,))", "cv": "[(array([    0,     1,     2, ..., 50957, 50958, 50960]), array([   18,    24,    28, ..., 50904, 509..., (array([    0,     1,     2, ..., 50956, 50958, 50959]), array([    3,    13,    15, ..., 50951, 509..., (array([    1,     3,     4, ..., 50958, 50959, 50960]), array([    0,     2,     8, ..., 50932, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    6,    10,    12, ..., 50942, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    9,    16,    22, ..., 50939, 509..., (array([    0,     1,     2, ..., 50957, 50959, 50960]), array([    7,    30,    44, ..., 50952, 509..., (array([    0,     2,     3, ..., 50958, 50959, 50960]), array([    1,    23,    36, ..., 50935, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    4,     5,    25, ..., 50938, 509...]", "n_jobs": -1, "method": "predict_proba", "verbose": "False"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to identify fraudulent credit card transactions using machine learning models. After loading the dataset, preprocessing and feature engineering are performed. The API is called to obtain the cross-validated predictions of the RandomForestClassifier model on the training data. The purpose is to evaluate the performance of the model using the AUC-ROC score. Subsequently, various classifier and regressor models are tested, their performance compared, and an ensemble model is created to make predictions on the test data. Finally, the submission file is generated containing the predicted probabilities of the test data."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-029", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-ensemble-randomforestregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"random_state": 2023, "min_samples_split": 12, "min_samples_leaf": 27, "max_leaf_nodes": 45, "max_features": 16, "max_depth": 39}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to recognize fraudulent credit card transactions using multiple machine learning models. After loading the dataset, preprocessing, and feature engineering, various models are tested for performance using the AUC metric. The RandomForestRegressor API is called with specific parameters to create a model, which is then evaluated using cross_val_auc function. Subsequently, an ensemble of models is built using XGBoost, CatBoost, and RandomForestRegressor, and predictions are generated for the test set. The results are then combined, and a submission file is created."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-030", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-cross-val-predict"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "RandomForestRegressor(max_depth=39, max_features=16, max_leaf_nodes=45,\n                      min_sa...", "X": "array(shape=(50961, 44))", "y": "series(shape=(50961,))", "cv": "[(array([    0,     1,     2, ..., 50957, 50958, 50960]), array([   18,    24,    28, ..., 50904, 509..., (array([    0,     1,     2, ..., 50956, 50958, 50959]), array([    3,    13,    15, ..., 50951, 509..., (array([    1,     3,     4, ..., 50958, 50959, 50960]), array([    0,     2,     8, ..., 50932, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    6,    10,    12, ..., 50942, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    9,    16,    22, ..., 50939, 509..., (array([    0,     1,     2, ..., 50957, 50959, 50960]), array([    7,    30,    44, ..., 50952, 509..., (array([    0,     2,     3, ..., 50958, 50959, 50960]), array([    1,    23,    36, ..., 50935, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    4,     5,    25, ..., 50938, 509...]", "n_jobs": -1, "verbose": "False"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to recognize fraudulent credit card transactions using various machine learning models. The dataset is processed, including feature engineering and scaling. The API call is made within the cross_val_auc function, which is used to evaluate multiple models in a loop. It calculates the AUC score for each model using cross_val_predict, which performs cross-validation and returns the predicted target values. The model's results are recorded in logs and visualized in a bar plot to compare their performance. The top-performing models are then combined into an ensemble to make predictions on the test set, which are saved in a submission file."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-031", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-ensemble-extratreesclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"random_state": 2023, "min_samples_split": 33, "min_samples_leaf": 27, "max_leaf_nodes": 50, "max_features": 23, "max_depth": 39}}}, {"role": "solutionSummary", "module": {"summary": "The task is to detect fraudulent credit card transactions using a given dataset. After exploring the data, preprocessing, and feature engineering, multiple machine learning models are evaluated to find the best model. The API call creates an ExtraTreesClassifier instance with specific hyperparameters and a fixed random state. The classifier is then evaluated using the cross_val_auc function to obtain its AUC score. The performance of multiple models is compared, and the best models are further used in an ensemble for the final prediction submitted to the competition."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-032", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-cross-val-predict"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "ExtraTreesClassifier(max_depth=39, max_features=23, max_leaf_nodes=50,\n                     min_samp...", "X": "array(shape=(50961, 44))", "y": "series(shape=(50961,))", "cv": "[(array([    0,     1,     2, ..., 50957, 50958, 50960]), array([   18,    24,    28, ..., 50904, 509..., (array([    0,     1,     2, ..., 50956, 50958, 50959]), array([    3,    13,    15, ..., 50951, 509..., (array([    1,     3,     4, ..., 50958, 50959, 50960]), array([    0,     2,     8, ..., 50932, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    6,    10,    12, ..., 50942, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    9,    16,    22, ..., 50939, 509..., (array([    0,     1,     2, ..., 50957, 50959, 50960]), array([    7,    30,    44, ..., 50952, 509..., (array([    0,     2,     3, ..., 50958, 50959, 50960]), array([    1,    23,    36, ..., 50935, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    4,     5,    25, ..., 50938, 509...]", "n_jobs": -1, "method": "predict_proba", "verbose": "False"}}}, {"role": "solutionSummary", "module": {"summary": "In this code snippet, the goal is to recognize fraudulent credit card transactions. The dataset is loaded, and feature engineering is performed. The API call is used to evaluate multiple machine learning models using cross-validation. This includes linear models (Logistic Regression, Lasso, and Ridge), tree-based classifiers (Decision Tree, Random Forest, Extra Trees, XGB, CatBoost, and LGBM), and tree-based regressors. The cross_val_predict function is called with the respective model and training data, and it returns the predicted probabilities for each fold in the cross-validation. These probabilities are then used to calculate the ROC AUC score, which is a measure of the model's performance. The best models are selected, and an ensemble is created to make predictions on the test data."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-033", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-ensemble-extratreesregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"random_state": 2023, "min_samples_split": 33, "min_samples_leaf": 27, "max_leaf_nodes": 50, "max_features": 23, "max_depth": 39}}}, {"role": "solutionSummary", "module": {"summary": "The goal is to recognize fraudulent credit card transactions. After loading the dataset, preprocessing it, and performing feature engineering, several machine learning models are tested to compare their performance. The API call is made to create an ExtraTreesRegressor model with specified hyperparameters. The model is then evaluated using cross-validation and its AUC score is logged. Furthermore, an ensemble of classifiers and regressors is created to generate final predictions, which are then submitted as part of a Kaggle competition."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-034", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-cross-val-predict"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "ExtraTreesRegressor(max_depth=39, max_features=23, max_leaf_nodes=50,\n                    min_sample...", "X": "array(shape=(50961, 44))", "y": "series(shape=(50961,))", "cv": "[(array([    0,     1,     2, ..., 50957, 50958, 50960]), array([   18,    24,    28, ..., 50904, 509..., (array([    0,     1,     2, ..., 50956, 50958, 50959]), array([    3,    13,    15, ..., 50951, 509..., (array([    1,     3,     4, ..., 50958, 50959, 50960]), array([    0,     2,     8, ..., 50932, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    6,    10,    12, ..., 50942, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    9,    16,    22, ..., 50939, 509..., (array([    0,     1,     2, ..., 50957, 50959, 50960]), array([    7,    30,    44, ..., 50952, 509..., (array([    0,     2,     3, ..., 50958, 50959, 50960]), array([    1,    23,    36, ..., 50935, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    4,     5,    25, ..., 50938, 509...]", "n_jobs": -1, "verbose": "False"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to detect fraudulent credit card transactions using various machine learning models. After loading the data and performing feature engineering, a cross-validation method is used to estimate the performance of different models. The API call is used to make predictions on the training data using cross-validation with the ExtraTreesRegressor model. This is part of a series of models being tested, where the goal is to compare and analyze each model's performance, measured by the AUC score. The final ensemble model is created using a combination of the best performing models."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-035", "modules": [{"role": "algorithm", "purpose": "API", "module": "xgboost-xgbclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"random_state": 2023, "subsample": 0.88, "min_child_weight": 89, "max_depth": 37, "learning_rate": 0.1, "gamma": 0.55, "colsample_bytree": 0.55}}}, {"role": "solutionSummary", "module": {"summary": "The goal is to recognize fraudulent credit card transactions using a variety of machine learning models. After loading the dataset, performing exploratory data analysis, and preprocessing the data, the API is called to create an XGBoost classifier model. The model is configured with specific hyperparameters found through a prior search. The model is then fitted, and its performance is evaluated using cross-validation. Following this, various other models are tested and their performance logged. Finally, an ensemble of the best-performing models is created, and predictions are made on the test set, which are then submitted."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-036", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-cross-val-predict"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, c...", "X": "array(shape=(50961, 44))", "y": "series(shape=(50961,))", "cv": "[(array([    0,     1,     2, ..., 50957, 50958, 50960]), array([   18,    24,    28, ..., 50904, 509..., (array([    0,     1,     2, ..., 50956, 50958, 50959]), array([    3,    13,    15, ..., 50951, 509..., (array([    1,     3,     4, ..., 50958, 50959, 50960]), array([    0,     2,     8, ..., 50932, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    6,    10,    12, ..., 50942, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    9,    16,    22, ..., 50939, 509..., (array([    0,     1,     2, ..., 50957, 50959, 50960]), array([    7,    30,    44, ..., 50952, 509..., (array([    0,     2,     3, ..., 50958, 50959, 50960]), array([    1,    23,    36, ..., 50935, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    4,     5,    25, ..., 50938, 509...]", "n_jobs": -1, "method": "predict_proba", "verbose": "False"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to recognize fraudulent credit card transactions using a variety of machine learning models. The dataset is loaded and preprocessed, including feature engineering and resampling. Before the API call, several models are initialized with specific parameters, and their performance is evaluated using cross-validation. The API call is used to generate cross-validated predictions with the specified models, and the resulting AUC scores are calculated and stored. After the API call, an ensemble of the best-performing models is created, and the predictions are combined to generate the final submission file."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-037", "modules": [{"role": "algorithm", "purpose": "API", "module": "xgboost-xgbregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"random_state": 2023, "n_estimators": 2000, "min_child_weight": 96, "max_depth": 7, "learning_rate": 0.18, "subsample": 0.9500000000000001, "colsample_bytree": 0.9500000000000001, "reg_lambda": 1.5, "reg_alpha": 1.5, "gamma": 1.5, "max_bin": 512, "objective": "binary:logistic", "tree_method": "hist", "eval_metric": "rmse"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to recognize fraudulent credit card transactions. After loading the dataset, preprocessing, and performing feature engineering, the API is called to create an XGBRegressor model with a set of hyperparameters. The model is then fitted and evaluated using cross-validation. Several other models, such as Logistic Regression, Decision Trees, and CatBoost, are also tested. Finally, an ensemble of the best performing models is created to compute predictions for the test dataset, and a submission file is generated."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-038", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-cross-val-predict"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, col...", "X": "array(shape=(50961, 44))", "y": "series(shape=(50961,))", "cv": "[(array([    0,     1,     2, ..., 50957, 50958, 50960]), array([   18,    24,    28, ..., 50904, 509..., (array([    0,     1,     2, ..., 50956, 50958, 50959]), array([    3,    13,    15, ..., 50951, 509..., (array([    1,     3,     4, ..., 50958, 50959, 50960]), array([    0,     2,     8, ..., 50932, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    6,    10,    12, ..., 50942, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    9,    16,    22, ..., 50939, 509..., (array([    0,     1,     2, ..., 50957, 50959, 50960]), array([    7,    30,    44, ..., 50952, 509..., (array([    0,     2,     3, ..., 50958, 50959, 50960]), array([    1,    23,    36, ..., 50935, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    4,     5,    25, ..., 50938, 509...]", "n_jobs": -1, "verbose": "False"}}}, {"role": "solutionSummary", "module": {"summary": "The goal is to recognize fraudulent credit card transactions. The dataset is preprocessed and combined with the original dataset, and various features are engineered. The API is called to evaluate the performance of an XGBRegressor model on the training data using a stratified k-fold cross-validation procedure. The predictions from the cross-validation are then used to compute the ROC-AUC score, which is logged. This process is repeated for various other models, including classifiers and regressors. Finally, an ensemble of the top-performing models is created and used to generate the final predictions for the test dataset."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-039", "modules": [{"role": "algorithm", "purpose": "API", "module": "catboost-catboostclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"verbose": "False", "random_state": 2023, "min_data_in_leaf": 450, "max_depth": 6, "learning_rate": 0.022, "l2_leaf_reg": 19.88, "colsample_bylevel": 0.88}}}, {"role": "solutionSummary", "module": {"summary": "The goal is to recognize fraudulent credit card transactions using various machine learning models. After loading the data, preprocessing, and feature engineering, the API is called to create a CatBoostClassifier model with specific hyperparameters. The model is then evaluated using cross-validation to measure its performance (AUC score). Subsequently, several other models are trained and evaluated, and their feature importance is assessed. Finally, an ensemble of the created models is used to make predictions for the test set, and the submission file is generated."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-040", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-cross-val-predict"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "<catboost.core.CatBoostClassifier object at 0x7c749e083100>", "X": "array(shape=(50961, 44))", "y": "series(shape=(50961,))", "cv": "[(array([    0,     1,     2, ..., 50957, 50958, 50960]), array([   18,    24,    28, ..., 50904, 509..., (array([    0,     1,     2, ..., 50956, 50958, 50959]), array([    3,    13,    15, ..., 50951, 509..., (array([    1,     3,     4, ..., 50958, 50959, 50960]), array([    0,     2,     8, ..., 50932, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    6,    10,    12, ..., 50942, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    9,    16,    22, ..., 50939, 509..., (array([    0,     1,     2, ..., 50957, 50959, 50960]), array([    7,    30,    44, ..., 50952, 509..., (array([    0,     2,     3, ..., 50958, 50959, 50960]), array([    1,    23,    36, ..., 50935, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    4,     5,    25, ..., 50938, 509...]", "n_jobs": -1, "method": "predict_proba", "verbose": "False"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to recognize fraudulent credit card transactions using various machine learning models. After loading the dataset, preprocessing, and feature engineering, the API call is used to make predictions using cross-validation on the training data. The performance of several classifiers and regressors is evaluated using the Area Under the ROC Curve (AUC). After testing and optimizing these models, an ensemble model is created by combining predictions from XGBoost, CatBoost, and LightGBM models. The final ensemble predictions are then used to create a submission file for the Kaggle competition."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-041", "modules": [{"role": "algorithm", "purpose": "API", "module": "catboost-catboostregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"verbose": "False", "random_state": 2023, "min_data_in_leaf": 250, "max_depth": 6, "learning_rate": 0.01, "l2_leaf_reg": 31.6, "colsample_bylevel": 0.73}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is designed to recognize fraudulent credit card transactions. After loading the dataset, performing feature engineering, and visualizing the data, several machine learning models are tested for their effectiveness. The API is called to create a CatBoostRegressor model with specific hyperparameters. This model is trained on a subset of the dataset created by combining the original data with synthetic samples. This process is repeated multiple times with different random states, and the predictions are averaged to create the final predictions. The CatBoostRegressor is part of an ensemble model combined with other classifiers and regressors to improve the overall prediction performance."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-042", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-cross-val-predict"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "<catboost.core.CatBoostRegressor object at 0x7c749e080880>", "X": "array(shape=(50961, 44))", "y": "series(shape=(50961,))", "cv": "[(array([    0,     1,     2, ..., 50957, 50958, 50960]), array([   18,    24,    28, ..., 50904, 509..., (array([    0,     1,     2, ..., 50956, 50958, 50959]), array([    3,    13,    15, ..., 50951, 509..., (array([    1,     3,     4, ..., 50958, 50959, 50960]), array([    0,     2,     8, ..., 50932, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    6,    10,    12, ..., 50942, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    9,    16,    22, ..., 50939, 509..., (array([    0,     1,     2, ..., 50957, 50959, 50960]), array([    7,    30,    44, ..., 50952, 509..., (array([    0,     2,     3, ..., 50958, 50959, 50960]), array([    1,    23,    36, ..., 50935, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    4,     5,    25, ..., 50938, 509...]", "n_jobs": -1, "verbose": "False"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is designed to recognize fraudulent credit card transactions. After loading and processing the data, various models are tested using cross-validation to assess their performance. In the specific API call, a CatBoostRegressor model with custom hyperparameters is created, and cross_val_predict is used to obtain the model's predictions using cross-validation. This allows for an estimation of the model's performance on unseen data. The process is repeated for multiple models, and their performance is compared to choose the best model. An ensemble model is then created using the chosen models, and the final predictions are submitted."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-043", "modules": [{"role": "algorithm", "purpose": "API", "module": "lightgbm-lgbmmodel"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"random_state": 2023, "num_rounds": 500, "num_leaves": 663, "min_gain_to_split": 1.44, "min_data_in_leaf": 14, "max_depth": 94, "learning_rate": 0.043000000000000003, "lambda_l2": 0.47000000000000003, "lambda_l1": 0.31, "feature_fraction": 0.55, "bagging_fraction": 0.001}}}, {"role": "solutionSummary", "module": {"summary": "The credit card fraud detection task focuses on using various machine learning models to predict fraudulent transactions. In the code snippet, the data is loaded, preprocessed, and feature engineered. The API call is used to create an LGBMClassifier model with provided hyperparameters, which is then evaluated using cross-validation. After evaluating other classifiers and regressors, an ensemble of models is built to make predictions on the test set, combining the best-performing models' predictions with specific weights. The final predictions are then saved to a submission file."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-044", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-cross-val-predict"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "LGBMClassifier(bagging_fraction=0.001, feature_fraction=0.55, lambda_l1=0.31,\n               lambda_...", "X": "array(shape=(50961, 44))", "y": "series(shape=(50961,))", "cv": "[(array([    0,     1,     2, ..., 50957, 50958, 50960]), array([   18,    24,    28, ..., 50904, 509..., (array([    0,     1,     2, ..., 50956, 50958, 50959]), array([    3,    13,    15, ..., 50951, 509..., (array([    1,     3,     4, ..., 50958, 50959, 50960]), array([    0,     2,     8, ..., 50932, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    6,    10,    12, ..., 50942, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    9,    16,    22, ..., 50939, 509..., (array([    0,     1,     2, ..., 50957, 50959, 50960]), array([    7,    30,    44, ..., 50952, 509..., (array([    0,     2,     3, ..., 50958, 50959, 50960]), array([    1,    23,    36, ..., 50935, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    4,     5,    25, ..., 50938, 509...]", "n_jobs": -1, "method": "predict_proba", "verbose": "False"}}}, {"role": "solutionSummary", "module": {"summary": "The task is to recognize fraudulent credit card transactions. The LFW dataset is first loaded, engineered, and standardized. The API call is used to perform cross-validation for the LGBMClassifier model using the provided hyperparameters, which is one of the several models being tested in the script. The predictions are made using the \"predict_proba\" method, and the area under the ROC curve (AUC) is calculated for the LGBMClassifier model. Various other models are similarly tested, and their AUC scores are gathered to show the performance comparison between different models."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-045", "modules": [{"role": "algorithm", "purpose": "API", "module": "lightgbm-lgbmmodel"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"random_state": 2023, "num_rounds": 188, "num_leaves": 227, "min_gain_to_split": 0.21, "min_data_in_leaf": 53, "max_depth": 32, "learning_rate": 0.18, "lambda_l2": 0.16, "lambda_l1": 0.052000000000000005, "feature_fraction": 0.44, "bagging_fraction": 0.33}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is focused on detecting fraudulent credit card transactions. After loading the data, feature engineering, and visualizing the data, the script tests multiple machine learning models to find the best performing one. The API call creates a LightGBM Regressor model with specific hyperparameters. The model is then evaluated using cross-validation, and the performance (AUC score) is recorded. Finally, an ensemble of the best-performing models is created, and predictions are made on the test data, which are then submitted to the competition."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-046", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-cross-val-predict"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "LGBMRegressor(bagging_fraction=0.33, feature_fraction=0.44, lambda_l1=0.052,\n              lambda_l2...", "X": "array(shape=(50961, 44))", "y": "series(shape=(50961,))", "cv": "[(array([    0,     1,     2, ..., 50957, 50958, 50960]), array([   18,    24,    28, ..., 50904, 509..., (array([    0,     1,     2, ..., 50956, 50958, 50959]), array([    3,    13,    15, ..., 50951, 509..., (array([    1,     3,     4, ..., 50958, 50959, 50960]), array([    0,     2,     8, ..., 50932, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    6,    10,    12, ..., 50942, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    9,    16,    22, ..., 50939, 509..., (array([    0,     1,     2, ..., 50957, 50959, 50960]), array([    7,    30,    44, ..., 50952, 509..., (array([    0,     2,     3, ..., 50958, 50959, 50960]), array([    1,    23,    36, ..., 50935, 509..., (array([    0,     1,     2, ..., 50958, 50959, 50960]), array([    4,     5,    25, ..., 50938, 509...]", "n_jobs": -1, "verbose": "False"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is focused on detecting fraudulent credit card transactions using various machine learning models. After loading the dataset, performing feature engineering, and scaling the data, the API call is used to run cross-validation for the LGBMRegressor model in the context of AUC (Area Under the Curve) evaluation. The model's hyperparameters have been previously tuned and provided as input. After the cross-validation, the performance of the LGBMRegressor model is recorded, and a series of other models are also tested for comparison. Finally, an ensemble of the best-performing models is constructed and used for making predictions on the test data."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-047", "modules": [{"role": "algorithm", "purpose": "API", "module": "xgboost-xgbclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"random_state": 2023, "subsample": 0.77, "min_child_weight": 23, "max_depth": 24, "learning_rate": 0.095, "gamma": 0.66, "colsample_bytree": 0.77}}}, {"role": "solutionSummary", "module": {"summary": "The task is to recognize fraudulent credit card transactions using a variety of machine learning models. The dataset is preprocessed, including feature engineering and standardization using RobustScaler. The API call is made to create an XGBoost classifier with specific hyperparameters. This classifier is trained multiple times with different random states and then combined in an ensemble model by averaging the predictions, together with predictions from CatBoost and LightGBM models. Finally, the ensemble's predictions are used to create a submission file for the Kaggle competition."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-048", "modules": [{"role": "algorithm", "purpose": "API", "module": "xgboost-xgbclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"random_state": 37, "subsample": 0.88, "min_child_weight": 89, "max_depth": 37, "learning_rate": 0.1, "gamma": 0.55, "colsample_bytree": 0.55}}}, {"role": "solutionSummary", "module": {"summary": "This code snippet aims to recognize fraudulent credit card transactions using a combination of different models, including XGBoost's XGBClassifier. The dataset is first loaded, preprocessed, and engineered with new features. Next, the API is called to create an instance of the XGBClassifier with specific hyperparameters. This classifier is then fitted on the training data, and predictions are made on the test data. This process is repeated 75 times with different random states, and the final predictions are an ensemble of these models, combined with other classifiers and regressors like CatBoost and LightGBM. Finally, the submission is created with the ensemble predictions and written to a CSV file."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-049", "modules": [{"role": "algorithm", "purpose": "API", "module": "catboost-catboostclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"verbose": "False", "random_state": 37, "min_data_in_leaf": 450, "max_depth": 6, "learning_rate": 0.022, "l2_leaf_reg": 19.88, "colsample_bylevel": 0.88}}}, {"role": "solutionSummary", "module": {"summary": "This code snippet's goal is to recognize fraudulent credit card transactions. The dataset is preprocessed, various visualizations are created, and several models are tested to find the best model for the task. The API call is used to create a CatBoostClassifier model with specific hyperparameters. The model is fitted on a balanced dataset created by combining the minority class with a random sample of the majority class. This process is repeated 75 times with different random states. The predictions of all iterations are combined and averaged to create the final ensemble submission, which is then saved to a CSV file."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-050", "modules": [{"role": "algorithm", "purpose": "API", "module": "xgboost-xgbregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"random_state": 37, "n_estimators": 2000, "min_child_weight": 96, "max_depth": 7, "learning_rate": 0.18, "subsample": 0.9500000000000001, "colsample_bytree": 0.9500000000000001, "reg_lambda": 1.5, "reg_alpha": 1.5, "gamma": 1.5, "max_bin": 512, "objective": "binary:logistic", "tree_method": "hist", "eval_metric": "rmse"}}}, {"role": "solutionSummary", "module": {"summary": "The goal is to recognize fraudulent credit card transactions. After loading, preprocessing, and feature engineering, the dataset is split into training and testing sets. Several machine learning models are trained and evaluated on the dataset. The API call is used to create an XGBoost regressor with specific hyperparameters, which is then fitted on the training data and used to make predictions on the test set. This process is repeated 75 times with different random states, and the final predictions are an ensemble of all the trained models."}}], "source": "kaggle"}, {"id": "kirillka95-eda-16-models-test-ensemble-051", "modules": [{"role": "algorithm", "purpose": "API", "module": "catboost-catboostregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"verbose": "False", "random_state": 37, "min_data_in_leaf": 250, "max_depth": 6, "learning_rate": 0.01, "l2_leaf_reg": 31.6, "colsample_bylevel": 0.73}}}, {"role": "solutionSummary", "module": {"summary": "The goal is to recognize fraudulent credit card transactions. The data is preprocessed, including feature engineering, and various models are tested for their performance. The API call is made to create a CatBoostRegressor model with specific hyperparameters in an ensemble approach. The model is trained on different subsets of the data in a loop. Predictions from the model are then combined with predictions from other models, including XGBoost and CatBoost classifiers, and regressors to create a final prediction for the test set. These predictions are then saved as a submission file for the competition."}}], "source": "kaggle"}, {"id": "marcinrutecki-regression-models-evaluation-metrics-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-labelencoder"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"drop": "first", "handle_unknown": "ignore"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet focuses on comparing various regression models for two datasets, the Avocado Prices dataset and the Boston House Prices dataset. Before the API call, the Avocado Prices dataset is preprocessed, including changing data types and creating new features. The API is called to perform One Hot Encoding on the 'region' column, which is a categorical feature. This encoding is done to transform the categorical variable into a numerical format that can be used by machine learning algorithms. After the encoding, the dataset undergoes further preprocessing such as outlier detection and removal, train-test split, and feature scaling before various regression models are evaluated and compared."}}], "source": "kaggle"}, {"id": "marcinrutecki-regression-models-evaluation-metrics-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-train-test-split"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"[0]": "dataframe(shape=(16168, 62))", "[1]": "series(shape=(16168,))", "test_size": 0.30000000000000004, "random_state": 42}}}, {"role": "solutionSummary", "module": {"summary": "This code snippet aims to compare the performance of various regression models on two datasets: Avocado Prices and Boston House Prices. After data preprocessing, including data transformations, outlier detection and removal, and feature scaling, the API call is used to split both datasets into training and testing sets. Following the split, several regression models such as Linear Regression, Random Forest, Ridge Regression, and XGBoost are trained and evaluated using different performance metrics. The results are then visualized and compared to determine the best performing model for each dataset."}}], "source": "kaggle"}, {"id": "marcinrutecki-regression-models-evaluation-metrics-003", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-train-test-split"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"[0]": "dataframe(shape=(506, 13))", "[1]": "series(shape=(506,))", "test_size": 0.30000000000000004, "random_state": 42}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to evaluate different regression models on two datasets: the Avocado Prices dataset and the Boston House Prices dataset. Prior to the API call, the datasets are preprocessed, including transformations, outlier detection, and removal. The API is called to split the datasets into training and testing sets, with 70% of the data used for training and 30% for testing. Following the split, various regression models, such as Linear Regression, Random Forest, Ridge Regression, and XGBoost, are trained and their performance metrics are calculated and compared. Additionally, hyperparameter tuning using GridSearchCV is performed on the Ridge Regression model to further optimize its performance."}}], "source": "kaggle"}, {"id": "marcinrutecki-regression-models-evaluation-metrics-004", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-standardscaler"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {}}}, {"role": "solutionSummary", "module": {"summary": "The goal of this code snippet is to compare different regression models' performance on Avocado and Boston House Prices datasets. After loading and processing the datasets, the API is called to standardize the features of the training and testing datasets using StandardScaler. Standardization is crucial because it scales the features to have a mean of 0 and a standard deviation of 1, which helps improve the performance of certain models, especially those that rely on distance measurements. After this preprocessing step, various regression models, such as Linear Regression, Random Forest, Ridge Regression, and XGBoost, are trained, and their performance is evaluated using evaluation metrics such as R2 Score, Adjusted R2 Score, Cross-Validated R2 Score, and RMSE."}}], "source": "kaggle"}, {"id": "marcinrutecki-regression-models-evaluation-metrics-005", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-standardscaler"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to compare different regression models to predict house prices in the Boston dataset and avocado prices. After pre-processing the data, including transformations and outlier removal, the API is called to standardize the features of both datasets. Standardizing the features is important as it ensures the features are on the same scale, which improves the performance of some machine learning algorithms, particularly those sensitive to feature scales, such as linear regression and support vector machines. The function Standard_Scaler is defined to apply the StandardScaler to the specified columns in the input dataframes. This function is then applied to the training and testing sets of both datasets before the regression models are trained and evaluated."}}], "source": "kaggle"}, {"id": "marcinrutecki-regression-models-evaluation-metrics-006", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-linear-model-linearregression"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "LinearRegression()", "X": "dataframe(shape=(11317, 62))", "y": "series(shape=(11317,))", "cv": 10}}}, {"role": "solutionSummary", "module": {"summary": "In this code snippet, the goal is to evaluate various regression models for predicting avocado prices and Boston house prices. After initial data preprocessing, feature scaling, and train-test splitting, the API call is used to perform cross-validation on the Linear Regression model with 10 folds. This helps in estimating the model's performance on unseen data by averaging the performance across the folds. After the API call, the evaluation metrics (R2 Score, Adjusted R2 Score, Cross Validated R2 Score, and RMSE) are stored in a DataFrame, and the same process is repeated for other regression models, such as Random Forest, Ridge Regression, and XGBoost. Finally, the model performances are compared and visualized."}}], "source": "kaggle"}, {"id": "marcinrutecki-regression-models-evaluation-metrics-007", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-cross-val-score"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "LinearRegression()", "X": "dataframe(shape=(354, 13))", "y": "series(shape=(354,))", "cv": 10}}}, {"role": "solutionSummary", "module": {"summary": "This code snippet is focused on comparing different regression models to predict avocado prices and Boston house prices. The API call evaluates the performance of the Linear Regression model using cross-validation. The dataset is split into training and testing sets, and several models, such as Linear Regression, Random Forest, Ridge Regression, and XGBoost, are fitted and compared. The performance of each model is assessed using metrics such as R2 Score, Adjusted R2 Score, Cross Validated R2 Score, and RMSE. The API call plays a crucial role in obtaining the Cross Validated R2 Score metric for the regression models to assess their performance."}}], "source": "kaggle"}, {"id": "marcinrutecki-regression-models-evaluation-metrics-008", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-ensemble-randomforestregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 10, "random_state": 0}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to compare different regression models on two datasets: Avocado Prices and Boston House Prices. The API call is used to create a RandomForestRegressor model for this comparison. Before the API call, the necessary libraries are imported, data is preprocessed, including feature scaling and train-test splitting. After the API call, the RandomForestRegressor model is trained on the training data and its performance is evaluated using various metrics like R2 Score, Adjusted R2 Score, Cross Validated R2 Score, and RMSE. The RandomForestRegressor model's performance is then compared with other models such as Linear Regression, Ridge Regression, XGBoost, and Recursive Feature Elimination (RFE)."}}], "source": "kaggle"}, {"id": "marcinrutecki-regression-models-evaluation-metrics-009", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-cross-val-score"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "RandomForestRegressor(n_estimators=10, random_state=0)", "X": "dataframe(shape=(11317, 62))", "y": "series(shape=(11317,))", "cv": 10}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is focused on evaluating the performance of multiple regression models on the Avocado and Boston datasets. After data preprocessing, feature scaling, and train-test split, the API call is used to calculate the cross-validated R2 score for the RandomForestRegressor model. This score gives a more unbiased estimate of the model's performance on unseen data. The cross-validated R2 score, along with other performance metrics such as R2 score, adjusted R2 score, and RMSE, are calculated for each model. The results are then visualized in bar plots to facilitate comparisons between the models' performances."}}], "source": "kaggle"}, {"id": "marcinrutecki-regression-models-evaluation-metrics-010", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-cross-val-score"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "RandomForestRegressor(n_estimators=10, random_state=0)", "X": "dataframe(shape=(354, 13))", "y": "series(shape=(354,))", "cv": 10}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet focuses on evaluating regression models to predict house prices and avocado prices. After pre-processing the data, which includes transformations, outlier detection and removal, train-test split, and feature scaling, the performance of multiple models, such as Linear Regression, Random Forest, Ridge Regression, and XGBoost, is compared using evaluation metrics. The API call is made within a custom function to calculate the cross-validated R2 score for each model. This score serves as a key evaluation metric to determine the performance of the model on the training data using k-fold cross-validation, where k is set to 10. The function also calculates other metrics such as R2, adjusted R2, and RMSE scores. These metrics are compiled into a DataFrame to visualize and compare the performance of different models on the given datasets."}}], "source": "kaggle"}, {"id": "marcinrutecki-regression-models-evaluation-metrics-011", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-linear-model-ridge"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"alpha": 3, "solver": "cholesky"}}}, {"role": "solutionSummary", "module": {"summary": "The goal of the code snippet is to evaluate the performance of multiple regression models, including Ridge Regression, on two datasets: Avocado Prices and Boston House Prices. After preprocessing the datasets, the API is called to create a Ridge Regression model with specified alpha and solver parameters. The model is then trained on the training data and used to make predictions on the test data. The performance of the Ridge Regression model is evaluated using various regression evaluation metrics, including R-squared, Adjusted R-squared, Cross-Validated R2, and RMSE. These performance metrics are then compared with those of other models, such as Linear Regression, Random Forest, XGBoost, and Recursive Feature Elimination (RFE)."}}], "source": "kaggle"}, {"id": "marcinrutecki-regression-models-evaluation-metrics-012", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-cross-val-score"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "Ridge(alpha=3, solver='cholesky')", "X": "dataframe(shape=(11317, 62))", "y": "series(shape=(11317,))", "cv": 10}}}, {"role": "solutionSummary", "module": {"summary": "The goal is to compare the performance of different regression models on two datasets, Avocado Prices and Boston House Prices. The code snippet first preprocesses the datasets by handling missing values, outliers, and feature scaling. Then, various regression models such as Linear Regression, Random Forest, Ridge Regression, and XGBoost are trained and evaluated. The API call is used to perform the cross-validation technique with 10 folds on the Ridge Regression model to obtain a more unbiased estimate of the model's performance. The cross-validated R-squared score is calculated for each model, and the results are presented in a bar plot for comparison."}}], "source": "kaggle"}, {"id": "marcinrutecki-regression-models-evaluation-metrics-013", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-cross-val-score"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "Ridge(alpha=3, solver='cholesky')", "X": "dataframe(shape=(354, 13))", "y": "series(shape=(354,))", "cv": 10}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet evaluates multiple regression models on two datasets, Avocado Prices and Boston House Prices. After preprocessing, including transformations, outlier removal, train-test split, and feature scaling, various regression models like Linear Regression, Random Forest, Ridge Regression, and XGBoost are fitted and evaluated. The API call is used to compute the cross-validated R\u00b2 score for the Ridge Regression model using 10-fold cross-validation. The results of the evaluation metrics, including R\u00b2 score, adjusted R\u00b2 score, cross-validated R\u00b2 score, and RMSE, are displayed for each model to help compare their performances and choose the best model for each dataset."}}], "source": "kaggle"}, {"id": "marcinrutecki-regression-models-evaluation-metrics-014", "modules": [{"role": "algorithm", "purpose": "API", "module": "xgboost-xgbregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 1000, "max_depth": 7, "eta": 0.1, "subsample": 0.8, "colsample_bytree": 0.8}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet's objective is to compare various regression models for two datasets: one about avocado prices and the other about Boston house prices. After preprocessing the data, the code calls the XGBoost API to create an XGBRegressor model with specific hyperparameters. The model is then fitted on the training data, and predictions are made on the test data. The performance of the XGBoost model is evaluated using different regression evaluation metrics and compared with other regression models, including Linear Regression, Random Forest, Ridge Regression, and Recursive Feature Elimination. This helps in determining the best performing model for each dataset."}}], "source": "kaggle"}, {"id": "marcinrutecki-regression-models-evaluation-metrics-015", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-cross-val-score"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, col...", "X": "dataframe(shape=(11317, 62))", "y": "series(shape=(11317,))", "cv": 10}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet compares different regression models' performances on predicting avocado prices and Boston house prices. After pre-processing the dataset, which includes transformations, outlier detection, and train-test split, it trains a series of regression models such as Linear Regression, Random Forest, Ridge Regression, XGBoost, and Recursive Feature Elimination (RFE), and evaluates their performance. The API call is used to perform 10-fold cross-validation on the XGBoost model and calculate the cross-validated R2 score, which is then used along with other evaluation metrics to compare the performance of the models."}}], "source": "kaggle"}, {"id": "marcinrutecki-regression-models-evaluation-metrics-016", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-cross-val-score"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, col...", "X": "dataframe(shape=(354, 13))", "y": "series(shape=(354,))", "cv": 10}}}, {"role": "solutionSummary", "module": {"summary": "The goal is to compare different regression models for the Avocado dataset and the Boston dataset. After preprocessing the data and training several models, the API is called to calculate cross-validated R2 scores for each model. This helps in assessing the performance of the models by providing a better estimation of their ability to generalize to new data. The cross-validated R2 scores are then used to create a comparison table and visualizations to understand the performance of each model on both datasets."}}], "source": "kaggle"}, {"id": "marcinrutecki-regression-models-evaluation-metrics-017", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-feature-selection-rfe"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "RandomForestRegressor()", "n_features_to_select": 60}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to compare the performance of different regression models on the Avocado and Boston datasets. The focus is on feature selection using Recursive Feature Elimination (RFE) and evaluating the performance of a Random Forest Regressor. The API is called to create an RFE object, which takes RandomForestRegressor as its estimator and selects the top 60 features. A pipeline is then created, with RFE and RandomForestRegressor as its steps, and the model is trained and tested on the Avocado and Boston datasets. Finally, the performance metrics of the model, including R2 Score, Adjusted R2 Score, Cross Validated R2 Score, and RMSE, are calculated and visualized."}}], "source": "kaggle"}, {"id": "marcinrutecki-regression-models-evaluation-metrics-018", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-ensemble-randomforestregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"steps": "[('s', RFE(estimator=RandomForestRegressor(), n_features_to_select=60)), ('m', RandomForestRegressor())]"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet demonstrates the evaluation of different regression models on two datasets, the Avocado Prices dataset and the Boston House Prices dataset. Prior to the API call, the datasets have been pre-processed, including transformations, outlier detection and removal, train-test splitting, and feature scaling. The API is called to create a pipeline that combines Recursive Feature Elimination (RFE) with a RandomForestRegressor model. RFE is employed as a feature selection technique to reduce the number of features for the RandomForestRegressor. The pipeline is then fit and used to make predictions on the test data. The performance of the pipeline, along with other models, is compared and visualized to determine the best model for each dataset."}}], "source": "kaggle"}, {"id": "marcinrutecki-regression-models-evaluation-metrics-019", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-cross-val-score"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "Pipeline(steps=[('s',\n                 RFE(estimator=RandomForestRegressor(),\n                     n...", "X": "dataframe(shape=(11317, 62))", "y": "series(shape=(11317,))", "cv": 10}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is focused on evaluating the performance of various regression models on two different datasets, Avocado Prices, and Boston House Prices. After preprocessing the data, including handling outliers and scaling, the models are fit on the training data. The API is called to perform cross-validation with 10-folds, which is used to assess the model's performance on unseen data. This cross-validated R2 score is then stored as a performance metric, and it is compared alongside other metrics such as R2 score, adjusted R2 score, and RMSE for each of the regression models. The models are visualized in bar plots to showcase their performance."}}], "source": "kaggle"}, {"id": "marcinrutecki-regression-models-evaluation-metrics-020", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-feature-selection-rfe"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "RandomForestRegressor()", "n_features_to_select": 8}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to evaluate and compare various regression models on two datasets: Avocado Prices and Boston House Prices. The API call creates a Recursive Feature Elimination (RFE) wrapper for a RandomForestRegressor to improve the model's performance by selecting the most important features. Before the API call, data pre-processing steps, such as transformations, outlier detection and removal, train-test split and feature scaling, are performed on both datasets. After creating the RFE model, it is fitted with the training data and the model's performance on the test data is evaluated using various metrics, such as R2 score, adjusted R2 score, cross-validated R2 score, and RMSE. The results from the RandomForest RFE model are compared with other regression models like Linear Regression, Random Forest, Ridge Regression, and XGBoost to determine the best performing model for each dataset."}}], "source": "kaggle"}, {"id": "marcinrutecki-regression-models-evaluation-metrics-021", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-ensemble-randomforestregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"steps": "[('s', RFE(estimator=RandomForestRegressor(), n_features_to_select=8)), ('m', RandomForestRegressor())]"}}}, {"role": "solutionSummary", "module": {"summary": "This code snippet is designed to compare different regression models for predicting avocado prices and Boston house prices. In this particular section, Recursive Feature Elimination (RFE) is used in combination with a Random Forest Regressor to improve the model's performance. RFE is a wrapper-type feature selection algorithm that works with a given machine learning algorithm (in this case, a Random Forest Regressor) to select important features. A pipeline is created with RFE and the RandomForestRegressor to streamline the process of feature selection and model fitting. The pipeline is then fit and used to make predictions on the test data, and the performance of the model is evaluated using various metrics like R2 score, adjusted R2 score, cross-validated R2 score, and RMSE."}}], "source": "kaggle"}, {"id": "marcinrutecki-regression-models-evaluation-metrics-022", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-cross-val-score"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "Pipeline(steps=[('s',\n                 RFE(estimator=RandomForestRegressor(),\n                     n...", "X": "dataframe(shape=(354, 13))", "y": "series(shape=(354,))", "cv": 10}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet focuses on comparing various regression models for two datasets, Avocado and Boston House Prices. After preprocessing the data, including transformations, outlier detection and removal, train-test splitting, and feature scaling, different models such as Linear Regression, Random Forest, Ridge Regression, XGBoost, and Recursive Feature Elimination (RFE) are trained. The API is called to perform cross-validation on each model, which helps in obtaining a less biased estimate of the model's performance. The evaluation metrics, including R2 score, adjusted R2 score, cross-validated R2 score, and RMSE, are computed for each model, and the results are visualized to compare the performances."}}], "source": "kaggle"}, {"id": "marcinrutecki-regression-models-evaluation-metrics-023", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-polynomialfeatures"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"degree": 2}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to compare the performance of different regression models on two datasets, Avocado Prices and Boston House Prices. Prior to the API call, the dataset is preprocessed, including train-test split, feature scaling, and transformations. The API is used to create polynomial features for the Ridge Regression model. The pipeline is then created combining PolynomialFeatures and Ridge Regression. The model is fitted to the training data, and hyperparameter tuning is performed using GridSearchCV. Model performance is assessed using evaluation metrics, and the results are compared and visualized across different regression models."}}], "source": "kaggle"}, {"id": "marcinrutecki-regression-models-evaluation-metrics-024", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-linear-model-ridge"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"alpha": 3.8, "fit_intercept": "True"}}}, {"role": "solutionSummary", "module": {"summary": "The goal is to compare different regression models on two datasets: Avocado Prices and Boston House Prices. After data processing and feature engineering, the Ridge regression model is created and trained with the specified alpha and fit_intercept arguments. The model's performance is then evaluated using various metrics, including R2 Score, Adjusted R2 Score, Cross Validated R2 Score, and RMSE. Additionally, hyperparameter tuning is performed through GridSearchCV to find the optimal alpha value for Ridge regression. The final performance comparison of the models is visualized to determine which model performs best on the given datasets."}}], "source": "kaggle"}, {"id": "marcinrutecki-regression-models-evaluation-metrics-025", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-pipeline-pipeline"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"steps": "[('poly', PolynomialFeatures()), ('model', Ridge(alpha=3.8))]"}}}, {"role": "solutionSummary", "module": {"summary": "The task is to compare different regression models on two datasets: Avocado Prices and Boston House Prices. After loading and preprocessing the data, multiple regression models are trained and evaluated. The API is called to create a Ridge Regression model pipeline with PolynomialFeatures as preprocessor. This pipeline is then fitted on the training data, and GridSearchCV is used to tune the hyperparameters of the Ridge Regression model. Finally, the performance of the tuned Ridge Regression model is compared with other models to identify the best model for each dataset."}}], "source": "kaggle"}, {"id": "marcinrutecki-regression-models-evaluation-metrics-026", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-gridsearchcv"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "Pipeline(steps=[('poly', PolynomialFeatures()), ('model', Ridge(alpha=3.8))])", "param_grid": "[{model__alpha: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]}]", "cv": 10}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet showcases the performance comparison of various regression models for predicting Avocado and Boston house prices. After pre-processing the data, multiple models, including Linear Regression, Random Forest, Ridge Regression, and XGBoost, are evaluated. As a bonus, the API call is used to perform hyperparameter tuning using GridSearchCV on Ridge Regression. This is done by creating a pipeline with PolynomialFeatures and Ridge Regression, and then using GridSearchCV to search for the optimal alpha value within a specified range. The tuned Ridge Regression model is then evaluated and the performance of all models is compared through visualizations."}}], "source": "kaggle"}, {"id": "marcinrutecki-regression-models-evaluation-metrics-027", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-cross-val-score"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "GridSearchCV(cv=10,\n             estimator=Pipeline(steps=[('poly', PolynomialFeatures()),\n         ...", "X": "dataframe(shape=(11317, 62))", "y": "series(shape=(11317,))", "cv": 10}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to compare different regression models on the Avocado and Boston House Prices datasets. Various models are trained, and their performance is evaluated using metrics like R2 Score, Adjusted R2 Score, and RMSE. The API is called to perform cross-validation on the trained models, which helps in assessing the models' performance on unseen data. After the cross-validation, the performance metrics are calculated and visualized in bar plots to compare different models and choose the best one based on the Cross Validated R2 Score."}}], "source": "kaggle"}, {"id": "marcinrutecki-regression-models-evaluation-metrics-028", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-polynomialfeatures"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"degree": 2}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to compare the performance of various regression models on two datasets: Avocado Prices and Boston House Prices. After data preprocessing, including transforming features and handling outliers, different models such as Linear Regression, Random Forest, Ridge Regression, and XGBoost are trained and evaluated. The API is called to create polynomial features, which are then used in a Ridge Regression model with hyperparameter tuning using GridSearchCV. The final performance comparison is visualized for both datasets, showing the Cross Validated R2 Score for each model."}}], "source": "kaggle"}, {"id": "marcinrutecki-regression-models-evaluation-metrics-029", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-linear-model-ridge"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"alpha": 3.8, "fit_intercept": "True"}}}, {"role": "solutionSummary", "module": {"summary": "The primary goal of this code snippet is to compare different regression models' performance on two datasets: Avocado Prices and Boston House Prices. After loading the datasets, cleaning, and preprocessing, various models such as Linear Regression, Random Forest, Ridge Regression, and XGBoost are built, trained, and evaluated using several metrics like R2 Score, Adjusted R2 Score, Cross-Validated R2 Score, and RMSE. The API call creates a Ridge Regression model with an alpha value of 3.8 and fit_intercept set to True, which is then used in a pipeline along with PolynomialFeatures. The model is trained and tested on both datasets, and its performance is assessed and visualized along with the other models. Additionally, hyperparameter tuning using GridSearchCV is performed for the Ridge Regression model to find the best alpha value for improved performance."}}], "source": "kaggle"}, {"id": "marcinrutecki-regression-models-evaluation-metrics-030", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-pipeline-pipeline"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"steps": "[('poly', PolynomialFeatures()), ('model', Ridge(alpha=3.8))]"}}}, {"role": "solutionSummary", "module": {"summary": "This code snippet is focused on evaluating and comparing different regression models for predicting avocado prices and Boston house prices. In this particular section, a Ridge Regression model with hyperparameter tuning using GridSearchCV is implemented. Before the API call, a pipeline is set up with two steps: (1) creating polynomial features using PolynomialFeatures() and (2) applying Ridge Regression with alpha=3.8. The pipeline is created and then fitted on the training data. Once the model is fitted, it is evaluated on the test data and the performance metrics are calculated for the tuned Ridge Regression model. This process is done for both the avocado and Boston datasets, and the final performance comparison is visualized using bar plots."}}], "source": "kaggle"}, {"id": "marcinrutecki-regression-models-evaluation-metrics-031", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-gridsearchcv"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "Pipeline(steps=[('poly', PolynomialFeatures()), ('model', Ridge(alpha=3.8))])", "param_grid": "[{model__alpha: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]}]", "cv": 10}}}, {"role": "solutionSummary", "module": {"summary": "The goal is to compare different regression models on two datasets, Avocado Prices and Boston House Prices. After preprocessing the data, various models are trained and evaluated using performance metrics such as R2 score, Adjusted R2 score, and RMSE. To further improve the performance of the Ridge Regression model, hyperparameter tuning is performed using GridSearchCV. Before the API call, a pipeline with PolynomialFeatures and Ridge Regression is set up, and a parameter grid with a range of alpha values is created. The API call performs a grid search with 10-fold cross-validation to find the best alpha value for the Ridge Regression model. After the tuning, the best parameter combination is identified, and the performance of the tuned model is evaluated and compared with other models."}}], "source": "kaggle"}, {"id": "marcinrutecki-regression-models-evaluation-metrics-032", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-cross-val-score"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "GridSearchCV(cv=10,\n             estimator=Pipeline(steps=[('poly', PolynomialFeatures()),\n         ...", "X": "dataframe(shape=(354, 13))", "y": "series(shape=(354,))", "cv": 10}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to evaluate regression models on the Avocado Prices dataset and the Boston House Prices dataset. After preprocessing the data, the API call is used to compute the cross-validated R2 score for each regression model, which includes Linear Regression, Random Forest, Ridge Regression, XGBoost, and Recursive Feature Elimination (RFE). By obtaining the cross-validated R2 score, the performance of each model can be compared, and the best model can be selected for the given datasets. The obtained performance metrics are then visualized using bar plots. Finally, hyperparameter tuning using GridSearchCV is demonstrated on Ridge Regression for both datasets."}}], "source": "kaggle"}, {"id": "taronzakaryan-predicting-stock-prnce-using-lstm-mo-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-minmaxscaler"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"feature_range": "(-1, 1)"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict IBM stock prices using an LSTM model with PyTorch. The dataset is loaded, processed, and cleaned by filling missing values with the forward fill method. The API call is used to create a MinMaxScaler that scales the 'Close' price column values between -1 and 1 to normalize the data, which helps in training the LSTM model. After scaling the data, it is split into training and testing sets, and the LSTM model is built, trained, and evaluated using the normalized data. Finally, the predictions are plotted against the actual IBM stock prices to visualize the model's performance."}}], "source": "kaggle"}, {"id": "firstkits-bigdata-engineer-test-sample-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-train-test-split"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"[0]": "dataframe(shape=(53940, 26))", "[1]": "series(shape=(53940,))", "train_size": 0.8, "shuffle": "False"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to find the top 100 most expensive diamond prices from a dataset that has been split into training and testing sets. The dataset is first loaded and the target variable (prices) is separated from the features. Then, the API is called to split the dataset into training (80%) and testing (20%) sets without shuffling, maintaining the order of the data. After the split, the dataset is processed further to find the top 100 most expensive diamond prices and the result is computed."}}], "source": "kaggle"}, {"id": "avnika22-world-happiness-reporn-eda-clustering-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-normalize"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"X": "dataframe(shape=(156, 7))"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to analyze the World Happiness Report and gain insights using hierarchical clustering and K-means clustering. Before applying these clustering methods, it is important to normalize the data to ensure that variables with different magnitudes do not bias the model. The API call is used to normalize the dataset, scaling the features to have unit norms. After normalization, the data is transformed into a dataframe, upon which dendrograms are plotted to determine the optimal number of clusters for hierarchical clustering. The K-means clustering method is then applied to the dataset with a specified number of clusters."}}], "source": "kaggle"}, {"id": "avnika22-world-happiness-reporn-eda-clustering-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-cluster-agglomerativeclustering"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_clusters": 2, "affinity": "euclidean", "linkage": "ward"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to analyze the World Happiness Report dataset and cluster countries based on their features. To achieve this, the AgglomerativeClustering API is called with specified parameters to create a hierarchical clustering model. Before the API call, the data is normalized to ensure variables are on the same scale. A dendrogram is then plotted to determine the optimal number of clusters. After the API call, the model's predicted clusters are visualized on a scatter plot, clearly showing two distinct clusters based on the 'GDP per capita' and 'Perceptions of corruption' features."}}], "source": "kaggle"}, {"id": "avnika22-world-happiness-reporn-eda-clustering-003", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-cluster-kmeans"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_clusters": 3}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to analyze the World Happiness Report dataset and explore clustering techniques. After preprocessing and visualizing the data, the API is called to perform K-Means clustering with three clusters on the selected features: \"Social support\" and \"Healthy life expectancy\". The centroids of the clusters are calculated and visualized on a scatter plot, showing the clear separation of the three clusters based on the chosen features. The clustering results can help identify patterns or relationships among countries with similar happiness factors."}}], "source": "kaggle"}, {"id": "aryantiwari123-diabetes-srediction-eda-10-models-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-train-test-split"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"[0]": "dataframe(shape=(768, 8))", "[1]": "series(shape=(768,))", "test_size": 0.2, "random_state": 0}}}, {"role": "solutionSummary", "module": {"summary": "The task is to predict the onset of diabetes using diagnostic measures from the Pima Indians Diabetes dataset. The dataset is first analyzed using various EDA techniques, such as correlation matrices, histograms, and boxplots. The API call splits the dataset into training and testing sets, allocating 80% of the data for training and 20% for testing. Ten different machine learning models are then trained on the training data and evaluated on the testing data, with their respective accuracy scores calculated and compared to determine the best-performing model."}}], "source": "kaggle"}, {"id": "aryantiwari123-diabetes-srediction-eda-10-models-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-linear-model-logisticregression"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_neighbors": 7}}}, {"role": "solutionSummary", "module": {"summary": "The goal of the code snippet is to predict the onset of diabetes based on diagnostic measures using various machine learning models and comparing their performance. After loading the dataset, performing exploratory data analysis, and splitting the data into training and testing sets, the API is called to create a K-Nearest Neighbors classifier with a specified number of neighbors. The model is then fit on the training data and used to predict the outcomes on the testing data. The performance of this model is then compared with other models, such as Logistic Regression, Support Vector Machines, Naive Bayes, Decision Trees, Random Forests, AdaBoost, Gradient Boosting, XGBoost, and Extra Trees classifier."}}], "source": "kaggle"}, {"id": "aryantiwari123-diabetes-srediction-eda-10-models-003", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-svm-svc"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is focused on predicting the onset of diabetes using the Pima Indians Diabetes Database. After loading the dataset, performing exploratory data analysis, and splitting the data into training and testing sets, the API is called to create and fit a Gaussian Naive Bayes classifier. Subsequently, the model's performance is evaluated using various metrics like classification reports, confusion matrices, mean squared error, and R2 score. The same process is followed for other classifiers, and the accuracy scores are compared to determine the best performing model."}}], "source": "kaggle"}, {"id": "aryantiwari123-diabetes-srediction-eda-10-models-004", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-tree-decisiontreeclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"max_depth": 6, "random_state": 123, "criterion": "entropy"}}}, {"role": "solutionSummary", "module": {"summary": "The goal is to predict the onset of diabetes based on diagnostic measures using various machine learning models. After loading the dataset, cleaning it, and performing exploratory data analysis, the dataset is split into training and testing sets. The API call is made to create a Decision Tree Classifier with specific parameters, which is trained and evaluated. Several other classifiers are also trained and evaluated, and their performance is compared using the accuracy score to find the best model for the given problem."}}], "source": "kaggle"}, {"id": "aryantiwari123-diabetes-srediction-eda-10-models-005", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-ensemble-randomforestclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"base_estimator": "None"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict the onset of diabetes using diagnostic measures. Various machine learning algorithms are applied to the Pima Indians Diabetes dataset. After loading the dataset and performing exploratory data analysis, the data is split into training and testing sets. The API is called to create an AdaBoost classifier with no base_estimator, and the model is fitted on the training data. Subsequently, the model's predictions are compared with the actual values, and the accuracy score is computed."}}], "source": "kaggle"}, {"id": "johndoeoeod-cyvid-19-lstm-xgbr-svr-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-labelencoder"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"feature_range": "(0, 1)"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict COVID-19 confirmed cases and fatalities using various machine learning models such as XGBoostRegressor. The dataset is loaded, preprocessed, and split into training and testing sets. Before the API call, the target columns, ConfirmedCases and Fatalities, are dropped from the input features. The API is called to scale the features within the range of 0 to 1. After scaling, the input features are further preprocessed using StandardScaler, and then several models, such as XGBRegressor, are trained and evaluated for predicting confirmed cases and fatalities. Finally, the predictions are combined and saved in a submission file."}}], "source": "kaggle"}, {"id": "johndoeoeod-cyvid-19-lstm-xgbr-svr-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-scale"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"X": "array(shape=(20580, 2))"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is designed to forecast the number of confirmed cases and fatalities of COVID-19. The dataset is loaded, preprocessed, and encoded to be suitable for model training. Before the API call, the data is transformed using MinMaxScaler, and the API is then called to standardize the dataset by removing the mean and scaling it to unit variance. After the standardization, train-test split is performed, and the XGBoost Regressor model is built and trained for each target variable, confirmed cases and fatalities. Finally, predictions are made, processed, and saved as a CSV file for submission."}}], "source": "kaggle"}, {"id": "johndoeoeod-cyvid-19-lstm-xgbr-svr-003", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-minmaxscaler"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"feature_range": "(0, 1)"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to forecast the number of confirmed cases and fatalities of COVID-19 using the XGBoost Regressor model. After loading the training dataset, preprocessing tasks are performed, including dropping unnecessary columns and handling missing values. The API call is used to apply MinMaxScaler with a feature range between 0 and 1 to the target variable 'Fatalities', which scales the variable to fit within the specified range. The dataset is then split into training and testing sets, the model is trained, and predictions are made for the test dataset. Finally, these predictions are saved to a submission file."}}], "source": "kaggle"}, {"id": "johndoeoeod-cyvid-19-lstm-xgbr-svr-004", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-scale"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"X": "array(shape=(20580, 1))"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to forecast the number of confirmed cases and fatalities of COVID-19 using the XGBoost Regressor model. The dataset is preprocessed, and the target variable for fatalities is extracted and stored in variable 'y'. The API is called to scale the target variable to ensure that the model's performance is not affected by the range of the target values. After scaling the target variable, the data is split into training and testing sets, and the XGBoost Regressor model is trained and used for predictions. Finally, a submission file is created with the predicted confirmed cases and fatalities."}}], "source": "kaggle"}, {"id": "johndoeoeod-cyvid-19-lstm-xgbr-svr-005", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-train-test-split"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"[0]": "array(shape=(20580, 2))", "[1]": "array(shape=(20580, 1))", "test_size": 0.2}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to forecast the number of confirmed cases and fatalities of COVID-19 using various machine learning models, including XGBoost. The training dataset is loaded, preprocessed, and label-encoded. The API call is used to split the dataset into training and testing sets. After the split, two separate XGBoost models are trained, one for predicting confirmed cases and the other for predicting fatalities. The models are then used to make predictions on the test dataset, and the final submission is prepared by combining the predictions for confirmed cases and fatalities before saving it to a CSV file."}}], "source": "kaggle"}, {"id": "johndoeoeod-cyvid-19-lstm-xgbr-svr-006", "modules": [{"role": "algorithm", "purpose": "API", "module": "xgboost-xgbregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 1000}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is focused on predicting the number of confirmed cases and fatalities for the COVID-19 global forecasting using the XGBoost regressor. The dataset is loaded, preprocessed, and split into training and testing sets. The API call is used to create an XGBoost Regressor model with 1000 estimators. Then, the model is fitted to the training data and used to make predictions on the transformed test data. The predictions are then merged with the original dataset and saved to a submission file."}}], "source": "kaggle"}, {"id": "johndoeoeod-cyvid-19-lstm-xgbr-svr-007", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-scale"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"X": "array(shape=(12642, 2))"}}}, {"role": "solutionSummary", "module": {"summary": "The goal of the code snippet is to forecast the number of COVID-19 confirmed cases and fatalities using various machine learning models, such as XGBoost Regressor. After loading the data and preprocessing it, including encoding categorical variables and filling missing values, the API is called to standardize the test dataset by removing the mean and scaling to unit variance. This is done to ensure that the models perform better since many algorithms assume that all features are centered around zero and have the same variance. Following this, the models are trained on the preprocessed data, and predictions are made on the standardized test dataset. The final submission is generated with the predictions and saved as a CSV file."}}], "source": "kaggle"}, {"id": "sixteenpython-covid-19-transmission-rates-and-fact-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "xgboost-xgbregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 2000}}}, {"role": "solutionSummary", "module": {"summary": "The primary goal of this analysis is to find factors that impact the transmission rate of COVID-19. After loading, preprocessing, and visualizing the data, the focus shifts to predictive analytics for forecasting confirmed cases and fatalities. The API is called to create an XGBoost Regressor model with 2000 estimators for predicting both confirmed cases and fatalities. The model is then fitted on training data for each country and state combination and used to predict the testing data. This process is repeated for both XGBoost and LightGBM models, and the final predictions are averaged between the two models before generating the submission file."}}], "source": "kaggle"}, {"id": "sixteenpython-covid-19-transmission-rates-and-fact-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "xgboost-xgbregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 2000}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet focuses on determining the factors that impact the transmission rate of COVID-19 and predicting the spread of the virus using predictive analytics. After loading and preprocessing the data, the XGBoost algorithm is employed to create regression models for predicting the number of confirmed cases and fatalities. The XGBRegressor API is called with n_estimators set to 2000 to build the models. The models are trained on the preprocessed data and used to predict the number of confirmed cases and fatalities for each country and state in the test dataset. The predictions from the XGBoost models are then combined with those from LightGBM models in order to produce the final predictions for submission."}}], "source": "kaggle"}, {"id": "sixteenpython-covid-19-transmission-rates-and-fact-003", "modules": [{"role": "algorithm", "purpose": "API", "module": "lightgbm-lgbmmodel"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 2000}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet's primary goal is to find the key factors that impact the transmission rate of COVID-19 and build a predictive model. The LightGBM API is used to create a gradient boosting model for predicting the number of confirmed cases and fatalities. Prior to the API call, the dataset is preprocessed, including handling missing values, encoding categorical variables, and grouping the data by country and state. The LightGBM model is then trained on the preprocessed data with 2000 estimators. After training, the model is used to make predictions on the test dataset. The final predictions are obtained by averaging the results of both LightGBM and XGBoost models, and the results are saved to a submission file."}}], "source": "kaggle"}, {"id": "sixteenpython-covid-19-transmission-rates-and-fact-004", "modules": [{"role": "algorithm", "purpose": "API", "module": "lightgbm-lgbmmodel"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 2000}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet focuses on predicting the transmission rate of COVID-19 based on factors such as temperature, relative humidity, and air travel. The dataset is preprocessed and divided into training and testing sets. The API is called to create a LightGBM Regressor model, which is a gradient boosting framework that utilizes tree-based learning algorithms. The model is then trained on the training set with the specified number of estimators. After training, the model is used to make predictions on the testing set. The process is done for both confirmed cases and fatalities. The predicted results are combined from two different models (XGBoost and LightGBM) with equal weights and the final submission file is created."}}], "source": "kaggle"}, {"id": "vaidyapragad84-ps3-e4-eda-sampling-ft-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-robustscaler"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 500, "learning_rate": 0.03, "one_hot_max_size": 12, "depth": 4, "l2_leaf_reg": 0.014, "colsample_bylevel": 0.06, "min_data_in_leaf": 12, "boosting_type": "Plain", "bootstrap_type": "Bernoulli", "verbose": "False"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is for detecting credit card fraud using a combination of CatBoost, LightGBM, and XGBoost classifiers. After importing the data, performing EDA, and transforming the features, the API is called to create a CatBoostClassifier with specific hyperparameters. Subsequently, the script also sets hyperparameters for LightGBM and XGBoost classifiers. The classifiers are then trained on various oversampled and undersampled subsets of the training data, and their predictions are combined to form an ensemble model. The classifiers' performance is evaluated using ROC-AUC scores, and the final predictions are prepared for submission."}}], "source": "kaggle"}, {"id": "vaidyapragad84-ps3-e4-eda-sampling-ft-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "lightgbm-lgbmmodel"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 500, "num_rounds": 274, "learning_rate": 0.1, "num_leaves": 195, "max_depth": 9, "min_data_in_leaf": 46, "lambda_l1": 0.01, "lambda_l2": 0.6000000000000001, "min_gain_to_split": 1.42, "bagging_fraction": 0.45, "feature_fraction": 0.30000000000000004, "verbose": -1}}}, {"role": "solutionSummary", "module": {"summary": "The task is credit card fraud detection using a combination of LightGBM, CatBoost, and XGBoost classifiers. The code snippet starts by loading the dataset, performing exploratory data analysis, and feature transformation. The LightGBM classifier is initialized with specific parameters. The classifiers are then trained on multiple combinations of oversampled and undersampled data in order to improve the model's performance on the imbalanced dataset. Finally, the predictions are combined to form an ensemble and submitted to the competition."}}], "source": "kaggle"}, {"id": "vaidyapragad84-ps3-e4-eda-sampling-ft-003", "modules": [{"role": "algorithm", "purpose": "API", "module": "xgboost-xgbclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 2000, "min_child_weight": 96, "max_depth": 7, "learning_rate": 0.18, "subsample": 0.9500000000000001, "colsample_bytree": 0.9500000000000001, "reg_lambda": 1.5, "reg_alpha": 1.5, "gamma": 1.5, "max_bin": 512, "random_state": 42, "objective": "binary:logistic", "tree_method": "hist", "eval_metric": "auc"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is focused on credit card fraud detection. It involves data preprocessing, feature transformation, and model training using multiple classifiers, including CatBoost, LightGBM, and XGBoost. The API call is used to create an XGBoost classifier with specific hyperparameters. The classifiers are trained on oversampled and undersampled data to address class imbalance. The classifiers' performance is evaluated based on the AUC-ROC score, and an ensemble of the classifiers is created for the final predictions. The predictions are then saved to a submission file for evaluation."}}], "source": "kaggle"}, {"id": "ohseokkim-diabetes-three-ensembleimodels-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-quantiletransformer"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_quantiles": 100, "random_state": 0, "output_distribution": "normal"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet focuses on solving a diabetes classification problem using ensemble models and the Pima Indians Diabetes dataset. After checking for missing values, target imbalance, and outliers, the data is preprocessed using the QuantileTransformer API to perform non-linear scaling. This is done to transform the data into a normal distribution, which can improve the performance of certain machine learning models. After applying the QuantileTransformer, the data is splitted into training and testing sets, and ensemble models such as stacking, soft voting, and hard voting are trained and evaluated for classification performance."}}], "source": "kaggle"}, {"id": "ohseokkim-diabetes-three-ensembleimodels-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-train-test-split"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"[0]": "dataframe(shape=(768, 8))", "[1]": "series(shape=(768,))", "test_size": 0.25, "random_state": 42}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to solve a diabetes classification problem by training ensemble models on a dataset with preprocessed features. After examining missing values, scaling the features, and performing dimensionality reduction, the dataset is split into training and testing sets using the API call. The test_size parameter represents the proportion of the dataset to be reserved for testing, while the random_state parameter ensures consistent results across multiple runs. After splitting the data, an ensemble modeling approach is employed, including stacking, soft voting, and hard voting, with the model performance evaluated using different metrics."}}], "source": "kaggle"}, {"id": "mostafaabdlhamedyavocado-prices-repression-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-labelencoder"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"score_func": "<function f_regression at 0x78a1df6bed40>", "k": 10}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict avocado prices using various features from a dataset. After data preprocessing, feature engineering, and data visualization, the API call is used to select the 10 most relevant features for model training, using the f_regression test. The selected features are then used to train and evaluate the performance of Linear Regression, Ridge Regression, and Lasso Regression models. Ridge Regression is identified as the best model, and its hyperparameters are further tuned using GridSearchCV. Finally, the model's performance is evaluated using R2 score and Mean Absolute Percentage Error (MAPE)."}}], "source": "kaggle"}, {"id": "mostafaabdlhamedyavocado-prices-repression-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-standardscaler"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"[0]": "array(shape=(18246, 12))", "[1]": "series(shape=(18246,))", "test_size": 0.2, "random_state": 0}}}, {"role": "solutionSummary", "module": {"summary": "The goal of the code snippet is to predict avocado prices using various regression models. After loading and preprocessing the data, including feature engineering and scaling, the API is called to split the dataset into training and testing sets. Following the split, different regression models, including Linear Regression, Ridge Regression, and Lasso Regression, are trained and evaluated using the training and testing sets. The best model is selected based on the R2 score, and GridSearchCV is then used to fine-tune the model's hyperparameters, ultimately providing the performance metrics of the best model."}}], "source": "kaggle"}, {"id": "mostafaabdlhamedyavocado-prices-repression-003", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-linear-model-linearregression"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"alpha": 1.0}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict avocado prices using various regression models. After preprocessing and feature engineering, the dataset is scaled, and a function is defined to evaluate and compare Linear Regression, Ridge Regression, and Lasso Regression models. In this context, the API call initializes a Ridge Regression model with a default alpha value. The function fits the models, calculates their performance metrics, and identifies the best model. Subsequently, the best model (Ridge Regression) is further tuned using GridSearchCV, and the Mean Absolute Percentage Error (MAPE) is calculated for the final model."}}], "source": "kaggle"}, {"id": "mostafaabdlhamedyavocado-prices-repression-004", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-polynomialfeatures"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"degree": 2, "interaction_only": "True", "include_bias": "False"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict avocado prices using linear regression, ridge regression, and lasso regression. After data preprocessing, feature engineering, and visualization, the API is called to generate polynomial features with a degree of 2 and only considering interaction terms. These polynomial features are then used to train and evaluate a lasso regression model. The performance of all three models is compared, and the best model is selected based on the R-squared score. Hyperparameter tuning is then performed using GridSearchCV on the best model, and the final performance is evaluated using the R-squared score and mean absolute percentage error (MAPE)."}}], "source": "kaggle"}, {"id": "mostafaabdlhamedyavocado-prices-repression-005", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-linear-model-lasso"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {}}}, {"role": "solutionSummary", "module": {"summary": "The goal is to predict the average price of avocados using various features such as region, type, and date. After cleaning and preprocessing the data, several visualizations are created to understand the relationships between features and the target variable. Ridge regression is then instantiated as one of the models to be evaluated. Other models, such as linear regression and Lasso regression, are also trained and evaluated on the dataset. The best model is then identified, and hyperparameter tuning is performed using GridSearchCV. After finding the optimal parameters, the performance of the best model is evaluated using R2 score and Mean Absolute Percentage Error (MAPE)."}}], "source": "kaggle"}, {"id": "mostafaabdlhamedyavocado-prices-repression-006", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-gridsearchcv"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimator": "Ridge()", "param_grid": "{alpha: [1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0, 100000.0, 1000000.0], max_iter: [100, 400, 500, 1000]}", "cv": 5, "scoring": "r2", "n_jobs": -1}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict avocado prices using various regression models. After data preprocessing, feature engineering, and visualization, the data is split into training and testing sets, and three regression models (Linear, Ridge, and Lasso) are evaluated. Ridge regression is identified as the best model, and then the API is called to perform hyperparameter tuning using GridSearchCV with a predefined parameter grid for alpha and max_iter values. After fitting, the best parameters and score are displayed, and the best model is used to make predictions on the testing set, followed by calculating the r2 score and Mean Absolute Percentage Error (MAPE) for evaluation."}}], "source": "kaggle"}, {"id": "shelars1x85-anomaly-detection-using-gaussian-distr-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-ensemble-randomforestclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 100, "criterion": "entropy", "random_state": 0}}}, {"role": "solutionSummary", "module": {"summary": "The task is to detect credit card fraud using an anomaly detection technique. After loading the dataset and preprocessing it, the API is called to create a RandomForestClassifier, which will be used to identify influential features in the data. The model is then fitted with selected features. Subsequently, the feature importances are plotted and features with low importance are dropped. The remaining features are used to create subsets for training, cross-validation, and testing. The code then focuses on finding the optimal threshold (epsilon value) and evaluating the model performance in detecting anomalous transactions using F1 score, recall, and precision."}}], "source": "kaggle"}, {"id": "ehsandahesh-stock-market-predict-voiume-with-lstm-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-minmaxscaler"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"feature_range": "(0, 1)"}}}, {"role": "solutionSummary", "module": {"summary": "The goal of the code snippet is to predict stock prices using a Long Short-Term Memory (LSTM) model. The dataset containing stock data is loaded, visualized, and preprocessed. The API call is used to create a MinMaxScaler object to normalize the data values to a range between 0 and 1. The normalized data is then transformed into a supervised learning problem format, split into training and testing sets, and reshaped for the LSTM model. Following the API call, the LSTM model is built, trained, and used to make predictions, which are then visualized and compared to the actual stock prices."}}], "source": "kaggle"}, {"id": "rajeshjnv-mq-tn-visuckigation-predsctiofyof-apparw-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-train-test-split"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"[0]": "dataframe(shape=(9360, 41))", "[1]": "array(shape=(9360,))", "test_size": 0.2, "random_state": 0}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is an exploratory data analysis and evaluation of Google Play Store apps dataset. The dataset is preprocessed using pandas, and categorical features are converted into dummy variables. The target variable is the app rating. The API call is used to split the dataset into training and testing sets, with 80% of the data used for training and 20% for testing. After the split, various machine learning models, such as Logistic Regression, Decision Tree Classifier, SVM Regressor, and Random Forest, are trained and tested on the dataset. The performance of each model is then compared to determine the best model for predicting app ratings."}}], "source": "kaggle"}, {"id": "rajeshjnv-mq-tn-visuckigation-predsctiofyof-apparw-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-standardscaler"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"random_state": 0}}}, {"role": "solutionSummary", "module": {"summary": "This code snippet aims to analyze the Google Play Store dataset and make predictions on app ratings. After cleaning and preparing the data, various machine learning models are tested and compared. The API is called to create a Logistic Regression model, which is then fit using the training data. After fitting the model, it is used to make predictions on the test dataset. The performance of the Logistic Regression model is evaluated and compared with other models like Decision Tree Classifier, SVM Regressor, and Random Forest Classifier, providing an insight into which model performs best for the given dataset."}}], "source": "kaggle"}, {"id": "rajeshjnv-mq-tn-visuckigation-predsctiofyof-apparw-003", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-tree-decisiontreeclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"criterion": "entropy", "random_state": 0}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict Google Play Store app ratings using various machine learning models. After loading the dataset, preprocessing and visualizing the data, dummy variables are created and the data is then split into training and testing sets. The API call is made to create a DecisionTreeClassifier with entropy as the criterion for splitting and a specified random state. The classifier is then fitted with the training data and used to make predictions on the testing data. The performance of this model is compared with other models such as Logistic Regression, Support Vector Machine, and RandomForest."}}], "source": "kaggle"}, {"id": "rajeshjnv-mq-tn-visuckigation-predsctiofyof-apparw-004", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-svm-svc"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"kernel": "rbf"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is an analysis of Google Play Store data, aiming to predict app ratings using various machine learning models. After data preprocessing, cleaning, visualization, and feature selection, the dataset is split into training and testing sets. The API call creates an instance of the Support Vector Machine (SVM) classifier with a radial basis function (RBF) kernel. This classifier is then fitted to the training data, and predictions are made on the testing data. The performance of the SVM classifier is evaluated and compared with other machine learning models, to determine the best performing model for the given dataset."}}], "source": "kaggle"}, {"id": "rajeshjnv-mq-tn-visuckigation-predsctiofyof-apparw-005", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-ensemble-randomforestclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 10, "criterion": "entropy", "random_state": 0}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is focused on the analysis of Google Play Store app data to gain insights and predict app ratings. After preprocessing the data, several machine learning models are trained and tested for accuracy, including Logistic Regression, Decision Tree Classifier, SVM Regressor, and the API call to create a Random Forest Classifier. The Random Forest Classifier is set up with 10 estimators, entropy criterion, and a random state for reproducibility. After training each model, their performance is compared using accuracy scores, and the results are visualized in a bar chart to determine the most accurate model for predicting app ratings."}}], "source": "kaggle"}, {"id": "parulpandby-intrepreting-machine-ldarfing-models-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-train-test-split"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"[0]": "dataframe(shape=(768, 8))", "[1]": "series(shape=(768,))", "test_size": 0.25, "random_state": 0}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to understand and explain the predictions of machine learning models. A dataset containing information about diabetic patients is loaded and preprocessed. The API call is used to split the dataset into training and testing sets. Various techniques are then applied for model interpretability, such as Permutation Importance, Partial Dependence Plots, SHAP values, and LIME. These techniques provide insights into the importance of different features on the model's predictions and help visualize the relationships between features and the target variable."}}], "source": "kaggle"}, {"id": "parulpandby-intrepreting-machine-ldarfing-models-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-ensemble-randomforestclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 100, "random_state": 0}}}, {"role": "solutionSummary", "module": {"summary": "The objective of this code snippet is to demonstrate various techniques for extracting human-understandable insights from machine learning models. The dataset used contains diagnostic measurements for predicting the presence of diabetes. The API call is made to build and train a RandomForestClassifier model on the training dataset. After the model is trained, various techniques such as Permutation Importance, Partial Dependence Plots, SHAP values, and LIME are applied in order to understand and interpret the model's predictions. These techniques help in identifying the importance of features, their marginal effects, and contributions to individual predictions, enabling better understanding of the model's decision-making process."}}], "source": "kaggle"}, {"id": "parulpandby-intrepreting-machine-ldarfing-models-003", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-tree-decisiontreeclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"random_state": 0}}}, {"role": "solutionSummary", "module": {"summary": "This code snippet focuses on explaining machine learning model decisions using various techniques, such as Permutation Importance, Partial Dependence Plots, SHAP Values, and LIME. The API call is used to create a Decision Tree Classifier for the diabetes dataset. After loading the dataset, preprocessing and splitting it into training and testing sets, the model is trained and fitted using the training data. The model's predictions are then used in conjunction with several interpretability techniques to understand and visualize the impact of different features on the model's decision-making process."}}], "source": "kaggle"}, {"id": "parulpandby-intrepreting-machine-ldarfing-models-004", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-tree-export-graphviz"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"decision_tree": "DecisionTreeClassifier(random_state=0)", "out_file": "None", "feature_names": "[\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\"]", "filled": "True"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet discusses various techniques to explain the interpretability of machine learning model predictions. In this context, a decision tree model is trained on the diabetes dataset to predict whether a patient has diabetes or not. The sklearn.tree.export_graphviz API is called to visualize the decision tree in a graph format, making it easier to understand the model's decision-making process. The graphviz library is then used to display the graph. The output graph can be further saved as an image file for better visualization and analysis. This visualization helps to comprehend the importance of different features in making predictions and provides insight into the model's decision-making process."}}], "source": "kaggle"}, {"id": "bryanb-stock-prices-forecasting-with-lstm-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-minmaxscaler"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"feature_range": "(0, 1)"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict stock prices using an LSTM model. First, the stock data is loaded, and the 'Close' column is extracted. To prepare the data for the LSTM model, the API call is made to create a MinMaxScaler that scales the closing prices to a range of (0, 1). After scaling, the data is split into the input and output for training the LSTM model. Once the model is trained and predictions are made, the MinMaxScaler is used to invert the scaling on the predicted prices to obtain actual price values."}}], "source": "kaggle"}, {"id": "lexcalibur-learning1-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-labelencoder"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet forecasts COVID-19 confirmed cases and fatalities using the XGBoost algorithm. The training and testing datasets are preprocessed by filling missing values, merging columns, and applying label encoding for categorical features. The API call is used to create a MinMaxScaler instance that scales the features of the training and testing datasets to a specific range. After scaling the data, the XGBoost model is trained separately for confirmed cases and fatalities and then used to make predictions on the testing dataset. The predictions are rounded off, and any negative values are replaced with zero. Finally, the output is saved into a submission file."}}], "source": "kaggle"}, {"id": "lexcalibur-learning1-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "xgboost-xgbregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 1500, "max_depth": 15, "learning_rate": 0.1}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to forecast the number of confirmed COVID-19 cases and fatalities using the XGBoost regressor. The datasets are preprocessed, which includes filling missing values, merging columns, splitting dates, encoding categorical features, and scaling the input data. The API is called to create two XGBRegressor models with specified hyperparameters. The models are then fitted on the training data for confirmed cases and fatalities separately. Finally, predictions are made on the test data, negative values are set to zero, and the results are written to a submission file."}}], "source": "kaggle"}, {"id": "lexcalibur-learning1-003", "modules": [{"role": "algorithm", "purpose": "API", "module": "xgboost-xgbregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 1500, "max_depth": 15, "learning_rate": 0.1}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is aimed at predicting the number of confirmed cases and fatalities of COVID-19 using an XGBoost Regressor model. After loading the data, preprocessing it, and encoding categorical variables, the dataset is split into training and testing sets. The API call creates an XGBoost Regressor model with specific hyperparameters. This model is then fitted separately for confirmed cases and fatalities using the training data. The model's predictions for the testing dataset are generated, rounded off, and negative values are set to zero. Finally, the results are saved to a 'submission.csv' file."}}], "source": "kaggle"}, {"id": "sagarbapodara-movie-recommendatifn-system-web-app-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-feature-extraction-text-countvectorizer"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"max_features": 5000, "stop_words": "english"}}}, {"role": "solutionSummary", "module": {"summary": "This code snippet aims to create a movie recommendation system using content-based filtering. After preprocessing the movie dataset, a new DataFrame is created containing movie_id, title, and tags. The tags are a combination of title, overview, genres, cast, keywords, and crew (director). The API call is used to vectorize the text in the 'tags' column into a matrix of token counts, with a maximum of 5000 features and removing English stop words. The text vectorization is followed by calculating the cosine similarity between movie vectors, which is used in the recommendation function to suggest similar movies based on the input movie title."}}], "source": "kaggle"}, {"id": "gauravsahani-avocado-pricgs-prediction-and-data-vi-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-train-test-split"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"[0]": "dataframe(shape=(18249, 62))", "[1]": "dataframe(shape=(18249, 1))", "test_size": 0.2, "random_state": 0}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet's task is to predict avocado prices with two different regression models, XGBoost and RandomForestRegressor. After loading the dataset and performing preprocessing, including dropping unnecessary columns and creating dummy variables for categorical features, the API call is used to split the dataset into training and testing sets. With the data split, the two regression models are trained on the training set, and their performance is evaluated on the test set using the R\u00b2 score metric."}}], "source": "kaggle"}, {"id": "gauravsahani-avocado-pricgs-prediction-and-data-vi-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "xgboost-xgbregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"random_state": 1}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is designed to predict the average price of avocados using a dataset containing various features related to the product. After loading the dataset, preprocessing is done by removing unwanted columns and creating dummy variables for the categorical features. The dataset is then split into training and testing sets using train_test_split. The API is called to create a RandomForestRegressor model with a fixed random state. The model is trained on the training set and predictions are made on the test set. The performance of the model is then evaluated using the R2 score."}}], "source": "kaggle"}, {"id": "alexandershumilin-ps-s3-e4-ensemble-model-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-robustscaler"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_splits": 2, "n_repeats": 30, "random_state": 42}}}, {"role": "solutionSummary", "module": {"summary": "The goal of the code snippet is to detect credit card fraud using a combination of classification and regression models. The API call is used to create a RepeatedStratifiedKFold object that will be used to split the training data into folds for cross-validation. Before the API call, the data is preprocessed with additional features and scaling. After the API call, multiple machine learning models, including CatBoost, XGBoost, and LightGBM, are trained using the RepeatedStratifiedKFold object. These models are then combined using a weighted average to create a final ensemble prediction, which is saved as a submission file."}}], "source": "kaggle"}, {"id": "alexandershumilin-ps-s3-e4-ensemble-model-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "catboost-catboostregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 500, "learning_rate": 0.03, "one_hot_max_size": 12, "depth": 4, "l2_leaf_reg": 0.014, "colsample_bylevel": 0.06, "min_data_in_leaf": 12, "boosting_type": "Plain", "bootstrap_type": "Bernoulli", "verbose": "False"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is designed to predict a binary class using various machine learning models, including CatBoostRegressor, on an imbalanced dataset. The dataset is preprocessed, and features are generated before the API call. Oversampling and undersampling techniques are applied to handle the imbalanced data. The API call creates a CatBoostRegressor model with specific parameters and fits it to the training data. The model is then stored in a list, and predictions are made on the test data. This process is repeated multiple times to create an ensemble of CatBoostRegressor models, and their average predictions are used for the final submission."}}], "source": "kaggle"}, {"id": "alexandershumilin-ps-s3-e4-ensemble-model-003", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-repeatedstratifiedkfold"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_splits": 2, "n_repeats": 30, "random_state": 42}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet's goal is to classify credit card fraud using an ensemble of various machine learning models. The dataset is first preprocessed and augmented by adding external data, feature engineering is performed, and the data is rescaled using RobustScaler. The API call is used to create a cross-validation strategy, specifically RepeatedStratifiedKFold, to evaluate different models' performance. The models include CatBoost, XGBoost, and LightGBM, and their hyperparameters are tuned using Optuna. The predictions from these models are combined using a weighted average to generate the final prediction, which is then saved in a submission file."}}], "source": "kaggle"}, {"id": "alexandershumilin-ps-s3-e4-ensemble-model-004", "modules": [{"role": "algorithm", "purpose": "API", "module": "catboost-catboostclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 500, "learning_rate": 0.03, "one_hot_max_size": 12, "depth": 4, "l2_leaf_reg": 0.014, "colsample_bylevel": 0.06, "min_data_in_leaf": 12, "boosting_type": "Plain", "bootstrap_type": "Bernoulli", "verbose": "False"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is aimed at predicting credit card fraud using an ensemble of models. Preprocessing steps include feature engineering, scaling, and creating an oversampled dataset. After these steps, the CatBoost classifier is created using the specified parameters, and it is trained on the oversampled dataset, which is a combination of the original oversampled data and a sampled subset of the undersampled data. This process is repeated multiple times, and the CatBoost classifier models are stored in a list. The final prediction is an ensemble of predictions from multiple models, including CatBoost classifiers, XGBoost classifiers, LGBM classifiers, and other models. Ultimately, the submission file is generated with the ensemble prediction."}}], "source": "kaggle"}, {"id": "alexandershumilin-ps-s3-e4-ensemble-model-005", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-repeatedstratifiedkfold"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_splits": 2, "n_repeats": 30, "random_state": 42}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet focuses on tackling a binary classification problem using various machine learning models. The RepeatedStratifiedKFold API call is used to create a cross-validation strategy, which ensures that the proportion of each class within each fold is the same, and that the same random state is maintained across multiple repetitions of the cross-validation. This strategy is applied to train and validate multiple models, including CatBoost, XGBoost, and LightGBM, with different configurations for each model. After training, the models' predictions are combined using different coefficients to generate a final prediction which is then saved as a submission file."}}], "source": "kaggle"}, {"id": "alexandershumilin-ps-s3-e4-ensemble-model-006", "modules": [{"role": "algorithm", "purpose": "API", "module": "xgboost-xgbregressor"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 2000, "min_child_weight": 96, "max_depth": 7, "learning_rate": 0.18, "subsample": 0.9500000000000001, "colsample_bytree": 0.9500000000000001, "reg_lambda": 1.5, "reg_alpha": 1.5, "gamma": 1.5, "max_bin": 512, "random_state": 42, "objective": "binary:logistic", "tree_method": "hist", "eval_metric": "rmse"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict credit card fraud using several machine learning algorithms, with an emphasis on ensembling their predictions. For this purpose, the data is preprocessed, feature-engineered, and concatenated with additional data. The API call creates an XGBoost Regressor model, which is then trained on a subsampled dataset multiple times. After training, the models' predictions are stored and later averaged to create a final prediction. This process is repeated for other algorithms such as CatBoost and LightGBM, and their averaged predictions are combined using coefficients determined via optimization to create a final submission file."}}], "source": "kaggle"}, {"id": "alexandershumilin-ps-s3-e4-ensemble-model-007", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-repeatedstratifiedkfold"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_splits": 2, "n_repeats": 30, "random_state": 42}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict fraud detection in an imbalanced dataset by combining multiple machine learning models, including CatBoost, XGBoost, and LightGBM. To achieve this, a RepeatedStratifiedKFold cross-validation is set up, which provides better utilization of the imbalanced data by splitting the dataset into multiple folds and repeating the process several times with different random seeds. This ensures that the models get trained on different combinations of the data, improving their generalization ability. After the API call, various models, such as CatBoost, XGBoost, and LightGBM, are trained using the created cross-validation setup, and their predictions are combined via weighted averaging to generate the final prediction."}}], "source": "kaggle"}, {"id": "alexandershumilin-ps-s3-e4-ensemble-model-008", "modules": [{"role": "algorithm", "purpose": "API", "module": "xgboost-xgbclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 2000, "min_child_weight": 96, "max_depth": 7, "learning_rate": 0.18, "subsample": 0.9500000000000001, "colsample_bytree": 0.9500000000000001, "reg_lambda": 1.5, "reg_alpha": 1.5, "gamma": 1.5, "max_bin": 512, "random_state": 42, "objective": "binary:logistic", "tree_method": "hist", "eval_metric": "auc"}}}, {"role": "solutionSummary", "module": {"summary": "The goal of this code snippet is to predict credit card fraud using an ensemble of machine learning models. After preprocessing the data, the API call is made to create an XGBoost classifier model. This model is trained using different subsets of undersampled data, which are combined with oversampled data to address the class imbalance problem. The model is fit multiple times with different subsets of the data, and the predictions are stored. The final model's predictions are combined with predictions from other models such as CatBoost and LightGBM using ensemble techniques to improve the overall performance, and the results are saved as a submission file."}}], "source": "kaggle"}, {"id": "alexandershumilin-ps-s3-e4-ensemble-model-009", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-repeatedstratifiedkfold"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_splits": 2, "n_repeats": 30, "random_state": 42}}}, {"role": "solutionSummary", "module": {"summary": "In this code snippet, the goal is to create a classification model for a credit card fraud detection problem. The dataset is prepared by combining and preprocessing the provided train, test, and additional data. The API is called to create a RepeatedStratifiedKFold object, which is used to perform cross-validation while maintaining the class distribution within each fold. This is crucial for imbalanced datasets such as fraud detection. Multiple models, including CatBoost, XGBoost, and Lasso, are trained using this cross-validation scheme, with the aim of blending their predictions in a later step to obtain the final submission."}}], "source": "kaggle"}, {"id": "alexandershumilin-ps-s3-e4-ensemble-model-010", "modules": [{"role": "algorithm", "purpose": "API", "module": "lightgbm-lgbmmodel"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 500, "num_rounds": 274, "learning_rate": 0.1, "num_leaves": 195, "max_depth": 9, "min_data_in_leaf": 46, "lambda_l1": 0.01, "lambda_l2": 0.6000000000000001, "min_gain_to_split": 1.42, "bagging_fraction": 0.45, "feature_fraction": 0.30000000000000004, "verbose": -1}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict credit card fraud using several machine learning models, including LightGBM. It starts by combining the playground-series-s3e4 dataset with additional data from a credit card fraud dataset, processing the data to generate new features, and scaling the features. The API call creates a LightGBM classifier with specified parameters and trains it multiple times on different samples of the dataset. The model's predictions are stored in an array, and the final prediction is obtained by averaging the predictions from multiple models. The process is repeated for other models such as CatBoost and XGBoost, and the final submission is generated by combining the predictions from all models using weighted coefficients."}}], "source": "kaggle"}, {"id": "alexandershumilin-ps-s3-e4-ensemble-model-011", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-repeatedstratifiedkfold"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_splits": 2, "n_repeats": 30, "random_state": 42}}}, {"role": "solutionSummary", "module": {"summary": "This code snippet aims to create a credit card fraud detection model using an ensemble of different algorithms, including CatBoost, XGBoost, and LightGBM. The API is used to create a RepeatedStratifiedKFold cross-validation strategy, which ensures that the proportions of the target classes are preserved in each fold and repeats the process a specified number of times to get a better estimate of the model performance. This cross-validation strategy is then applied to train multiple models with different algorithms and hyperparameters, and their predictions are combined to create the final submission."}}], "source": "kaggle"}, {"id": "alexandershumilin-ps-s3-e4-ensemble-model-012", "modules": [{"role": "algorithm", "purpose": "API", "module": "lightgbm-lgbmmodel"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_estimators": 500, "num_rounds": 274, "learning_rate": 0.1, "num_leaves": 195, "max_depth": 9, "min_data_in_leaf": 46, "lambda_l1": 0.01, "lambda_l2": 0.6000000000000001, "min_gain_to_split": 1.42, "bagging_fraction": 0.45, "feature_fraction": 0.30000000000000004, "verbose": -1}}}, {"role": "solutionSummary", "module": {"summary": "The goal of this code snippet is to create an ensemble model for predicting credit card fraud. The dataset is preprocessed, and additional features are generated. The API is called to create a LightGBM model using specific parameters. This model is added to an ensemble alongside CatBoost, XGBoost, and Lasso models. The model is trained several times on different samples of the data to reduce overfitting. After the training is complete, the predictions from all the models are combined using a weighted average to create the final ensemble predictions, which are then used for creating a submission file."}}], "source": "kaggle"}, {"id": "alexandershumilin-ps-s3-e4-ensemble-model-013", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-linear-model-lasso"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"alpha": 0.001}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is designed to predict credit card fraud by training multiple models, including CatBoost, XGBoost, and LightGBM classifiers and regressors. The dataset is first preprocessed and oversampling as well as undersampling techniques are applied. After training several models, the Lasso linear regression model is trained using the selected alpha value of 0.001 to control the strength of the L1 penalty term. Once the model is trained, its predictions are combined with the predictions of the other models using a weighted average, and the final prediction results are saved to a CSV file for submission."}}], "source": "kaggle"}, {"id": "prasadckulkabni-dc-vs-marvel-tableau-eda-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-train-test-split"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"[0]": "dataframe(shape=(2097, 6))", "[1]": "series(shape=(2097,))", "test_size": 0.30000000000000004, "random_state": 342}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet's goal is to analyze data on DC and Marvel comic characters and make predictions using a Decision Tree Classifier. The dataset is preprocessed by removing null values and using one-hot encoding to handle categorical data. The API call is then used to split the preprocessed dataset into training and testing sets. The Decision Tree Classifier model is trained on the training set, and predictions are made on the test set. The model's train and test accuracy scores are computed to evaluate its performance."}}], "source": "kaggle"}, {"id": "prasadckulkabni-dc-vs-marvel-tableau-eda-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-tree-decisiontreeclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"criterion": "entropy", "max_depth": 6, "random_state": 3}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to analyze DC and Marvel comic characters data using various visualization techniques and a decision tree classifier. After preprocessing the data, removing missing values, and applying one-hot encoding on the categorical columns, the DecisionTreeClassifier API is called with specific parameters to create a model. The model is then fit on the training data and used to make predictions on the test data. Finally, the accuracy of the model's predictions on both the training and test sets is calculated and displayed. The process helps in understanding the characteristics of comic characters and comparing trends between the DC and Marvel universes."}}], "source": "kaggle"}, {"id": "prasadckulkabni-dc-vs-marvel-tableau-eda-003", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-train-test-split"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"[0]": "dataframe(shape=(2097, 42))", "[1]": "dataframe(shape=(2097, 3))", "test_size": 0.30000000000000004, "random_state": 342}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet analyzes data on DC and Marvel comic characters, focusing on their attributes like alignment, eye color, and hair color. After loading the DC dataset and preprocessing it by removing null values, one-hot encoding is performed on categorical columns. The API call is used to split the data into training and testing sets with a 70:30 ratio. A Decision Tree Classifier is then trained on the one-hot encoded training data, and predictions are made on the testing data. Finally, the model's accuracy on the training and testing sets is calculated and displayed."}}], "source": "kaggle"}, {"id": "carolynjonesconway-predicting-happiness-by-country-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-linear-model-linearregression"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"[0]": "dataframe(shape=(157, 11))", "test_size": 0.25}}}, {"role": "solutionSummary", "module": {"summary": "The code aims to predict a country's happiness score based on various features using linear regression. The World Happiness dataset is loaded, cleaned, and the correlation between features and the happiness score is analyzed. The API call is used to split the dataset into training and testing sets, with 75% of the data used for training and the remaining 25% for testing. After the split, a linear regression model is fit on the training data, predictions are made on the test data and the root mean squared error is calculated to evaluate the model's performance."}}], "source": "kaggle"}, {"id": "yclaudel-recommendation-efgine-with-networkx-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-feature-extraction-text-tfidfvectorizer"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"max_df": 0.4, "min_df": 1, "stop_words": "english", "lowercase": "True", "use_idf": "True", "norm": "l2", "smooth_idf": "True"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to build a recommendation engine using Adamic Adar measure and a graph-based approach for the Netflix dataset. Before the API call, a dataset is loaded, preprocessed, and transformed into a graph with nodes representing movies, persons, categories, countries, and similarity clusters. The API call is used to create a TfidfVectorizer that calculates the TF-IDF matrix for the movie descriptions, enabling the identification of movies with similar descriptions. This information is then incorporated into the graph structure, and the recommendation engine function is implemented to explore the neighborhood of the target movie and calculate the Adamic Adar measure between movies, ultimately providing the top recommendations."}}], "source": "kaggle"}, {"id": "yclaudel-recommendation-efgine-with-networkx-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-cluster-minibatchkmeans"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_clusters": 200}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to build a recommendation engine for Netflix movies and series using a graph-based approach. After loading and preprocessing the dataset, a TF-IDF matrix is computed using movie descriptions. The API is called to perform clustering on the TF-IDF matrix using the MiniBatchKMeans algorithm. Although the resulting clusters are not used due to imbalance, the TF-IDF matrix is utilized to find similar descriptions for each movie. A graph is then constructed with nodes representing movies, people, categories, countries, and similar descriptions. The Adamic Adar measure is applied to compute the closeness of nodes based on their shared neighbors, allowing the recommendation function to provide relevant suggestions for a target movie or series."}}], "source": "kaggle"}, {"id": "manavd22-boosting-ensemblezbaymsian-tunnng-cv-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-robustscaler"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"estimators": "[('cat', <catboost.core.CatBoostClassifier object at 0x79a0cbf5a950>), ('xgb', XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel..., ('lgb', LGBMClassifier(class_weight={0: 0.5, 1: 233}, verbose=-1))]", "voting": "soft"}}}, {"role": "solutionSummary", "module": {"summary": "The goal of this code snippet is to classify fraudulent transactions using an ensemble of CatBoost, XGBoost, and LightGBM models. The data is loaded, preprocessed, transformed, and feature engineering is applied. The API call creates a VotingClassifier with soft voting, combining the three models to improve the overall performance. A Bayesian optimization is performed using BayesSearchCV to find the optimal hyperparameters for each model in the ensemble. The ensemble is then fit using the best hyperparameters found, and predictions are made on the test set, which are saved to a submission file."}}], "source": "kaggle"}, {"id": "manavd22-boosting-ensemblezbaymsian-tunnng-cv-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "xgboost-xgbclassifier"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"scale_pos_weight": 466.0, "verbosity": 0}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to create a classification model for credit card fraud detection using an ensemble of CatBoost, XGBoost, and LightGBM models. After reading the input data and preprocessing it, the API is called to create the XGBoost classifier with specific parameters. This classifier is combined with CatBoost and LightGBM classifiers in a VotingClassifier. Then, a Bayesian optimization is performed to tune the hyperparameters of the ensemble model using a 5-fold cross-validation and the AUC scoring metric. Finally, the best parameters are printed and the ensemble is used to make predictions on the test dataset for submission."}}], "source": "kaggle"}, {"id": "manavd22-boosting-ensemblezbaymsian-tunnng-cv-003", "modules": [{"role": "algorithm", "purpose": "API", "module": "lightgbm-lgbmmodel"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"class_weight": "{0: 0.5, 1: 233}", "verbose": -1}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict credit card fraud using an ensemble of CatBoost, XGBoost, and LightGBM models. After loading, preprocessing, and feature engineering, the API call is used to create an instance of the LightGBM model with class weights to handle the imbalance in the dataset and a specified verbosity. The VotingClassifier is used to create an ensemble model with 'soft' voting, which combines the probability estimates from each model. The final model is optimized using Bayesian optimization (BayesSearchCV) with a search space for hyperparameters of each base model, and the best parameters are found, fitted, and used to generate predictions for the test set."}}], "source": "kaggle"}, {"id": "nobodymattin-lightgbm-explanation-practice-with-da-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-train-test-split"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"[0]": "dataframe(shape=(569, 16))", "[1]": "series(shape=(569,))", "test_size": 0.2, "random_state": 100, "stratify": "series(shape=(569,))"}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet is aimed at classifying breast cancer malignancy using the LightGBM algorithm. The dataset is loaded and preprocessed, which includes dropping unnecessary columns and converting the 'diagnosis' column to binary values. The dataset is split into training and testing sets using the API call with a test size of 20%, ensuring the class distribution is preserved with the 'stratify' parameter. After the split, the LightGBM model is optimized using Bayesian optimization, and the model parameters are set based on the optimization results. The model is then evaluated using various metrics such as accuracy, AUC, confusion matrix, and ROC curve."}}], "source": "kaggle"}, {"id": "nobodymattin-lightgbm-explanation-practice-with-da-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-minmaxscaler"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict breast cancer using the LightGBM model. After loading and preprocessing the dataset, including selecting relevant features and visualizing their distributions, the API is called to encode discrete variables. The OrdinalEncoder is used to convert the categorical data into numerical format. Once the discrete variables are processed, the transformed data is merged with the continuous variables, and the final dataset is used to perform Bayesian Optimization to find the best hyperparameters for the LightGBM model. The model is then trained, and performance metrics such as accuracy, AUC, and confusion matrices are evaluated."}}], "source": "kaggle"}, {"id": "nobodymattin-lightgbm-explanation-practice-with-da-003", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-stratifiedkfold"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"n_splits": 2, "shuffle": "True", "random_state": 1}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict breast cancer diagnosis using the LightGBM model. The dataset is loaded, features with high correlations to the target variable are selected, and preprocessed. The API is called to create a StratifiedKFold cross-validator with two splits to maintain the same class distribution in each fold as in the entire dataset. This is especially important in imbalanced classification problems to ensure that each fold contains a representative sample of the class distribution. Bayesian optimization is then used to tune the hyperparameters of the LightGBM model, followed by model training, evaluation, and visualization of results."}}], "source": "kaggle"}, {"id": "amyjang-tensorflow-pneumonia-classification-on-x-r-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-train-test-split"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"[0]": "[\"gs://kds-c889c9ab196d9e827248c145c7933f98a1baa9cdd1014362a4605339/chest_xray/train/NORMAL/IM-0115-0001.jpeg\", \"gs://kds-c889c9ab196d9e827248c145c7933f98a1baa9cdd1014362a4605339/chest_xray/train/NORMAL/IM-0117-0001.jpeg\", \"gs://kds-c889c9ab196d9e827248c145c7933f98a1baa9cdd1014362a4605339/chest_xray/train/NORMAL/IM-0119-0001.jpeg\", \"gs://kds-c889c9ab196d9e827248c145c7933f98a1baa9cdd1014362a4605339/chest_xray/train/NORMAL/IM-0122-0001.jpeg\", \"gs://kds-c889c9ab196d9e827248c145c7933f98a1baa9cdd1014362a4605339/chest_xray/train/NORMAL/IM-0125-0001.jpeg\", \"gs://kds-c889c9ab196d9e827248c145c7933f98a1baa9cdd1014362a4605339/chest_xray/train/NORMAL/IM-0127-0001.jpeg\", \"gs://kds-c889c9ab196d9e827248c145c7933f98a1baa9cdd1014362a4605339/chest_xray/train/NORMAL/IM-0128-0001.jpeg\", \"gs://kds-c889c9ab196d9e827248c145c7933f98a1baa9cdd1014362a4605339/chest_xray/train/NORMAL/IM-0129-0001.jpeg\", \"gs://kds-c889c9ab196d9e827248c145c7933f98a1baa9cdd1014362a4605339/chest_xray/train/NORMAL/IM-0131-0001.jpeg\", \"gs://kds-c889c9ab196d9e827248c145c7933f98a1baa9cdd1014362a4605339/chest_xray/train/NORMAL/IM-0133-0001.jpeg\", \"gs://kds-c889c9ab196d9e827248c145c7933f98a1baa9cdd1014362a4605339/chest_xray/train/NORMAL/IM-0135-0001.jpeg\", \"gs://kds-c889c9ab196d9e827248c145c7933f98a1baa9cdd1014362a4605339/chest_xray/train/NORMAL/IM-0137-0001.jpeg\", \"gs://kds-c889c9ab196d9e827248c145c7933f98a1baa9cdd1014362a4605339/chest_xray/train/NORMAL/IM-0140-0001.jpeg\", \"gs://kds-c889c9ab196d9e827248c145c7933f98a1baa9cdd1014362a4605339/chest_xray/train/NORMAL/IM-0141-0001.jpeg\", \"gs://kds-c889c9ab196d9e827248c145c7933f98a1baa9cdd1014362a4605339/chest_xray/train/NORMAL/IM-0143-0001.jpeg\", \"gs://kds-c889c9ab196d9e827248c145c7933f98a1baa9cdd1014362a4605339/chest_xray/train/NORMAL/IM-0145-0001.jpeg\", \"gs://kds-c889c9ab196d9e827248c145c7933f98a1baa9cdd1014362a4605339/chest_xray/train/NORMAL/IM-0147-0001.jpeg\", \"gs://kds-c889c9ab196d9e827248c145c7933f98a1baa9cdd1014362a4605339/chest_xray/train/NORMAL/IM-0149-0001.jpeg\", \"gs://kds-c889c9ab196d9e827248c145c7933f98a1baa9cdd1014362a4605339/chest_xray/train/NORMAL/IM-0151-0001.jpeg\", \"gs://kds-c889c9ab196d9e827248c145c7933f98a1baa9cdd1014362a4605339/chest_xray/train/NORMAL/IM-0152-0001.jpeg\", \"gs://kds-c889c9ab196d9e827248c145c7933f98a1baa9cdd1014362a4605339/chest_xray/train/NORMAL/IM-0154-0001.jpeg\", \"gs://kds-c889c9ab196d9e827248c145c7933f98a1baa9cdd1014362a4605339/chest_xray/train/NORMAL/IM-0156-0001.jpeg\", \"gs://kds-c889c9ab196d9e827248c145c7933f98a1baa9cdd1014362a4605339/chest_xray/train/NORMAL/IM-0158-0001.jpeg\", \"gs://kds-c889c9ab196d9e827248c145c7933f98a1baa9cdd1014362a4605339/chest_xray/train/NORMAL/IM-0160-0001.jpeg\", \"gs://kds-c889c9ab196d9e827248c145c7933f98a1baa9cdd1014362a4605339/chest_xray/train/NORMAL/IM-0162-0001.jpeg\", \"gs://kds-c889c9ab196d9e827248c145c7933f98a1baa9cdd1014362a4605339/chest_xray/train/NORMAL/IM-0164-0001.jpeg\", \"gs://kds-c889c9ab196d9e827248c145c7933f98a1baa9cdd1014362a4605339/chest_xray/train/NORMAL/IM-0166-0001.jpeg\", \"gs://kds-c889c9ab196d9e827248c145c7933f98a1baa9cdd1014362a4605339/chest_xray/train/NORMAL/IM-0168-0001.jpeg\", \"gs://kds-c889c9ab196d9e827248c145c7933f98a1baa9cdd1014362a4605339/chest_xray/train/NORMAL/IM-0170-0001.jpeg\", \"gs://kds-c889c9ab196d9e827248c145c7933f98a1baa9cdd1014362a4605339/chest_xray/train/NORMAL/IM-0172-0001.jpeg\", ...]", "test_size": 0.2}}}, {"role": "solutionSummary", "module": {"summary": "The goal is to build a deep learning model that can classify X-ray images as either normal or pneumonia. The dataset is preprocessed by combining the original training and validation sets, then partitioning them into new training and validation sets using an 80:20 split ratio. The API call is used to perform this split. After splitting the dataset, the model is trained on the training data, and the performance is evaluated using the validation data. Various techniques such as data preprocessing, building a CNN, handling data imbalance, and fine-tuning the model are carried out throughout the code snippet to improve model performance."}}], "source": "kaggle"}, {"id": "mohaiminulh01-video-game-hales-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-preprocessing-standardscaler"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"[0]": "array(shape=(16540, 91))", "[1]": "series(shape=(16540,))", "train_size": 0.8}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict global video game sales using a neural network model. The dataset is loaded, preprocessed, and one-hot encoded. Next, the data is standardized using the StandardScaler. The API call is used to split the dataset into training and testing sets, with 80% of the data used for training. The neural network model is constructed using TensorFlow, and it is compiled with an RMSprop optimizer and mean squared error loss function. The model is then trained on the training data, and the training and validation loss are visualized. Finally, the model's performance is evaluated using R^2 score and mean squared error on the testing set."}}], "source": "kaggle"}, {"id": "nishantkumar1292-scoreyprediction-using-keras-mode-001", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-model-selection-train-test-split"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"[0]": "dataframe(shape=(1000, 17))", "[1]": "dataframe(shape=(1000, 3))", "test_size": 0.30000000000000004, "random_state": 1}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict student performance in math, reading, and writing exams based on various factors such as gender, race/ethnicity, parental level of education, lunch, and test preparation course. After loading the dataset and visualizing relationships between the features and scores, the data is prepared by one-hot encoding the categorical variables. The API call is used to split the dataset into training and testing sets. Subsequently, different machine learning models, including Linear Regression, Random Forest, and Neural Networks, are trained on the training set and evaluated for their performance."}}], "source": "kaggle"}, {"id": "nishantkumar1292-scoreyprediction-using-keras-mode-002", "modules": [{"role": "algorithm", "purpose": "API", "module": "sklearn-linear-model-linearregression"}, {"role": "algorithm", "purpose": "API parameters", "module": {"config": {"min_samples_split": 20, "n_jobs": 2, "random_state": 0, "n_estimators": 100}}}, {"role": "solutionSummary", "module": {"summary": "The code snippet aims to predict students' math, reading, and writing scores based on their demographic and educational attributes. After loading the data, exploratory data analysis is performed using various visualizations. Then, one-hot encoding is applied to categorical features, and the dataset is split into training and testing sets. The API call is made to fit a RandomForestRegressor model with specified parameters to the training data. The model's performance is evaluated using the coefficient of determination (R^2 score). Subsequently, a neural network model is built and evaluated using Keras and cross-validation, yielding impressive results."}}], "source": "kaggle"}]